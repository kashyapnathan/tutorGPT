{"prompt": "Lecture notes from 09_continuous_rv_annotated.txt\n\n###\n\n", "completion": "09: Continuous RVs\nJerry Cain\nApril 19th, 2024\nLecture Discussion on Ed\n1\nContinuous RVs\n2\nPeople heights\nYou are volunteering at the local elementary school fundraiser.\n\u2022 To buy a t-shirt for your friend Vanessa, you need to know her height.\n1. What is the probability that your\nEssentially 0\nfriend is 54.0923857234 inches tall?\n2. What is the probability that Vanessa is between 52\u201356 inches tall?\n44 \u2026 52 56 60 0 \u2026 44 52 60 \u2026 90 0 \u2026 44 52 60 \u2026 90\n\ud835\udc65\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\n\ud835\udc65\n\ud835\udc53\n\ud835\udc43 52 < \ud835\udc4b \u2264 56\nsmaller- \u221e-ly\nwidth small\nbars bars\nprobability\ndensity\nfunction\n)\ud835\udc65(\ud835\udc5d )\ud835\udc65(\ud835\udc5d\n\ud835\udc43 52 < \ud835\udc4b \u2264 54\n+ \ud835\udc43 54 < \ud835\udc4b \u2264 56\n\ud835\udc43 52 < \ud835\udc4b \u2264 56\n48 52 56 60\n\ud835\udc65\nContinuous RV definition\nA random variable \ud835\udc4b is continuous if there is a probability density function\n\ud835\udc53 \ud835\udc65 \u2265 0 such that for \u2212\u221e < \ud835\udc65 < \u221e:\n\"\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = 0 \ud835\udc53(\ud835\udc65) \ud835\udc51\ud835\udc65\n!\nIntegrating a PDF must always yield a valid probability, no matter the values of a\nand b. The PDF must also satisfy:\n$\n0 \ud835\udc53(\ud835\udc65) \ud835\udc51\ud835\udc65 = \ud835\udc43 \u2212\u221e < \ud835\udc4b < \u221e = 1\n#$\nNote: \ud835\udc53 \ud835\udc65 is sometimes written as \ud835\udc53 (\ud835\udc65) to be clear the random variable is \ud835\udc4b.\n%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nMain takeaway\n4 inches\nIntegrate \ud835\udc53(\ud835\udc65) to get\n\ud835\udc53 \ud835\udc65 : prob/inch\nprobabilities.\n0 \u2026 44 52 60 \u2026 90\n\ud835\udc65\n!#\nPDF Units: probability per units of \ud835\udc4b \ud835\udc43 52 \u2264 \ud835\udc4b \u2264 56 = - \ud835\udc53(\ud835\udc65) \ud835\udc51\ud835\udc65\n!\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nPMF vs PDF\nDiscrete random variable \ud835\udc4b Continuous random variable \ud835\udc4b\nProbability mass function (PMF): Probability density function (PDF):\n\ud835\udc5d \ud835\udc65 \ud835\udc53 \ud835\udc65\nTo get probability: To get probability:\n-\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 = \ud835\udc5d \ud835\udc65\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = * \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n,\nBoth are measures of how likely \ud835\udc4b is to take\non a value or some range of values.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nComputing probability\nLet \ud835\udc4b be a continuous RV with PDF: 1.00\n\ud835\udc65\n0.50\nif 0 \u2264 \ud835\udc65 \u2264 2\n\ud835\udc53 \ud835\udc65 = ,2\n0.00\n0 otherwise\n0.00 1.00 2.00\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\n)\"(!\n\"\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = 2 \ud835\udc53(\ud835\udc65)\ud835\udc51\ud835\udc65\n!\n!\nWhat is \ud835\udc43 \ud835\udc4b \u2265 1 ?\nComputing probability\nLet \ud835\udc4b be a continuous RV with PDF: 1.00\n\ud835\udc65\n0.50\nif 0 \u2264 \ud835\udc65 \u2264 2\n\ud835\udc53 \ud835\udc65 = ,2\n0.00\n0 otherwise\n0.00 1.00 2.00\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n)\"(!\n\"\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = 2 \ud835\udc53(\ud835\udc65)\ud835\udc51\ud835\udc65\n!\n!\nWhat is \ud835\udc43 \ud835\udc4b \u2265 1 ?\nStrategy 1: Integrate Strategy 2: Know triangles\n% \"\n1 1 1 3\n\ud835\udc43 1 \u2264 \ud835\udc4b < \u221e = - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 = - \ud835\udc65\ud835\udc51\ud835\udc65 1 \u2212 =\n2 2 2 4\n$ $\n1 1 \" 1 1 3 Wait! Is this even legal?\n\"\n= \ud835\udc65 2 = 2 \u2212 =\n$\n2 2 $ 2 2 4 \ud835\udc43 0 \u2264 \ud835\udc4b < 1 = \u222b \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 ? ?\n&\nPDF Properties\nFor a continuous RV \ud835\udc4b with PDF \ud835\udc53,\n\ud835\udc53 \ud835\udc65\n-\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = * \ud835\udc53(\ud835\udc65) \ud835\udc51\ud835\udc65\n, \ud835\udc65\n\ud835\udc65 \ud835\udc65 \ud835\udc65\n$ \" \u2019\nTrue/False: support: values of\n\ud835\udc65 where \ud835\udc53 \ud835\udc65 > 0\n1. \ud835\udc43 \ud835\udc4b = \ud835\udc50 = 0\n\u2b50 Interval width \ud835\udc51\ud835\udc65 \u2192 0\n\u2b50 2. \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = \ud835\udc43 \ud835\udc4e < \ud835\udc4b < \ud835\udc4f = \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b < \ud835\udc4f = \ud835\udc43 \ud835\udc4e < \ud835\udc4b \u2264 \ud835\udc4f\n3. \ud835\udc53(\ud835\udc65) is a probability\n\u274c It\u2019s a probability density!\n\u2b50 4. In the graphed PDF above,\n\ud835\udc43 \ud835\udc65 \u2264 \ud835\udc4b \u2264 \ud835\udc65 > \ud835\udc43 \ud835\udc65 \u2264 \ud835\udc4b \u2264 \ud835\udc65\nCompare area under the curve\n8 9 9 :\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\n\"\nDetermining valid PDFs \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = 2 \ud835\udc53(\ud835\udc65)\ud835\udc51\ud835\udc65\n!\nWhich of the following functions are valid PDFs?\n1. \ud835\udc53 \ud835\udc65 % 2. \ud835\udc54 \ud835\udc65 %\n- \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 = 0.5 - \ud835\udc54 \ud835\udc65 \ud835\udc51\ud835\udc65 = 1\n(% (%\n\ud835\udc65 \ud835\udc65\n\ud835\udc65 \ud835\udc65 \ud835\udc65 \ud835\udc65\n$ \" \u2019 )\n3. \u210e \ud835\udc65 4. \ud835\udc64 \ud835\udc65\n%\n%\n- \u210e \ud835\udc65 \ud835\udc51\ud835\udc65 = 1\n- \ud835\udc64 \ud835\udc65 \ud835\udc51\ud835\udc65 = 1\n2\n(%\n(%\n0 \ud835\udc65\n1 \ud835\udc65 \ud835\udc65\n! #\n\ud835\udc65\n0.5 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nUniform RV\n11\nUniform Random Variable\ndef A Uniform random variable \ud835\udc4b is defined as follows:\n1\nif \ud835\udefc \u2264 \ud835\udc65 \u2264 \ud835\udefd\nPDF\n\ud835\udc53 \ud835\udc65 = >\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc4b~Uni(\ud835\udefc, \ud835\udefd)\n0 otherwise\n\ud835\udefc + \ud835\udefd\nExpectation \ud835\udc38 \ud835\udc4b =\nSupport: \ud835\udefc, \ud835\udefd\n2\n(sometimes defined\n9\n\ud835\udefd \u2212 \ud835\udefc\nover \ud835\udefc, \ud835\udefd ) Variance Var \ud835\udc4b =\n12\n\ud835\udc53 \ud835\udc65\n1\n\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc65\n\ud835\udefc \ud835\udefd\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nQuick check\nIf \ud835\udc4b~Uni(\ud835\udefc, \ud835\udefd), the PDF of \ud835\udc4b is:\n\ud835\udc53 \ud835\udc65\n1\n8\nif \ud835\udefc \u2264 \ud835\udc65 \u2264 \ud835\udefd\n\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc53 \ud835\udc65 = ,BCD\n0 otherwise\n\ud835\udc65\n\ud835\udefc \ud835\udefd\n8\nWhat is if the following graphs are PDFs of Uniform RVs \ud835\udc4b?\nBCD\n1. 2. 3.\n\ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc65\n?\n?\n?\n\ud835\udc65 \ud835\udc65 \ud835\udc65\n0 25 1 3/2 5\n\u22125\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nQuick check\nIf \ud835\udc4b~Uni(\ud835\udefc, \ud835\udefd), the PDF of \ud835\udc4b is:\n\ud835\udc53 \ud835\udc65\n1\n8\nif \ud835\udefc \u2264 \ud835\udc65 \u2264 \ud835\udefd\n\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc53 \ud835\udc65 = ,BCD\n0 otherwise\n\ud835\udc65\n\ud835\udefc \ud835\udefd\n8\nWhat is if the following graphs are PDFs of Uniform RVs \ud835\udc4b?\nBCD\n1. 2. 3.\n\ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc65 1 \ud835\udc53 \ud835\udc65\n?\n10\n??\n2\n1\n??\n25 \ud835\udc65 \ud835\udc65 \ud835\udc65\n0 25 1 3/2 5\n\u22125\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nExpectation and Variance\nDiscrete RV \ud835\udc4b Continuous RV \ud835\udc4b\n%\n\ud835\udc38 \ud835\udc4b = C \ud835\udc65 \ud835\udc5d \ud835\udc65 \ud835\udc38 \ud835\udc4b = - \ud835\udc65\ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n(%\n*\n%\n\ud835\udc38 \ud835\udc54(\ud835\udc4b) = C \ud835\udc54(\ud835\udc65) \ud835\udc5d \ud835\udc65 \ud835\udc38 \ud835\udc54(\ud835\udc4b) = - \ud835\udc54 \ud835\udc65 \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n(%\n*\nBoth continuous and discrete RVs\nLinearity of\n\ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f\nExpectation\n9 9 9\nVar(\ud835\udc4b) = \ud835\udc38 (\ud835\udc4b \u2212 \ud835\udc38[\ud835\udc4b]) = \ud835\udc38 \ud835\udc4b \u2212 (\ud835\udc38[\ud835\udc4b])\nProperties of\n9\nVar(\ud835\udc4e\ud835\udc4b + \ud835\udc4f) = \ud835\udc4e Var(\ud835\udc4b) variance\nTL;DR: \u2211- \u21d2\n\u222b-\n*+,\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nUniform RV expectation\n%\n\ud835\udc53 \ud835\udc65\n\ud835\udc38 \ud835\udc4b = - \ud835\udc65 \u22c5 \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n(% 1\n\ud835\udefd \u2212 \ud835\udefc\n/\n1\n= - \ud835\udc65 \u22c5 \ud835\udc51\ud835\udc65\n\ud835\udc65\n\ud835\udefd \u2212 \ud835\udefc\n. \ud835\udefc \ud835\udefd\n/\n1 1\n\"\n= \u22c5 \ud835\udc65 G\n\ud835\udefd \u2212 \ud835\udefc 2\n.\n1 1\n\" \"\n= \u22c5 \ud835\udefd \u2212 \ud835\udefc\n\ud835\udefd \u2212 \ud835\udefc 2\n1 \ud835\udefd + \ud835\udefc \ud835\udefd \u2212 \ud835\udefc \ud835\udefc + \ud835\udefd Interpretation:\n= \u22c5 =\n2 \ud835\udefd \u2212 \ud835\udefc 2 Average the start & end\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nUniform Random Variable\ndef An Uniform random variable \ud835\udc4b is defined as follows:\n1\nif \ud835\udefc \u2264 \ud835\udc65 \u2264 \ud835\udefd\nPDF\n\ud835\udc53 \ud835\udc65 = >\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc4b~Uni(\ud835\udefc, \ud835\udefd)\n0 otherwise\n\ud835\udefc + \ud835\udefd\nExpectation \ud835\udc38 \ud835\udc4b = Just now\nSupport: \ud835\udefc, \ud835\udefd\n2\n(sometimes defined\n9\n\ud835\udefd \u2212 \ud835\udefc\nover \ud835\udefc, \ud835\udefd ) Variance Var \ud835\udc4b =\n12\n\ud835\udc53 \ud835\udc65\n1 On your own!\n\ud835\udefd \u2212 \ud835\udefc\n\ud835\udc65\n\ud835\udefc \ud835\udefd\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nExponential RV\n18\nGrid of random variables\nNumber of Time until\nsuccesses success\nBer(\ud835\udc5d) Geo(\ud835\udc5d)\nOne trial One success\n\ud835\udc5b = 1 \ud835\udc5f = 1\nSeveral Several\nBin(\ud835\udc5b, \ud835\udc5d) NegBin(\ud835\udc5f, \ud835\udc5d)\ntrials successes\nInterval Amount of time\nPoi(\ud835\udf06) Exp?(\ud835\udf06)\nof time before first success\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nExponential Random Variable\nConsider an experiment that lasts a duration of time until success occurs.\ndef An Exponential random variable \ud835\udc4b is the amount of time until success.\nCIJ\n\ud835\udf06\ud835\udc52 if \ud835\udc65 \u2265 0\nPDF \ud835\udc53 \ud835\udc65 = A\n0 otherwise\n\ud835\udc4b~Exp(\ud835\udf06)\n1\nExpectation \ud835\udc38 \ud835\udc4b = (in extra slides)\n\ud835\udf06\nSupport: 0, \u221e\n1\nVariance Var \ud835\udc4b = (on your own)\n\ud835\udf069\nExamples:\n1\n0.8\n\u2022 Time until next earthquake\n0.6\n\ud835\udc53 \ud835\udc65\n\u2022 Time for request to reach web server 0.4\n0.2\n\u2022 Time until water main break on Campus Dr.\n\ud835\udc65\n0\n0 1 2 3 4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nEarthquakes\n1906 Earthquake\nMagnitude 7.8\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\ud835\udc38 \ud835\udc4b = 1/\ud835\udf06\nEarthquakes\n\ud835\udc4b~Exp(\ud835\udf06)\n\ud835\udc53 \ud835\udc65 = \ud835\udf06\ud835\udc52#$% if \ud835\udc65 \u2265 0\nMajor earthquakes (magnitude 8.0+) occur once every 500 years.*\n1. What is the probability of a major earthquake in the next 30 years?\nDefine events/ Solve\nRecall\nRVs & state goal\n1\n\u222b \ud835\udc52&%\ud835\udc51\ud835\udc65 = \ud835\udc52&%\n\ud835\udc4b: when next \ud835\udc50\nearthquake happens\n\ud835\udc4b ~Exp \ud835\udf06 = 0.002\n\ud835\udf06: year($ = 1/500\nWant: \ud835\udc43 \ud835\udc4b < 30\n*In California, according to historical data form LUisSaG YaSn,, C2h0ri1s P5iech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\ud835\udc38 \ud835\udc4b = 1/\ud835\udf06\nEarthquakes\n\ud835\udc4b~Exp(\ud835\udf06)\n\ud835\udc53 \ud835\udc65 = \ud835\udf06\ud835\udc52#$% if \ud835\udc65 \u2265 0\nMajor earthquakes (magnitude 8.0+) occur once every 500 years.*\n1. What is the probability of a major earthquake in the next 30 years?\n2. What is the standard deviation of years until the next earthquake?\nDefine events/ Solve\nRVs & state goal\n\ud835\udc4b: when next\nearthquake happens\n\ud835\udc4b ~Exp \ud835\udf06 = 0.002\n\ud835\udf06: year($\nWant: \ud835\udc43 \ud835\udc4b < 30\n*In California, according to historical data form LUisSa GYaSn,, C2h0ris1 P5iech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nCumulative\nDistribution\nFunctions\n24\nCumulative Distribution Function (CDF)\nFor a random variable \ud835\udc4b, the cumulative distribution function (CDF) is\ndefined as\n\ud835\udc39 \ud835\udc4e = \ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e , where \u2212 \u221e < \ud835\udc4e < \u221e\nR\nFor a discrete RV \ud835\udc4b, the CDF is:\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = I \ud835\udc5d(\ud835\udc65)\nall\nJS,\nCDF is a probability,\nFor a continuous RV \ud835\udc4b, the CDF is:\nthough PDF is not.\n,\n\ud835\udc53 \ud835\udc65\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = * \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\nIf you learn to use\n\ud835\udc39 \ud835\udc4e CT\nCDFs, you can avoid\n\ud835\udc65\nintegrating the PDF.\n\ud835\udc4e\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nUsing the CDF for continuous RVs\nFor a continuous random variable \ud835\udc4b with PDF \ud835\udc53(\ud835\udc65), the CDF of \ud835\udc4b is\n,\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = * \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\nCT\nMatching (choices are used 0/1/2 times)\n1. \ud835\udc43 \ud835\udc4b < \ud835\udc4e A. \ud835\udc39 \ud835\udc4e\n2. \ud835\udc43 \ud835\udc4b > \ud835\udc4e B. 1 \u2212 \ud835\udc39(\ud835\udc4e)\n3. \ud835\udc43 \ud835\udc4b \u2265 \ud835\udc4e C. \ud835\udc39 \ud835\udc4f \u2212 \ud835\udc39(\ud835\udc4e)\n4. \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f D. \ud835\udc39 \ud835\udc4e \u2212 \ud835\udc39(\ud835\udc4f)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nUsing the CDF for continuous RVs\nFor a continuous random variable \ud835\udc4b with PDF \ud835\udc53(\ud835\udc65), the CDF of \ud835\udc4b is\n,\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = * \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\nCT\nMatching (choices are used 0/1/2 times)\n1. \ud835\udc43 \ud835\udc4b < \ud835\udc4e A. \ud835\udc39 \ud835\udc4e\n2. \ud835\udc43 \ud835\udc4b > \ud835\udc4e B. 1 \u2212 \ud835\udc39(\ud835\udc4e)\n3. \ud835\udc43 \ud835\udc4b \u2265 \ud835\udc4e C. \ud835\udc39 \ud835\udc4f \u2212 \ud835\udc39(\ud835\udc4e)\n(next slide)\n4. \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f D. \ud835\udc39 \ud835\udc4e \u2212 \ud835\udc39(\ud835\udc4f)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nUsing the CDF for continuous RVs\nFor a continuous random variable \ud835\udc4b with PDF \ud835\udc53(\ud835\udc65), the CDF of \ud835\udc4b is\n,\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = * \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\nCT\n\ud835\udc53 \ud835\udc65\n4. \ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4f = \ud835\udc39 \ud835\udc4f \u2212 \ud835\udc39(\ud835\udc4e)\n\ud835\udc65\nProof:\n\ud835\udc4e \ud835\udc4f\n- ,\n\ud835\udc39 \ud835\udc4f \u2212 \ud835\udc39 \ud835\udc4e = - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 \u2212 - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n\u00a5 \u00a5 \u2212 =\n( (\n, - ,\n\ud835\udc39 \ud835\udc4f \ud835\udc39 \ud835\udc4e\n= - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 + - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 \u2212 - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n\u00a5 \u00a5\n( , (\n-\n= - \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nCDF of an Exponential RV \ud835\udc4b~Exp(\ud835\udf06) \ud835\udc53 \ud835\udc65 = \ud835\udf06\ud835\udc52#$% if \ud835\udc65 \u2265 0\n!\"#\n\ud835\udc4b~Exp(\ud835\udf06) \ud835\udc39 \ud835\udc65 = 1 \u2212 \ud835\udc52\nif \ud835\udc65 \u2265 0\nProof:\nJ J Recall\nCIU 1\n\ud835\udc39 \ud835\udc65 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = * \ud835\udc53 \ud835\udc66 \ud835\udc51\ud835\udc66 = * \ud835\udf06\ud835\udc52 \ud835\udc51\ud835\udc66 \u222b \ud835\udc52&%\ud835\udc51\ud835\udc65 = \ud835\udc52&%\n\ud835\udc50\nUVCT UVW\nJ\n1\nCIU\n= \ud835\udf06 \ud835\udc52 K\n\u2212\ud835\udf06\nW\nCIJ CIW\n= \u22121 \ud835\udc52 \u2212 \ud835\udc52\nCIJ\n= 1 \u2212 \ud835\udc52\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n\ud835\udc65 \u2265 0:\n\ud835\udc53 \ud835\udc65 = \ud835\udf06\ud835\udc52#$%\nPDF/CDF \ud835\udc4b~Exp(\ud835\udf06 = 1) \ud835\udc4b~Exp(\ud835\udf06)\n\ud835\udc39 \ud835\udc65 = 1 \u2212 \ud835\udc52#$%\n\ud835\udc53 \ud835\udc65 1 \ud835\udc53 \ud835\udc65 1\n0.8 0.8\n( )\n0.6 0.6\n2 \ud835\udf06\ud835\udc52#$%\ud835\udc51\ud835\udc65 \u2248 0.86 2 \ud835\udf06\ud835\udc52#$%\ud835\udc51\ud835\udc65 \u2248 0.14\n0.4 0.4\n\u2019 (\n0.2 0.2\n0 0 \ud835\udc65\n\ud835\udc65\n0 1 2 3 4 5 0 1 2 3 4 5\n\ud835\udc39 \ud835\udc65 1.2 \ud835\udc39 \ud835\udc65 1.2\n1 \u2212 \ud835\udc52#($ \u2248 0.86 1 \u2212 \ud835\udc39 2 = \ud835\udc52#($ \u2248 0.14\n1 1\n0.8 0.8\n0.6 0.6\n0.4 0.4\n0.2 0.2\n0 \ud835\udc65 0 \ud835\udc65\n0 1 2 3 4 5 0 1 2 3 4 5\n\ud835\udc43 \ud835\udc4b \u2264 2 \ud835\udc43 \ud835\udc4b > 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nMemoryless\nProperty\n31\nMemorylessness: Hurry Up and Wait\nA continuous probability distribution is said to be memoryless if a\nrandom variable \ud835\udc4b on that probability distribution satisfies the following for\nall \ud835\udc60, \ud835\udc61 \u2265 0:\n\ud835\udc43 \ud835\udc4b \u2265 \ud835\udc60 + \ud835\udc61 | \ud835\udc4b \u2265 \ud835\udc60 = \ud835\udc43 \ud835\udc4b \u2265 \ud835\udc61\n\u2022 Here, \ud835\udc60 represents the time you\u2019ve already spent waiting.\n\u2022 The above states that after you\u2019ve waited \ud835\udc60 time units, the probability\nyou\u2019ll need to wait an additional \ud835\udc61 time units is equal to the probability\nyou\u2019d have to wait \ud835\udc61 time units without having waited those \ud835\udc60 time units\nin the first place.\n\u2022 Example: If train arrival is guided by a memoryless random variable, the\nfact that you\u2019ve waited 15 minutes doesn\u2019t obligate the train to arrive\nany faster!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nMemorylessness: Hurry Up and Wait\nA continuous probability distribution is said to be memoryless if a\nrandom variable \ud835\udc4b on that probability distribution satisfies the following for\nall \ud835\udc60, \ud835\udc61 \u2265 0:\n\ud835\udc43 \ud835\udc4b \u2265 \ud835\udc60 + \ud835\udc61 | \ud835\udc4b \u2265 \ud835\udc60 = \ud835\udc43 \ud835\udc4b \u2265 \ud835\udc61\nUsing the definition of conditional probability, we can show that our\nExponential distribution exhibits the memoryless property. Just let\n\ud835\udc4b ~ Exp(\ud835\udf06) and trust the math:\nCI(]^_)\n\ud835\udc43 \ud835\udc4b \u2265 \ud835\udc60 + \ud835\udc61 \ud835\udc52\nCI_\n\ud835\udc43 \ud835\udc4b \u2265 \ud835\udc60 + \ud835\udc61 | \ud835\udc4b \u2265 \ud835\udc60 = = = \ud835\udc52 = \ud835\udc43 \ud835\udc4b \u2265 \ud835\udc61\n\ud835\udc43 \ud835\udc4b \u2265 \ud835\udc60 \ud835\udc52CI]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nExercises\n34\nEarthquakes\nMajor earthquakes (magnitude 8.0+) occur independently on average\nonce every 500 years.*\nWhat is the probability of zero major earthquakes next year?\n*In California, according to historical data form LUisSa GYaSn,, C2h0ris1 P5iech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nEarthquakes\nMajor earthquakes (magnitude 8.0+) occur independently on average\nonce every 500 years.*\nWhat is the probability of zero major earthquakes next year?\nStrategy 1: Exponential RV\nDefine events/RVs & state goal\n\ud835\udc47: when first earthquake happens\n\ud835\udc47 ~Exp(\ud835\udf06 = 0.002)\nWant: \ud835\udc43 \ud835\udc47 > 1 = 1 \u2212 \ud835\udc39(1)\nSolve\nCI\u22c58 CI\n\ud835\udc43 \ud835\udc47 > 1 = 1 \u2212 1 \u2212 \ud835\udc52 = \ud835\udc52\n*In California, according to historical data form LUisSa GYaSn,, C2h0ris1 P5iech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\n\ud835\udf06*\nEarthquakes\n\ud835\udc4c~Poi(\ud835\udf06) \ud835\udc5d \ud835\udc58 = \ud835\udc52#$\n\ud835\udc58!\nMajor earthquakes (magnitude 8.0+) occur independently on average\nonce every 500 years.*\nWhat is the probability of zero major earthquakes next year?\nStrategy 1: Exponential RV Strategy 2: Poisson RV\nDefine events/RVs & state goal Define events/RVs & state goal\n\ud835\udc47: when first earthquake happens \ud835\udc41: # earthquakes next year\n\ud835\udc47 ~Exp(\ud835\udf06 = 0.002) \ud835\udc41 ~Poi(\ud835\udf06 = 0.002)\nearthquakes\n\ud835\udf06:\nWant: \ud835\udc43 \ud835\udc47 > 1 = 1 \u2212 \ud835\udc39(1) Want: \ud835\udc43 \ud835\udc41 = 0 year\nSolve Solve\nW CI\n\ud835\udf06 \ud835\udc52\nCI\u22c58 CI\n\ud835\udc43 \ud835\udc47 > 1 = 1 \u2212 1 \u2212 \ud835\udc52 = \ud835\udc52 CI\n\ud835\udc43 \ud835\udc41 = 0 = = \ud835\udc52 \u2248 0.998\n0!\n*In California, according to historical data form LUisSa GYaSn,, C2h0ris1 P5iech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\n\ud835\udc38 \ud835\udc4b = 1/\ud835\udf06\nReplacing your laptop\n\ud835\udc4b~Exp(\ud835\udf06)\n\ud835\udc39 \ud835\udc65 = 1 \u2212 \ud835\udc52#$%\nLet \ud835\udc4b = # hours of use until your laptop dies.\n\u2022 \ud835\udc4b is distributed as an Exponential RV, where\n\u2022 On average, laptops die after 5000 hours of use.\n\u2022 You use your laptop 5 hours a day.\nWhat is \ud835\udc43 your laptop lasts 4 years ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\n\ud835\udc38 \ud835\udc4b = 1/\ud835\udf06\nReplacing your laptop\n\ud835\udc4b~Exp(\ud835\udf06)\n\ud835\udc39 \ud835\udc65 = 1 \u2212 \ud835\udc52#$%\nLet \ud835\udc4b = # hours of use until your laptop dies.\n\u2022 \ud835\udc4b is distributed as an Exponential RV, where\n\u2022 On average, laptops die after 5000 hours of use.\n\u2022 You use your laptop 5 hours a day.\nWhat is \ud835\udc43 your laptop lasts 4 years ?\nDefine Solve\n\ud835\udc4b: # hours until \ud835\udc43 \ud835\udc4b > 7300 = 1 \u2212 \ud835\udc39(7300)\nlaptop death\n( 3\u2019&&/!&&& ($.)#\n= 1 \u2212 1 \u2212 \ud835\udc52 = \ud835\udc52 \u2248 0.2322\n\ud835\udc4b ~Exp(\ud835\udf06 = 1/5000)\nBetter plan ahead if you\u2019re co-terming!\nWant: \ud835\udc43 \ud835\udc4b > 5 \u22c5 365 \u22c5 4\n\u2022 5-year plan:\n($.6\"!\n\ud835\udc43 \ud835\udc4b > 9125 = \ud835\udc52 \u2248 0.1612\n\u2022 6-year plan:\n(\".$7\n\ud835\udc43 \ud835\udc4b > 10950 = \ud835\udc52 \u2248 0.1119\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nExtra\n40\nExpectation of the Exponential \ud835\udc4b~Exp(\ud835\udf06) \ud835\udc53 \ud835\udc65 = \ud835\udf06\ud835\udc52#$% if \ud835\udc65 \u2265 0\n1\n\ud835\udc4b~Exp(\ud835\udf06)\nExpectation \ud835\udc38 \ud835\udc4b =\n\ud835\udf06\nIntegration by parts\nProof:\nT T\n\ud835\udc38 \ud835\udc4b = * \ud835\udc65\ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 = * \ud835\udc65\ud835\udf06\ud835\udc52CIJ \ud835\udc51\ud835\udc65 - \ud835\udc65\ud835\udf06\ud835\udc52(8* \ud835\udc51\ud835\udc65 = - \ud835\udc62 V \ud835\udc51\ud835\udc63\nCT W\nT\nT (8*\n\ud835\udc62 = \ud835\udc65 \ud835\udc51\ud835\udc63 = \ud835\udf06\ud835\udc52 \ud835\udc51\ud835\udc65\nCIJ CIJ\n= \u2212\ud835\udc65\ud835\udc52 U + * \ud835\udc52 \ud835\udc51\ud835\udc65\n(8*\n\ud835\udc51\ud835\udc62 = \ud835\udc51\ud835\udc65 \ud835\udc63 = \u2212\ud835\udc52\nW\nW\nT 1 T\nCIJ CIJ\n= \u2212\ud835\udc65\ud835\udc52 U \u2212 \ud835\udc52 U\n\u03bb\nW W\n\u22121 - \ud835\udc62 V \ud835\udc51\ud835\udc63 = \ud835\udc62 V \ud835\udc63 \u2212 - \ud835\udc63 V \ud835\udc51\ud835\udc62\n= 0 \u2212 0 + 0 \u2212\n\ud835\udf06\n\u2212\u2212\ud835\udc65\ud835\udc65\ud835\udc52\ud835\udc52((88**\n\u2212\u2212 \u222b\u222b\n\u2212\u2212\ud835\udc52\ud835\udc52((88**\n\ud835\udc51\ud835\udc51\ud835\udc65\ud835\udc65\n1\n=\n\ud835\udf06\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41 <END>"} 
{"prompt": "Lecture notes from 05_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May9,2024\nConditional Expectation, Introductory Inference\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\nWarm-ups\n1 Why Multiple Random Variables?\nWhatisaprobabilisticmodelwithmultiplerandomvariables?Whatdoestheterminference\nmean?Whatdoyoucalltheprobabilityofanassignmenttoallvariablesinaprobabilisticmodel?\nWhyisthatuseful?Whycanitbehardtorepresent?\n2 Joint Random Variables Statistics\nTrueorFalse?Thesymbol\ud835\udc36\ud835\udc5c\ud835\udc63 iscovariance,thesymbol\u2227islogical-and,thesymbol \ud835\udf0c is\nPearsoncorrelation,thesymbol =\u21d2 islogicalimplication,and \ud835\udc4b \u22a5\ud835\udc4c isjustafancywaytosay\nthat \ud835\udc4b and\ud835\udc4c areindependent.\nAstatementlike\u201d\ud835\udc34 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(10,0.5) \u2227 \ud835\udc35 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(10,0.5) \u2227 \ud835\udc34 \u22a5 \ud835\udc35 =\u21d2 \ud835\udc34+ \ud835\udc35 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(20,0.5)\u201d\nreads\u201dIf \ud835\udc34 and \ud835\udc35 arebothdistributedasBinomialswiththesameparameters,then \ud835\udc34+ \ud835\udc35 isa\nBinomialaswellwiththesame \ud835\udc5d parameterandan \ud835\udc5b parameterthat\u2019sthesumofthethosefor \ud835\udc34\nand \ud835\udc35.\u201d\n\ud835\udc4b \u22a5\ud835\udc4c =\u21d2 \ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc4b,\ud835\udc4c) = 0 \ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b + \ud835\udc4b) = 2\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b)\n\ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc4b,\ud835\udc4c) = 0 =\u21d2 \ud835\udc4b \u22a5\ud835\udc4c \ud835\udc4b \u223c N(0,1) \u2227\ud835\udc4c \u223c N(0,1) =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 1\n\ud835\udc4c = \ud835\udc4b2 =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 1 \ud835\udc4c = 3\ud835\udc4b =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 3\n3 Random Number of Random Variables\nLet \ud835\udc41 beanon-negativeinteger-valuedrandomvariable\u2014thatis,arandomvariablethattakeson\nvaluesin {0,1,2,...}.Let \ud835\udc4b ,\ud835\udc4b ,\ud835\udc4b ,... beaninfinitesequenceofindependentandidentically\n1 2 3\ndistributedrandomvariables(independentof \ud835\udc41),eachwithmean \ud835\udf07,and \ud835\udc4b = (cid:205) \ud835\udc56\ud835\udc41\n=1\n\ud835\udc4b \ud835\udc56 bethesum\nofthefirst \ud835\udc41 ofthem.\nBeforedoinganywork,whatdoyouthink \ud835\udc38[\ud835\udc4b] willturnouttobe?Thenshowitmathematically\ntoseeifyourintuitioniscorrect.\n\u20132\u2013\nProblems\n1 CS106A Is Popular\nCS106AisStanford\u2019sintroductoryprogrammingcourseandlargelyconsideredtheprimary\ngatewaytoourundergraduatemajor.Assumenextquarter\u2019sofferingofCS106Aisexactly600\npeople,thateachofthefourundergraduateclassesiscompromisedof1750students,andthatnext\nquarter\u2019sCS106Arosterisjustsomerandomsampleofthe7000undergraduates.Let \ud835\udc34, \ud835\udc35,\ud835\udc36,and\n\ud835\udc37 countthenumberoffreshman,sophomores,juniors,andseniorsintheclassof600.\n\u2022 Presentthejointprobabilitymassfunctionof \ud835\udc34,\ud835\udc35,\ud835\udc36,\ud835\udc37?Restated,presentanexpression\nfor \ud835\udc43(\ud835\udc34 = \ud835\udc4e,\ud835\udc35 = \ud835\udc4f,\ud835\udc36 = \ud835\udc50,\ud835\udc37 = \ud835\udc51).\n\u2022 DoesyourPMFfromparta)describeamultinomialrandomvariable?Intuitivelyjustify\nyouranswer.\n\u2022 Whatistheconditionalprobabilitydistributionof \ud835\udc34 giventhat \ud835\udc35+\ud835\udc36 = 300?Restated,what\nis \ud835\udc43(\ud835\udc34 = \ud835\udc4e|\ud835\udc35+\ud835\udc36 = 300)?\n\u2022 Doyouexpect\ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc34,\ud835\udc35) tobepositive,zero,ornegative?Justifyyouranswer.\n2 Managing Screen Time\nPushnotificationslightupourphonesataratethat\u2019sguidedbyaPoissonprocesswithanconstant\naveragerateof5notificationsperhouratallhours,nightandday.Inanefforttomaximize\nproductivity,youputyourphonedownandignoreitasmuchaspossible.Youdo,however,\nperiodicallycheckittoclearallnotifications.Youcheckat7amwhenyouwakeup,noonwhenyou\ngrablunch,5pmasyouwrapupclassesfortheday,andthenagainat10pmbeforeyougotosleep.\nLetW,X,Y,andZbePoissonrandomvariablesthatcountthenumberofpushnotificationsthat\nhaveaccumulatedfrom10pmto7am,7amtonoon,noonto5pm,and5pmto10pm,respectively.\nWeassumethatthenumberofpushnotificationsthatarrivewithineachintervalareallmutually\nindependentofallotherintervals.\n\u2022 ComputethejointPMFonW,X,Y,andZ.\n\u2022 ComputetheconditionaljointPMFonW,X,Y,andZgiventhatW+X+Y+Z=150.\n\u2022 ComputetheconditionalPMFofX+Y+Z\u2014that\u2019sthenumberofnotificationsthatarrive\nwhileyou\u2019reawake\u2014giventhatW+X+Y+Z=150.\n\u2022 Compute \ud835\udc38[\ud835\udc4b +\ud835\udc4c + \ud835\udc4d|\ud835\udc4a + \ud835\udc4b +\ud835\udc4c + \ud835\udc4d = 150] and\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b +\ud835\udc4c + \ud835\udc4d|\ud835\udc4a + \ud835\udc4b +\ud835\udc4c + \ud835\udc4d = 150).\n\u20133\u2013\nA=0 A=1\nB=0 B=1 B=0 B=1\nC=0 0.36 0.20 0.00 0.00\nC=1 0.04 0.20 0.10 0.10\n3 Understanding Bayes Nets\nThejointprobabilitytable(above)forrandomvariables \ud835\udc34, \ud835\udc35 and\ud835\udc36 isequivalenttotheBayes\nnetwork(below).Bothgivetheprobabilityofanycombinationoftherandomvariables.Inthe\nBayesnetworktheprobabilityofeachrandomvariableisprovidedgivenitscausalparents.\n\u2022 UsetheBayesnetworktoexplainwhy \ud835\udc43(\ud835\udc34 = 0,\ud835\udc35 = 1,\ud835\udc36 = 1) = 0.20\n\u2022 Whatis \ud835\udc43(\ud835\udc34 = 1|\ud835\udc36 = 1)?\n\u2022 Is \ud835\udc34 independentof \ud835\udc35?Explainyouranswer.\n\u2022 Is \ud835\udc34 independentof \ud835\udc35 given\ud835\udc36 = 1?Explainyouranswer.\n4 Fish Sticks [courtesy of Lisa Yan]\nFishSticks,theonlineplatformdesignedtomeetallofyourfishstickneeds,wantstomodeltheir\nhourlyhomepagetrafficfromStanford.Thecompanydecidestomodeltwodifferentbehaviorsfor\nhomepagevisitsaccordingtotheBayesianNetworkbelow:\n\ud835\udc34 and \ud835\udc35 arethenumbersofStanfordstudentsandfaculty,respectively,whovisittheFishSticks\nhomepageinanhour.SinceFishSticksdoesnotknowwhenStanfordpeopleeat,thecompany\n\u20134\u2013\nmodelsdemandasa\u201dhidden\u201dBernoullirandomvariable \ud835\udc37,whichdeterminesthedistributionof\n\ud835\udc34and \ud835\udc35.RecallthatinaBayesianNetwork,randomvariablesareconditionallyindependentgiven\ntheirparents.Forexample,given \ud835\udc37 = 0, \ud835\udc34 \u223c Poi(5) and \ud835\udc35 \u223c Poi(3),twoindependentrandom\nvariables.\na. Giventhat6usersfromgroup \ud835\udc34 visitthehomepageinthenexthour,whatistheprobability\nthat \ud835\udc37 = 0?\nb. Whatistheprobabilitythatinthenexthour,thetotal numberofuserswhovisitthe\nhomepagefromgroups \ud835\udc34 and \ud835\udc35 isequalto12,i.e.,whatis \ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12)?\nc. Nowsimulate \ud835\udc43(\ud835\udc34+ \ud835\udc35 = total),wheretotal = 12,byimplementingthe\ninfer prob total(total, ntrials)functionbelowusingrejectionsampling.\n\u2022 totalisthetotalnumberofusersfromgroups \ud835\udc34 and \ud835\udc35 intheevent \ud835\udc34+ \ud835\udc35 = total.\n\u2022 ntrialsisthenumberofobservationstogenerateforrejectionsampling.\n\u2022 probisthereturnvaluetothefunction,whereprob \u2248 \ud835\udc43(\ud835\udc34+ \ud835\udc35 = total).\n\u2022 Thefunctioncallisimplementedforyouatthebottomofthecodeblock.\nYoucancallthefollowingfunctionsfromthescipypackage:\n\u2022 stats.bernoulli.rvs(\ud835\udc5d),whichrandomlygeneratesa1withprobability \ud835\udc5d,and\ngeneratesa0otherwise.\n\u2022 stats.poisson.rvs(\ud835\udf06),whichrandomlygeneratesavalueaccordingtoaPoisson\ndistributionwithparameter\ud835\udf06\nYouarenotrequiredtouselistsornumpyarraysinthisquestion(butyoucanifyouwant).\nPseudo-codeisfineaslongasyourcodeaccuratelyconveysyourapproach.\nimport numpy as np\nfrom scipy import stats\ndef infer_prob_total(total, ntrials):\n# here's where your implementation belongs\nreturn prob\ntotal = 12\nntrials = 50000\nprint('Simulated% P(A + B)=', infer_prob_total(total, ntrials))\n5 ChatGPT, Watermarking, and Bayesian Inference\nChatGPTisagenerativeAItechnologythatcanbecoarselysummarizedtobeachatbotwitha\nseeminglyboundlessabilitytodiscussanytopic\u2014history,computerscience,art,nuclearphysics,\nprobability,andeventheethicsofusingChatGPT\u2014inanyoneofseveralwrittenlanguages,\nincludingEnglish,French,Spanish,C++,JavaScript,Python,andsome100others.\n\u20135\u2013\nUnsurprisingly,wewillsoonbelefttowonderwhetherapoem,aTweet,aC++function,ora\ncollegethesisiswrittenbyChatGPTorahumanbeing.Questionsaboutauthorship,accuracy,and\nattributionhavepromptedOpenAI,thecompanybehindChatGPT,toaddresstheseconcernsby\nimplementingChatGPTtoemploywhat\u2019stermedwatermarkingandinsertcertainwordsmoreor\nlessoftenthaniscustomaryineventhebestofhuman-authoredwriting.\nToillustrate,let\u2019sassumethatmosthumansusethewordtheanaverageof4.8timesper100\nwords,whereasChatGPTmightgenerateprosewheretheappearsonaverage6.5timesper100\nwords.Similarly,humansusethewordofonaverageabout3.9timesper100words,whereas\nChatGPTmightleverageofabout6.2timesper100words.Conversely,ChatGPTmightgenerate\nthewordbyonly1.6timesper100words,whereashumansusethewordbyabout2.7timesper\n100words.\na. YouelecttomodelwordfrequencyofallwordsusingeitheraPoissonforparagraphsof200\norsowords\u2014butasaGaussianforlargerdocuments\u2014say10000wordsormore.Explain\nwhytheGaussianmightbethebetterchoiceforlargerdocumentsthanthePoisson,whereas\nPoissonismoreeasilydefendedforsmallerdocuments.\nb. Adeeperstatisticalanalysisofmanyhuman-writtendocumentsstronglysuggeststhat\n\ud835\udc3b \u223c N(5,1) and \ud835\udc3b \u223c N(4,1),whereasaseparatebutequallydeepanalysisstrongly\nthe by\nsuggeststhat\ud835\udc36 \u223c N(3,1) and\ud835\udc36 \u223c N(2,1).(Theparametersareroundedvaluesfor\nthe by\nsimplicityandassumedtobeper-100-words.)\nAssumingapriorbeliefthataverylongdocumentwaswrittenbyahumanis0.99,whatis\nyourposteriorbeliefthatthedocumentwaswrittenbyahumanifthedocumentcontainsan\naverageof5the\u2019severy100wordsbutonly1byevery100words.Youmayassumeall\nGaussiandistributionsofinterestareindependent.\nc. Inreality,theGaussiansherearenotindependent,sincethepresenceofonewordimplies\ntheabsenceofanother.Assumingacorrelationvalue \ud835\udf0c thatisslightlynegative,wouldyou\nexpecttheobservationsstatedinpartb)toresultinalargerposteriorprobabilityora\nsmallerone?Brieflyexplainwhy. <END>"}
{"prompt": "Lecture notes from 20_mle_annotated.txt\n\n###\n\n", "completion": "20: Maximum\nLikelihood Estimation\nJerry Cain\nMay 15th, 2024\nLecture Discussion on Ed\n1\nBootstrap:\np-value\n2\nNull hypothesis test\nNepal Bhutan\nHappiness Happiness\n4.45 0.91\n2.45 0.34\n6.37 1.91\n2.07 1.61\n\u2026 \u2026\n1.63 1.08\n! !\n\ud835\udc4b = 3.1 \ud835\udc4b = 2.4\n! \"\nClaim: The difference in mean happiness between Nepal and\nBhutan is 0.7 happiness points, and this is statistically\nsignificant.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nNull hypothesis test\ndef null hypothesis \u2013 It\u2019s possible the two distributions are essentially\nthe same, and your claim looks significant but really is not.\ndef p-value \u2013 What is the probability that the observed difference occurs\nunder the null hypothesis?\nExample:\n\u2022 Flip some coin 100 times.\nNull hypothesis assumes\n\u2022 Flip some coin 150 times.\nwe use the same coin\n\u2022 Compute fraction of heads in both groups.\n\u2022 There is a possibility we\u2019ll see the observed difference\np-value\nin these fractions even if we used the same coin\nA significant p-value (< 0.05) means we reject the null hypothesis.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\n(this is what the null\nUniversal sample\nhypothesis assumes)\n!\n\ud835\udc4b = 3.1\n!\n!\n\ud835\udc4b = 2.4\n\"\n! !\nWant p-value: probability \ud835\udc4b \u2212 \ud835\udc4b \u2265 3.1 \u2212 2.4 happens under null hypothesis\n! \"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nBootstrap for p-values\n1. Create a universal sample using i.e., recreate the\nyour two samples\nnull hypothesis\n= \u2248\n+\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nBootstrap for p-values\nbhutan_sample\n1. Create a universal sample using\nnepal_sample\nyour two samples\n2. Repeat 10,000 times:\na. Resample both samples\nb. Recalculate the mean difference\nbetween the resamples\nProbability\nthat observed\n# (mean diffs >= observed diff)\ndifference arose\n3. p-value =\nn by chance\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nBootstrap for p-values\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n1. Create a universal\nBootstrap for p-values\nsample using\nyour two samples\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\n2. a. Resample both samples\nBootstrap for p-values\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n2. b. Recalculate the mean\nBootstrap for p-values\ndifference b/t resamples\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n3. p-value =\n# (mean diffs > observed diff)\nBootstrap for p-values\nn\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nBootstrap for p-values\ndef pvalue_boot(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nobserved_diff = |mean of bhutan_sample \u2013 mean of nepal_sample|\nuni_sample = combine bhutan_sample and nepal_sample\ncount = 0\nwith replacement!\nrepeat 10,000 times:\nbhutan_resample = draw N resamples from the uni_sample\nnepal_resample = draw M resamples from the uni_sample\nmuBhutan = sample mean of the bhutan_resample\nmuNepal = sample mean of the nepal_resample\ndiff = |muNepal - muBhutan|\nif diff >= observed_diff:\ncount += 1\npValue = count / 10,000\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nBootstrap\nLet\u2019s go try it!\nGoogle colab notebook link\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nNull hypothesis test\nNepal Bhutan\nHappiness Happiness\n4.45 0.91\n2.45 0.34\n6.37 1.91\n2.07 1.61\n\u2026 \u2026\n1.63 1.08\n! !\n\ud835\udc4b = 3.1 \ud835\udc4b = 2.4\n! \"\nRedux: The happiness of Nepal and Bhutan have a 0.7 difference\nof means, and this is statistically significant (p < 0.05).\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nParameter\nEstimation\n16\nStory so far\nAt this point:\n1\n\ud835\udc4c ~ Exp\nWhen provided with a model and\n5\nall the necessary parameters, we\n\ud835\udc4b , \u2026 , \ud835\udc4b iid\ncan make predictions! ! #\n\ud835\udc4b ~Ber 0.2 ,\n$\n#\n\ud835\udc4b = \u2211 \ud835\udc4b\n$%! $\nCan we infer parameters for a given model when provided with some data?\nWhat if you want to learn the structure of the model, too? Glimpse: Week 10\nMachine Learning\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nSome estimators\n\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b are \ud835\udc5b iid random variables,\n! \" #\n\"\nwhere \ud835\udc4b drawn from distribution \ud835\udc39 with \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e .\n$ $ $\n#\n1\nSample mean: \ud835\udc4b! = 0 \ud835\udc4b unbiased estimate of \ud835\udf07\n$\n\ud835\udc5b\n$%!\n#\n1\nSample variance: \ud835\udc46\" = 0 \ud835\udc4b \u2212 \ud835\udc4b! \" unbiased estimate of \ud835\udf0e\"\n$\n\ud835\udc5b \u2212 1\n$%!\npotentially useful estimates if trying to infer parameters of a Gaussian\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nWhat are parameters?\ndef Most random variables we\u2019ve seen thus far are parametric models:\nDistribution = model + parameter \ud835\udf03\n\u2192\nex The distribution Ber 0.2 model is Bernoulli, parameter is \ud835\udf03 = 0.2.\nFor each of the distributions below, what is the parameter \ud835\udf03?\n1. Ber \ud835\udc5d \ud835\udf03 = \ud835\udc5d\n2. Poi \ud835\udf06\n3. Uni \ud835\udefc, \ud835\udefd\n!\n4. \ud835\udca9(\ud835\udf07, \ud835\udf0e )\n5. \ud835\udc4c = \ud835\udc5a\ud835\udc4b + \ud835\udc4f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nWhat are parameters?\ndef Most random variables we\u2019ve seen thus far are parametric models:\nDistribution = model + parameter \ud835\udf03\n\u2192\nex The distribution Ber 0.2 model is Bernoulli, parameter is \ud835\udf03 = 0.2.\nFor each of the distributions below, what is the parameter \ud835\udf03?\n1. Ber \ud835\udc5d \ud835\udf03 = \ud835\udc5d\n\ud835\udf03 = \ud835\udf06\n2. Poi \ud835\udf06\n3. Uni \ud835\udefc, \ud835\udefd \ud835\udf03 = \ud835\udefc, \ud835\udefd\n4. \ud835\udca9(\ud835\udf07, \ud835\udf0e! ) \ud835\udf03 = \ud835\udf07, \ud835\udf0e\"\n5. \ud835\udc4c = \ud835\udc5a\ud835\udc4b + \ud835\udc4f \ud835\udf03 = \ud835\udc5a, \ud835\udc4f \ud835\udf03 is the parameter of a distribution.\n\ud835\udf03 can be a vector.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nWhy do we care?\nIn the real world, we don\u2019t know the true parameters.\n\u2022 But we observe data: # times coin comes up heads, # requests for\nRydeShare per minute, # visitors to website per\nday, offer amount for that used bike you can\u2019t sell\n;\ndef estimator \ud835\udf03: a random variable estimating the true parameter \ud835\udf03.\nIn parameter estimation,\nWe\u2019ll initially and often rely on point estimates\u2014i.e., the best single value\n\u2022 Provides an understanding of why data looks the way it does\n\u2022 Can make future predictions using that model\n\u2022 Can run simulations to generate more data\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nMaximum\nLikelihood\nEstimator\n22\nDefining the likelihood of data: Bernoulli\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n\u2022 \ud835\udc4b was drawn from distribution \ud835\udc39 ~ Ber \ud835\udf03 with unknown parameter \ud835\udf03.\n$\n\u2022 Observed sample:\n0, 0, 1, 1, 1, 1, 1, 1, 1, 1 (\ud835\udc5b = 10)\nHow likely is this sample if, say, \ud835\udf03 = 0.4?\n& \"\n\ud835\udc43 sample|\ud835\udf03 = 0.4 = 0.4 0.6 = 0.000236\nLikelihood of data\ngiven parameter \ud835\udf03 = 0.4\nIs there a better choice for \ud835\udf03?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nDefining the likelihood of data\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n\u2022 \ud835\udc4b was drawn from a distribution with density function \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n$ $\n\u2022 Sample: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" #\nLikelihood question:\nHow likely is the sample \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b given the parameter \ud835\udf03?\n! \" #\nLikelihood function, \ud835\udc3f \ud835\udf03 :\n#\n\ud835\udc3f \ud835\udf03 = \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 = C \ud835\udc53 \ud835\udc4b |\ud835\udf03\n! \" # $\n$%!\nThis is just a product, since the \ud835\udc4b are iid.\n$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nMaximum Likelihood Estimator\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , drawn from a\n! \" #\ndistribution \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n$\ndef The Maximum Likelihood Estimator (MLE) of \ud835\udf03 is the value of \ud835\udf03 that\nmaximizes \ud835\udc3f \ud835\udf03 .\n\ud835\udf03 = arg max \ud835\udc3f \ud835\udf03\n!\"#\n$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nMaximum Likelihood Estimator\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , drawn from a\n! \" #\ndistribution \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n$\ndef The Maximum Likelihood Estimator (MLE) of \ud835\udf03 is the value of \ud835\udf03 that\nmaximizes \ud835\udc3f \ud835\udf03 .\n\ud835\udf03 = arg max \ud835\udc3f \ud835\udf03\n!\"#\n$\nLikelihood of your sample\n#\n\ud835\udc3f \ud835\udf03 = C \ud835\udc53 \ud835\udc4b |\ud835\udf03\n$\n$%!\nFor continuous \ud835\udc4b , \ud835\udc53 \ud835\udc4b |\ud835\udf03 is PDF, and for discrete \ud835\udc4b , \ud835\udc53 \ud835\udc4b |\ud835\udf03 is PMF\n$ $ $ $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nMaximum Likelihood Estimator\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , drawn from a\n! \" #\ndistribution \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n$\ndef The Maximum Likelihood Estimator (MLE) of \ud835\udf03 is the value of \ud835\udf03 that\nmaximizes \ud835\udc3f \ud835\udf03 .\n\ud835\udf03 = arg max \ud835\udc3f \ud835\udf03\n!\"#\n$\nthe argument \ud835\udf03\nthat maximizes \ud835\udc3f \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nargmax and log\nlikelihood\n28\nNew function: arg max\nThe argument \ud835\udc65 that\narg max \ud835\udc53 \ud835\udc65\nmaximizes the function \ud835\udc53 \ud835\udc65 .\n%\n1. max \ud835\udc53 \ud835\udc65 ?\n\ud835\udc53 \ud835\udc65\n\u2019\n\" 4\nLet \ud835\udc53 \ud835\udc65 = \u2212\ud835\udc65 + 4,\n= 4\nwhere \u22122 < \ud835\udc65 < 2. 3\n2\n2. arg max \ud835\udc53 \ud835\udc65 ?\n1 \u2019\n\ud835\udc65 = 0\n0\n-2 -1 0 1 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nArgmax properties\nThe argument \ud835\udc65 that\narg max \ud835\udc53 \ud835\udc65\nmaximizes the function \ud835\udc53 \ud835\udc65 .\n%\n= arg max log \ud835\udc53 \ud835\udc65 (log is an increasing function:\n\ud835\udc65 < \ud835\udc66 \u27fa log \ud835\udc65 < log \ud835\udc66)\n%\n= arg max \ud835\udc50 log \ud835\udc53 \ud835\udc65\n(\ud835\udc65 < \ud835\udc66 \u27fa \ud835\udc50 log \ud835\udc65 < \ud835\udc50 log \ud835\udc66)\n%\nfor any positive constant \ud835\udc50\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nFinding the argmax with calculus\n\"\nLet \ud835\udc53 \ud835\udc65 = \u2212\ud835\udc65 + 4,\n\ud835\udc65/ = arg max \ud835\udc53 \ud835\udc65\nwhere \u22122 < \ud835\udc65 < 2.\n%\n\ud835\udc53 \ud835\udc65\n\ud835\udc51 \ud835\udc51\nDifferentiate w.r.t.\n\ud835\udc53 \ud835\udc65 = \ud835\udc65\" + 4 = 2\ud835\udc65 4\nargmax\u2019s argument\n\ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc65\n3\n2\nSet to 0 and solve 2\ud835\udc65 = 0 \u21d2 \ud835\udc65O = 0\n1\n0 \ud835\udc65\n-2 -1 0 1 2\nMake sure \ud835\udc65? \u2022 Check \ud835\udc53 \ud835\udc65? \u00b1 \ud835\udf16 < \ud835\udc53 \ud835\udc65?\nis a maximum \u2022 Often ignored in expository derivations\n\u2022 We\u2019ll ignore it as well (and we won\u2019t require it in\nclass or on problem sets and exams)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nMaximum Likelihood Estimator\n#\nConsider a sample of \ud835\udc5b iid random\n\ud835\udc3f \ud835\udf03 = C \ud835\udc53 \ud835\udc4b |\ud835\udf03\nvariables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , drawn from a\n$\n! \" #\ndistribution \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n$%!\n$\n\ud835\udf03 maximizes the likelihood of our \ud835\udf03 = arg max \ud835\udc3f \ud835\udf03\n()* ()*\nsample, \ud835\udc3f \ud835\udf03 : +\n\ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n\ud835\udf03 also maximizes the log-likelihood\n()* !\"#\nfunction, \ud835\udc3f\ud835\udc3f \ud835\udf03 : $\n# #\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = log \ud835\udc3f \ud835\udf03 = log B\ud835\udc53 \ud835\udc4b |\ud835\udf03 = D log \ud835\udc53 \ud835\udc4b |\ud835\udf03 \ud835\udc3f\ud835\udc3f \ud835\udf03 is often easier to\n$ $\ndifferentiate than \ud835\udc3f \ud835\udf03 .\n$%! $%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nMLE: Bernoulli\n33\n\ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nComputing the MLE\n!\"#\n$\nGeneral approach for finding \ud835\udf03 , the MLE of \ud835\udf03:\n()*\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 w.r.t. (each) \ud835\udf03 equations\n#\nTo maximize:\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 algebra or\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D log \ud835\udc53 \ud835\udc4b |\ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n$\n= 0 computer\n\ud835\udf15\ud835\udf03\n\ud835\udf15\ud835\udf03\n$%!\n\ud835\udc3f\ud835\udc3f \ud835\udf03 is often easier to\ndifferentiate than \ud835\udc3f \ud835\udf03 .\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ?\n()* ()*\n#\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D log \ud835\udc53 \ud835\udc4b |\ud835\udc5d\n$\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n\ud835\udc5d if \ud835\udc4b = 1\n$%! $\n\ud835\udc53 \ud835\udc4b |\ud835\udc5d = P\n$ 1 \u2212 \ud835\udc5d if \ud835\udc4b = 0\n? $\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03\nwrt (each) \ud835\udf03, set to 0\n3. Solve resulting\nequations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ? \u2022 \ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\n()* ()*\n#\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D log \ud835\udc53 \ud835\udc4b |\ud835\udc5d\n$\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n\ud835\udc5d if \ud835\udc4b = 1\n$%! $\n\ud835\udc53 \ud835\udc4b |\ud835\udc5d = P\n$ 1 \u2212 \ud835\udc5d if \ud835\udc4b = 0\n$\n7 !87\n\ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d ! 1 \u2212 \ud835\udc5d ! where \ud835\udc4b \u2208 {0,1}\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 $ $\nwrt (each) \ud835\udf03, set to 0\n3. Solve resulting \u2022 differentiable with respect to \ud835\udc5d\n\u2705\nequations \u2022 valid PMF over discrete domain\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ? \u2022 \ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\n()* ()*\n# #\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D log \ud835\udc53 \ud835\udc4b |\ud835\udc5d = D log \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n$%! $%!\n#\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 = D \ud835\udc4b log \ud835\udc5d + 1 \u2212 \ud835\udc4b log 1 \u2212 \ud835\udc5d\n$ $\nwrt (each) \ud835\udf03, set to 0\n$%!\n#\n3. Solve resulting\n= \ud835\udc4c log \ud835\udc5d + \ud835\udc5b \u2212 \ud835\udc4c log 1 \u2212 \ud835\udc5d , where \ud835\udc4c = D \ud835\udc4b\nequations $\n$%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ? \u2022 \ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\n()* ()*\n#\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D \ud835\udc4b log \ud835\udc5d + 1 \u2212 \ud835\udc4b log 1 \u2212 \ud835\udc5d\n$ $\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n$%! #\n= \ud835\udc4c log \ud835\udc5d + \ud835\udc5b \u2212 \ud835\udc4c log 1 \u2212 \ud835\udc5d , where \ud835\udc4c = D \ud835\udc4b\n$\n$%!\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 1 \u22121\n= \ud835\udc4c + \ud835\udc5b \u2212 \ud835\udc4c = 0\nwrt (each) \ud835\udf03, set to 0 \ud835\udf15\ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d\n3. Solve resulting\nequations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ? \u2022 \ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\n()* ()*\n#\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D \ud835\udc4b log \ud835\udc5d + 1 \u2212 \ud835\udc4b log 1 \u2212 \ud835\udc5d\n$ $\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n$%! #\n= \ud835\udc4c log \ud835\udc5d + \ud835\udc5b \u2212 \ud835\udc4c log 1 \u2212 \ud835\udc5d , where \ud835\udc4c = D \ud835\udc4b\n$\n$%!\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 1 \u22121\n= \ud835\udc4c + \ud835\udc5b \u2212 \ud835\udc4c = 0\nwrt (each) \ud835\udf03, set to 0 \ud835\udf15\ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d\n3. Solve resulting\nequations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nMaximum Likelihood with Bernoulli\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Ber \ud835\udc5d .\n! \" # $\nWhat is \ud835\udf03 = \ud835\udc5d ? \u2022 \ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& !\n$\n()* ()*\n#\n1. Determine\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D \ud835\udc4b log \ud835\udc5d + 1 \u2212 \ud835\udc4b log 1 \u2212 \ud835\udc5d\n$ $\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03\n$%! #\n= \ud835\udc4c log \ud835\udc5d + \ud835\udc5b \u2212 \ud835\udc4c log 1 \u2212 \ud835\udc5d , where \ud835\udc4c = D \ud835\udc4b\n$\n$%!\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 1 \u22121\n= \ud835\udc4c + \ud835\udc5b \u2212 \ud835\udc4c = 0\nwrt (each) \ud835\udf03, set to 0 \ud835\udf15\ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d\n# MLE of the Bernoulli parameter, \ud835\udc5d ,\n1 1 ()*\n3. Solve resulting \ud835\udc5d = \ud835\udc4c = D \ud835\udc4b is the sample mean, \ud835\udc4b! , which is an\n()* $\n\ud835\udc5b \ud835\udc5b\nequations unbiased estimator of the true mean.\n$%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nQuick check\n\u2022 You draw \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b from the distribution \ud835\udc39,\n! \" #\nyielding the following sample:\n0, 0, 1, 1, 1, 1, 1, 1, 1, 1 (\ud835\udc5b = 10)\n\u2022 Suppose distribution \ud835\udc39 = Ber \ud835\udc5d with unknown parameter \ud835\udc5d.\n1. What is \ud835\udc5d , the MLE of the parameter \ud835\udc5d?\n()*\nA. 1.0\nB. 0.5\n#\n1\n!\nC. 0.8 \ud835\udc5d = \ud835\udc4b = D \ud835\udc4b\n()* $\n\ud835\udc5b\nD. 0.2 $%!\nE. None/other\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nQuick check\n\u2022 You draw \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b from the distribution \ud835\udc39,\n! \" #\nyielding the following sample:\n0, 0, 1, 1, 1, 1, 1, 1, 1, 1 (\ud835\udc5b = 10)\n\u2022 Suppose distribution \ud835\udc39 = Ber \ud835\udc5d with unknown parameter \ud835\udc5d.\n1. What is \ud835\udc5d , the MLE of the parameter \ud835\udc5d? C. 0.8\n()*\n2. What is the likelihood \ud835\udc3f \ud835\udf03 of this specific sample?\n\ud835\udc53 \ud835\udc4b |\ud835\udc5d = \ud835\udc5d& ! 1 \u2212 \ud835\udc5d !\u2019& ! where \ud835\udc4b \u2208 {0,1}\n$ $\n#\nwhere \ud835\udf03 = \ud835\udc5d\n\ud835\udc3f \ud835\udf03 = B\ud835\udc53 \ud835\udc4b |\ud835\udc5d\n$\n$%!\n= \ud835\udc5d+ 1 \u2212 \ud835\udc5d \" = 0.8+ 0.2\" = 0.0067\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nMLE: Poisson\nand Uniform\n43\nMaximum Likelihood with Poisson\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Poi \ud835\udf06 .\n! \" # $ \u2019, &\n\ud835\udc52 \ud835\udf06 !\nWhat is \ud835\udf03 = \ud835\udf06 ? \u2022 PMF: \ud835\udc53 \ud835\udc4b $|\ud835\udf06 =\n()* ()* \ud835\udc4b !\n$\n( (\n1. Determine\n\ud835\udc52)*\ud835\udf06+\n!\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = $ log = $ \u2212\ud835\udf06 log \ud835\udc52 + \ud835\udc4b log \ud835\udf06 \u2212 log \ud835\udc4b !\n% %\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udc4b !\n%\n%&\u2019 %&\u2019\n( (\nusing natural log,\n= \u2212\ud835\udc5b\ud835\udf06 + log \ud835\udf06 $ \ud835\udc4b \u2212 $ log \ud835\udc4b !\n% % i.e., ln\ud835\udc52 = 1\n%&\u2019 %&\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nMaximum Likelihood with Poisson\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Poi \ud835\udf06 .\n! \" # $ \u2019, &\n\ud835\udc52 \ud835\udf06 !\nWhat is \ud835\udf03 = \ud835\udf06 ? \u2022 PMF: \ud835\udc53 \ud835\udc4b $|\ud835\udf06 =\n()* ()* \ud835\udc4b !\n$\n( (\n1. Determine\n\ud835\udc52)*\ud835\udf06+\n!\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = $ log = $ \u2212\ud835\udf06 log \ud835\udc52 + \ud835\udc4b log \ud835\udf06 \u2212 log \ud835\udc4b !\n% %\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udc4b !\n%\n%&\u2019 %&\u2019\n( (\nusing natural log,\n= \u2212\ud835\udc5b\ud835\udf06 + log \ud835\udf06 $ \ud835\udc4b \u2212 $ log \ud835\udc4b !\n% % i.e., ln\ud835\udc52 = 1\n%&\u2019 %&\u2019\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n= ?\nw.r.t. (each) \ud835\udf03, set to 0\n\ud835\udf15\ud835\udf06\n#\nA. ( ( B. C.\n1\n1 1 \ud835\udf15\ud835\udc4b ! Stop trying\n%\n\u2212\ud835\udc5b + A\ud835\udc4b + \ud835\udc5blog\ud835\udf06 \u2212 A \u22c5 \u2212\ud835\udc5b + D \ud835\udc4b \ud83e\udd14\n% $\n\ud835\udf06 \ud835\udc4b ! \ud835\udf15\ud835\udc4b \ud835\udf06\n% %\n%&\u2019 %&\u2019\n$%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nMaximum Likelihood with Poisson\nConsider a sample of \ud835\udc5b iid RVs \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b . \u2022 Let \ud835\udc4b ~Poi \ud835\udf06 .\n! \" # $ \u2019, &\n\ud835\udc52 \ud835\udf06 !\nWhat is \ud835\udf03 = \ud835\udf06 ? \u2022 PMF: \ud835\udc53 \ud835\udc4b $|\ud835\udf06 =\n()* ()* \ud835\udc4b !\n$\n( (\n1. Determine\n\ud835\udc52)*\ud835\udf06+\n!\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = $ log = $ \u2212\ud835\udf06 log \ud835\udc52 + \ud835\udc4b log \ud835\udf06 \u2212 log \ud835\udc4b !\n% %\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udc4b !\n%\n%&\u2019 %&\u2019\n( (\nusing natural log,\n= \u2212\ud835\udc5b\ud835\udf06 + log \ud835\udf06 $ \ud835\udc4b \u2212 $ log \ud835\udc4b !\n% % i.e., ln\ud835\udc52 = 1\n%&\u2019 %&\u2019\n#\n2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 1\n= \u2212\ud835\udc5b + D \ud835\udc4b = 0\nw.r.t. (each) \ud835\udf03, set to 0 $\n\ud835\udf15\ud835\udf06 \ud835\udf06\n$%! MLE of the Poisson parameter,\n# \ud835\udf06 , is the sample mean, \ud835\udc4b! ,\n1 ()*\n3. Solve resulting\n\ud835\udf06 = D \ud835\udc4b which is an unbiased estimator of\n()* $\nequations \ud835\udc5b\nthe true mean.\n$%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nQuick Review\n1. A particular experiment can be modeled as a #\n1\nPoisson RV with parameter \ud835\udf06, in terms of \ud835\udf06 = D \ud835\udc4b\n()* $\n\ud835\udc5b\nevents/minute.\n$%!\nCollect data: observe 53 events over the next\n10 minutes. What is \ud835\udf06 ?\n()*\n2. Is the Bernoulli MLE an unbiased estimator of\nthe Bernoulli parameter \ud835\udc5d?\n\u2705\n3. Is the Poisson MLE an unbiased estimator of\nthe Poisson variance?\n\u2705\nUnbiased: If you repeat your\n4. What does unbiased mean?\nexperiment multiple times, on average,\nyou\u2019ll get what you are looking for.\n\ud835\udc38 estimator = the truth\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 47\nMaximum Likelihood with Uniform\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\nif \ud835\udefc \u2264 \ud835\udc65 \u2264 \ud835\udefd\nLet \ud835\udc4b ~Uni \ud835\udefc, \ud835\udefd . \ud835\udc53 \ud835\udc4b |\ud835\udefc, \ud835\udefd = T $\n\ud835\udefd \u2212 \ud835\udefc\n$ $\n0 otherwise\n#\n1\n1. Determine\nif \ud835\udefc \u2264 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \u2264 \ud835\udefd\n\ud835\udc3f \ud835\udf03 = V ! \" #\nformula for \ud835\udc3f \ud835\udf03 \ud835\udefd \u2212 \ud835\udefc\n0 otherwise\n2. Differentiate \ud835\udc3f \ud835\udf03\nA. Great, let\u2019s do it\nwrt each \ud835\udf03, set to 0\nB. Use \ud835\udc3f\ud835\udc3f \ud835\udf03 instead\nC. Constraint \ud835\udefc \u2264 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \u2264 \ud835\udefd\n! \" # \ud83e\udd14\nmakes differentiation hard\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\nMaximum Likelihood with Uniform: Sample\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n#\n1\nLet \ud835\udc4b ~Uni \ud835\udefc, \ud835\udefd .\nif \ud835\udefc \u2264 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \u2264 \ud835\udefd\n$\n\ud835\udc3f \ud835\udf03 = V ! \" #\n\ud835\udefd \u2212 \ud835\udefc\n0 otherwise\nUnderlying \ud835\udc4b ~ Uni 0,1 0.15, 0.20, 0.30, 0.40, 0.65, 0.70, 0.75\n$\nYou observe data:\nA. Uni \ud835\udefc = 0.00, \ud835\udefd = 1.00\nWhich parameters\nB. Uni \ud835\udefc = 0.15, \ud835\udefd = 0.75\nmaximize \ud835\udc3f \ud835\udf03 ?\nC. Uni \ud835\udefc = 0.15, \ud835\udefd = 0.70\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 49\nMaximum Likelihood with Uniform: Sample\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n#\n1\nLet \ud835\udc4b ~Uni \ud835\udefc, \ud835\udefd .\nif \ud835\udefc \u2264 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \u2264 \ud835\udefd\n$\n\ud835\udc3f \ud835\udf03 = V ! \" #\n\ud835\udefd \u2212 \ud835\udefc\n0 otherwise\nUnderlying \ud835\udc4b ~ Uni 0,1 0.15, 0.20, 0.30, 0.40, 0.65, 0.70, 0.75\n$\nYou observe data:\n1\nA. Uni \ud835\udefc = 0.00, \ud835\udefd = 1.00 1 = 1\nWhich parameters\n1\n!\nB. Uni \ud835\udefc = 0.15, \ud835\udefd = 0.75 = 59.5\nmaximize \ud835\udc3f \ud835\udf03 ?\n-.0\n0\n!\nC. Uni \ud835\udefc = 0.15, \ud835\udefd = 0.70 \u22c5 0 = 0\n-.//\nOriginal parameters may not yield maximum likelihood.\n\u26a0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 50\nMaximum Likelihood with Uniform\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n#\n1\nLet \ud835\udc4b ~Uni \ud835\udefc, \ud835\udefd .\nif \ud835\udefc \u2264 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \u2264 \ud835\udefd\n$\n\ud835\udc3f \ud835\udf03 = V ! \" #\n\ud835\udefd \u2212 \ud835\udefc\n0 otherwise\n\ud835\udf03 : \ud835\udefc = min \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 \ud835\udefd = max \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65\n()* ()* ! \" # ()* ! \" #\nIntuition:\n\u2022 Want interval size \ud835\udefd \u2212 \ud835\udefc to be as narrow\nas possible to maximize likelihood function.\n(demo)\n\u2022 Need to ensure all datapoints are included\nin interval. Otherwise, \ud835\udc3f \ud835\udf03 = 0.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 51\nSmall samples = problems with MLE\nMaximum Likelihood Estimator \ud835\udf03 :\n()* \ud835\udf03 = arg max \ud835\udc3f \ud835\udf03\n()*\n\u2022 Best explains the data we\u2019ve seen\n+\n\u2022 Does not attempt to generalize to data not yet observed.\n#\n1\n(MLE for Bernoulli \ud835\udc5d,\n\u2705 In many cases, \ud835\udf07 ()* = D \ud835\udc4b $ Sample mean\n\ud835\udc5b Poisson \ud835\udf06, Normal \ud835\udf07)\n$%!\n\u2022 Unbiased (\ud835\udc38 \ud835\udf07 = \ud835\udf07, regardless of sample size)\n()*\n\u26a0 For some cases, like Uniform: \ud835\udefc \u2265 \ud835\udefc, \ud835\udefd \u2264 \ud835\udefd\n()* ()*\n\u2022 Ad hoc, biased, and problematic for small sample sizes\n\u2022 Example: If \ud835\udc5b = 1, then \ud835\udefc = \ud835\udefd, and our estimates yield an invalid\ndistribution\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 52\nMLE: Gaussian\n53\nMaximum Likelihood with Normal\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\n\u2022 Let \ud835\udc4b ~ \ud835\udca9 \ud835\udf07, \ud835\udf0e\" . \ud835\udc53 \ud835\udc4b |\ud835\udf07, \ud835\udf0e\" = \ud835\udc52\u2019 & !\u20192 \"/ \"4\"\n$ $\n2\ud835\udf0b\ud835\udf0e\n\"\nWhat is \ud835\udf03 = \ud835\udf07 , \ud835\udf0e ?\n()* ()* ()*\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 wrt (each) \ud835\udf03, set to 0 equations\n# #\n1\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = D log \ud835\udc52\u2019 & !\u20192 \"/ \"4\" = D \u2212 log 2\ud835\udf0b\ud835\udf0e \u2212 \ud835\udc4b \u2212 \ud835\udf07 \" / 2\ud835\udf0e\"\n$\n2\ud835\udf0b\ud835\udf0e\n$%! $%! (using natural log)\n# #\n= \u2212 D log 2\ud835\udf0b\ud835\udf0e \u2212 D \ud835\udc4b \u2212 \ud835\udf07 \"/ 2\ud835\udf0e\"\n$\n$%! $%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 54\nMaximum Likelihood with Normal\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\n\u2022 Let \ud835\udc4b ~ \ud835\udca9 \ud835\udf07, \ud835\udf0e\" . \ud835\udc53 \ud835\udc4b |\ud835\udf07, \ud835\udf0e\" = \ud835\udc52\u2019 & !\u20192 \"/ \"4\"\n$ $\n2\ud835\udf0b\ud835\udf0e\n\"\nWhat is \ud835\udf03 = \ud835\udf07 , \ud835\udf0e ?\n()* ()* ()*\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 wrt (each) \ud835\udf03, set to 0 equations\n# #\nwith respect to \ud835\udf07\n\" \"\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = \u2212 D log 2\ud835\udf0b\ud835\udf0e \u2212 D \ud835\udc4b \u2212 \ud835\udf07 / 2\ud835\udf0e\n$\n$%! $%!\n#\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n\"\n= D 2 \ud835\udc4b \u2212 \ud835\udf07 / 2\ud835\udf0e\n$\n\ud835\udf15\ud835\udf07\n$%!\n#\n1\n= D \ud835\udc4b \u2212 \ud835\udf07 = 0\n$\n\ud835\udf0e\"\n$%! Lisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 55\nMaximum Likelihood with Normal\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\n\u2022 Let \ud835\udc4b ~ \ud835\udca9 \ud835\udf07, \ud835\udf0e\" . \ud835\udc53 \ud835\udc4b |\ud835\udf07, \ud835\udf0e\" = \ud835\udc52\u2019 & !\u20192 \"/ \"4\"\n$ $\n2\ud835\udf0b\ud835\udf0e\n\"\nWhat is \ud835\udf03 = \ud835\udf07 , \ud835\udf0e ?\n()* ()* ()*\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 wrt (each) \ud835\udf03, set to 0 equations\n# #\nwith respect to \ud835\udf07 with respect to \ud835\udf0e\n\" \"\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = \u2212 D log 2\ud835\udf0b\ud835\udf0e \u2212 D \ud835\udc4b \u2212 \ud835\udf07 / 2\ud835\udf0e\n$\n$%! $%!\n# # #\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 1\n\" \" 5\n= D 2 \ud835\udc4b \u2212 \ud835\udf07 / 2\ud835\udf0e = \u2212 D + D 2 \ud835\udc4b \u2212 \ud835\udf07 / 2\ud835\udf0e\n$ $\n\ud835\udf15\ud835\udf07 \ud835\udf15\ud835\udf0e \ud835\udf0e\n$%! $%! $%!\n# #\n1 \ud835\udc5b 1\n= D \ud835\udc4b \u2212 \ud835\udf07 = 0 = \u2212 + D \ud835\udc4b \u2212 \ud835\udf07 \" = 0\n$ $\n\ud835\udf0e\" \ud835\udf0e \ud835\udf0e5\n$%! Lisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 $%! 56\nMaximum Likelihood with Normal\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\n\u2022 Let \ud835\udc4b ~ \ud835\udca9 \ud835\udf07, \ud835\udf0e\" . \ud835\udc53 \ud835\udc4b |\ud835\udf07, \ud835\udf0e\" = \ud835\udc52\u2019 & !\u20192 \"/ \"4\"\n$ $\n2\ud835\udf0b\ud835\udf0e\n\"\nWhat is \ud835\udf03 = \ud835\udf07 , \ud835\udf0e ?\n()* ()* ()*\n# #\n1 \ud835\udc5b 1\n3. Solve resulting Two equations,\n\"\nD \ud835\udc4b \u2212 \ud835\udf07 = 0 \u2212 + D \ud835\udc4b \u2212 \ud835\udf07 = 0\nequations two unknowns: \ud835\udf0e\" $ \ud835\udf0e \ud835\udf0e5 $\n$%! $%!\n# # # #\nFirst, solve 1 1 1\nD \ud835\udc4b \u2212 D \ud835\udf07 = 0 \u21d2 D \ud835\udc4b = \ud835\udc5b\ud835\udf07 \u21d2 \ud835\udf07 = D \ud835\udc4b\nfor \ud835\udf07 : \ud835\udf0e\" $ \ud835\udf0e\" $ ()* \ud835\udc5b $\n()*\n$%! $%! $%! unbiased $%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 57\nMaximum Likelihood with Normal\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n1\n\u2022 Let \ud835\udc4b ~ \ud835\udca9 \ud835\udf07, \ud835\udf0e\" . \ud835\udc53 \ud835\udc4b |\ud835\udf07, \ud835\udf0e\" = \ud835\udc52\u2019 & !\u20192 \"/ \"4\"\n$ $\n2\ud835\udf0b\ud835\udf0e\n\"\nWhat is \ud835\udf03 = \ud835\udf07 , \ud835\udf0e ?\n()* ()* ()*\n# #\n1 \ud835\udc5b 1\n3. Solve resulting Two equations,\n\"\nD \ud835\udc4b \u2212 \ud835\udf07 = 0 \u2212 + D \ud835\udc4b \u2212 \ud835\udf07 = 0\nequations two unknowns: \ud835\udf0e\" $ \ud835\udf0e \ud835\udf0e5 $\n$%! $%!\n# # # #\nFirst, solve 1 1 1\nD \ud835\udc4b \u2212 D \ud835\udf07 = 0 \u21d2 D \ud835\udc4b = \ud835\udc5b\ud835\udf07 \u21d2 \ud835\udf07 = D \ud835\udc4b\nfor \ud835\udf07 : \ud835\udf0e\" $ \ud835\udf0e\" $ ()* \ud835\udc5b $\n()*\n$%! $%! $%! unbiased $%!\n# # #\nNext, solve\n1 \ud835\udc5b 1\nD \ud835\udc4b \u2212 \ud835\udf07 \" = \u21d2 D \ud835\udc4b \u2212 \ud835\udf07 \" = \ud835\udf0e\" \ud835\udc5b \u21d2 \ud835\udf0e\" = D \ud835\udc4b \u2212 \ud835\udf07 \"\nfor \ud835\udf0e ()*: \ud835\udf0e5 $ \ud835\udf0e $ ()* \ud835\udc5b $ ()*\n$%! $%! biased $%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 58 <END>"}
{"prompt": "Lecture notes from 23_naive_bayes_annotated.txt\n\n###\n\n", "completion": "23: Na\u00efve Bayes\nJerry Cain\nMay 22, 2024\nLecture Discussion on Ed\n1\nPreamble:\nMachine\nLearning\n2\nThe Path Before Us\nDeep Learning\nR\nL ei gn re ea sr si o n N a B\u00ef av ye e s L o\ne\ng gi rs et i sc s i o n\nR\nParameter Estimation\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nThe Path Before Us\nDeep Learning\nR\nL ei gn re ea sr si o n N a B\u00ef av ye e s L o\ne\ng gi rs et i sc s i o n\nR\nnext\ng\nn\nU en sb i tia ms\ne\na\ntd\no r s M a lix ki\nem lii hz i\no o d B ea sy tie s\nmia\na\ntn\ni o n\n\u2705 \u2705 \u2705\n\ud835\udf03 \ud835\udf03\n\ud835\udc4b\" , \ud835\udc46$ !\"# !%&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nMachine Learning uses a lot of data.\nMany different forms of machine learning\n\u25e6 We focus on the problem of prediction given prior observations.\nTask: Identify the chair\nData: All the chairs ever\nSupervised learning: A\ncategory of machine learning\nwhere you have labeled data for\nthe problem you are solving.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nSupervised learning\nReal World Problem\nModel the problem\nTraining\nFormal Model \ud835\udf03 Data\nLearning Algorithm\nEvaluation\nTesting\nPrediction\nscore\nData \"\nFunction \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nSupervised learning\nReal World Problem\nModel the problem\nModeling\nTraining\nNot CS109\u2019s focus.\nCS228 is awesome. Formal Model \ud835\udf03 Data\nLearning Algorithm\nEvaluation\nTesting\nPrediction\nscore\nData \"\nFunction \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nSupervised learning\nReal World Problem\nParameter estimation\nis a basis for learning Model the problem\nfrom data.\nTraining\nFormal Model \ud835\udf03 Data\nTraining\nLearning Algorithm\nEvaluation\nTesting\nPrediction\nscore\nData \"\nFunction \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nModel and dataset\nMany different forms of machine learning\n\u2022 We focus on one specific type: prediction from past observations.\nGoal Based on observed \ud835\udc7f, predict some unknown \ud835\udc4c\n\u2022 Features Vector \ud835\udc7f of \ud835\udc5a observations (new term: feature vector)\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" #\n\u2022 Output Variable \ud835\udc4c (also called class label if discrete)\n(\nModel \ud835\udc4c = \ud835\udc54 \ud835\udc7f , a function on \ud835\udc7f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nTraining data\n\u2026\nFeature 1 Feature 2 Feature 300 Output\nPatient 1 1 0 \u2026 1 1\nPatient 2 1 1 \u2026 0 0\n\u2026\nPatient \ud835\udc5b 0 0 \u2026 1 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # #$$\nTraining data notation\n! ! \" \" $ $\n\ud835\udc99 , \ud835\udc66 , \ud835\udc99 , \ud835\udc66 , \u2026, \ud835\udc99 , \ud835\udc66\n\ud835\udc5b datapoints, assumed to be iid\n% %\n\ud835\udc56\u2013th datapoint \ud835\udc99 , \ud835\udc66 :\n% % %\n%\n\u2022 \ud835\udc5a features: \ud835\udc99 = \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65\n! \" #\n%\n\u2022 A single output \ud835\udc66\n\u2022 Independent of all other datapoints\nUse these \ud835\udc5b datapoints to learn a\nTraining Goal:\n(\nmodel \ud835\udc4c = \ud835\udc54 \ud835\udc7f that predicts \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nSupervised learning\nReal World Problem\nModel the problem\nTraining\nFormal Model \ud835\udf03 Data\nLearning Algorithm\nEvaluation\nTesting\nPrediction\nTesting\nscore\nData \"\nFunction \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nTesting data notation\n! ! \" \" $ $\n\ud835\udc99 , \ud835\udc66 , \ud835\udc99 , \ud835\udc66 , \u2026, \ud835\udc99 , \ud835\udc66\n\ud835\udc5b other datapoints, assumed to be iid\n&\u2019(&\n&) % %\n\ud835\udc56 datapoint \ud835\udc99 , \ud835\udc66 :\n\u2022 Has the same structure as your training data\n(\nLeveraging the model \ud835\udc4c = \ud835\udc54 \ud835\udc7f that you trained,\nTesting Goal:\nsee how well you can predict \ud835\udc4c on known data\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nTwo tasks we will focus on\nMany different forms of machine learning\n\u2022 We focus on the problem of prediction based on observations.\nGoal Based on observed \ud835\udc7f, predict some unknown \ud835\udc4c\n\u2022 Features Vector \ud835\udc7f of \ud835\udc5a observations (new term: feature vector)\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" #\n\u2022 Output Variable \ud835\udc4c (also called class label if discrete)\n(\nModel \ud835\udc4c = \ud835\udc54 \ud835\udc7f , a function on \ud835\udc7f\n\u2022 Regression prediction when \ud835\udc4c is continuous\n\u2022 Classification prediction when \ud835\udc4c is discrete\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nRegression: Predicting real numbers\nTraining data: \ud835\udc99 \u2019 , \ud835\udc66 \u2019 , \ud835\udc99 $ , \ud835\udc66 $ , \u2026, \ud835\udc99 ( , \ud835\udc66 (\n\u2026\nCO2 levels Output\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n\u2026 \u2026\nGlobal Land-Ocean\ntemperature\nSea\nFeature \ud835\udc5a\nlevel\nYear 1 338.8 0 \u2026 1 0.26\nYear 2 340.0 1 \u2026 0 0.32\n\u2026\nYear \ud835\udc5b 340.76 0 \u2026 1 0.14\nClassification: Predicting class labels\n\u2026\nFeature 1 Feature 2 Feature 300 Output\nPatient 1 1 0 \u2026 1 1\nPatient 2 1 1 \u2026 0 0\n\u2026\nPatient \ud835\udc5b 0 0 \u2026 1 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # #$$\nBrute Force Bayes\n17\nClassification: Healthy hearts\nSingle feature: Region of Interest (ROI) is\nhealthy (1) or unhealthy (0)\nFeature 1 Output\nHow can we predict whether\nPatient 1 1 0\nheart is healthy (1) or not (0)?\nPatient 2 1 1\nPatient \ud835\udc5b 0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b\n!\nThe following strategy is not used in practice but\nhelps us understand how to approach classification.\nClassification: Brute Force Bayes\nOur prediction for \ud835\udc4c\n(\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f\nis a function of \ud835\udc7f\n= arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f Proposed model: Choose the \ud835\udc4c that is\n*+ ,,! more or most likely given \ud835\udc7f\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n= arg max (Bayes\u2019 Theorem)\n\ud835\udc43 \ud835\udc7f\n*+ ,,!\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c (1/\ud835\udc43 \ud835\udc7f is constant wrt \ud835\udc66)\n*+ ,,!\nIf we estimate \ud835\udc43 \ud835\udc7f|\ud835\udc4c and \ud835\udc43 \ud835\udc4c , we can classify data points.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nTraining: Estimate parameters\nFeature 1 Output\nPatient 1 1 0\nPatient 2 1 1\nPatient \ud835\udc5b 0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b\n! ( ( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n*+ ,,!\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\nConditional\n\ud835\udc4b = 0 \ud835\udf03 \ud835\udf03\nprobability \u2019 \u2019 )\ntables \ud835\udc431 \ud835\udc7f|\ud835\udc4c \ud835\udc4b = 1 \ud835\udf03 \ud835\udf03\n\u2019 $ *\n1\n\ud835\udc43 \ud835\udc4c\nMarginal\n\ud835\udc4c = 0 \ud835\udf03\nprobability +\ntable \ud835\udc431 \ud835\udc4c \ud835\udc4c = 1 \ud835\udf03 ,\nUse \ud835\udc5b datapoints to learn\nTraining\n2 \u22c5 2 + 2 = 6 parameters.\nGoal:\n!\nTraining: Estimate parameters \ud835\udc43 \ud835\udc7f|\ud835\udc4c\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\n\ud835\udc4b = 0 \ud835\udf03 \ud835\udf03\n\u2019 \u2019 )\n\ud835\udc4b = 1 \ud835\udf03 \ud835\udf03\n\u2019 $ *\nFeature 1 Output\nPatient 1 1 0\n\ud835\udc7f|\ud835\udc4c = 0 and \ud835\udc7f|\ud835\udc4c = 1\nPatient 2 1 1 are each multinomials with 2 outcomes!\nPatient \ud835\udc5b 0 1\nUse MLE or Laplace (MAP) estimate\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c and \ud835\udc43 \ud835\udc4c as parameters.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\u2026 \u2026\nCount: # datapoints\n\ud835\udc4b = 0, Y = 0: 4\n\u2019\n\ud835\udc4b = 1, Y = 0: 6\n\u2019\n\ud835\udc4b = 0, Y = 1: 0\n\u2019\n\ud835\udc4b = 1, Y = 1: 100\n\u2019\nTotal: 110\n!\nTraining: MLE estimates, \ud835\udc43 \ud835\udc7f|\ud835\udc4c\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\n\ud835\udc4b = 0 0.4 0.0\n\u2019\n\ud835\udc4b = 1 0.6 1.0\n\u2019\n# \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\nE\nL 1 \u2019\nM MLE of \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 =\n\u2019\n# \ud835\udc4c = \ud835\udc66\nJust count!\nFeature 1 Output\nPatient 1 1 0\nPatient 2 1 1\nPatient \ud835\udc5b 0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\u2026 \u2026\nCount: # datapoints\n\ud835\udc4b = 0, Y = 0: 4\n\u2019\n\ud835\udc4b = 1, Y = 0: 6\n\u2019\n\ud835\udc4b = 0, Y = 1: 0\n\u2019\n\ud835\udc4b = 1, Y = 1: 100\n\u2019\nTotal: 110\n!\nTraining: Laplace (MAP) estimates, \ud835\udc43 \ud835\udc7f|\ud835\udc4c\nFeature 1 Output\nPatient 1 1 0\nPatient 2 1 1\nPatient \ud835\udc5b 0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n\u2026 \u2026\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\n\ud835\udc4b = 0 0.4 0.0\n\u2019\n\ud835\udc4b = 1 0.6 1.0\n\u2019\n# \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\nE\nL 1 \u2019\nM MLE of \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 =\n\u2019\nCount: # datapoints # \ud835\udc4c = \ud835\udc66\nJust count!\n\ud835\udc4b = 0, Y = 0: 4\n\u2019\n\ud835\udc4b = 1, Y = 0: 6\n\u2019\n\ud835\udc4b = 0, Y = 1: 0\n\u2019 M A\nP\n\ud835\udc4b = 1, Y = 1: 100\n\u2019\nTotal: 110\n1\nLaplace of \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 = ?\n\u2019\nJust count + add imaginary trials!\n!\nTraining: Laplace (MAP) estimates, \ud835\udc43 \ud835\udc7f|\ud835\udc4c\nFeature 1 Output\nPatient 1 1 0\nPatient 2 1 1\nPatient \ud835\udc5b 0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n\u2026 \u2026\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\n\ud835\udc4b = 0 0.4 0.0\n\u2019\n\ud835\udc4b = 1 0.6 1.0\n\u2019\n# \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\nE\nL 1 \u2019\nM MLE of \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 =\n\u2019\nCount: # datapoints # \ud835\udc4c = \ud835\udc66\nJust count!\n\ud835\udc4b = 0, Y = 0: 4\n\u2019\n\ud835\udc4b = 1, Y = 0: 6\n\u2019\n1 1\n\ud835\udc4b = 0, Y = 1: 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc7f|\ud835\udc4c = 1\n\u2019 M A\nP\n\ud835\udc4b = 1, Y = 1: 100 \ud835\udc4b = 0 0.42 0.01\n\u2019 \u2019\nTotal: 110\n\ud835\udc4b = 1 0.58 0.99\n\u2019\n# \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66 + 1\n\u2019\n1\nLaplace of \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 =\n\u2019\n# \ud835\udc4c = \ud835\udc66 + 2\nJust count + add imaginary trials!\nTesting\n( ( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n*+ ,,!\n(MAP) \ud835\udc431 \ud835\udc7f|\ud835\udc4c = 0 \ud835\udc431 \ud835\udc7f|\ud835\udc4c = 1 (MLE) \ud835\udc431 \ud835\udc4c\n\ud835\udc4b = 0 0.42 0.01 \ud835\udc4c = 0 0.09\n\u2019\n\ud835\udc4b = 1 0.58 0.99 \ud835\udc4c = 1 0.91\n\u2019\n(\nNew patient has a healthy ROI (\ud835\udc4b = 1). What is your prediction, \ud835\udc4c?\n!\n( (\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 \ud835\udc43 \ud835\udc4c = 0 = 0.58 \u22c5 0.09 \u2248 0.052\n!\n( (\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 \ud835\udc43 \ud835\udc4c = 1 = 0.99 \u22c5 0.91 \u2248 0.901\n!\n(\nA. 0.052 < 0.5 \u21d2 \ud835\udc4c = 1\n(\nB. 0.901 > 0.5 \u21d2 \ud835\udc4c = 1\n(\nC. 0.052 < 0.901 \u21d2 \ud835\udc4c = 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nBrute Force Bayes classifier\n( ( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c (\ud835\udc431 \ud835\udc4c is an estimate of \ud835\udc43 \ud835\udc4c ,\n*+ ,,! 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c is an estimate of \ud835\udc43 \ud835\udc7f|\ud835\udc4c )\nEstimate these\n(\n\ud835\udc43 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udc4c = 1\n! \" #\nprobabilities\u2014i.e.,\n(\nTraining \ud835\udc43 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udc4c = 0\n! \" #\nlearn these parameters\n( (\n\ud835\udc43 \ud835\udc4c = 1 \ud835\udc43 \ud835\udc4c = 0\nusing MLE or Laplace (MAP)\nGiven an observation \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , predict\n! \" #\nTesting\n( ( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n! \" #\n*+ ,,!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 2266\nNa\u00efve Bayes\n27\nBrute Force Bayes: \ud835\udc5a = 300 (# features)\n\u2026\nFeature 1 Feature 2 Feature 300 Output\nPatient 1 1 0 \u2026 1 1\nPatient 2 1 1 \u2026 0 0\n\u2026\nPatient \ud835\udc5b 0 0 \u2026 1 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # #$$\nThis won\u2019t be\ntoo bad, right?\nBrute Force Bayes: \ud835\udc5a = 300 (# features)\n\u2026\nFeature 1 Feature 2 Feature 300 Output\nPatient 1 1 0 \u2026 1 1\nPatient 2 1 1 \u2026 0 0\n\u2026\nPatient \ud835\udc5b 0 0 \u2026 1 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n\u2026 \u2026\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # #$$\nCount: # datapoints\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 0, \ud835\udc4b = 0, Y = 0: 0\n\u2019 $ $-- )..\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 0, \ud835\udc4b = 1, Y = 0: 0\n\u2019 $ $-- )..\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 1, \ud835\udc4b = 0, Y = 0: 1\n\u2019 $ $-- )..\n\u2026\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 0, \ud835\udc4b = 0, Y = 1: 2\n\u2019 $ $-- )..\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 0, \ud835\udc4b = 1, Y = 1: 1\n\u2019 $ $-- )..\n\ud835\udc4b = 0, \ud835\udc4b = 0, \u2026, \ud835\udc4b = 1, \ud835\udc4b = 0, Y = 1: 1\n\u2019 $ $-- )..\nThis won\u2019t be\ntoo bad, right?\nBrute Force Bayes: \ud835\udc5a = 300 (# features)\n1\n\u2022 \ud835\udc43 \ud835\udc4c = 1 | \ud835\udc99 : estimated probability a\n( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f heart is healthy given \ud835\udc99\n*+ ,,!\n\u2022 \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b : whether 300\n\u2019 $ )..\nregions of interest (ROI) are healthy (1)\nor unhealthy (0)\n( (\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n= arg max\n( How many parameters do we\n\ud835\udc43 \ud835\udc7f\n*+ ,,!\nhave to learn?\n( (\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n*+ ,,!\nA. 2 \u22c5 2 + 2 = 6\nLearn parameters B. 2 \u22c5 300 + 2 = 602\nthrough MLE or MAP 4,,\nC. 2 \u22c5 2 + 2 = a lot\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nBrute Force Bayes: \ud835\udc5a = 300 (# features)\n1\n\u2022 \ud835\udc43 \ud835\udc4c = 1 | \ud835\udc99 : estimated probability a\n( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f heart is healthy given \ud835\udc99\n*+ ,,!\n\u2022 \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b : whether 300\n\u2019 $ )..\nregions of interest (ROI) are healthy (1)\nor unhealthy (0)\n( (\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n= arg max\n( How many parameters do we\n\ud835\udc43 \ud835\udc7f\n*+ ,,!\nhave to learn?\n( (\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n1 1\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n*+ ,,!\nA. 2 \u22c5 2 + 2 = 6\nLearn parameters B. 2 \u22c5 300 + 2 = 602\nthrough MLE or MAP 4,,\nC. 2 \u22c5 2 + 2 = a lot\nThis approach requires you to learn\n\ud835\udc42 2/ parameters.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nThe problem with our current classifier\nChoose the \ud835\udc4c that is\n( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\nmost likely given \ud835\udc7f\n*+ ,,!\n( (\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n(Bayes\u2019 Theorem)\n= arg max\n(\n\ud835\udc43 \ud835\udc7f\n*+ ,,!\n( (\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c (1/\ud835\udc43 \ud835\udc7f is constant w.r.t. \ud835\udc66)\n*+ ,,!\nEstimating this joint conditional\n(\n\ud835\udc43 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udc4c\n! \" # distribution is intractable.\nWhat if we could make a simplifying assumption\u2014even if incredibly na\u00efve\u2014\nto make our parameter estimation effort computationally tractable?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nThe Na\u00efve Bayes assumption\n( (\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\nAssumption:\n*+ ,,!\n\ud835\udc4b , \u2026 , \ud835\udc4b are all conditionally\n! %\n( ( independent given \ud835\udc4c.\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n= arg max\n(\n\ud835\udc43 \ud835\udc7f\n*+ ,,!\n( (\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n*+ ,,!\n#\nNa\u00efve Bayes\n( (\n= arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\nAssumption\n5\n*+ ,,!\n5+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nNa\u00efve Bayes Classifier\n#\n( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\nWhat is the Big-O of # of\nTraining parameters we need to learn?\nA. \ud835\udc42 \ud835\udc5a\n#\nB. \ud835\udc42 2\nC. other\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3344\nNa\u00efve Bayes Classifier\n#\n( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\n(\nfor \ud835\udc57 = 1, \u2026 , \ud835\udc5a: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 ,\n5\nUse MLE or\nTraining (\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1\n5 Laplace (MAP)\n(\n\ud835\udc43 \ud835\udc4c = 1\n#\nTesting ( ( (\n\ud835\udc4c = arg max log \ud835\udc43 \ud835\udc4c + M log \ud835\udc43 \ud835\udc4b |\ud835\udc4c\n5\n*+ ,,!\n5+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3355\nand Learn\n%\nA. \ud835\udc99\nClassification terminology check\n%\nB. \ud835\udc66\n% %\nTraining data: \ud835\udc99 \u2019 , \ud835\udc66 \u2019 , \ud835\udc99 $ , \ud835\udc66 $ , \u2026, \ud835\udc99 ( , \ud835\udc66 ( C. \ud835\udc99 , \ud835\udc66\n%\nD. \ud835\udc65\n5\n\u2026\nMovie 1 Movie 2 Movie \ud835\udc5a Output\nUser 1 1. 1 0 \u2026 1 2. 1\nUser 2 3. 1 1 \u2026 0 0\n\u2026\nUser \ud835\udc5b 0 0 \u2026 1 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\n\u2026 \u2026\n1: like movie\n0: dislike movie\n4.\nPredicting user TV preferences\nWill a user like the Pok\u00e9mon TV series?\nObserve indicator variables \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : Output \ud835\udc4c indicator:\n! \"\n\ud835\udc4b = 1: \ud835\udc4b = 1: \ud835\udc4c = 1:\n! \"\n\"likes Star Wars\" \"likes Harry Potter\" \"likes Pok\u00e9mon\"\n( (\nPredict \ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\n*+ ,,!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\n\ud835\udc4c6 = arg max\ud835\udc436 \ud835\udc7f|\ud835\udc4c \ud835\udc436 \ud835\udc4c\nPredicting user TV preferences\n!\" #,%\n$\nNa\u00efve Bayes\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = 5\ud835\udc43 \ud835\udc4b |\ud835\udc4c\nWhich probabilities do you need to estimate? !\nAssumption\n!\"#\nHow many are there?\n\u2022 Brute Force Bayes\n(strawman, without NB assumption)\n\u2022 Na\u00efve Bayes\nDuring training, how to estimate the prob\n(\n\ud835\udc43 \ud835\udc4b = 1, \ud835\udc4b = 1|\ud835\udc4c = 0 with MLE? with Laplace?\n! \"\n\u2022 Brute Force Bayes \u2022 Na\u00efve Bayes\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nEx 1. Na\u00efve Bayes Classifier (MLE)\n#\n( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\n( (\n\u2200\ud835\udc56: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 , Use MLE or\n5 5\nTraining ( ( Laplace (MAP)\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 ,\n5 5\n( (\n\ud835\udc43 \ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4c = 0\n#\nTesting ( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4400\nTraining: Na\u00efve Bayes for TV shows (MLE)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 $\n0 1 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 3 10 0 5 8\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 4 13 1 7 10\nTraining data counts\n1. How many datapoints (\ud835\udc5b)\nare in our training data?\n2. Compute MLE estimates\n\ud835\udc4b\n\u2019\n0 1\n(\nfor \ud835\udc43 \ud835\udc4b |\ud835\udc4c : \ud835\udc4c\n!\n0 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 0 \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 0\n\u2019 \u2019\n1 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 1 \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 1\n\u2019 \u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nTraining: Na\u00efve Bayes for TV shows (MLE)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 $\n0 1 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 3 10 0 5 8\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 4 13 1 7 10\nTraining data counts\n1. How many datapoints (\ud835\udc5b)\nare in our training data?\n2. Compute MLE estimates\n\ud835\udc4b\n\u2019\n0 1\n(\nfor \ud835\udc43 \ud835\udc4b |\ud835\udc4c : \ud835\udc4c\n!\n0 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 0 \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 0\n\u2019 \u2019\n1 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 1 \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 1\n\u2019 \u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nTraining: Na\u00efve Bayes for TV shows (MLE)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 $\n0 1 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 3 10 0 5 8 0 13\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 4 13 1 7 10 1 17\nTraining data counts\n\ud835\udc4b \ud835\udc4b\n\u2019 $\n0 1 0 1\n\ud835\udc4c \ud835\udc4c \ud835\udc4c\n0 0.23 0.77 0 5/13 \u2248 0.38 8/13 \u2248 0.62 0 13/30 \u2248 0.43\n1 0.24 0.76 1 7/17 \u2248 0.41 10/17 \u2248 0.59 1 17/30 \u2248 0.57\n(from last slide)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nTraining: Na\u00efve Bayes for TV shows (MLE)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 0 1 $ 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 0.23 0.77 0 0.38 0.62 0 0.43\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 0.24 0.76 1 0.41 0.59 1 0.57\nNow that we\u2019ve trained and found parameters,\nIt\u2019s time to classify new users!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nEx 1. Na\u00efve Bayes Classifier (MLE)\n#\n( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\n( (\n\u2200\ud835\udc56: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 , Use MLE or\n5 5\nTraining ( ( Laplace (MAP)\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 ,\n5 5\n( (\n\ud835\udc43 \ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4c = 0\n#\nTesting ( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4455\nTesting: Na\u00efve Bayes for TV shows (MLE)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 0 1 $ 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 0.23 0.77 0 0.38 0.62 0 0.43\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 0.24 0.76 1 0.41 0.59 1 0.57\nSuppose a new person \u201clikes Star Wars\u201d (\ud835\udc4b = 1) but \u201cdislikes Harry Potter\u201d (\ud835\udc4b = 0).\n\u2019 $\nWill they like Pokemon? Need to predict \ud835\udc4c:\n1 1 1 1 1 1\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c = arg max \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n\u2019 $\n78 .,\u2019 78 .,\u2019\nIf \ud835\udc4c = 0: \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 0 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 0 \ud835\udc431 \ud835\udc4c = 0 = 0.77 \u22c5 0.38 \u22c5 0.43 = 0.126\n\u2019 $\nIf \ud835\udc4c = 1: \ud835\udc431 \ud835\udc4b = 1|\ud835\udc4c = 1 \ud835\udc431 \ud835\udc4b = 0|\ud835\udc4c = 1 \ud835\udc431 \ud835\udc4c = 1 = 0.76 \u22c5 0.41 \u22c5 0.57 = 0.178\n\u2019 $\n1\nSince term is greatest when Y = 1, predict \ud835\udc4c = 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nEx 2. Na\u00efve Bayes Classifier (MAP)\n#\n( ( (\n\ud835\udc4c = arg max H \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n5\n*+ ,,!\n5+!\n( (\n\u2200\ud835\udc56: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 , Use MLE or\n5 5\nTraining ( ( Laplace (MAP)\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 ,\n5 5\n( (\n\ud835\udc43 \ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4c = 0\n#\nTesting \ud835\udc4c( = arg max H \ud835\udc43( \ud835\udc4b |\ud835\udc4c \ud835\udc43( \ud835\udc4c (note the same as before)\n5\n*+ ,,!\n5+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4477\nTraining: Na\u00efve Bayes for TV shows (MAP)\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 $\n0 1 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 3 10 0 5 8\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 4 13 1 7 10\nTraining data counts\n1\n\ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 :\n:\n,\n# @ +A B+*\n!\nA.\nWhat are our MAP estimates\n# B+*\nusing Laplace smoothing ,\n# @ +A B+* C!\n!\nB.\n(\nfor \ud835\udc43 \ud835\udc4b |\ud835\udc4c ?\n5 # B+* C\"\n,\n# @ +A B+* C!\n!\nC.\n# B+* CD\nD. other\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\n\u2019\nTraining: Na\u00efve Bayes for TV shows (MAP) \ud835\udc4c\" = arg max +\ud835\udc43\" \ud835\udc4b |\ud835\udc4c \ud835\udc43\" \ud835\udc4c\n&\n!\" #,%\n&\"%\nObserve indicator vars. \ud835\udc7f = \ud835\udc4b , \ud835\udc4b : \ud835\udc4b \ud835\udc4b\n\u2019 $ \u2019 $\n0 1 0 1\n\u2022 \ud835\udc4b : \u201clikes Star Wars\u201d \ud835\udc4c \ud835\udc4c \ud835\udc4c\n\u2019\n\u2022 \ud835\udc4b : \u201clikes Harry Potter\u201d 0 3 10 0 5 8 0 13\n$\nPredict \ud835\udc4c: \u201clikes Pok\u00e9mon\u201d 1 4 13 1 7 10 1 17\nTraining data counts\n\ud835\udc4b \ud835\udc4b\n\u2019 $\n0 1 0 1\n\ud835\udc4c \ud835\udc4c\n0 0.27 0.73 0 0.40 0.60\nIn practice:\n1 0.26 0.74 1 0.42 0.58 \u2022 We use Laplace for \ud835\udc43! \ud835\udc4b |\ud835\udc4c in case\n&\nsome events \ud835\udc4b = \ud835\udc65 don\u2019t appear\n& &\n\u2022 We don\u2019t use Laplace for \ud835\udc43! \ud835\udc4c ,\nbecause all class labels should\nappear reasonably often\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 49 <END>"}
{"prompt": "Lecture notes from 11_joint_rvs_annotated.txt\n\n###\n\n", "completion": "11: Joint (Multivariate)\nDistributions\nJerry Cain\nApril 24th, 2024\nLecture Discussion on Ed\n1\nNormal\nApproximation\n2\nNormal Random Variables\nmean variance\n!\n\ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e )\n\u2022 Used to model many real-life situations because it maximizes entropy\n(i.e., randomness) for a given mean and variance.\n\u2022 Also useful for approximating the Binomial random variable!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nWebsite testing\n\u2022 100 people are presented with a new website design.\n\u2022 \ud835\udc4b = # people whose time on site increases\n\u2022 PM assumes design has no effect, so assume P(stickier) = 0.5 independently.\n\u2022 CEO will endorse the new design if \ud835\udc4b \u2265 65.\nWhat is \ud835\udc43 CEO endorses change ? Give a numerical approximation.\nApproach 1: Binomial\nDefine\n\ud835\udc4b~Bin \ud835\udc5b = 100, \ud835\udc5d = 0.5\nWant: \ud835\udc43 \ud835\udc4b \u2265 65\nSolve %&&\n100\n! %&&\u2019!\n\ud835\udc43 \ud835\udc4b \u2265 65 = . 0.5 1 \u2212 0.5\n\ud835\udc58\n!\"#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nDon\u2019t worry, Normal approximates Binomial\nGalton Board\n(We\u2019ll explain why in 2 weeks)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\njerry$ python\nWebsite testing\n>>> from scipy.stats import binom, norm\n>>> binom.pmf(range(65, 101), n, p).sum()\n0.001758820861485058\n\u2022 100 people are given a new website design. >>> 1 - norm(50, 5).cdf(65)\n0.0013498980316301035\n\u2022 \ud835\udc4b = # people whose time on site increases\n\u2022 PM assumes design has no effect, so P(stickier) = 0.5 independently.\n\u2022 CEO will endorse the new design if \ud835\udc4b \u2265 65.\nWhat is \ud835\udc43 CEO endorses change ? Give a numerical approximation.\nApproach 1: Binomial Approach 2: approximate with Normal\nDefine Define\n\ud835\udf07 = \ud835\udc5b\ud835\udc5d = 50\n\ud835\udc4b~Bin \ud835\udc5b = 100, \ud835\udc5d = 0.5 \ud835\udc4c~\ud835\udca9 \ud835\udf07, \ud835\udf0e( \ud835\udf0e! = \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d = 25\n\ud835\udf0e = 25 = 5\nWant: \ud835\udc43 \ud835\udc4b \u2265 65\nSolve\nSolve\n\ud835\udc43 \ud835\udc4b \u2265 65 \u2248 \ud835\udc43 \ud835\udc4c \u2265 65 = 1 \u2212 \ud835\udc39 (65) \ud83e\udd28\n\"\n\ud835\udc43 \ud835\udc4b \u2265 65 \u2248 0.0018\n#$%$&\n= 1 \u2212 \u03a6 = 1 \u2212 \u03a6 3 \u2248 0.0013 ?\n$\n\u26a0 \u26a0 (this approach is missing something important)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nWebsite testing (with continuity correction)\nIn our website testing, \ud835\udc4c~\ud835\udca9 50, 25 approximates \ud835\udc4b~Bin 100,0.5 .\n65\n\ud835\udc43 \ud835\udc4b \u2265 65\nBinomial\n\u2248 \ud835\udc43 \ud835\udc4c \u2265 64.5\nNormal\n64 65 66\n\u2248 0.0018 \u2705 You must perform a continuity correction when\nthe better\napproximating a Binomial RV with a Normal RV.\nApproach 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nContinuity correction\nIf \ud835\udc4c~\ud835\udca9 \ud835\udc5b\ud835\udc5d, \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d) approximates \ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d), how do we approximate\nthe following probabilities?\nDiscrete (e.g., Binomial) Continuous (Normal)\nprobability question probability question\n\ud835\udc43 \ud835\udc4b = 6\n\ud835\udc43 \ud835\udc4b \u2265 6\n\ud835\udc43 \ud835\udc4b > 6\n\u2026 5 6 7 \u2026\n\ud835\udc43 \ud835\udc4b < 6\n\ud835\udc43 \ud835\udc4b \u2264 6\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nContinuity correction\nIf \ud835\udc4c~\ud835\udca9 \ud835\udc5b\ud835\udc5d, \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d) approximates \ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d), how do we approximate\nthe following probabilities?\nDiscrete (e.g., Binomial) Continuous (Normal)\nprobability question probability question\n\ud835\udc43 \ud835\udc4b = 6 \ud835\udc43 5.5 \u2264 \ud835\udc4c \u2264 6.5\n\ud835\udc43 \ud835\udc4b \u2265 6 \ud835\udc43 \ud835\udc4c \u2265 5.5\n\ud835\udc43 \ud835\udc4b > 6 \ud835\udc43 \ud835\udc4c \u2265 6.5\n\ud835\udc43 \ud835\udc4c \u2264 5.5 \u2026 5 6 7 \u2026\n\ud835\udc43 \ud835\udc4b < 6\n\ud835\udc43 \ud835\udc4c \u2264 6.5\n\ud835\udc43 \ud835\udc4b \u2264 6\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nWho gets to approximate?\n\ud835\udc4b~Bin \ud835\udc5b, \ud835\udc5d\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nVar \ud835\udc4b = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\n?\n!\n\ud835\udc4c~Poi(\ud835\udf06) \ud835\udc4c~\ud835\udca9 \ud835\udf07, \ud835\udf0e\n\ud835\udf06 = \ud835\udc5b\ud835\udc5d \ud835\udf07 = \ud835\udc5b\ud835\udc5d\n(\n\ud835\udf0e = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nWho gets to approximate?\n0.25\n0.2\n0.15\n0.1\n0.05\n0\n0 10\nPoisson approximation Normal approximation\n\ud835\udc5b large (> 20), \ud835\udc5d small (< 0.05) \ud835\udc5b large (> 20), \ud835\udc5d mid-ranged (\ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d > 10)\nslight dependence okay independence\n1. If there is a choice, use Gaussian to approximate.\n2. When using Normal to approximate a discrete RV, use a continuity correction.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n)#\n=\n\"(!\n0.09\n0.08\nBin(100,0.04)\n0.07\nN(4,1.96)\n0.06\nPoi(4)\n0.05\n0.04\n0.03\n0.02\n0.01\n0\n30 40 50 60 70\n$\n)#\n=\n\"(!\nBin(100,0.5)\nN(50,5)\nPoi(50)\n$\nStanford Admissions (a while back)\nStanford accepts 2480 students.\n\u2022 Each admitted student matriculates with p = 0.68 (independently)\n\u2022 Let \ud835\udc4b = # of students who will attend\nWhat is \ud835\udc43 \ud835\udc4b > 1745 ? Give a numerical approximation.\nStrategy: A. Just Binomial\nB. Poisson\nC. Normal\nD. None/other\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nStanford Admissions (a while back)\nStanford accepts 2480 students.\n\u2022 Each admitted student matriculates with p = 0.68 (independently)\n\u2022 Let \ud835\udc4b = # of students who will attend\nWhat is \ud835\udc43 \ud835\udc4b > 1745 ? Give a numerical approximation.\nStrategy: A. Just Binomial computationally expensive (also not an approximation)\nB. Poisson \ud835\udc5d = 0.68, not small enough\nC. Normal\n\u2705 Variance \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d = 540 > 10\nD. None/other\nDefine an approximation Solve\nLet \ud835\udc4c~\ud835\udca9 \ud835\udc38 \ud835\udc4b , Var \ud835\udc4b \ud835\udc43 \ud835\udc4c \u2265 1745.5 = 1 \u2212 \ud835\udc39 1745.5\n1745.5 \u2212 1686\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d = 1686\n= 1 \u2212 \u03a6\nVar \ud835\udc4b = \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d \u2248 540 \u2192 \ud835\udf0e = 23.3 23.3\n\ud835\udc43 \ud835\udc4b > 1745 \u2248 \ud835\udc43 \ud835\udc4c \u2265 1745.5 \u26a0 Continuity = 1 \u2212 \u03a6 2.54 \u2248 0.0055\ncorrection\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nDiscrete Joint\nRVs\n14\nFrom last slide deck Review\n\ud835\udc43 \ud835\udc34 > \ud835\udc34\n! \"\nThis is a probability of an event\ninvolving two random variables!\nWhat is the probability that the Warriors win?\nHow do you model zero-sum games?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nJoint probability mass functions\nRoll two 6-sided dice, yielding values \ud835\udc4b and \ud835\udc4c.\n\ud835\udc43 \ud835\udc4b = 1\n\ud835\udc4b \ud835\udc43 \ud835\udc4b = \ud835\udc58\nprobability of\nrandom variable probability mass function\nan event\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nJoint probability mass functions\nRoll two 6-sided dice, yielding values \ud835\udc4b and \ud835\udc4c.\n\ud835\udc43 \ud835\udc4b = 1\n\ud835\udc4b \ud835\udc43 \ud835\udc4b = \ud835\udc58\nprobability of\nrandom variable probability mass function\nan event\n\ud835\udc4b, \ud835\udc4c \ud835\udc43 \ud835\udc4b = 1 \u2229 \ud835\udc4c = 6\n\ud835\udc43 \ud835\udc4b = \ud835\udc4e, \ud835\udc4c = \ud835\udc4f\nrandom variables \ud835\udc43 \ud835\udc4b = 1, \ud835\udc4c = 6\nnew notation: the comma\nprobability of the intersection joint probability mass function\nof two events\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nDiscrete joint distributions\nFor two discrete joint random variables \ud835\udc4b and \ud835\udc4c,\nthe joint probability mass function is defined as:\n\ud835\udc5d \ud835\udc4e, \ud835\udc4f = \ud835\udc43 \ud835\udc4b = \ud835\udc4e, \ud835\udc4c = \ud835\udc4f\n!,#\nThe marginal distributions of the joint PMF are defined as:\n\ud835\udc5d \ud835\udc4e = \ud835\udc43 \ud835\udc4b = \ud835\udc4e = . \ud835\udc5d \ud835\udc4e, \ud835\udc66\n5 5,8\n6\n\ud835\udc5d \ud835\udc4f = \ud835\udc43 \ud835\udc4c = \ud835\udc4f = . \ud835\udc5d \ud835\udc65, \ud835\udc4f Use marginal distributions to\n8 5,8\nextract a 1D RV from a joint PMF.\n9\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nTwo dice\nRoll two 6-sided dice, yielding values \ud835\udc4b and \ud835\udc4c.\n1. What is the joint PMF of \ud835\udc4b and \ud835\udc4c?\n\ud835\udc5d \ud835\udc4e, \ud835\udc4f = 1/36 \ud835\udc4e, \ud835\udc4f \u2208 1,1 , \u2026 , 6,6\n5,8\n\ud835\udc4b\n1 2 3 4 5 6\n1 1/36 ... ... ... ... 1/36\n\ud835\udc43 \ud835\udc4b = 4, \ud835\udc4c = 3\n2 ... ... ... ... ... ...\nProbability table\n3 ... ... ... ... ... ...\n\u2022 All possible outcomes\n\ud835\udc4c\n4 ... ... ... ... ... ... for several discrete RVs\n\u2022 Not parametric (e.g.,\n5 ... ... ... ... ... ...\nparameter \ud835\udc5d in Ber(\ud835\udc5d))\n6 1/36 ... ... ... ... 1/36\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nTwo dice\nRoll two 6-sided dice, yielding values \ud835\udc4b and \ud835\udc4c.\n1. What is the joint PMF of \ud835\udc4b and \ud835\udc4c?\n\ud835\udc5d \ud835\udc4e, \ud835\udc4f = 1/36 \ud835\udc4e, \ud835\udc4f \u2208 1,1 , \u2026 , 6,6\n5,8\n2. What is the marginal PMF of \ud835\udc4b?\n#\n1 1\n\ud835\udc5d \ud835\udc4e = \ud835\udc43 \ud835\udc4b = \ud835\udc4e = D \ud835\udc5d \ud835\udc4e, \ud835\udc66 = D = \ud835\udc4e \u2208 1, \u2026 , 6\n) ),\"\n36 6\n* *,-\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nA computer (or three) in every house.\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 ? .07 .04\n1 .12 .14 .12 0\n2 .07 .12 0 0\n3 .04 0 0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n)sCP\n#(\n\ud835\udc4c\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n1. What is \ud835\udc43 \ud835\udc4b = 1, \ud835\udc4c = 0 , the missing entry in the probability table?\nA computer (or three) in every house.\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n1. What is \ud835\udc43 \ud835\udc4b = 1, \ud835\udc4c = 0 , the missing entry in the probability table?\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 .12 .07 .04\n1 .12 .14 .12 0\n2 .07 .12 0 0\n3 .04 0 0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n)sCP\n#(\n\ud835\udc4c\nA joint PMF must sum to 1:\nD D \ud835\udc5d \ud835\udc65, \ud835\udc66 = 1\n),\"\n. *\nA computer (or three) in every house.\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 .12 .07 .04 .39\n1 .12 .14 .12 0 .38\n2 .07 .12 0 0 .19\n3 .04 0 0 0 .04\n.39 .38 .19 .04\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n)sCP\n#(\n\ud835\udc4c\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n2. How do you compute the marginal PMF of \ud835\udc4b?\nA\nC\nB\nsum cols here\nereh\nswor\nmus\nA computer (or three) in every house.\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 .12 .07 .04 .39\n1 .12 .14 .12 0 .38\n2 .07 .12 0 0 .19\n3 .04 0 0 0 .04\n.39 .38 .19 .04\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n)sCP\n#(\n\ud835\udc4c\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n2. How do you compute the marginal PMF of \ud835\udc4b?\nA\nC\nB\nsum cols here\nereh\nswor\nmus\nA. \ud835\udc5d \ud835\udc65, 0 = \ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = 0\n),\"\nB. Marginal PMF of \ud835\udc4b \ud835\udc5d \ud835\udc65 = 2\ud835\udc5d \ud835\udc65,\ud835\udc66\n! !,$\n\"\nC. Marginal PMF of \ud835\udc4c \ud835\udc5d \ud835\udc66 = 2\ud835\udc5d \ud835\udc65,\ud835\udc66\n$ !,$\n%\nTo find a marginal distribution over one variable,\nsum over all other variables in the joint PMF.\nA computer (or three) in every house.\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 .12 .07 .04\n1 .12 .14 .12 0\n2 .07 .12 0 0\n3 .04 0 0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\n)sCP\n#(\n\ud835\udc4c\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n3. Let \ud835\udc36 = \ud835\udc4b + \ud835\udc4c. What is \ud835\udc43 \ud835\udc36 = 3 ?\nA computer (or three) in every house.\n\ud835\udc4b (# Macs)\n0 1 2 3\n0 .16 .12 .07 .04\n1 .12 .14 .12 0\n2 .07 .12 0 0\n3 .04 0 0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\n)sCP\n#(\n\ud835\udc4c\nConsider households in Silicon Valley.\n\u2022 A household has \ud835\udc4b Macs and \ud835\udc4c PCs.\n\u2022 Each house has a maximum of 3 computers total (Macs + PCs).\n3. Let \ud835\udc36 = \ud835\udc4b + \ud835\udc4c. What is \ud835\udc43 \ud835\udc36 = 3 ?\n\ud835\udc43 \ud835\udc36 = 3 = \ud835\udc43 \ud835\udc4b + \ud835\udc4c = 3\nLaw of Total Probability\n= <<\ud835\udc43 \ud835\udc4b + \ud835\udc4c = 3|\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\n! \"\n\ud835\udc43 \ud835\udc4b = 0, \ud835\udc4c = 3 + \ud835\udc43 \ud835\udc4b = 1, \ud835\udc4c = 2\n=\n+\ud835\udc43 \ud835\udc4b = 2, \ud835\udc4c = 1 + \ud835\udc43 \ud835\udc4b = 3, \ud835\udc4c = 0\nWe\u2019ll come back to sums of RVs next lecture!\nMultinomial RV\n27\nRecall the good times\nPermutations\n\ud835\udc5b!\nHow many ways are\nthere to order \ud835\udc5b\nobjects?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nCounting unordered objects\nBinomial coefficient Multinomial coefficient\nHow many ways are there How many ways are there\nto group \ud835\udc5b objects into to group \ud835\udc5b objects into\ntwo groups of size \ud835\udc58 and \ud835\udc5f groups of sizes \ud835\udc5b , \ud835\udc5b , \u2026, \ud835\udc5b\n- ! 4\n\ud835\udc5b \u2212 \ud835\udc58, respectively? respectively?\n\ud835\udc5b \ud835\udc5b! \ud835\udc5b \ud835\udc5b!\n= =\n\ud835\udc58 \ud835\udc58! \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc5b , \ud835\udc5b , \u2026 , \ud835\udc5b \ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b !\n% ( C\n% ( C\nCalled the binomial coefficient\nMultinomials generalize\nbecause of something from aLgEbRa\nBinomials for counting.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nProbability\nBinomial RV Multinomial RV\nWhat is the probability What is the probability of\nof getting \ud835\udc58 successes getting \ud835\udc50 of outcome 1,\n-\nand \ud835\udc5b \u2212 \ud835\udc58 failures \ud835\udc50 of outcome 2, \u2026, and\n!\nin \ud835\udc5b trials? \ud835\udc50 of outcome \ud835\udc5a\n5\nin \ud835\udc5b trials?\n\ud835\udc5b\n! \"#!\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nBinomial # of ways of Probability of each ordering\nordering the successes of \ud835\udc58 successes is equal +\nMultinomial RVs also generalize\nmutually exclusive\nBinomial RVs for probability!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nMultinomial Random Variable\nConsider an experiment of \ud835\udc5b independent trials:\n)\n\u2022 Each trial results in one of \ud835\udc5a outcomes. \ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , <\ud835\udc5d = 1\nE &\n&\u2019(\n\u2022 Let \ud835\udc4b = # trials with outcome \ud835\udc56\nE\nJoint PMF\n\ud835\udc5b\n$ $ $\n\ud835\udc43 \ud835\udc4b = \ud835\udc50 , \ud835\udc4b = \ud835\udc50 , \u2026 , \ud835\udc4b = \ud835\udc50 = \ud835\udc5d #\ud835\udc5d $ \u22ef \ud835\udc5d %\n! ! \" \" # # \ud835\udc50 , \ud835\udc50 , \u2026 , \ud835\udc50 ! \" #\n! \" #\n5 5\nwhere D \ud835\udc50 = \ud835\udc5b and D \ud835\udc5d = 1\n6 6\n6,- 6,-\nMultinomial # of ways of Probability of each ordering\nordering the outcomes is equal + mutually exclusive\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nHello dice rolls, my old friends\nA fair, six-sided die is rolled 7 times.\n\u2022 1 one \u2022 0 threes \u2022 0 fives\nWhat is the probability of getting: \u2022 1 two \u2022 2 fours \u2022 3 sixes\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nHello dice rolls, my old friends\nA fair, six-sided die is rolled 7 times.\n\u2022 1 one \u2022 0 threes \u2022 0 fives\nWhat is the probability of getting: \u2022 1 two \u2022 2 fours \u2022 3 sixes\n\ud835\udc43 \ud835\udc4b = 1, \ud835\udc4b = 1, \ud835\udc4b = 0, \ud835\udc4b = 2, \ud835\udc4b = 0, \ud835\udc4b = 3\n% ( F G $ #\n% % & ( & F H\n1 1 1 1 1 1 1\n7\n= = 420\n1,1,0,2,0,3 6 6 6 6 6 6 6\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nHello dice rolls, my old friends\nA fair, six-sided die is rolled 7 times.\n\u2022 1 one \u2022 0 threes \u2022 0 fives\nWhat is the probability of getting: \u2022 1 two \u2022 2 fours \u2022 3 sixes\n# of times\na six appears\n\ud835\udc43 \ud835\udc4b = 1, \ud835\udc4b = 1, \ud835\udc4b = 0, \ud835\udc4b = 2, \ud835\udc4b = 0, \ud835\udc4b = 3\n% ( F G $ #\n% % & ( & F H\n1 1 1 1 1 1 1\n7\n= = 420\n1,1,0,2,0,3 6 6 6 6 6 6 6\nprobability\nchoose where of rolling a six this many times\nthe sixes appear\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nProbabilistic text analysis\nIgnoring the order of words\u2026\nWhat is the probability of any given word that you write in English?\n\u2022 \ud835\udc43 word =\"the\" > \ud835\udc43 word = \"susurration\"\n\u2022 \ud835\udc43 word = \"Stanford\" > \ud835\udc43 word = \"Cal\"\nProbabilities of counts of words = Multinomial distribution \ud83d\udc48\nA document is a large multinomial.\n(according to the Global Language Monitor,\nthere are 988,968 words in the English language\nused on the internet.)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nProbabilistic text analysis\nProbabilities of counts of words = multinomial distribution\nExample document: #words: \ud835\udc5b = 48\n\"When my late husband was alive he deposited some amount of Money\nwith overseas Bank in which the amount will be declared to you once you\nrespond to this message indicating your interest in helping to receive the\nfund and use it for Heavens work as my wish.\"\nbank = 1\nfund = 1\n48!\nmoney = 1 % % F\n\ud835\udc43 spam = \ud835\udc5d \ud835\udc5d \u22ef \ud835\udc5d\nbank fund to\nwish = 1 1! 1! 1! 1! \u22ef 3!\n\u2026\nto = 3 Note: \ud835\udc43 bank spam \u226b \ud835\udc43 bank legit\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nOld and New Analysis\nAuthorship of the Federalist Papers\n\u2022 85 essays advocating ratification\nof the US constitution\n\u2022 Written under the pseudonym \"Publius\"\n(really, Alexander Hamilton, James Madison, John Jay)\nWho wrote which essays?\n\u2022 Analyze probability of words in each essay and compare against word\ndistributions from known writings of three authors\n\u2022 Curious what the analysis is? Read this!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nStatistics of\nTwo RVs\n38\nExpectation and Covariance\nIn real life, we often have many RVs interacting at once.\n\u2022 We\u2019ve seen some simpler cases (e.g., sum of independent Bernoullis).\n\u2022 Come Friday, we\u2019ll discuss sums of Binomials, Poissons, etc.\n\u2022 In general, manipulating joint PMFs is difficult.\n\u2022 Fortunately, you don\u2019t need to model joint RVs completely all the time.\nInstead, we\u2019ll focus next on reporting statistics of multiple RVs:\n\u2022 Expectation of sums (you\u2019ve seen some of this, more on Friday)\n\u2022 Covariance: measure of how two random variable vary with each other\n(more next Monday and Wednesday)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nProperties of Expectation, extended to two RVs\n1. Linearity:\n\ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f\ud835\udc4c + \ud835\udc50 = \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f\ud835\udc38 \ud835\udc4c + \ud835\udc50\n2. Expectation of a sum = sum of expectation:\nwe\u2019ve seen this!\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\nwe\u2019ll prove momentarily.\n3. Unconscious statistician:\n\ud835\udc38 \ud835\udc54 \ud835\udc4b, \ud835\udc4c = . . \ud835\udc54 \ud835\udc65, \ud835\udc66 \ud835\udc5d (\ud835\udc65, \ud835\udc66) True for both independent\n5,8\nand dependent random\n9 6\nvariables!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nProof of expectation of a sum of RVs \ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\nLOTUS,\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = D D \ud835\udc65 + \ud835\udc66 \ud835\udc5d \ud835\udc65, \ud835\udc66\n),\"\n\ud835\udc54 \ud835\udc4b,\ud835\udc4c = \ud835\udc4b + \ud835\udc4c\n. *\n= D D \ud835\udc65\ud835\udc5d \ud835\udc65, \ud835\udc66 + D D \ud835\udc66\ud835\udc5d \ud835\udc65, \ud835\udc66\n),\" ),\"\n. * . *\nLinearity of summations\n(cont. case: linearity of integrals)\n= D \ud835\udc65 D \ud835\udc5d \ud835\udc65, \ud835\udc66 + D \ud835\udc66 D \ud835\udc5d \ud835\udc65, \ud835\udc66\n),\" ),\"\n. * * .\n= D \ud835\udc65\ud835\udc5d \ud835\udc65 + D \ud835\udc66\ud835\udc5d \ud835\udc66\nMarginal PMFs for \ud835\udc4b and \ud835\udc4c\n) \"\n. *\n= \ud835\udc38 \ud835\udc4b + \ud835\udc38[\ud835\udc4c]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41 <END>"}
{"prompt": "Lecture notes from cs109_lec08_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 8: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nAll About Poisson 3 / 3 pts\n1.1 Poisson: When Applicable? 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Poisson: In the Limit 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.3 Poisson: Support 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nManaging Email 2 / 2 pts\n\uf00c + 2 pts Correct\n+ 0 pts Incorrect\nQ1 All About Poisson\n3 Points\nSelect the appropriate responses to each of the short answer questions about\nthe Poisson distribution.\nQ1.1 Poisson: When Applicable?\n1 Point\nWhat is one general problem that the Poisson RV models?\nAmount of time until next event occurs.\nProbability of k requests in the next 1 minute.\nNumber of ways to place k balls in n bins.\nAmount of time until first success.\nQ1.2 Poisson: In the Limit\n1 Point\nIt can be proven that the Poisson distribution is the limit of the ____ distribution.\nbinomial\ngeometric\nexponential\nQ1.3 Poisson: Support\n1 Point\nPick all of the following values that a Poisson RV can take on:\n-1\n0\n0.5\n1\n1.5\n10000\nQ2 Managing Email\n2 Points\nSuppose you receive a steady-state average of 5 emails every hour during all\nhours of the day. What is the probability you'll receive at least one email in the\nnext five minutes? You may assume email arrival can be modeled as a traditional\nPoisson distribution.\nExpress your probability with a leading zero and four decimal places.\n0.3408 <END>"}
{"prompt": "Lecture notes from 24_gradient_ascent_annotated.txt\n\n###\n\n", "completion": "24: Linear Regression\nand Gradient Ascent\nJerry Cain and Matt Harvill\nMay 24, 2024\nLecture Discussion on Ed\n1\nand Learn\nnaively\nWhat is Bayes doing in my mail server?\nLet\u2019s get Bayesian on your spam:\nContent analysis details: (49.5 hits, 7.0 required)\n0.9 RCVD_IN_PBL RBL: Received via a relay in Spamhaus PBL\n[93.40.189.29 listed in zen.spamhaus.org]\n1.5 URIBL_WS_SURBL Contains an URL listed in the WS SURBL blocklist\n[URIs: recragas.cn]\n5.0 URIBL_JP_SURBL Contains an URL listed in the JP SURBL blocklist\n[URIs: recragas.cn]\n5.0 URIBL_OB_SURBL Contains an URL listed in the OB SURBL blocklist\n[URIs: recragas.cn]\n5.0 URIBL_SC_SURBL Contains an URL listed in the SC SURBL blocklist\n[URIs: recragas.cn]\n2.0 URIBL_BLACK Contains an URL listed in the URIBL blacklist\n[URIs: recragas.cn]\n8.0 BAYES_99 BODY: Bayesian spam probability is 99 to 100%\n[score: 1.0000]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 3\nEmail classification\nGoal Based on email content \ud835\udc7f, predict if email is spam or not.\nFeatures Consider a lexicon \ud835\udc5a words (for English: \ud835\udc5a \u2248 100,000).\n\ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , \ud835\udc5a indicator variables\n! \" #\n\ud835\udc4b = 1 if word \ud835\udc57 appeared in document\n$\nOutput \ud835\udc4c = 1 if email is spam\n$\nNote: \ud835\udc5a is huge. Make Na\u00efve Bayes assumption: \ud835\udc43 \ud835\udc7f|spam = %\ud835\udc43 \ud835\udc4b |spam\n!\n!\"#\nAppearances of words in email are conditionally independent\ngiven the email is spam or not\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 4\nTraining: Na\u00efve Bayes Email classification\n! ! \" \" % %\nTrain set \ud835\udc5b previous emails \ud835\udc99 , \ud835\udc66 , \ud835\udc99 , \ud835\udc66 , \u2026, \ud835\udc99 , \ud835\udc66\n& & & for each word, whether it\n&\n\ud835\udc99 = \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65\n! \" #\nappears in email \ud835\udc56\n&\n\ud835\udc66 = 1 if spam, 0 if not spam\nNote: \ud835\udc5a is huge. Many words are\nlikely to not\nappear at all in\nWhich estimator should A. MLE the training set!\n0\nwe use for \ud835\udc43 \ud835\udc4b |\ud835\udc4c ? B. Laplace estimate (MAP)\n$\nC. Other MAP estimate\nD. Both A and B\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 5\nEx 3. Na\u00efve Bayes Classifier (\ud835\udc5a, \ud835\udc5b large)\n#\n0 0 0\n\ud835\udc4c = arg max 9 \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n$\n\u2019( ),!\n$(!\n0 0\n\u2200\ud835\udc57: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 , Use MLE or\n$ $\nTraining 0 0 Laplace (MAP)\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 ,\n$ $\n0 0\n\ud835\udc43 \ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4c = 0\n#\nLaplace (MAP) estimates avoid estimating\nTesting 0 0 0\n\ud835\udc4c = arg max 9 \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n$\n0 probabilities for events that don\u2019t occur\n\u2019( ),!\n$(!in your training data.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 66\nTesting: Na\u00efve Bayes Email classification\nFor a new email:\n\u2022 Generate \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n# % $\n\u2022 Classify as spam or not using Na\u00efve Bayes assumption\nNote: \ud835\udc5a is huge.\nSuppose train set size \ud835\udc5b also huge (many labeled emails).\nCan we still use the below prediction?\n#\n0 0 0\n\ud835\udc4c = arg max 9 \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n$\n\u2019( ),!\n$(!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 7\nTesting: Na\u00efve Bayes Email classification\nFor a new email:\n\u2022 Generate \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n# % $\n\u2022 Classify as spam or not using Na\u00efve Bayes assumption\nNote: \ud835\udc5a is huge.\nSuppose train set size \ud835\udc5b also huge (many labeled emails).\nCan we still use the below prediction?\n#\n0 0 0 Will probably lead to underflow!\n\ud835\udc4c = arg max 9 \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n$\n\u2019( ),!\n$(!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 8\nEx 3. Na\u00efve Bayes Classifier (\ud835\udc5a, \ud835\udc5b large)\n#\n0 0 0\n\ud835\udc4c = arg max 9 \ud835\udc43 \ud835\udc4b |\ud835\udc4c \ud835\udc43 \ud835\udc4c\n$\n\u2019( ),!\n$(!\n0 0\n\u2200\ud835\udc56: \ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 0 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 , Use MLE or\n$ $ Use sums of log-\nTraining 0 0 Laplace (MAP)\n\ud835\udc43 \ud835\udc4b = 1|\ud835\udc4c = 1 , \ud835\udc43 \ud835\udc4b = 0|\ud835\udc4c = 0 ,\nprobabilities for\n$ $\n\ud835\udc430\n\ud835\udc4c = 1 ,\n\ud835\udc430\n\ud835\udc4c = 0\nnumerical stability.\n#\nTesting 0 0 0\n\ud835\udc4c = arg max log \ud835\udc43 \ud835\udc4c + ? log \ud835\udc43 \ud835\udc4b |\ud835\udc4c\n$\n\u2019( ),!\n$(!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 99\nHow well does Na\u00efve Bayes perform?\nAfter training, you can test with another set of data, called the test set.\n\u2022 Test set also has known values for \ud835\udc4c so we can see how often\n0\nwe were right/wrong in our predictions \ud835\udc4c.\nTypical workflow:\n\u2022 Have a dataset of 1789 emails (1578 spam, 211 ham)\n\u2022 Train set: First 1538 emails (by time)\n\u2022 Test set: Next 251 messages\nEvaluation criteria on test set:\nSpam Non-spam\n# correctly predicted class \ud835\udc4c\nPrec. Recall Prec. Recall\nprecision =\n# predicted class \ud835\udc4c\nWords only\n97.1% 94.3% 87.7% 93.4%\n# correctly predicted class \ud835\udc4c\nWords +\nrecall =\n# real class \ud835\udc4c messages addtl features 100% 98.3% 96.2% 100%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 10\nWhat are precision and recall?\nAccuracy (# correct)/(# total) sometimes just doesn\u2019t cut it.\nPrecision: Of the emails you predicted as spam, Measure of\nhow many are truly spam? false positives\nRecall: Of the emails that are truly spam, Measure of\nhow many did you predict? false negatives\nMore on Wikipedia (https://en.wikipedia.org/wiki/Precision_and_recall)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 11\nLinear\nRegression\n12\nToday\u2019s goals\nWe are going to learn linear regression.\n\u2022 Informally known as \"fitting data to a straight line\"\n\u2022 Linear models, admittedly, are often too simple for complex datasets\n\u2022 Many tasks in computer science call for classification, not regression\nWe still cover this topic so we can learn compelling techniques that will\nhelp us design and understand more complicated learning algorithms:\n& &\n1. How to model likelihood of training data \ud835\udc99 , \ud835\udc66\n2. What rules of calculus and argmax are important to remember\n3. What gradient ascent is and why it is useful\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 13\nRegression: Predicting real numbers\nTraining data: \ud835\udc99 # , \ud835\udc66 # , \ud835\udc99 % , \ud835\udc66 % , \u2026, \ud835\udc99 & , \ud835\udc66 &\nCO2 levels Output\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 14\n\u2026\nReview\nGlobal Land-\nOcean\ntemperature\nYear 1 338.8 0.26\nModel:\nYear 2 340.0 0.32\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f ,\n\u2026\nfor some parametric\nYear \ud835\udc5b 340.76 0.14\nfunction \ud835\udc54\n\ud835\udc7f = \ud835\udc4b\n#\n\ud835\udc4c \u2208 \u211d\n(assume one feature)\nLinear Regression\nAssume linear model\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n(and \ud835\udc7f is 1-D):\nTraining data: \ud835\udc65 ! , \ud835\udc66 ! , \ud835\udc65 \" , \ud835\udc66 \" , \u2026, \ud835\udc65 % , \ud835\udc66 %\nTraining\nLearn parameters \ud835\udf03 = \ud835\udc4e, \ud835\udc4f\nTwo approaches:\n\u2022 Analytical solution via mean squared error\n\u2022 Iterative solution via MLE and gradient ascent\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 15\nLinear\nRegression:\nMSE\n16\nMean Squared Error (MSE)\nFor most regressions, we generally choose a \ud835\udc54 \ud835\udc4b that minimizes MSE:\n\" \"\n0\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4c = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc54 \ud835\udc4b\n+,-\n. .\n0\n\u2022 \ud835\udc4c and \ud835\udc4c = \ud835\udc54 \ud835\udc4b are both random variables\n\u2022 Intuitively: Choose parameter \ud835\udf03 that minimizes the expected squared\n0\ndeviation\u2014what can be called an error\u2014of your \ud835\udc4c predictor from true \ud835\udc4c\n0\nFor linear regression, where \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f (so that \ud835\udf03 = \ud835\udc4e, \ud835\udc4f ):\n\"\n\ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 17\nDon\u2019t make me go nonlinear!\n\"\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f\n+,-\n.( /,0\n\ud835\udf0e\n1\n\ud835\udc4e = \ud835\udf0c \ud835\udc4b, \ud835\udc4c , \u2212\ud835\udc4f = \ud835\udf07 \u2212 \ud835\udc4e \ud835\udf07\n+,- +,- 1 +,- 2\n\ud835\udf0e\n2\n(derivation included at the end of slides)\nCan we compute these statistics for \ud835\udc4b and \ud835\udc4c from our training data?\n! ! \" \" % %\nTraining data: \ud835\udc65 , \ud835\udc66 , \ud835\udc65 , \ud835\udc66 , \u2026, \ud835\udc65 , \ud835\udc66\nTechnically no, but we can estimate them!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 18\nDon\u2019t make me go nonlinear!\n\"\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f\n+,-\n.( /,0\n\ud835\udf0e\n1\n\ud835\udc4e = \ud835\udf0c \ud835\udc4b, \ud835\udc4c , \u2212\ud835\udc4f = \ud835\udf07 \u2212 \ud835\udc4e \ud835\udf07\n+,- +,- 1 +,- 2\n\ud835\udf0e\n2\n(derivation included at the end of slides)\nCan we compute these statistics for \ud835\udc4b and \ud835\udc4c from our training data?\n! ! \" \" % %\nTraining data: \ud835\udc65 , \ud835\udc66 , \ud835\udc65 , \ud835\udc66 , \u2026, \ud835\udc65 , \ud835\udc66\n\ud835\udf0c\u2019 \ud835\udc4b,\ud835\udc4c :\nEstimate parameters\n\ud835\udc46\n1 0 V V Sample\n\ud835\udc4eT = \ud835\udf0cT \ud835\udc4b, \ud835\udc4c , \ud835\udc4f = \ud835\udc4c \u2212 \ud835\udc4eT \ud835\udc4b\nbased on observed +,- +,- +,- correlation\n\ud835\udc46\n2 (Wikipedia)\ntraining data:\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 19\nSummary: Linear Regression\nAssume linear model (and \ud835\udc7f is 1-D):\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\nTraining data: \ud835\udc65 ! , \ud835\udc66 ! , \ud835\udc65 \" , \ud835\udc66 \" , \u2026, \ud835\udc65 % , \ud835\udc66 %\nTraining\nLearn parameters \ud835\udf03 = \ud835\udc4e, \ud835\udc4f\nIf we want to minimize the mean squared error of our prediction,\n\ud835\udc46\n1 0 V V\n\ud835\udc4eT = \ud835\udf0cT \ud835\udc4b, \ud835\udc4c , \ud835\udc4f = \ud835\udc4c \u2212 \ud835\udc4eT \ud835\udc4b\n+,- +,- +,-\n\ud835\udc46\n2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 20\nLinear\nRegression:\nMLE\n21\nLinear Regression Review\nAssume linear model\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n(and \ud835\udc7f is 1-D, i.e., \ud835\udc7f = \ud835\udc4b):\nLearn parameters \ud835\udf03 = \ud835\udc4e, \ud835\udc4f\nTraining\n! ! \" \" % %\nTraining data: \ud835\udc65 , \ud835\udc66 , \ud835\udc65 , \ud835\udc66 , \u2026, \ud835\udc65 , \ud835\udc66\nWe\u2019ve seen which parameters\u2014that is, what choices of a and b\u2014minimize\n0\nmean squared error: \ud835\udc4e and \ud835\udc4f , estimated by \ud835\udc4eT and \ud835\udc4f .\n+,- +,- +,- +,-\nNote: Maximizing likelihood is\nWhat if we want parameters that maximize\ntypically an objective for\nthe likelihood of the training data?\nclassification models.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 22\nLikelihood, it\u2019s been a minute Review\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" %\n\u2022 \ud835\udc4b was drawn from some distribution with density function \ud835\udc53 \ud835\udc4b |\ud835\udf03 .\n& &\n\u2022 Observed sample: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" %\nLikelihood question:\nHow likely is the observed sample \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b given parameter \ud835\udf03?\n! \" %\nLikelihood function, \ud835\udc3f \ud835\udf03 :\n%\n\ud835\udc3f \ud835\udf03 = \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 = 9 \ud835\udc53 \ud835\udc4b |\ud835\udf03\n! \" % &\n&(!\nThis is just a product, since \ud835\udc4b are iid\n-\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 23\nLikelihood of the training data\nTraining data (\ud835\udc5b datapoints):\n(shorthand)\n\u2022 \ud835\udc65 - , \ud835\udc66 - drawn iid from a distribution \ud835\udc53 \ud835\udc4b = \ud835\udc65 - , \ud835\udc4c = \ud835\udc66 - |\ud835\udf03 = \ud835\udc53 \ud835\udc65 - , \ud835\udc66 - |\ud835\udf03\n1\n\u2022 \ud835\udc4c = \ud835\udc54 \ud835\udc4b , where \ud835\udc54 is a function on \ud835\udc4b and parameter \ud835\udf03\nWe can show that \ud835\udf03 maximizes the\n+3-\nlog conditional likelihood function:\n%\n& &\n\ud835\udf03 = arg max ? log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n+3-\n.\n&(!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 24\nLinear Regression, MLE\n1. Assume linear model\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n(and \ud835\udc7f is 1-D):\n%\n2. Define maximum likelihood\n& &\n\ud835\udf03 = arg max ? log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n+3-\nestimator:\n.\n&(!\n0\n\u2022 Drama: We have a model for \ud835\udc4c, not \ud835\udc4c\n\u26a0\n\u2022 Remember the MSE approach, where we minimize the squared error\n0\nbetween \ud835\udc4c and \ud835\udc4c?\n\u2022 Here we model this error directly! \u2019\n\ud835\udc4c = \ud835\udc4c + \ud835\udc4d error/noise\n(also random)\n= \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 25\nComparison: MSE vs MLE\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\nMinimum Mean Squared Error Maximum Likelihood Estimation\n%\n\"\n& &\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc54 \ud835\udc4b \ud835\udf03 = arg max ? log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n+,- +3-\n. .\n&(!\n\u2022 Don\u2019t directly model \ud835\udc4c (or any errors) \u2022 Directly model error between\n1\npredicted \ud835\udc4c and \ud835\udc4c as an RV \ud835\udc4d\n\u2022 Parameters are estimates of\n1\nstatistics from training data: \ud835\udc4c = \ud835\udc4c + \ud835\udc4d = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d\n\ud835\udc46\n\ud835\udc4e3 = \ud835\udf0c3 \ud835\udc4b, \ud835\udc4c 1 If we assume error \ud835\udc4d~\ud835\udca9 0, \ud835\udf0e% , then\n./0\n\ud835\udc46\n2 these two estimators are equivalent.\n1 8 8\n\ud835\udc4f = \ud835\udc4c \u2212 \ud835\udc4e3 \ud835\udc4b\n./0 ./0 \ud835\udf03 = \ud835\udf03 !\n./0 .30\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 26\nLinear Regression, MLE (next steps)\n1. Assume linear model\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n(and \ud835\udc7f is 1-D):\n%\n2. Define maximum likelihood\n& &\n\ud835\udf03 = arg max ? log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n+3-\nestimator:\n.\n&(!\n!\n3. Model error, \ud835\udc4d: \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d, where Z~\ud835\udca9 0, \ud835\udf0e\n4. Pick \ud835\udf03 = \ud835\udc4e, \ud835\udc4f that maximizes\nWe won\u2019t find a solution analytically.\nlikelihood of training data\nInstead, we\u2019ll leverage gradient ascent, an\niterative optimization algorithm.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 27\nGradient\nAscent\n28\nMultiple ways to calculate argmax\n\"\nLet \ud835\udc53 \ud835\udc65 = \u2212\ud835\udc65 + 4,\nWhat is arg max \ud835\udc53 \ud835\udc65 ?\nwhere \u22122 < \ud835\udc65 < 2.\n4\nobjective function\nA. Graph and guess B. Differentiate, C. Gradient ascent: educated\nset derivative to guess & iteratively update\n0, and solve\n\ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc65\n4 4\n\ud835\udc51\ud835\udc53\n3 3\n= \u22122\ud835\udc65 = 0\n\ud835\udc51\ud835\udc65\n2 2\n1 \ud835\udc65 = 0 1\n\ud835\udc65 \ud835\udc65\n0 0\n-2 -1 0 1 2 -2 -1 0 1 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 29\nGradient ascent\nWalk uphill and you\u2019ll find a local maxima\n(if your step is small enough).\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 30\n\ud835\udf03\n\ud835\udc3f\n\ud835\udf03\n\ud835\udf03\n\"\n!\nIf your function is concave,\nLocal maxima = global maxima\nGradient ascent algorithm\nWalk uphill and you\u2019ll find a local maxima\n(if your step is small enough).\n\"\nLet \ud835\udc53 \ud835\udc65 = \u2212\ud835\udc65 + 4,\n1. \ud835\udc51\ud835\udc53\n= \u22122\ud835\udc65 Gradient at \ud835\udc65\nwhere \u22122 < \ud835\udc65 < 2.\n\ud835\udc51\ud835\udc65\n2. Gradient ascent algorithm:\ninitialize x\n(demo)\nrepeat many times:\ncompute gradient\nx += \u03b7 * gradient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 31\nLinear Regression, MLE (so far)\nAssume linear model\n$\n\ud835\udc4c = \ud835\udc54 \ud835\udc7f = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n(and \ud835\udc7f is 1-D):\nModel \ud835\udc4c as \ud835\udc4c0 + \ud835\udc4d: \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d, where \ud835\udc4d~\ud835\udca9 0, \ud835\udf0e!\n\ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nPick \ud835\udf03 = \ud835\udc4e, \ud835\udc4f that maximizes .30\n4\n&\nlikelihood of training data\n- -\n= arg max G log \ud835\udc53 \ud835\udc65 , \ud835\udc66 , |\ud835\udf03\n4\n-\"#\n&\n(\ud835\udf03 also maximizes\n!\"# - -\n= arg max G log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\nlog conditional likelihood)\n4\n-\"#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 32\nComputing the MLE with gradient ascent\nGeneral approach for finding \ud835\udf03 , the MLE of \ud835\udf03:\n+3-\n1. Determine formula 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nfor \ud835\udc3f\ud835\udc3f \ud835\udf03 w.r.t. (each) \ud835\udf03 equations\nlog conditional likelihood\n& &\n\ud835\udf15\n(computer)\n- - - -\nG log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03 G log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n\ud835\udf15\ud835\udf03 Gradient Ascent\n!\n-\"# -\"#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 33\n1. Determine formula for log conditional likelihood\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\nOver the next few slides, we will show that\nour MLE linear regression \ud835\udf03 reduces to\n+3-\n&\n!\n$ $\narg max \u2212 < \ud835\udc66 \u2212 \ud835\udc4e\ud835\udc65 \u2212 \ud835\udc4f\n#\n$%\"\nobjective function\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 34\n1. Determine formula for log conditional likelihood\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019 %\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e% goal arg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f &\n!\n\"#$\n1. What is the conditional\ndistribution, \ud835\udc4c|\ud835\udc4b, \ud835\udf03?\n2. Substitute 1. into objective fn.\n3. Use argmax properties\nto simplify objective fn.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 35\n1. Determine formula for log conditional likelihood\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\n%\n1. What is the conditional \ud835\udc4c|\ud835\udc4b, \ud835\udf03~ \ud835\udca9 \ud835\udc4e\ud835\udc4b + \ud835\udc4f, \ud835\udf0e\ndistribution, \ud835\udc4c|\ud835\udc4b, \ud835\udf03? 1 \"\n- - A B ! A CD ! EF / %H\"\n\ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03 = \ud835\udc52\n2\ud835\udf0b\ud835\udf0e\n2. Substitute 1. into objective fn.\n( (\n1 (\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03 = arg max<log \ud835\udc52) * \u2019 )+, \u2019 )- / /0(\n2\ud835\udf0b\ud835\udf0e\n$ $\n%&\u2019 %&\u2019\n( (\n1\nusing /\n= arg max <\u2212log 2\ud835\udf0b\ud835\udf0e \u2212 < \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\nnatural log\n2\ud835\udf0e/\n$\n%&\u2019 %&\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 36\n1. Determine formula for log conditional likelihood\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\n( (\n3. Use argmax properties 1 /\narg max \u2019 \u2212 log 2\ud835\udf0b\ud835\udf0e \u2212 \u2019 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\nto simplify objective fn. 2\ud835\udf0e/\n$\n%&\u2019 %&\u2019\n(from previous slide)\n(\n1 Argmax refresher #1:\n/\n= arg max \u2212 \u2019 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n2\ud835\udf0e/ Invariant to additive constants\n$\n%&\u2019\n(\nArgmax refresher #2:\n/\n= arg max \u2212 \u2019 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\nInvariant to positive constant scalars\n$\n%&\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 37\n1. Determine formula for log conditional likelihood\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\narg max<log\ud835\udc53 \ud835\udc66 % | \ud835\udc65 % ,\ud835\udf03\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\n4. Celebrate!\n&\n!\n$ $\narg max \u2212 < \ud835\udc66 \u2212 \ud835\udc4e\ud835\udc65 \u2212 \ud835\udc4f\n#\n$%\"\n\ud83c\udf89\ud83c\udf89\ud83c\udf8a\ud83c\udf8a\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 38\nComputing the MLE with gradient ascent\nGeneral approach for finding \ud835\udf03 , the MLE of \ud835\udf03:\n+3-\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 w.r.t. (each) \ud835\udf03 (simultaneous)\nequations\nlog conditional likelihood\n& &\n\ud835\udf15\n(computer)\n- - - -\nG log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03 G log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n\ud835\udf15\ud835\udf03 Gradient Ascent\n!\n-\"# -\"#\n2-D gradient:\n(\n/\n\u210e \ud835\udf03 = \u2212< \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udf15\u210e \ud835\udf03 \ud835\udf15\u210e \ud835\udf03\n,\n%&\u2019 \ud835\udf15\ud835\udc4e \ud835\udf15\ud835\udc4f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 39\n2. Compute gradient\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\n/\narg max \u2212< \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\n1. What is the derivative of the\nobjective function w.r.t. \ud835\udc4e?\n(\n\ud835\udf15\n/\n\u2212 \u2019 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f =\n\ud835\udf15\ud835\udc4e\n%&\u2019\n2. What is the derivative of the\nobjective function wrt \ud835\udc4f?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 40\n2. Compute gradient\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\n/\narg max \u2212< \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\nCalculus refresher #1:\n1. What is the derivative of the\nDerivative(sum) = sum(derivative)\nobjective function w.r.t. \ud835\udc4e?\n( Calculus refresher #2:\n\ud835\udf15\n/\n\u2212 \u2019 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f = Chain rule \ud83c\udf1f \ud83c\udf1f \ud83c\udf1f\n\ud835\udf15\ud835\udc4e\n%&\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 41\n2. Compute gradient\n(\nModel: \ud835\udf03 = \ud835\udc4e, \ud835\udc4f Optimization\n/\narg max \u2212< \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d problem:\n$\n%&\u2019\n\ud835\udc4d~\ud835\udca9 0, \ud835\udf0e%\n(\n1. What is the derivative of the\n\u2019 2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nobjective function wrt \ud835\udc4e?\n%&\u2019\n(\n2. What is the derivative of the\n\u2019 2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\nobjective function wrt \ud835\udc4f?\n%&\u2019\nanalytical solution for \ud835\udc4e , \ud835\udc4f : Set Next up: We will reach the same solution\n.30 .30\nto 0 and solve simultaneous equations computationally with gradient ascent.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 42\nComputing the MLE with gradient ascent\nGeneral approach for finding \ud835\udf03 , the MLE of \ud835\udf03:\n+3-\n1. Determine 2. Differentiate \ud835\udc3f\ud835\udc3f \ud835\udf03 3. Solve resulting\nformula for \ud835\udc3f\ud835\udc3f \ud835\udf03 wrt (each) \ud835\udf03 (simultaneous)\nequations\nlog conditional likelihood\n& &\n\ud835\udf15\n(computer)\n- - - -\nG log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03 G log \ud835\udc53 \ud835\udc66 | \ud835\udc65 , \ud835\udf03\n\ud835\udf15\ud835\udf03 Gradient Ascent\n!\n-\"# -\"#\n%\n\ud835\udf15\u210e \ud835\udf03\n( = <2 \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f \ud835\udc65 \"\n\ud835\udf15\ud835\udc4e\n/\n\u210e \ud835\udf03 = \u2212< \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \"#$\n%\n%&\u2019 \ud835\udf15\u210e \ud835\udf03\n= <2 \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n\"#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 43\n3. Gradient ascent with multiple parameters (if time)\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\ninitialize \ud835\udf03\nrepeat many times:\nHow does this\ncompute gradient\nwork for\n\ud835\udf03 += \u03b7 * gradient\nmultiple\nparameters?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 44\n3. Gradient ascent with multiple parameters\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0\nHow do we\n# TODO: fill in\npseudocode the\ngradients we\nderived?\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 45\n3. Gradient ascent with multiple parameters\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0 Finish computing\nfor each training example (x, y): gradient before\ndiff = y \u2013 (a * x + b) updating any part\ngradient_a += 2 * diff * x of \ud835\udf03.\ngradient_b += 2 * diff\n(demo)\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 46\nGlobal land-ocean temperature prediction\nTraining data: \ud835\udc99 # , \ud835\udc66 # , \ud835\udc99 % , \ud835\udc66 % , \u2026, \ud835\udc99 & , \ud835\udc66 &\nCO2 levels Output\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 47\n\u2026\nMinimizing Review\nMean Square Error\n%\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc54 \ud835\udc4b\nYear 1 338.8 0.26\n./0\n4\nYear 2 340.0 0.32\n\ud835\udc46\n1\n1 8 8\n\ud835\udc4c = \ud835\udf0c3 \ud835\udc4b, \ud835\udc4c \ud835\udc4b \u2212 \ud835\udc4b + \ud835\udc4c\n\u2026 \ud835\udc46\n2\n\ud835\udc4e = 0.01452\nYear \ud835\udc5b 340.76 0.14 !\"#\n\ud835\udc4f = 0.17511\n\ud835\udc7f = \ud835\udc4b !\"#\n#\n\ud835\udc4c \u2208 \u211d\n(assume one feature)\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0 Updates to\nfor each training example (x, y): \ud835\udc4e and \ud835\udc4f should\ndiff = y \u2013 (a * x + b)\ninclude information\ngradient_a += 2 * diff * x\nfrom all \ud835\udc5b training\ngradient_b += 2 * diff\ndatapoints\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 48\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\nHow do we interpret\ngradient_a, gradient_b = 0, 0\nthe contribution of\nfor each training example (x, y):\nthe i-th training\ndiff = y \u2013 (a * x + b)\ndatapoint?\ngradient_a += 2 * diff * x\ngradient_b += 2 * diff\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 49\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0\nfor each training example (x, y):\nPrediction error!\ndiff = y \u2013 (a * x + b)\ngradient_a += 2 * diff * x \ud835\udc66 & \u2212 \ud835\udc66T &\ngradient_b += 2 * diff\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 50\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0\nfor each training example (x, y):\nprediction_error = y \u2013 (a * x + b)\ngradient_a += 2 * prediction_error * x\ngradient_b += 2 * prediction_error\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 51\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0\nfor each training example (x, y):\n0\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, so\nprediction_error = y \u2013 (a * x + b)\ngradient_a += 2 * prediction_error * x update to \ud835\udc4e should\ngradient_b += 2 * prediction_error &\nalso scale by \ud835\udc65\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 52\n3b. Interpret\n%\n(\nOptimization & Gradient: \ud835\udf15\u210e \ud835\udf03\narg max \u2212< \ud835\udc66 \" \u2212 \ud835\udc4e\ud835\udc65 \" \u2212 \ud835\udc4f = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f \ud835\udc65 %\nproblem: ! \ud835\udf15\ud835\udc4e\n\"#$\n%&\u2019\n= arg max \u210e \ud835\udf03 (\n\ud835\udf15\u210e \ud835\udf03\n4 = <2 \ud835\udc66 % \u2212 \ud835\udc4e\ud835\udc65 % \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n%&\u2019\na, b = 0, 0 # initialize \ud835\udf03\nrepeat many times:\ngradient_a, gradient_b = 0, 0\nfor each training example (x, y):\n0\n\ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, so\nprediction_error = y \u2013 (a * x + b)\ngradient_a += 2 * prediction_error * x update to \ud835\udc4f just\ngradient_b += 2 * prediction_error * 1\nscales by 1\na += \u03b7 * gradient_a # \ud835\udf03 += \u03b7 * gradient\nb += \u03b7 * gradient_b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 53\nExtra:\nDerivations\n54\nDon\u2019t make me get nonlinear!\n\"\n\ud835\udf03 = arg min \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f\n+,-\n.( /,0\n1. Differentiate \ud835\udf15 \ud835\udf15\n(\ud835\udc38 \u22c5 is a linear\n\ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f / = \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f /\nwrt (each) \ud835\udf03, \ud835\udf15\ud835\udc4e \ud835\udf15\ud835\udc4e function w.r.t. \ud835\udc4e)\nset to 0\n= \ud835\udc38 \u22122 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f \ud835\udc4b\n= \u22122\ud835\udc38 \ud835\udc4b\ud835\udc4c + 2\ud835\udc4e\ud835\udc38 \ud835\udc4b/ + 2\ud835\udc4f\ud835\udc38 \ud835\udc4b\n\ud835\udf15\n\ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f / = \ud835\udc38 \u22122 \ud835\udc4c \u2212 \ud835\udc4e\ud835\udc4b \u2212 \ud835\udc4f\n\ud835\udf15\ud835\udc4f\n= \u22122\ud835\udc38 \ud835\udc4c + 2\ud835\udc4e\ud835\udc38 \ud835\udc4b + 2\ud835\udc4f\n2. Solve resulting \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c Cov \ud835\udc4b,\ud835\udc4c \ud835\udf0e\n2\n\ud835\udc4e = = = \ud835\udf0c \ud835\udc4b,\ud835\udc4c\nsimultaneous !1# \ud835\udc38 \ud835\udc4b/ \u2212 \ud835\udc38 \ud835\udc4b / Var \ud835\udc4b \ud835\udf0e\n3\n\ud835\udf0e\nequations\n2\n= \ud835\udf07 \u2212 \ud835\udf0c \ud835\udc4b,\ud835\udc4c \ud835\udf07\n\ud835\udc4f = \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc4e \ud835\udc38 \ud835\udc4b 2 3\n!1# !1# \ud835\udf0e\n3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 55\nR\n\ud835\udc4c = \ud835\udc54 \ud835\udc4b , where \ud835\udc54 \u22c5 is a\nLog conditional likelihood, a derivation\nfunction with parameter \ud835\udf03\n&\nShow that \ud835\udf03 maximizes the\n+3- \ud835\udf03 = arg max G log \ud835\udc53 \ud835\udc66 - | \ud835\udc65 - , \ud835\udf03\n.30\nlog conditional likelihood function:\n4\n-\"#\n( (\n(\ud835\udf03 also\nProof: \ud835\udf03 = arg maxN\ud835\udc53 \ud835\udc65 % ,\ud835\udc66 % |\ud835\udf03 = arg max<log\ud835\udc53 \ud835\udc65 % ,\ud835\udc66 % |\ud835\udf03 !\"#\n!\"# maximizes \ud835\udc3f\ud835\udc3f \ud835\udf03 )\n$ $\n%&\u2019 %&\u2019\n( (\n(chain rule,\n= arg max<log\ud835\udc53 \ud835\udc65 % |\ud835\udf03 + <log\ud835\udc53 \ud835\udc66 % |\ud835\udc65 % ,\ud835\udf03\nlog of product = sum of logs)\n$\n%&\u2019 %&\u2019\n( (\n= arg max<log\ud835\udc53 \ud835\udc65 % + <log\ud835\udc53 \ud835\udc66 % |\ud835\udc65 % ,\ud835\udf03 (\ud835\udc65 % indep. of \ud835\udf03)\n$\n%&\u2019 %&\u2019\n(\n= arg max<log\ud835\udc53 \ud835\udc66 % |\ud835\udc65 % ,\ud835\udf03 (\ud835\udc53 \ud835\udc65 % constant w.r.t. \ud835\udf03)\n$\n%&\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 56 <END>"}
{"prompt": "Lecture notes from 01_section_soln.txt\n\n###\n\n", "completion": "CS109 April11,2024\nSection 1 Solution: Combinatorics and Probability\nChrisPiech,MehranSahami,JerryCain,LisaYan,andnumerousCS109CA\u2019s.\nOverview of Section Materials\nThewarm-upquestionsprovidedwillhelpstudentspracticeconceptsintroducedinlectures.Thesectionprob-\nlemsaremeanttoapplytheseconceptsinmorecomplexscenariossimilartowhatyouwillseeinproblemsets\nandexams.Infact,manyofthemareoldexamquestions.\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019ssection.The\nCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\nWarm-ups\n1. Equality versus Inequality\nShowthatforanyevents \ud835\udc34 and \ud835\udc35 that\n\ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35) \u22121 \u2264 \ud835\udc43(\ud835\udc34\u2229 \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34\u222a \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35)\nForeachofthethreeinequalities,describesets \ud835\udc34 and \ud835\udc35 thatwouldresultinequality.\nWe\u2019llshoweachofthethreetobetrue,onebyone.\n\u2022 TheInclusion-ExclusionPrincipleisclearthat \ud835\udc43(\ud835\udc34 \u222a \ud835\udc35) = \ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35) \u2212 \ud835\udc43(\ud835\udc34 \u2229 \ud835\udc35).Becauseall\nprobabilities,includingthoseofintersections,aregreaterthanorequalto0,wehavethat \ud835\udc43(\ud835\udc34 \u222a \ud835\udc35) =\n\ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35) \u2212 \ud835\udc43(\ud835\udc34 \u2229 \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35).Whendoestheequalityhold?When \ud835\udc34 and \ud835\udc35 aremutually\nexclusiveeventssothattheprobabilitythatbotheventsoccuris0.\n\u2022 \ud835\udc43(\ud835\udc34\u2229 \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34\u222a \ud835\udc35) istruesimplybecause \ud835\udc34\u2229 \ud835\udc35 \u2286 \ud835\udc34\u222a \ud835\udc35.Equalityholdswhen \ud835\udc34 and \ud835\udc35 arethesame\nevent.\n\u2022 Inclusion-Exclusionstatesthat \ud835\udc43(\ud835\udc34\u222a\ud835\udc35) = \ud835\udc43(\ud835\udc34)+\ud835\udc43(\ud835\udc35)\u2212\ud835\udc43(\ud835\udc34\u2229\ud835\udc35) sothat \ud835\udc43(\ud835\udc34\u222a\ud835\udc35)+\ud835\udc43(\ud835\udc34\u2229\ud835\udc35) = \ud835\udc43(\ud835\udc34)+\n\ud835\udc43(\ud835\udc35).Becauseallprobabilitiesareatmost1,wehave \ud835\udc43(\ud835\udc34)+\ud835\udc43(\ud835\udc35) = \ud835\udc43(\ud835\udc34\u2229\ud835\udc35)+\ud835\udc43(\ud835\udc34\u222a\ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34\u2229\ud835\udc35)+1,\nsothat \ud835\udc43(\ud835\udc34)+\ud835\udc43(\ud835\udc35)\u22121 \u2264 \ud835\udc43(\ud835\udc34\u2229\ud835\udc35).Equalityholdswhentheunionof \ud835\udc34 and \ud835\udc35 isthefullsamplespace \ud835\udc46.\n2. Fish Pond\nSupposethereare7bluefish,4redfish,and8greenfishinalargefishingtank.Youdropanetintoitandendup\nwith2fish.Whatistheprobabilityyouget2bluefish?\nForthefullsamplespace,weconsiderthenumberofwayswecanselect2fishfromall19fishwithoutregard\nforblue,red,orgreen.Wetreatallofthefishasdistinctinordertomakesurethateacheventisequallylikely.\nWedon\u2019tconsiderorderoffishtomatter.Thesizeofoursamplespaceisthus\n(cid:0)19(cid:1)\n.Foroureventspace,wecon-\n2\nsiderthenumberofwayswecanselect2bluefish.Thereare7distinctbluefishfromwhichwecanchosetwo.\nRecallthattheeventspacemustbeconsistentwiththesamplespace:\n(cid:0)7(cid:1)\n21\n\ud835\udc5d = 2 = \u2248 0.123\n(cid:0)19(cid:1) 171\n2\nThesameanswercouldbearrivedatbyusingthechainrule.Theprobabilitythatthefirstfishisblueis7/19.\nTheprobabilitythatthesecondfishisblue,giventhatthefirstfishwasblueis6/18.Theprobabilitythatboth\nfishareblueis7/19\u00b76/18 \u2248 0.123\nProblems\n3. Rolling Fair Dice\nConsideranexperimentwherewerollafair,six-sideddiemultipletimes.\na. Whatistheprobabilitythatatleastone3appearswhenyourollthesamefairdie10times?\nLet \ud835\udc34 betheeventthatwerolloneormore3\u2019sin10rollsofthefairdie.It\u2019seasiertoexcludethescenario\nwherewenevergetany3\u2019sthanitistoincludeallthewaystogetoneormoreofthem.Wecompute \ud835\udc43(\ud835\udc34)\nbycountingequallylikelyoutcomes,wherethefullsamplespaceisofsize610.Thenumberofwaystoget\npreciselyzero3\u2019sis510,sothat \ud835\udc43(\ud835\udc34\ud835\udc36) = 510 and \ud835\udc43(\ud835\udc34) = 1\u2212 510 .\n610 610\nWhatistheprobabilitythatatleasttwo3\u2019sappearwhenyourollthesamefairdie20times?Youmay\nleaveyouranswerintermsofoneormorechooseterms.\nLet \ud835\udc35 betheeventofinterestthistime,andonceagainlet\u2019scompute \ud835\udc43(\ud835\udc35\ud835\udc36) bycountingthefractionof\nequallylikelyeventsthatleadto0or13\u2019samongthe20rollsofthedie.Theoutcomespaceisofsize620\nthistime,andthereare520 waystobedevoidof3\u2019s,and (cid:0)20(cid:1) 519 waystogenerateexactlyone3somewhere\n1\nwithin19othernon-3\u2019s.Thatmeansthat:\n520 + (cid:0)20(cid:1) 519\n\ud835\udc43(\ud835\udc35\ud835\udc36 ) = 1\n620\n520 + (cid:0)20(cid:1) 519\n\ud835\udc43(\ud835\udc35) = 1\u2212 1\n620\nb. Whatistheprobabilitythatatleast \ud835\udc5b 3\u2019sappearwhenyourollthesamefairdie10\ud835\udc5b times?Youranswer\nwillcertainlyinvolveasumofmanycombinatorialterms,andyouneedn\u2019tsimplifyprovidedweunder-\nstandthestructureofyouranswer.\nWe\u2019llgowith \ud835\udc37 thistime,since\ud835\udc36 alreadymeanseventcomplement.\n(cid:205)\ud835\udc5b\u22121 (cid:0)10\ud835\udc5b(cid:1) 510\ud835\udc5b\u2212\ud835\udc58\n\ud835\udc43(\ud835\udc37\ud835\udc36\n) =\n\ud835\udc58=0 \ud835\udc58\n610\ud835\udc5b\n(cid:205)\ud835\udc5b\u22121 (cid:0)10\ud835\udc5b(cid:1) 510\ud835\udc5b\u2212\ud835\udc58\n\ud835\udc43(\ud835\udc37) = 1\u2212 \ud835\udc58=0 \ud835\udc58\n610\ud835\udc5b\nc. Doyouexpecttheprobabilityfrompartctoincreaseordecreaseas \ud835\udc5b increases?Providesomeintuitionas\ntowhyyouexpecttheincreaseordecrease.\nWeshouldexpecttheprobabilitytoincreasean \ud835\udc5b getslargerandlargerandapproach1.0.Intuitively,asn\ngrowstowardsinfinity,weshouldexpectthenumberof3\u2019stoberoughly 1 (orabout16.6%)ofallrolls,\n6\nsotheprobabilitythatthenumberof3\u2019sbelessthan10%ofallrollsshouldeventuallyvanishasfarcically\nimprobable.\n4. Baking Cookies\nThefollowingproblemisbasedontrueevents.Itwasalsoatake-homeexamquestionseveralyearsago.\nJerryandtheCS109coursestaffarebakingM&McookiesonarainySaturdaymorning,buttheyonlyhave\nenoughflourtomake6cookies.Theyhave15M&M\u2019s,allofwhicharedifferentcolors.Forallsub-parts,as-\nsumethatwedon\u2019tdistinguishbetweendifferentarrangementsofM&M\u2019sonthesamecookie.Thatis,M&M\u2019s\nhavenoorderingonacookie.\na. Howmanywayscanthe15M&M\u2019sbedistributedacrossthesixcookies?Forthissubpart,assumethe\ncookiesthemselvesAREdistinguishable,andtheM&M\u2019sAREdistinguishable.Itispossibleforacookie\ntohavenoM&M\u2019s,anditispossibleforacookietohaveallofthem.\n615\nThereare6placestoputthefirstM&M,6placestoputthesecondM&M,...allthewayto15.Usingthe\nproductrule,thisgivesus6\u22176\u2217...\nb. Howmanywayscanthe15M&M\u2019sbedistributedacrossthesixcookies?Forthissubpart,assumethe\ncookiesthemselvesaredistinguishable,andtheM&M\u2019sareindistinguishable.Itispossibleforacookieto\nhavenoM&M\u2019s,anditispossibleforacookietohaveallofthem.\n(cid:18) (cid:19)\n15+6\u22121\n6\u22121\nWeusethedividermethodbecausethe\u201ditems\u201d(M&M\u2019s)areindistinguishableandtheamountswecan\nputineach\u201dbucket\u201d(cookie)arenotfixed.Wehave15itemsand6buckets,so6\u22121dividers.\nc. What\u2019stheprobabilitythateachofthesixcookiesendsupwithadifferentnumberofM&M\u2019s?Notethat\nthiswouldrequirethateachofthesixcookiesget0,1,2,3,4,and5M&M\u2019sinsomeorder.Forthissub-\npart,assumethecookiesthemselvesaredistinguishable,andtheM&M\u2019saredistinguishable.Assumefur-\ntherthatanM&Misequallylikelytoappearonanycookie.\n|\ud835\udc38| 6!(cid:0) 1,2,1 35 ,4,5(cid:1)\n=\n|\ud835\udc46| 615\nItwouldalsobeacceptableforthemultinomialcoefficienttobe (cid:0) 15 (cid:1) .Sincealltheoutcomesofthe\n0,1,2,3,4,5\n|\ud835\udc38|\nsamplespaceareequallylikely,theprobabilityofaneventis .\n|\ud835\udc46|\n|\ud835\udc46| canbecomputedas615 becausethereare6placestoputthefirstM&M,6placestoputthesecond\nM&M,...allthewayto15.Usingtheproductrule,thisgivesus6\u22176\u2217....\n|\ud835\udc38| canbecomputedastheproductof\n\u2022 6!becausethisaccountsforthepermutationsoftheliteralnumbers0,1,2,3,4,5\n\u2022 (cid:0) 15 (cid:1) becausewearecountingallthewaystoputdistinguishableitemsintogroupsofsizes\n1,2,3,4,5\n0,1,2,3,4,5.\nd. IfwenolongerrequireallM&M\u2019sbeused,what\u2019stheprobabilityallcookiesendupwiththesamenum-\nberofM&M\u2019s?Forthissubpart,assumethecookiesthemselvesaredistinguishable,andtheM&M\u2019s\naredistinguishable.AssumefurtherthatanM&Misequallylikelytoappearonanycookie,andthatwe\nshouldincludethepossibilitythatnoneofthecookiesgetM&M\u2019s.Concretely,treat\u201cnocookie\u201dasan-\nothercookiewithequallikelihoodtoothercookies.\n15! 15! \u2217 1\n1 (15\u22126)! (15\u221212)! (2!)6\n+ +\n715 715 715\n\ud835\udc43(allhavesamenumber) = \ud835\udc43(allhave0\u222aallhave1\u222aallhave2)\n= \ud835\udc43(all0) + \ud835\udc43(all1) + \ud835\udc43(all2) (Axiom3,lecture3)\n15! 15! \u2217 1\n1 (15\u22126)! (15\u221212)! (2!)6\n= + +\n715 715 715\nThesamplespaceis715 (asopposedto615)becauseweassigntheunusedM&M\u2019stoanimaginarysev-\nenthcookieweneverbake.\n\u2022 Theeventspacefor \ud835\udc43(all0) computestojustoneoutcome(noM&M\u2019sonanycookie)\n\u2022 Theeventspacefor \ud835\udc43(all1) computesto 15! becausethefirstcookiehas15M&M\u2019stochoose\n(15\u22126)!\nfrom,thesecondcookiehas14M&M\u2019s,thethirdhas13M&M\u2019s,etc.Theremaining9gointoUN-\nUSED.\n\u2022 Theeventspacefor \ud835\udc43(all2) computestotheproductof 15! (becausethefirstslotonthefirst\n(15\u221212)!\ncookiehas15M&M\u2019stochoosefrom,thesecondslotonthefirstcookiehas14M&M\u2019s,thefirst\nslotonthesecondcookiehas13M&M\u2019s,etc.)and 1 becausewewanttodiscountdifferentar-\n(2!)6\nrangementsonthesamecookie.\n5. The Birthday Problem\nWhensolvingacountingproblem,itcanoftenbeusefultocomeupwithagenerativeprocess,aseriesofsteps\nthat\u201cgenerates\u201dexamples.Acorrectgenerativeprocesstocounttheelementsofset \ud835\udc34 will(1)generateeveryel-\nementof \ud835\udc34 and(2)notgenerateanyelementof \ud835\udc34 morethanonce.Ifourprocesshastheaddedpropertythat(3)\nanygivenstepalwayshasthesamenumberofpossibleoutcomes,thenwecanusetheproductruleofcounting.\nProblem:Assumethatbirthdayshappenonanyofthe365daysoftheyearwithequallikelihood(we\u2019llignore\nleapyears).\na. Whatistheprobabilitythatofthe \ud835\udc5b peopleinclass,atleasttwopeoplesharethesamebirthday?\nComputing \ud835\udc43(atleast2peopleshareabirthday) isdifficult.Werealizethatthiscanbethoughtofas\n\ud835\udc43(exactly2peoplesharebirthday\u222aexactly3\u222aexactly4\u222a...\u222aexactly \ud835\udc5b peoplesharebirthday)\nUsingtheadditivityaxiomofprobability,werealizethatthiscanbesplitupbecausetheeventsaremutu-\nallyexclusive.\n\ud835\udc43(exactly2peoplesharebirthday) +\ud835\udc43(exactly3) +\ud835\udc43(exactly4) +...+\ud835\udc43(exactly \ud835\udc5b peoplesharebirthday)\nHowever,thisisverytedious!\nItismucheasiertocalculate1 \u2212 \ud835\udc43(noonesharesabirthday).Letoursamplespace, \ud835\udc46 bethesetofall\npossibleassignmentsofbirthdaystothestudentsinsection.Bytheassumptionsofthisproblem,eachof\nthoseassignmentsisequallylikely,sothisisagoodchoiceofsamplespace.Wecanusetheproductrule\nofcountingtocalculate |\ud835\udc46|:\n|\ud835\udc46| = (365)\ud835\udc5b\nOurevent \ud835\udc38 willbethesetofassignmentsinwhichtherearenomatches(i.e.everyonehasadifferent\nbirthday).Wecanthinkofthisasagenerativeprocesswherethereare365choicesofbirthdaysforthe\nfirststudent,364forthesecond(sinceitcan\u2019tbethesamebirthdayasthefirststudent),andsoon.Verify\nforyourselfthatthisprocesssatisfiesthethreeconditionslistedabove.Wecanthenusetheproductruleof\ncounting:\n|\ud835\udc38| = (365) \u00b7 (364) \u00b7\u00b7\u00b7\u00b7\u00b7 (365\u2212\ud835\udc5b+1)\n\ud835\udc43(birthdaymatch) = 1\u2212 \ud835\udc43(nomatches)\n|\ud835\udc38|\n= 1\u2212\n|\ud835\udc46|\n(365) \u00b7 (364)...(365\u2212\ud835\udc5b+1)\n= 1\u2212\n(365)\ud835\udc5b\nAcommonmisconceptionisthatthesizeoftheevent \ud835\udc38 canbecomputedas |\ud835\udc38| = (cid:0)365(cid:1) bychoosing \ud835\udc5b\n\ud835\udc5b\ndistinctbirthdaysfrom365options.However,outcomesinthisevent(\ud835\udc5b unordereddistinctdates)cannot\nrecreateanyoutcomesinthesamplespace |\ud835\udc46| = 365\ud835\udc5b (\ud835\udc5b distinctdates,oneforeachdistinctperson).How-\neverifwecomputethesizeofevent \ud835\udc38 as |\ud835\udc38| = (cid:0)365(cid:1)\ud835\udc5b!(equivalenttothenumberabove),thenwecan\n\ud835\udc5b\nassignthe \ud835\udc5b birthdaystoeachpersoninawayconsistentwiththesamplespace.Theexpression (cid:0)365(cid:1)\ud835\udc5b!is\n\ud835\udc5b\nequivalentto 365! whichisknownasa\u201dfallingfactorial\u201dandalsoas\u201d365permute \ud835\udc5b\u201doutsideofthis\n(365\u2212\ud835\udc5b)!\nclass.\nInterestingvalues: (\ud835\udc5b = 13 : \ud835\udc5d \u2248 0.19), (\ud835\udc5b = 23 : \ud835\udc5d \u2248 0.5), (\ud835\udc5b = 70 : \ud835\udc5d \u2265 0.99).\nb. Whatistheprobabilitythatthisclasscontainsexactlyonepairofpeoplewhoshareabirthday?\nWecanusethesamesamplespace,butoureventisalittlebittrickier.Now \ud835\udc38 isthesetofbirthdayassignments\ninwhichexactlytwostudentsshareabirthdayandtheresthavedifferentbirthdays.Onegenerativeprocessthat\nworksforthisis(1)choosethetwostudentswhoshareabirthday,(2)choose \ud835\udc5b\u22121birthdaysinthesamemanner\nasinparta(i.e.oneforthepairofstudentsandoneforeachoftheremainingstudents).Wethenhave:\n|\ud835\udc38| (cid:0)\ud835\udc5b(cid:1) (365) \u00b7 (364) \u00b7...\u00b7 (365\u2212\ud835\udc5b+2)\n\ud835\udc43(exactlyonematch) = = 2\n|\ud835\udc46| (365)\ud835\udc5b\nManyothergenerativeprocessesworkforthisproblem.Trytothinkofsomeotheronesandmakesureyouget\nthesameanswer!\n6. Flipping Coins\nOnethingthatstudentsoftenfindtrickywhenlearningcombinatoricsishowtofigureoutwhenaproblemin-\nvolvespermutationsandwhenitinvolvescombinations.Naturally,wewilllookataproblemthatcanbesolved\nwithbothapproaches.Payattentiontowhatpartsofyoursolutionrepresentdistinctobjectsandwhatpartsrep-\nresentindistinctobjects.\nProblem:Weflipafaircoin \ud835\udc5b times,hoping(forsomereason)toget \ud835\udc58 heads.\na. Howmanywaysaretheretogetexactly \ud835\udc58 heads?CharacterizeyouranswerasapermutationofH\u2019sand\nT\u2019s.\nWewanttoknowthenumberofsequencesof \ud835\udc5b H\u2019sandT\u2019ssuchthatthereare \ud835\udc58 H\u2019sand \ud835\udc5b\u2212 \ud835\udc58 T\u2019s.Thisis\nthesameaspermuting \ud835\udc5b objectsofwhichonesetof \ud835\udc58 isindistinguishableandonesetof \ud835\udc5b \u2212 \ud835\udc58 isindistin-\nguishable.Usingourformulaforthepermutationofindistinguishableobjects,weget\n\ud835\udc5b!\n\ud835\udc58!(\ud835\udc5b\u2212\ud835\udc58)!\nb. Forwhat\ud835\udc65 and \ud835\udc66 isyouranswertopart(a)equalto (cid:0)\ud835\udc65(cid:1) ?Whydoesthiscombinationmakesenseasanan-\n\ud835\udc66\nswer?\n(cid:0)\ud835\udc5b(cid:1)\nOuranswertopartaisequalto .Thismakessensebecausewecancomeupwithavalidsequenceby\n\ud835\udc58\nchoosing \ud835\udc58 flipstocomeouttoheads(andimplicitlydefinetheother \ud835\udc5b \u2212 \ud835\udc58 tobetails).Theanswerisalso\n(cid:0) \ud835\udc5b (cid:1)\nequivalentto forwhichthesamelogicappliesexceptwithchoosingflipstobetails.\n\ud835\udc5b\u2212\ud835\udc58\nc. Whatistheprobabilitythatwegetexactly \ud835\udc58 heads?\nIfwedefineoursamplespacetobeallpossiblesequencesofflips,thenoureventisthenumberofse-\nquenceswherewegetexactly \ud835\udc58 heads,meaningthat |\ud835\udc38| is(conveniently)theanswertotheprevioustwo\nparts.Ourprobabilityisthen\n|\ud835\udc38|\n=\n(\ud835\udc5b \ud835\udc58)\n.\n|\ud835\udc46| 2\ud835\udc5b\n7. Combinatorial Proofs\nShowthat\n(cid:0)\ud835\udc5a+\ud835\udc5b(cid:1)\n=\n(cid:205)\ud835\udc58 (cid:0)\ud835\udc5a(cid:1)(cid:0) \ud835\udc5b (cid:1)\nviaacombinatorialproof.\n\ud835\udc58 \ud835\udc57=0 \ud835\udc57 \ud835\udc58\u2212\ud835\udc57\nAfullyalgebraicproofrequiresfluencyincombinatoricsbeyondthelevelthatyou\u2019llseeinthisclass.However,\nwecanprovetheabovebyrelyingonacombinatorialargument!\nThelefthandsidecountsthenumberofwaysIcanformacommitteeofsize \ud835\udc58 fromthecombinedjuniorand\nseniorhighschoolclasses,eachofsize \ud835\udc5a and \ud835\udc5b respectively.Therighthandsidesaysthecommitteecanbe\nformedbychoosing \ud835\udc58 ofthe \ud835\udc5a juniorsandnoseniors, \ud835\udc58 \u2212 1ofthe \ud835\udc5a juniorsandjust1ofthe \ud835\udc5b seniors, \ud835\udc58 \u2212 2\njuniorsandand2seniors,andsoforth.Ingeneral,wecanformthecommitteebyselecting \ud835\udc57 juniorsinanyone\n(cid:0)\ud835\udc5a(cid:1)\nof ways,andforeachofthoseselections,wecanindependentlyfillouttherestofthecommitteebyselecting\n\ud835\udc57\n\ud835\udc58 \u2212 \ud835\udc57 seniorsinanyoneof (cid:0) \ud835\udc5b (cid:1) ways,forallreasonablevaluesof \ud835\udc57.\n\ud835\udc58\u2212\ud835\udc57 <END>"}
{"prompt": "Lecture notes from 17_cont_joint_ii_annotated.txt\n\n###\n\n", "completion": "17: Continuous Joint\nDistributions II\nJerry Cain\nMay 8th, 2024\nLecture Discussion on Ed\n1\nConvolution:\nSum of\nindependent\nUniform RVs\n2\nToday\u2019s lecture\nTake what we\u2019ve seen with discrete joint distributions\u2026\n\u2026and generalize to continuous joint distributions.\n#\nFor the most part, this Marginal\n\ud835\udc5d \ud835\udc4e = *\ud835\udc5d \ud835\udc4e,\ud835\udc66 \ud835\udc53 \ud835\udc4e = $ \ud835\udc53 \ud835\udc4e,\ud835\udc66 \ud835\udc51\ud835\udc66\n! !,% ! !,%\ndistributions\nisn\u2019t too bad. Examples: \"#\n&\nIndependent RVs \ud835\udc5d \ud835\udc65,\ud835\udc66 = \ud835\udc5d \ud835\udc65 \ud835\udc5d \ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66 = \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc66\n!,% ! % !,% ! %\nBut some concepts, while mathematically accessible given what we\u2019ve\nlearned, are difficult to implement in practice.\nWe\u2019ll focus on some of these today.\nGoal of CS109 continuous joint\ndistributions unit: build\nmathematical maturity\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nDance, Dance, Convolution Review\nRecall that for independent discrete random variables \ud835\udc4b and \ud835\udc4c:\nthe convolution\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = \u2019 \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\nof \ud835\udc5d and \ud835\udc5d\n+ ,\n!\n6/36\n5/36\n4/36\n3/36\n2/36\n1/36\n0\n2 3 4 5 6 7 8 9 10 11 12\n% + ' = )\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\n)\n=\n'\n+\n%\n.\n1 2 3 4 5 6\n! = #\n#=\n!\n$\n1 2 3 4 5 6\n! = #\n#\n=\n!\n$\n+\n=\nIndependent \ud835\udc4b, \ud835\udc4c\nDance, Dance, Convolution\nRecall that for independent discrete random variables \ud835\udc4b and \ud835\udc4c:\nthe convolution\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = \u2019 \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\nof \ud835\udc5d and \ud835\udc5d\n+ ,\n!\nFor independent continuous random variables \ud835\udc4b and \ud835\udc4c:\n&\nthe convolution\n\ud835\udc53 \ud835\udefc = , \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n\"#$ \" $\nof \ud835\udc53 and \ud835\udc53\n+ ,\n%&\n1/2\n%\n0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\n%\n&\n#\"!\n\" ! \" !\n! !\n1\n+ = ?\n1 1\n! ! 0\n0 1 0 1\n1/2 1 3/2 2\nIndependent \ud835\udc4b, \ud835\udc4c\nSum of independent Uniforms\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs.\n/\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n\ud835\udc53 \ud835\udefc = ( \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n+-,\n+-, + ,\n./\nIsn\u2019t this just\n\" ! \ud835\udc53 \ud835\udc65\n! , one??\n1\n!\n0 1\nNot so fast\u2026 \ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nSum of independent Uniforms\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs.\n/\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n\ud835\udc53 \ud835\udefc = ( \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n+-,\n+-, + ,\n./\n\ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n+ ,\n1 1\n?\n\ud835\udc65 \ud835\udc65\n0 1\n1 if 0 \u2264 \ud835\udc65 \u2264 1 1 if 0 \u2264 \ud835\udefc \u2212 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = 0 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = 0\n+ 0 otherwise , 0 otherwise\n\ud835\udefc is a constant\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc in the integral\n= 0\n0 otherwise w.r.t. \ud835\udc65.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n\ud835\udc53 \ud835\udc65\n!\n1\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n%\n\ud835\udc65\n0 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n2. \ud835\udefc = 1/2 1/2\n\ud835\udc53 \ud835\udc65\n!\n1\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n%\n\ud835\udc65\n0 1\nIntegral = area under the curve\nThis curve = product of 2 functions of \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n2. \ud835\udefc = 1/2 1/2\n3. \ud835\udefc = 1\n4. \ud835\udefc = 3/2\n5. \ud835\udefc \u2265 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n2. \ud835\udefc = 1/2 1/2\n\ud835\udc53 \ud835\udc65\n!\n1\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n%\n3. \ud835\udefc = 1 1\n!\n0 1\n4. \ud835\udefc = 3/2\n5. \ud835\udefc \u2265 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n2. \ud835\udefc = 1/2 1/2\n\ud835\udc53 \ud835\udc65\n!\n1\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n%\n3. \ud835\udefc = 1 1\n!\n0 1\n4. \ud835\udefc = 3/2 1/2\n5. \ud835\udefc \u2265 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs. 1 if 0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc65 = .\n\"\n0 otherwise\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1 if \ud835\udefc \u2212 1 \u2264 \ud835\udc65 \u2264 \ud835\udefc\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 = .\n1. \ud835\udefc \u2264 0 0 !\n0 otherwise\n\ud835\udc53 \ud835\udc65\n!\n2. \ud835\udefc = 1/2 1/2\n\ud835\udc53 \ud835\udefc \u2212 \ud835\udc65\n%\n1\n3. \ud835\udefc = 1 1\n!\n0 1\n4. \ud835\udefc = 3/2 1/2\n5. \ud835\udefc \u2265 2 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\n\ud835\udc4b and \ud835\udc4c #\nSum of independent Uniforms independent \ud835\udc53 \ud835\udefc = $ \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udefc \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n!\u2019% ! %\n+ continuous \"#\nLet \ud835\udc4b~Uni 0,1 and \ud835\udc4c~Uni 0,1 be independent RVs.\nWhat is the distribution of \ud835\udc4b + \ud835\udc4c, \ud835\udc53 \ud835\udefc ?\n+-,\n1. \ud835\udefc \u2264 0 0\n2. \ud835\udefc = 1/2 1/2 1/2\n\ud835\udefc\n0\n3. \ud835\udefc = 1 1\n\ud835\udefc 0 \u2264 \ud835\udefc \u2264 1\n4. \ud835\udefc = 3/2 1/2\n\ud835\udc53 \ud835\udefc = 32 \u2212 \ud835\udefc 1 \u2264 \ud835\udefc \u2264 2\n+-,\n0 otherwise\n5. \ud835\udefc \u2265 2 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\n\ud835\udefc\n\ud835\udc53\n!#\"\n1\n0\n1/2 1 3/2 2\nDance, Dance, Convolution Extreme\n6/36\n5/36\n4/36\n3/36\n2/36\n1/36\n0\n2 3 4 5 6 7 8 9 10 11 12\n% + ' = )\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n)\n=\n'+\n%\n.\n1 2 3 4 5 6\n!=#\n#=!\n$\n1 2 3 4 5 6\n!=#\n#=!\n$\n+\n=\n1/2\n%\n0\n%\n&\n#\"!\nIndependent \ud835\udc4b, \ud835\udc4c\n\" ! \" !\n! !\n1\n+ =\n1 1\n! ! 0\n0 1 0 1\n1/2 1 3/2 2\nIndependent \ud835\udc4b, \ud835\udc4c\nRatio of PDFs\n16\nRelative probabilities of continuous random variables\nLet \ud835\udc4b = time to finish Problem Set 4.\nSuppose \ud835\udc4b~\ud835\udca9 10, 2 .\nHow much more likely are you to\ncomplete in 10 hours than 5 hours?\n5 10 !\n\ud835\udc43 \ud835\udc4b = 10\n= A. 0/0 = undefined\n\ud835\udc43 \ud835\udc4b = 5\nB. 2\n4 56\nC.\n4 7\n4 8\nD.\n4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\n)!(\"\nRelative probabilities of continuous random variables\nLet \ud835\udc4b = time to finish problem set 4.\nSuppose \ud835\udc4b~\ud835\udca9 10, 2 .\nHow much more likely are you to\ncomplete in 10 hours than 5 hours?\n5 10 !\n\ud835\udc43 \ud835\udc4b = 10\n= A. 0/0 = undefined\n\ud835\udc43 \ud835\udc4b = 5\nB. 2\n4 56\nC.\n4 7\n4 8\nD.\n4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n)!(\"\nRelative probabilities of continuous random variables\n5 10 !\n\ud835\udc43 \ud835\udc4b = 10 \ud835\udc53 10 &\n= \ud835\udf00 \ud835\udf00 $# \u2019\n\ud835\udc43 \ud835\udc4b = 5 \ud835\udc53 5 \ud835\udc43 \ud835\udc4b = \ud835\udc4e = \ud835\udc43 \ud835\udc4e \u2212 \u2264 \ud835\udc4b \u2264 \ud835\udc4e + = ? \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 \u2248 \ud835\udf00\ud835\udc53(\ud835\udc4e)\n2 2 &\n$%\n\u2019\n\ud835\udc43 \ud835\udc4b = \ud835\udc4e \ud835\udf00\ud835\udc53 \ud835\udc4e \ud835\udc53 \ud835\udc4e\nTherefore = =\n\ud835\udc43 \ud835\udc4b = \ud835\udc4f \ud835\udf00\ud835\udc53 \ud835\udc4f \ud835\udc53 \ud835\udc4f\n1 )* \" + !\n\ud835\udc52\" ,-!\n\"\n)* \")* ! \ud835\udc52(\n\ud835\udf0e 2\ud835\udf0b \ud835\udc52 ,\u22c5, Ratios of PDFs\n= = = = 518\n1\n\ud835\udc52\"\n.\n,\n\"\n-\n+\n!\n!\n\ud835\udc52\"\n. \"\n,\n\u22c5) ,* ! \ud835\udc52%\u2019 *)\nare meaningful!\n\ud835\udf0e 2\ud835\udf0b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\n)!(\"\nLet \ud835\udc4b = time to finish problem set 4.\nSuppose \ud835\udc4b~\ud835\udca9 10, 2 .\nHow much more likely are you to\ncomplete in 10 hours than 5 hours?\nContinuous\nconditional\ndistributions\n20\nContinuous conditional distributions\nFor continuous RVs \ud835\udc4b and \ud835\udc4c, the conditional PDF of \ud835\udc4b given \ud835\udc4c is\n\ud835\udc53 \ud835\udc65, \ud835\udc66\n\",$\n\ud835\udc53 \ud835\udc65|\ud835\udc66 =\nwhere \ud835\udc53 \ud835\udc66 > 0\n\"|$ !\n\ud835\udc53 \ud835\udc66\n$\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 \ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udf00 \ud835\udf00\n+,, + ,\nIntuition: \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 = \ud835\udc53 \ud835\udc65 \ud835\udc66 \ud835\udf00 =\n\ud835\udc43 \ud835\udc4c = \ud835\udc66 +|, + \ud835\udc53 \ud835\udc66 \ud835\udf00\n, ,\nNote that conditional PDF \ud835\udc53 is a \"true\" density:\n+|,\n/ /\n\ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udc53 \ud835\udc66\n+,, ,\n( \ud835\udc53 \ud835\udc65|\ud835\udc66 \ud835\udc51\ud835\udc65 = ( \ud835\udc51\ud835\udc65 = = 1\n+|,\n\ud835\udc53 \ud835\udc66 \ud835\udc53 \ud835\udc66\n./ ./ , ,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nWhy sums of random variables?\nSometimes modeling and understanding a complex RV, \ud835\udc4b, is difficult.\nBut if we can decompose \ud835\udc4b into the sum of simpler, independent RVs,\n\u2022 We can compute distributions on \ud835\udc4b.\n\u2022 We can better understand how \ud835\udc4b changes as its constituent RVs change.\nWhat can we model\nSum of uniforms!\nwith a triangular PDF?\n\ud835\udc53 \ud835\udc65\n! )\n1 \"\nWe\u2019re covering the\n1 \ud835\udc53 \ud835\udc65\nreverse direction for\n0 1 \ud835\udc65\n1/2 )\nnow; the forward\n\ud835\udc53 \ud835\udc65\n! ,\n1 !\n0 + direction will come\n\ud835\udc65\n0 1/2 1 3/2 2 on Friday\n0 1\n\ud835\udc65\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nEverything* in probability is a sum or a product (or both)\n*except conditional probability (a ratio)\n/\n\ud835\udc38 \ud835\udc4b = ; \ud835\udc65\ud835\udc5d \ud835\udc65\n\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = ( \ud835\udc65\ud835\udc53 \ud835\udc65|\ud835\udc66 \ud835\udc51\ud835\udc65\n+|,\nSum of values that can\n: ./\nweight\nbe considered separately weight\n>\n>\n(possibly weighted by\n\ud835\udc43(\ud835\udc38) = ; \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39\n; ; \ud835\udc43 \ud835\udc38 = ; \ud835\udc43 \ud835\udc38\nprob. of happening) ;\n;<=\nweight ;<=\nLaw of Total Probability Axiom 3, \ud835\udc38 = \ud835\udc38 \u222a \u22ef\u222a \ud835\udc38\n+ ,\n\ud835\udc43(\ud835\udc38 \u2229 \ud835\udc39 \u2229 \ud835\udc3a) = \ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39|\ud835\udc38 \ud835\udc43 \ud835\udc3a|\ud835\udc38\ud835\udc39\nChain Rule\nProduct of values that\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = *\ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\ncan each be considered\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc66 0\n+,, + ,\nin sequence Sum of indep. discrete RVs\nIndependent cont. RVs (convolution)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nConditional probability and Bayes\u2019 Theorem\nDefinition\nIndependence\n\ud835\udc43 \ud835\udc38 \u2229 \ud835\udc39 \ud835\udc38,\ud835\udc39 independent\n\ud835\udc43 \ud835\udc39|\ud835\udc38 =\n\ud835\udc43 \ud835\udc39|\ud835\udc38 = \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc38\nSample space doesn\u2019t need\nScaling to the correct sample space\nto be scaled\nBayes\u2019 Theorem Prior: some prob. of event \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39\nLikelihood\n\ud835\udc43 \ud835\udc39|\ud835\udc38 =\n\ud835\udc43 \ud835\udc38\nPosterior: prob. of\n\ud835\udc39 knowing that \ud835\udc38\nScaling to the correct sample space\nhappened\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nMultiple Bayes\u2019 Theorems\n\ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39\nwith\n\ud835\udc43 \ud835\udc39|\ud835\udc38 =\nevents \ud835\udc43 \ud835\udc38\n\ud835\udc5d \ud835\udc66 \ud835\udc5d \ud835\udc65|\ud835\udc66\n! #|!\n\ud835\udc5d \ud835\udc66|\ud835\udc65 =\nwith\n!|#\n\ud835\udc5d \ud835\udc65\ndiscrete RVs #\nYou are given\nthis value\u2026\n\ud835\udc53 \ud835\udc66 \ud835\udc53 \ud835\udc65|\ud835\udc66\n! #|!\nwith \ud835\udc53 \ud835\udc66|\ud835\udc65 =\n!|#\nReally all the\n\ud835\udc53 \ud835\udc65\ncontinuous RVs\n#\nsame idea!\n\u2026so this is just a scalar\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nIntense\nExercise\n26\nTracking in 2-D space\nYou want to know\nthe 2-D location of\nan object.\nYour satellite ping\ngives you a noisy 1-D\nmeasurement of the\ndistance of the object\nfrom the satellite (0,0).\nUsing the satellite\nmeasurement,\nwhere is the object?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nTracking in 2-D space\n\u2022 Before measuring, we have some Top-down view\nprior belief about the 2-D location\nof an object, \ud835\udc4b, \ud835\udc4c .\nSatellite at (0, 0)\n\u2022 We observe some noisy\nmeasurement \ud835\udc37 = 4, the Euclidean\ndistance of the object to a satellite.\n\ud835\udc37 = 4\n\u2022 After the measurement, what is our ?\nupdated (posterior) belief of the 2-\nD location of the object?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nTracking in 2-D space\n\u2022 You hold some prior beliefs about the 2-D location of an object, \ud835\udc4b, \ud835\udc4c .\n\u2022 You observe a noisy distance measurement, \ud835\udc37 = 4.\n\u2022 How do you update your beliefs about the 2-D location of the object after\nthat noisy measurement?\nprior\nlikelihood\nbelief\nposterior (of evidence)\nRecall Bayes\nbelief\nterminology: \ud835\udc53 \ud835\udc51|\ud835\udc65, \ud835\udc66 \ud835\udc53 \ud835\udc65, \ud835\udc66\n%|#,! #,!\n\ud835\udc53 \ud835\udc65, \ud835\udc66|\ud835\udc51 =\n#,!|%\n\ud835\udc53 \ud835\udc51\n%\nnormalization constant\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n1. Define prior\nYou have a prior belief about the 2-D location of an object, \ud835\udc4b, \ud835\udc4c .\nTop-down view\nLet \ud835\udc4b, \ud835\udc4c = object\u2019s 2-D location,\nassuming satellite is at (0,0)\nSuppose the prior distribution is a\nsymmetric bivariate normal distribution: \ud835\udc66\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\n\ud835\udc66,\ud835\udc65\n\ud835\udc53\n%,!\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n\ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\n3-D view\n:.G !- H.G ! & &\n1 #$% \u2019 ($%\n.\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc52 E E! = \ud835\udc3e \u22c5 \ud835\udc52%\n+,, 2\ud835\udf0b2E 5 )\nnormalizing constant\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n2. Define likelihood \ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\nYou observe a noisy distance measurement, \ud835\udc37 = 4.\nIf you knew your actual location to be \ud835\udc65, \ud835\udc66 , you could argue\nJust how likely a measurement of \ud835\udc37 = 4 actually is.\nLet \ud835\udc37 = measured radial distance from the satellite, where\nactual \ud835\udc65, \ud835\udc66 is known!\n\u2022 \ud835\udc37 is still noisy! Suppose noise is standard normal.\n\u2022 On average, \ud835\udc37 is your true Euclidean distance: \ud835\udc65E + \ud835\udc66E\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n2. Define likelihood \ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\nYou observe a noisy distance measurement, \ud835\udc37 = 4.\nIf you knew your actual location to be \ud835\udc65, \ud835\udc66 , you could argue\nJust how likely a measurement of \ud835\udc37 = 4 actually is.\nLet \ud835\udc37 = measured radial distance from the satellite, where\nactual \ud835\udc65, \ud835\udc66 is known!\n\u2022 \ud835\udc37 is still noisy! Suppose noise is standard normal.\n\u2022 On average, \ud835\udc37 is your true Euclidean distance: \ud835\udc65E + \ud835\udc66E\n\ud835\udc37|\ud835\udc4b, \ud835\udc4c~\ud835\udc41 \ud835\udf07 = \ud835\udc65& + \ud835\udc66&, \ud835\udf0e& = 1\n(\ud835\udc34) (\ud835\udc35)\n1 = !\n. (\ud835\udc37J). :!-H!\n\ud835\udc53 \ud835\udc37 = \ud835\udc51|\ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 = \ud835\udc52 E\nI|+,,\n(2\ud835\udc36)\ud835\udf0b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n2. Define likelihood \ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\nYou observe a noisy distance measurement, \ud835\udc37 = 4.\nIf you knew your actual location to be \ud835\udc65, \ud835\udc66 , you could argue\nJust how likely a measurement of \ud835\udc37 = 4 actually is.\nLet \ud835\udc37 = measured radial distance from the satellite, where\nactual \ud835\udc65, \ud835\udc66 is known!\n\u2022 \ud835\udc37 is still noisy! Suppose noise is standard normal.\n\u2022 On average, \ud835\udc37 is your true Euclidean distance: \ud835\udc65E + \ud835\udc66E\n&\n\ud835\udc37 \ud835\udc37| |\ud835\udc4b \ud835\udc4b, , \ud835\udc4c \ud835\udc4c~ ~\ud835\udc41 \ud835\udc41 \ud835\udf07 \ud835\udf07= = \ud835\udc34 \ud835\udc65& +, \ud835\udf0e \ud835\udc66&,= \ud835\udf0e & =\ud835\udc35 1\n1\n1 = ! = !\n\ud835\udc53 \ud835\udc53I|+,, \ud835\udc37 \ud835\udc37= =\ud835\udc51 \ud835\udc51| |\ud835\udc4b \ud835\udc4b= =\ud835\udc65 \ud835\udc65, ,\ud835\udc4c \ud835\udc4c= =\ud835\udc66 \ud835\udc66 = = \ud835\udc52. E J. \ud835\udc52: !-H!I = \ud835\udc3e \u22c5 \ud835\udc52. E J. :!-H!\nI|+,, \ud835\udc36 2\ud835\udf0b 8\n2\ud835\udf0b\nnormalizing constant\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n3. Compute posterior \ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\nWhat is your updated (posterior) belief of the 2-D location of the object\nafter observing the measurement?\nCompute:\nPosterior\n\ud835\udc53 \ud835\udc65, \ud835\udc66|4 = \ud835\udc53 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66|\ud835\udc37 = 4\n\",$|M \",$|M\nbelief\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\n\ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 \ud835\udc53 \ud835\udc65,\ud835\udc66\n2|!,% !,%\n3. Compute posterior \ud835\udc53 \ud835\udc65,\ud835\udc66|\ud835\udc51 =\n!,%|2\n\ud835\udc53 \ud835\udc51\n2\nWhat is your updated (posterior) belief of the 2-D location of the object\nafter observing the measurement?\nCompute:\nPosterior\n\ud835\udc53 \ud835\udc65, \ud835\udc66|4 = \ud835\udc53 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66|\ud835\udc37 = 4\n\",$|M \",$|M\nbelief\nKnow:\n+ 3\nPrior ! ! Observation % 0% 13#23\n\"#$ % &#$ \ud835\udc53 \ud835\udc51|\ud835\udc65,\ud835\udc66 = \ud835\udc3e \u22c5 \ud835\udc52 \u2019\n. -|\",! \u2019\nbelief \ud835\udc53 \ud835\udc65,\ud835\udc66 = \ud835\udc3e \u22c5 \ud835\udc52 \u2019 likelihood\n!,% )\nTips\n\u2022 Use Bayes\u2019 Theorem!\n\u2022 \ud835\udc53 4 is just a scaling constant. Why?\nI\n\u2022 How can we approximate the final\nscaling constant with a computer?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nTracking in 2-D space\nWhat is your updated (posterior) belief of the 2-D location of the object\nafter observing the measurement?\nlikelihood of \ud835\udc37 = 4 prior belief\n\ud835\udc53 \ud835\udc37 = 4|\ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 \ud835\udc53 \ud835\udc65, \ud835\udc66\nM|\",$ \",$ Bayes\u2019\n\ud835\udc53 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66|\ud835\udc37 = 4 =\n\",$|M\n\ud835\udc53(\ud835\udc37 = 4) Theorem\n!\nM. :!-H! :.G !- H.G !\n. .\n\ud835\udc3e \u22c5 \ud835\udc52 E \u22c5 \ud835\udc3e \u22c5 \ud835\udc52 N\nE =\n=\n\ud835\udc53(\ud835\udc37 = 4)\n!\nM. :!-H! :.G !- H.G !\nKey: Once we know the\n. -\n\ud835\udc3e \u22c5 \ud835\udc52 E N\nG\npart dependent on \ud835\udc65, \ud835\udc66, we =\n\ud835\udc53(\ud835\udc37 = 4)\ncan computationally\n!\napproximate \ud835\udc3e so that ! !\nM (# \" %& ! !\n\"#$ % &#$\n\ud835\udc53 is a valid PDF. . -\n= \ud835\udc3e \u22c5 \ud835\udc52\n+,,|I ! \u2019\nM\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nTracking in 2-D space\nWith this continuous version of Bayes\u2019 Top-down view 3-D view\ntheorem, we can explore new domains.\n\u2022 Before measuring, you hold some\n!\nprior beliefs about the 2-D location of\nan object, \ud835\udc4b, \ud835\udc4c . \"\n\u2022 You observe a noisy distance\nTop-down view 3-D view\nmeasurement, \ud835\udc37=4.\n\u2022 After the measurement, do you\n0.08\n0.04\nupdate your beliefs about the 2-D\nlocation of the object after that\nnoisy measurement.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nTracking in 2-D space: Posterior belief\nPrior belief Posterior belief\nTop-down view 3-D view Top-down view 3-D view\n0.08\n0.04\n\ud835\udc66\n\ud835\udc66\n\ud835\udc65\n\ud835\udc65\n\"#$ ! % &#$ ! \ud835\udc53 \ud835\udc65, \ud835\udc66|4 =\n. +,,|I\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc3e \u22c5 \ud835\udc52\n\u2019\n+,, = !\nM. :!-H! :.G !- H.G !\n. -\n\ud835\udc3e \u22c5 \ud835\udc52 E N\nM\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nHow\u2019d you compute that \ud835\udc3e ?\n!\n/ /\nTo be a valid conditional PDF, ( ( \ud835\udc53 \ud835\udc65, \ud835\udc66|4 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = 1\n+,,|I\n./ ./\n!\n/ / M. :!-H! :.G !- H.G !\n. -\n( ( \ud835\udc3e \u22c5 \ud835\udc52 E N \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = 1\nM\n./ ./\n!\n1 / / M. :!-H! :.G !- H.G !\n. -\n= ( ( \ud835\udc52 E N \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 (pull out \ud835\udc3e , divide)\n*\n\ud835\udc3e\nM ./ ./\nApproximate:\n!\n1 M. :!-H! :.G !- H.G !\n. -\n\u2248 ; ; \ud835\udc52 E N \u2206\ud835\udc65\u2206\ud835\udc66 Use a computer!\n\ud835\udc3e\nM\nH :\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39 <END>"}
{"prompt": "Lecture notes from 19_sampling_bootstrap_annotated.txt\n\n###\n\n", "completion": "19: Sampling and the\nBootstrap\nJerry Cain\nMay 13th, 2024\nLecture Discussion on Ed\n1\nSampling\ndefinitions\n2\nMotivating example\nYou want to know the true mean and\nvariance of happiness in Bhutan.\n\u2022 You can\u2019t ask everyone very easily, so..\n\u2022 You poll 200 random people.\n\u2022 Your poll data looks like this:\nHappiness = {72, 85, 79, 91, 68, \u2026, 71}\n\u2022 The mean of all these numbers is 83.\nIs this the true average happiness of all\nBhutanese people?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nPopulation\nThis is a population.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nSample\nA sample is selected from a population.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nSample\nA sample is selected from a population.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nReasonable Questions Starting Out\n1. In situations where we can\u2019t obverse the entire population, what can we\nsafely infer by polling a sample drawn from that population?\n2. How large does your sample need to be before your conclusions become\ntrustworthy, and how do we express our confidence in those\nconclusions.\n3. Are there alternative ways to infer population statistics without polling\nentire populations?\n\ud835\udf0e\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nA sample, mathematically\nConsider \ud835\udc5b random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\nThe sequence \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b is a sample from distribution \ud835\udc39 if:\n! \" #\n\u2022 \ud835\udc4b are all independent and identically distributed (iid)\n$\n\u2022 \ud835\udc4b all have same distribution function \ud835\udc39 (the underlying distribution),\n$\n\"\nwhere \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e\n$ $\n\ud835\udf07\n\ud835\udf0e\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nA sample, mathematically\nA sample of size 8: 2x\n\ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b\n! \" # $ % & \u2019 (\nThe realization of a sample of size 8:\n\ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b , \ud835\udc4b\n59 87 94 99 87 78 69 91\n! \" # $ % & \u2019 (\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nA single sample\nIf we had a distribution \ud835\udc39 of our entire population,\nwe could compute exact statistics about happiness.\nBut we only have 200 people\u2014or rather, a sample.\nAssuming we have just a single sample,\n\u2022 how do we report estimated statistics?\nA happy \u25e6 We\u2019re careful to call them estimated mean and estimated\nvariance, since they\u2019re based on a sample\nBhutanese person\n\u2022 How do we report confidence intervals on these\nestimates?\n\u2022 How do we perform something called\nhypothesis testing? Oh, and what is it?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nUnbiased\nestimators\n11\nA single sample\nIf we had a distribution \ud835\udc39 of our entire\npopulation, we could compute exact statistics\nabout happiness.\nBut we only have a sample of happiness\nscores from 200 people.\nA happy\nThese population-level statistics are unknown:\nBhutanese person\n\u2022 \ud835\udf07, the population mean\n\"\n\u2022 \ud835\udf0e , the population variance\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nA single sample\nIf we had a distribution \ud835\udc39 of our entire\npopulation, we could compute exact statistics\nabout happiness.\nBut we only have a sample of happiness\nscores from 200 people.\nA happy \u2022 Using this sample, what is our best guess\nBhutanese person estimate of the population mean and the\npopulation variance?\n\u2022 How exactly do we define best guess\nestimate?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nEstimating the population mean\n1. What is our best estimate of \ud835\udf07, the mean\nhappiness of Bhutanese people?\nIf we only have \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b :\n! \" #\n#\n1\n2\nThe best estimate of \ud835\udf07 is the sample mean: \ud835\udc4b = 3 \ud835\udc4b\n$\n\ud835\udc5b\n$%!\n2 2\n\ud835\udc4b is an unbiased estimator of the population mean \ud835\udf07. \ud835\udc38 \ud835\udc4b = \ud835\udf07\n!\n\ud835\udf0e\n)\nIntuition: By the CLT, \ud835\udc4b ~ \ud835\udca9(\ud835\udf07, )\nIf we could take multiple samples of size \ud835\udc5b:\n\ud835\udc5b\n1. For each sample, compute sample mean\n2. On average, we would get the population mean\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nSample mean\n#\n\ud835\udf0e\n\ud835\udc4b ~\ud835\udc39 !\n\ud835\udc4b ~ \ud835\udca9(\ud835\udf07, )\n$\n\ud835\udc5b\nEven if we can\u2019t report \ud835\udf07, we can report our\nsample mean of 83, which is an unbiased\nestimate of \ud835\udf07.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nEstimating the population variance\n\"\n2. What is \ud835\udf0e , the variance of happiness of\nBhutanese people?\nIf we knew the entire population \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 :\n! \" &\npopulation mean\n%\npopulation 1\n! ! !\n\ud835\udf0e = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07 = 9 \ud835\udc65 \u2212 \ud835\udf07\nvariance \"\n\ud835\udc41\n\"#$\nIf we only have one sample: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b :\nsample mean\n! \" #\n#\n1\nsample\n\" 2 \"\n\ud835\udc46 = 3 \ud835\udc4b \u2212 \ud835\udc4b\n$\nvariance \ud835\udc5b \u2212 1\n$%!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n#\nIntuition about the sample variance, \ud835\udc46\n\"\nActual, \ud835\udf0e\npopulation mean\n&\n1\npopulation\n\" \"\n\ud835\udf0e = 3 \ud835\udc65 \u2212 \ud835\udf07\n$\nvariance \ud835\udc41\n$%!\n\ud835\udc65 \u2212 \ud835\udf07\n\"\n0\n150\nHappiness\n\ud835\udf07\nPopulation size, \ud835\udc41\nCalculating population statistics exactly\nrequires us knowing all \ud835\udc41 datapoints.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\n#\nIntuition about the sample variance, \ud835\udc46\n\" \"\nActual, \ud835\udf0e Estimate, \ud835\udc46\npopulation mean sample mean\n& #\n1 1\npopulation sample\n\" \" \" 2 \"\n\ud835\udf0e = 3 \ud835\udc65 \u2212 \ud835\udf07 \ud835\udc46 = 3 \ud835\udc4b \u2212 \ud835\udc4b\nvariance \ud835\udc41 $ variance \ud835\udc5b \u2212 1 $\n$%! $%!\n0\n150\nHappiness\n\ud835\udf07\nPopulation size, \ud835\udc41\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n#\nIntuition about the sample variance, \ud835\udc46\n\" \"\nActual, \ud835\udf0e Estimate, \ud835\udc46\npopulation mean sample mean\n& #\n1 1\npopulation sample\n\" \" \" 2 \"\n\ud835\udf0e = 3 \ud835\udc65 \u2212 \ud835\udf07 \ud835\udc46 = 3 \ud835\udc4b \u2212 \ud835\udc4b\nvariance \ud835\udc41 $ variance \ud835\udc5b \u2212 1 $\n$%! $%!\n0\n150\nHappiness\n\ud835\udc4b$ \ud835\udf07\nPopulation size, \ud835\udc41\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\n#\nIntuition about the sample variance, \ud835\udc46\n\" \"\nActual, \ud835\udf0e Estimate, \ud835\udc46\npopulation mean sample mean\n& #\n1 1\npopulation sample\n\" \" \" 2 \"\n\ud835\udf0e = 3 \ud835\udc65 \u2212 \ud835\udf07 \ud835\udc46 = 3 \ud835\udc4b \u2212 \ud835\udc4b\nvariance \ud835\udc41 $ variance \ud835\udc5b \u2212 1 $\n$%! $%!\n)\n\ud835\udc4b \u2212 \ud835\udc4b\n$\n0\n150\nHappiness\n\ud835\udc4b$ \ud835\udf07\nPopulation size, \ud835\udc41\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nEstimating the population variance\n\"\n2. What is \ud835\udf0e , the variance of happiness of\nBhutanese people?\nIf we only have a sample, \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b :\n! \" #\n#\n1\nThe best estimate of \ud835\udf0e\" is the sample variance: \ud835\udc46\" = 3 \ud835\udc4b \u2212 \ud835\udc4b2 \"\n$\n\ud835\udc5b \u2212 1\n$%!\n\" \" \" \"\n\ud835\udc46 is an unbiased estimator of the population variance, \ud835\udf0e . \ud835\udc38 \ud835\udc46 = \u03c3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n#\nProof that \ud835\udc46 is unbiased (just for reference) \ud835\udc38 \ud835\udc46\" = \ud835\udf0e\"\n% %\n1\n\ud835\udc38 \ud835\udc46! = \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udc4b/ ! \u21d2 \ud835\udc5b \u2212 1 \ud835\udc38 \ud835\udc46! = \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udc4b/ !\n\" \"\n\ud835\udc5b \u2212 1\n\"#$ \"#$\n%\n!\n\ud835\udc5b \u2212 1 \ud835\udc38 \ud835\udc46! = \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udf07 + \ud835\udf07 \u2212 \ud835\udc4b/ (introduce \ud835\udf07 \u2212 \ud835\udf07)\n\"\n\"#$\n$\n% % %\n2 \ud835\udf07 \u2212\ud835\udc4b$ \u2019 \ud835\udc4b \u2212\ud835\udf07\n= \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udf07 ! + - \ud835\udf07 \u2212 \ud835\udc4b/ ! + 2- \ud835\udc4b \u2212 \ud835\udf07 \ud835\udf07 \u2212 \ud835\udc4b/ !\n\" \" !\"#\n$\n\"#$ \"#$ \"#$\n% 2 \ud835\udf07 \u2212\ud835\udc4b$ \u2019\ud835\udc4b \u2212\ud835\udc5b\ud835\udf07\n!\n= \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udf07 ! + \ud835\udc5b \ud835\udf07 \u2212 \ud835\udc4b/ ! \u2212 2\ud835\udc5b \ud835\udf07 \u2212 \ud835\udc4b/ ! !\"#\n\"\n2 \ud835\udf07 \u2212 \ud835\udc4b) \ud835\udc5b \ud835\udc4b) \u2212 \ud835\udf07\n\"#$\n% %\n\u22122\ud835\udc5b \ud835\udf07 \u2212 \ud835\udc4b) !\n= \ud835\udc38 - \ud835\udc4b \u2212 \ud835\udf07 ! \u2212 \ud835\udc5b \ud835\udf07 \u2212 \ud835\udc4b/ ! = -\ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07 ! \u2212 \ud835\udc5b\ud835\udc38 \ud835\udc4b/ \u2212 \ud835\udf07 !\n\" \"\n\"#$ \"#$\n\ud835\udf0e!\n= \ud835\udc5b\ud835\udf0e! \u2212 \ud835\udc5bVar \ud835\udc4b/ = \ud835\udc5b\ud835\udf0e! \u2212 \ud835\udc5b = \ud835\udc5b\ud835\udf0e! \u2212 \ud835\udf0e! = \ud835\udc5b \u2212 1 \ud835\udf0e! Therefore, \ud835\udc38 \ud835\udc46! = \ud835\udf0e!\n\ud835\udc5b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nStandard error\n23\nEstimating population statistics\nA particular outcome\n72, 85,79,79,91,68, \u2026 , 71\n1. Collect a sample, \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n\ud835\udc5b = 200\n!\n2. Compute sample mean,\n\ud835\udc4b2\n=\n\u2211#\n\ud835\udc4b .\n\ud835\udc4b2\n= 83\n$%! $\n#\n3. Compute sample deviation, \ud835\udc4b \u2212 \ud835\udc4b2 . \u221211, 2, \u22124, \u22124,8, \u221215, \u2026 , \u221212\n$\n!\n4. Compute sample variance, \ud835\udc46\" = \u2211# \ud835\udc4b \u2212 \ud835\udc4b2 \" . \ud835\udc46\" = 793\n$%! $\n#6!\n$ \" \"\nHow close are our estimates \ud835\udc4b and \ud835\udc46 to the true \ud835\udf07 and \ud835\udf0e ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nSample mean\n#\n\ud835\udf0e\n\ud835\udc4b ~\ud835\udc39 !\n\ud835\udc4b ~ \ud835\udca9(\ud835\udf07, )\n$\n\ud835\udc5b\n2 2\n\u2022 Var \ud835\udc4b is a measure of how close \ud835\udc4b is to \ud835\udf07.\n2\n\u2022 How do we estimate Var \ud835\udc4b ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\n!\nHow close is our estimate \ud835\udc4b to \ud835\udf07?\n\"\n\ud835\udf0e\n$ We want to\n\ud835\udc38 \ud835\udc4b = \ud835\udf07 2\nVar \ud835\udc4b =\n\ud835\udc5b estimate this\ndef The standard error of the mean is an\n\ud835\udc46\"\n2\nestimate of the standard deviation of \ud835\udc4b.\n\ud835\udc46\ud835\udc38 =\n\ud835\udc5b\nIntuition:\n! !\n\u2022 \ud835\udc46 is an unbiased estimate of \ud835\udf0e\n\u2022 \ud835\udc46! /\ud835\udc5b is an unbiased estimate of \ud835\udf0e! /\ud835\udc5b = Var \ud835\udc4b)\n\u2022 \ud835\udc46!/\ud835\udc5b is an estimate of Var \ud835\udc4b) More info on bias of\nstandard error: wikipedia\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nStandard error of the mean\n1. Mean happiness:\nClaim: The average happiness of Bhutan is 83,\n83\nwith a standard error of 1.99.\nBhutan\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nssenippaH\negarevA\nthis is our best\nerror bars\nestimate of \ud835\udf07\n\ud835\udc46\ud835\udc38\nthis is our estimate of\nClosed\n\ud835\udc46!\n\ud835\udc46\ud835\udc38 = how close we are\n\ud835\udc5b\nform:\n0\n)\nThese 2 statistics give a sense of how \ud835\udc4b\u2014that is,\nthe sample mean random variable\u2014behaves.\nStandard error of variance?\n1. Mean happiness:\nClaim: The average happiness of Bhutan is 83,\n83\nwith a standard error of 1.99.\nBhutan\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nssenippaH\negarevA\nerror bars\n\ud835\udc46\ud835\udc38\nClosed\n\ud835\udc46!\n\ud835\udc46\ud835\udc38 =\n\ud835\udc5b\nform:\n0\nthis is our best\n2. Variance of happiness:\nestimate of \ud835\udf0e!\nClaim: The variance of happiness of Bhutan is 793.\nBut how close Up next: Compute\nClosed\nNot covered \u26a0\nare we?\nstatistics with code!\nform: in CS109\nBootstrap:\nSample mean\n29\nBootstrap\nThe Bootstrap:\nProbability for Computer Scientists\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nComputing statistic of sample mean\n2\nWhat is the standard deviation of the sample mean \ud835\udc4b? (sample size \ud835\udc5b = 200)\n\ud835\udf0e\n= 1.886 Exact statistic\nPopulation\n\ud835\udc5b\n(we don\u2019t have this)\ndistribution\n(we don\u2019t have this)\nSimulated statistic\n1.869\n(we don\u2019t have this)\n\ud835\udc46\nEstimated statistic,\n\ud835\udc46\ud835\udc38 = = 1.992\n\ud835\udc5b by formula,\nSample\nstandard error\ndistribution\n(we do have this) Simulated\n???\nestimated statistic\nNote: We don\u2019t have access to the population.\nBut Doris is sharing the exact statistic with you.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nBootstrap insight 1: Estimate the true distribution\n\u2248\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nBootstrap insight 1: Estimate the true distribution\nYou can estimate the PMF of the underlying distribution, using your sample.*\n\u2248\n#\n\ud835\udc39 \u2248 \ud835\udc39\nThe underlying the sample distribution\ndistribution (aka the histogram of\nyour sample data)\n*This is just a histogram of your da List aa Ya! n, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nBootstrap insight 2: Simulate a distribution\n2\nApproximate the procedure of simulating a distribution of a statistic, e.g., \ud835\udc4b.\nPopulation\ndistribution\nSimulated distribution of\n(we don\u2019t have this)\nsample means\n\u2248\nSample\nSimulated distribution of\nBootstrap\ndistribution\nmeans sample means\n(we do have this)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nBootstrapped sample means\nmeans = [84.7, 83.9, 80.6, 79.8, 90.3, \u2026, 85.2]\nnp.std(means)\n2.003\nEstimate the true PMF \u2026generate a whole \u2026and compute the\nusing our \"PMF\" (histogram) bunch of sample means standard deviation\nof our sample. using this estimated distribution\u2026 of this distribution.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nComputing statistic of sample mean\n2\nWhat is the standard deviation of the sample mean \ud835\udc4b? (sample size \ud835\udc5b = 200)\n\ud835\udf0e\n= 1.886 Exact statistic\nPopulation\n\ud835\udc5b\n(we don\u2019t have this)\ndistribution\n(we don\u2019t have this)\nSimulated statistic\n1.869\n(we don\u2019t have this)\n\ud835\udc46\nEstimated statistic,\n\ud835\udc46\ud835\udc38 = = 1.992\n\ud835\udc5b by formula,\nSample\nstandard error\ndistribution\n(we do have this) Simulated estimated\n2.003\nstatistic, bootstrapped\nstandard error\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nBootstrap algorithm\nBootstrap Algorithm (sample):\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample mean on the resample\n3. You now have a distribution of your sample mean\nWhat is the distribution of your sample mean?\nWe\u2019ll talk about this algorithm\nin detail with a demo!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nBootstrap algorithm\nBootstrap Algorithm (sample):\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the statistic on the resample\n3. You now have a distribution of your statistic\nWhat is the distribution of your statistic?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nBootstrapped sample variance\nBootstrap Algorithm (sample):\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nWhat is the distribution of your sample variance?\nEven without closed forms,\nwe estimate statistics of the sample variance with bootstrapping!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nBootstrap:\nSample variance\n40\nBootstrapped sample variance\nBootstrap Algorithm (sample):\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nGoal What is the distribution of your sample variance?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nBootstrapped variance\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nBootstrapped variance\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nBootstrapped variance\n[52, 38, 98, 107, ..., 94]\nWhy are these\n1. Estimate the PMF using the sample\n\u26a0\nsamples different?\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nThis resampled sample is\ngenerated with replacement.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nBootstrapped variance\n[52, 38, 98, 107, ..., 94]\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nBootstrapped variance\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nBootstrapped variance\n[116, 76, 132, 85, ..., 78]\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 47\nBootstrapped variance\n[116, 76, 132, 85, ..., 78]\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4, 846.1]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\nBootstrapped variance\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4, 846.1]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 49\nBootstrapped variance\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the sample variance on the resample\n3. You now have a distribution of your sample variance\nvariances = [827.4, 846.1, 726.0, \u2026, 860.7]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 50\nBootstrapped variance\n3. You now have a distribution of your sample variance\nvariances = [827.4,\n846.1, 726.0, \u2026,\n860.7]\nWhat is the bootstrapped\nstandard error?\nnp.std(variances)\n\u2022 Simulate a distribution of\nBootstrapped standard error: 66.16\nsample variances\n\u2022 Compute standard deviation\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 51\nStandard error\n1. Mean happiness:\nClaim: The average happiness of Bhutan is 83,\n83\nwith a standard error of 1.99.\nBhutan\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 52\nssenippaH\negarevA\n\ud835\udc46\ud835\udc38\nClosed\n\ud835\udc46!\n\ud835\udc46\ud835\udc38 =\n\ud835\udc5b\nform:\n0\n\ud835\udc46! is our best\n2. Variance of happiness:\nestimate of \ud835\udf0e!\nClaim: The variance of happiness of Bhutan is 793,\nwith a bootstrapped standard error of 66.16.\nthis is how confident we are\nAlgorithm in practice: Resampling\n1. Estimate the PMF using the sample\n2. Repeat 10,000 times:\na. Resample sample.size() from PMF\nb. Recalculate the statistic on the resample\n3. You now have a distribution of your statistic\n[116, 76, 132, 85, ..., 78]\n?\n# values in sample equal to \ud835\udc58\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 =\n\ud835\udc5b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 53\nAlgorithm in practice: Resampling\ndef resample(sample, n):\n# estimate the PMF using the sample\n# draw n new samples from the PMF\nreturn np.random.choice(sample, n, replace = True)\n[116, 76, 132, 85, ..., 78]\n?\n# values in sample equal to \ud835\udc58 This resampled sample is\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 =\n\ud835\udc5b generated with replacement.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 54\nTo the code!\nBootstrap provides a way to calculate probabilities of\nstatistics using code.\nBootstrapping works for any statistic*\n*as long as your sample is iid and the underlying distribution does not have a long tail\nGoogle colab notebook link\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 55\nBradley Efron\n\u2022 Invented bootstrapping in 1979\n\u2022 Still a professor at Stanford\n\u2022 Won a National Science Medal\nInventor of Efron\u2019s dice: 4 dice \ud835\udc34, \ud835\udc35, \ud835\udc36, \ud835\udc37 where:\n\"\n\ud835\udc43 \ud835\udc34 > \ud835\udc35 = \ud835\udc43 \ud835\udc35 > \ud835\udc36 = \ud835\udc43 \ud835\udc36 > \ud835\udc37 = \ud835\udc43 \ud835\udc37 > \ud835\udc34 =\n7\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 56 <END>"}
{"prompt": "Lecture notes from 02_section.txt\n\n###\n\n", "completion": "CS109 April18,2024\nSection 2: Conditional Probability and Bayes\nChrisPiech,MehranSahami,JerryCain,LisaYan,andnumerousCS109CA\u2019s.\nOverview of Section Materials\nThewarm-upquestionsprovidedwillhelpstudentspracticeconceptsintroducedinlectures.Thesectionprob-\nlemsaremeanttoapplytheseconceptsinmorecomplexscenariossimilartowhatyouwillseeinproblemsets\nandexams.Infact,manyofthemareoldexamquestions.\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019ssection.The\nCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\nWarm-ups\n1. Definitions:CiteBayes\u2019Theorem.Canyouexplainwhy \ud835\udc43(\ud835\udc34|\ud835\udc35) isdifferentthan \ud835\udc43(\ud835\udc35|\ud835\udc34)?\n2. TrueorFalse.NotethattruemeanstrueforALLcases.\n(a) Ingeneral, \ud835\udc43(\ud835\udc34\ud835\udc35|\ud835\udc36) = \ud835\udc43(\ud835\udc35|\ud835\udc36)\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36)\n(b) If \ud835\udc34 and \ud835\udc35 areindependent,soare \ud835\udc34 and \ud835\udc35\ud835\udc36 .\n1 Taking Expectation: Breaking Vegas\nPreamble:Whenarandomvariablefitsneatlyintoafamilywe\u2019veseenbefore(e.g.Binomial),wegetitsexpec-\ntationforfree.Whenitdoesnot,wehavetousethedefinitionofexpectation.\nProblem:Ifyoubeton\u201cRed\u201dinRoulette,thereis \ud835\udc5d = 18/38thatyouwithwin$Yanda (1\u2212\ud835\udc5d) probabilitythat\nyoulose$Y.Considerthisalgorithmforaseriesofbets:\nLetY=$1.FirstyoubetY.Ifyouwin,thenstop.Ifyoulose,thensetYtobe2Yandrepeat.\nWhatareyourexpectedwinningswhenyoustop?Itwillhelptorecallthatthesumofageometricseries \ud835\udc4e0+\ud835\udc4e1+\n\ud835\udc4e2 +\u00b7\u00b7\u00b7 = 1 if0 < \ud835\udc4e < 1.Vegasbreaksyou:Whydoesn\u2019teveryonedothis?\n1\u2212\ud835\udc4e\n2 Conditional Probabilities: Missing Not at Random\nPreamble:Wehavethreebigtoolsformanipulatingconditionalprobabilities:\n\u2022 Definitionofconditionalprobability: \ud835\udc43(\ud835\udc38\ud835\udc39) = \ud835\udc43(\ud835\udc38|\ud835\udc39)\ud835\udc43(\ud835\udc39)\n\u2022 LawofTotalProbability: \ud835\udc43(\ud835\udc38) = \ud835\udc43(\ud835\udc38\ud835\udc39) + \ud835\udc43(\ud835\udc38\ud835\udc39\ud835\udc36) = \ud835\udc43(\ud835\udc38|\ud835\udc39)\ud835\udc43(\ud835\udc39) + \ud835\udc43(\ud835\udc38|\ud835\udc39\ud835\udc36)\ud835\udc43(\ud835\udc39\ud835\udc36)\n\u2022 BayesRule: \ud835\udc43(\ud835\udc38|\ud835\udc39) = \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38) = \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38)\n\ud835\udc43(\ud835\udc39) \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38)+\ud835\udc43(\ud835\udc39|\ud835\udc38\ud835\udc36)\ud835\udc43(\ud835\udc38\ud835\udc36)\nThisisagoodtimetocommitthesethreetomemoryandstartthinkingaboutwheneachofthemisuseful.\nProblem:YoucollectdataonwhetherornotpeopleintendtovoteforAyesha,acandidateinanupcomingelec-\ntion.Yousendanelectronicpollto100randomlychosenpeople.Youassumeall100responsesareindependent\nandidenticallydistributed.\nUserResponse Count\nRespondedthattheywillvoteforAyesha 40\nRespondedthattheywillnotvoteforAyesha 45\nDidnotrespond 15\nLet \ud835\udc34 betheeventthatapersonwillvoteforAyesha.Let \ud835\udc40 betheeventthatauserdidnotrespondtothepoll.\nWeareinterestedinestimating \ud835\udc43(\ud835\udc34),thoughcomputingthatestimateisdifficult,giventhat15usersdidn\u2019tactu-\nallyrespond.\na. WhatistheprobabilitythatausersaidtheywillvoteforAyeshaandthattheyrespondedtothepoll \ud835\udc43(\ud835\udc34 and \ud835\udc40\ud835\udc36)?\nb. Whichformulafromclasswouldyouusetocalculate \ud835\udc43(\ud835\udc34)?Yourformulashouldrelyonthecontextthat\nvotersforAyeshaareinoneoftwo(mutuallyexclusive)groups:thosethatmissedthepoll,andthosethat\ndidnot.\nc. Calculatethe \ud835\udc43(\ud835\udc34).Youestimatethattheprobabilitythatavoterismissing,giventhattheyweregoingto\nvoteforAyeshais \ud835\udc43(\ud835\udc40|\ud835\udc34) = 1.\n5\n3 Sending Bits to Space\nPreamble: Whensendingbinarydatatosatellites(orreallyoveranynoisychannel),thebitscanbeflippedwith\nhighprobability.In1947,RichardHammingdevelopedasystemtomorereliablysenddata.ByusingErrorCor-\nrectingHammingCodes,youcansendastreamof4bitsalongwith3redundantbits.Ifzerooroneoftheseven\nbitsarecorrupted,usingerrorcorrectingcodes,areceivercanidentifytheoriginal4bits.\nProblem: Letsconsiderthecaseofsendingasignaltoasatellitewhereeachbitisindependentlyflippedwith\nprobability \ud835\udc5d = 0.1.\na. Ifyousend4bits,whatistheprobabilitythatthecorrectmessagewasreceived(i.e.noneofthebitsare\nflipped).\nb. Ifyousend4bits,with3Hammingerrorcorrectingbits,whatistheprobabilitythataninterpretablemes-\nsage(i.e.amessagewithzerooroneerrors)wasreceived?\nc. InsteadofusingHammingcodes,youdecidetosend100copiesofeachofthefourbits.Ifforeverysingle\nbit,morethan50ofthecopiesarenotflipped,thesignalwillbecorrectable.Whatistheprobabilitythata\ncorrectablemessagewasreceived?\nExtra:Explanationofthe\u201dHamming(7,4)\u201dtechnique\nIfwearetryingtotransmit4bits,wecansendanadditional3\u201dparity\u201dbitsthatwecanusetocorrectourorig-\ninalmessageifabitgetsflippedduetoanerrorintransmission.Considerthediagram.Thedatabitsare \ud835\udc51\n1\nthrough \ud835\udc51 .The\u201dparity\u201dbitsare \ud835\udc5d through \ud835\udc5d .Aparitybitissettowhatevervaluewouldmakeit\u2019slargecir-\n4 1 3\nclehaveanevennumberofbits.Forexample,thegreencircleconsistsof \ud835\udc5d , \ud835\udc51 , \ud835\udc51 ,and \ud835\udc51 .If \ud835\udc51 = 1, \ud835\udc51 = 1,\n1 1 2 4 1 2\nand \ud835\udc51 = 1,then \ud835\udc5d wouldbesetto1inordertoensurethereareanevennumberofbitsinthatcircle(inthis\n4 1\ncase,4bits).\nConvinceyourselfthatasingleerrorwhichappearedinanybitcouldbeidentifiedandcorrected!Forexample,\nif \ud835\udc51 isflipped,itwouldthrowofftheparityforthegreenandredcircles.Therefore,flipping \ud835\udc51 backistheonly\n2 2\nwaytocorrecttheparity.Asanotherexample,if \ud835\udc5d isflipped,thenonlythebluecirclewouldhaveaparityis-\n2\nsue,andflipping \ud835\udc5d backistheuniquesolutiontofixingtheparity.\n2 <END>"}
{"prompt": "Lecture notes from cs109_lec07_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 7: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nUnderstanding Variance 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nCoin Flips 3 / 3 pts\n2.1 Coin Flips: Seven Up 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 Coin Flips: Which Coin? 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.3 Coin Flips: Expectation 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Understanding Variance\n1 Point\nTrue or False: The variance of a probability distribution be negative?\nTrue\nFalse\nQ2 Coin Flips\n3 Points\nYou have one biased coin (where the probability of getting heads is 0.7 on any\nflip) and one unbiased coin. You randomly select one of these two coins and\nproceed to flip it exactly 10 times.\nQ2.1 Coin Flips: Seven Up\n1 Point\nWhat is the probability that you get 7 heads in all 10 flips? (to 3 decimal places,\nformatted as 0.abc)\n0.192\nQ2.2 Coin Flips: Which Coin?\n1 Point\nGiven that I see 7 heads in 10 flips, what is the probability that I chose the biased\ncoin? (to 3 decimal places, formatted as 0.abc))\n0.695\nQ2.3 Coin Flips: Expectation\n1 Point\nSuppose that your friend now tells you that you indeed chose the biased coin.\nWhat is the expected number of heads you will flip on 10 trials using the biased\ncoin?\n7 <END>"}
{"prompt": "Lecture notes from 06_rvs_annotated.txt\n\n###\n\n", "completion": "06: Random Variables\nJerry Cain\nApril 12th, 2024\nLecture Discussion on Ed\n1\nConditional\nIndependence\n2\nConditional Paradigm\nFor any events A, B, and E, you can condition consistently on E,\nand all formulas still hold:\nAxiom 1 0 \u2264 \ud835\udc43 \ud835\udc34 \ud835\udc38 \u2264 1\n!\nCorollary 1 (complement) \ud835\udc43 \ud835\udc34 \ud835\udc38 = 1 \u2212 \ud835\udc43 \ud835\udc34 |\ud835\udc38\nTransitivity \ud835\udc43 \ud835\udc34\ud835\udc35 \ud835\udc38 = \ud835\udc43(\ud835\udc35\ud835\udc34|\ud835\udc38)\nChain Rule \ud835\udc43 \ud835\udc34\ud835\udc35 \ud835\udc38 = \ud835\udc43(\ud835\udc35|\ud835\udc38)\ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38\n\ud835\udc43 \ud835\udc35 \ud835\udc34\ud835\udc38 \ud835\udc43 \ud835\udc34|\ud835\udc38\nBayes\u2019 Theorem \ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38 =\n\ud835\udc43(\ud835\udc35|\ud835\udc38) \u2018s theorem?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nIndependent \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nConditional Independence\nevents \ud835\udc38 and \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 = \ud835\udc43(\ud835\udc38)\nTwo events \ud835\udc34 and \ud835\udc35 are defined as conditionally independent given \ud835\udc38 if:\n\ud835\udc43 \ud835\udc34\ud835\udc35|\ud835\udc38 = \ud835\udc43 \ud835\udc34|\ud835\udc38 \ud835\udc43(\ud835\udc35|\ud835\udc38)\nAn equivalent definition:\nA. \ud835\udc43 \ud835\udc34 \ud835\udc35 = \ud835\udc43 \ud835\udc34\nB. \ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38 = \ud835\udc43 \ud835\udc34\nC. \ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38 = \ud835\udc43 \ud835\udc34|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nIndependent \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nConditional Independence\nevents \ud835\udc38 and \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 = \ud835\udc43(\ud835\udc38)\nTwo events \ud835\udc34 and \ud835\udc35 are defined as conditionally independent given \ud835\udc38 if:\n\ud835\udc43 \ud835\udc34\ud835\udc35|\ud835\udc38 = \ud835\udc43 \ud835\udc34|\ud835\udc38 \ud835\udc43(\ud835\udc35|\ud835\udc38)\nAn equivalent definition:\nA. \ud835\udc43 \ud835\udc34 \ud835\udc35 = \ud835\udc43 \ud835\udc34\nE is the \"new sample space\",\nB. \ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38 = \ud835\udc43 \ud835\udc34\nso left and right side must\nboth be conditioned on E.\nC. \ud835\udc43 \ud835\udc34 \ud835\udc35\ud835\udc38 = \ud835\udc43 \ud835\udc34|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nNetflix and Condition Review\nLet \ud835\udc38 = a user watches Life is Beautiful.\nLet \ud835\udc39 = a user watches Amelie.\nWhat is \ud835\udc43 \ud835\udc38 ?\n# people who have watched movie\n$%,\u2019(),\u2019($\n\ud835\udc43 \ud835\udc38 \u2248 = \u2248 0.20\n# people on Netflix\n*%,+\u2019(,$\u2019(\nWhat is the probability that a user watches\nLife is Beautiful, given they watched Amelie?\n\ud835\udc43 \ud835\udc38\ud835\udc39 # people who have watched both\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = = \u2248 0.42\n\ud835\udc43(\ud835\udc39) # people who have watched Amelie\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nNetflix and Condition Review\nLet \ud835\udc38 be the event that a user watches the given movie.\nLet \ud835\udc39 be the event that the same user watches Amelie.\n\ud835\udc43 \ud835\udc38 = 0.19 \ud835\udc43 \ud835\udc38 = 0.32 \ud835\udc43 \ud835\udc38 = 0.20 \ud835\udc43 \ud835\udc38 = 0.09 \ud835\udc43 \ud835\udc38 = 0.20\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.14 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.35 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.20 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.72 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.42\nIndependent!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nNetflix and Condition (on many movies)\nWill they\nWatched:\nwatch?\n\ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38\n( ) * +\nWhat if \ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 are not independent?\n(e.g., all international emotional comedies)\n$ \u2019 ( )\n\ud835\udc43 \ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 # people who have watched all 4\n$ \u2019 ( )\n=\n\ud835\udc43 \ud835\udc38 |\ud835\udc38 \ud835\udc38 \ud835\udc38 =\n) $ \u2019 ( \ud835\udc43 \ud835\udc38 \ud835\udc38 \ud835\udc38 # people who have watched those 3\n$ \u2019 (\nWe need to keep track of an exponential number of movie-watching statistics\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nNetflix and Condition (on many movies)\n\ud835\udc3e: likes international emotional comedies\nWill they\nWatched:\nwatch?\n\ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38\n( ) * +\nAssume: \ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 are conditionally independent given \ud835\udc3e\n$ \u2019 ( )\n\ud835\udc43 \ud835\udc38 |\ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc3e = \ud835\udc43 \ud835\udc38 |\ud835\udc3e\n\ud835\udc43 \ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 ) $ \u2019 ( )\n$ \u2019 ( )\n\ud835\udc43 \ud835\udc38 |\ud835\udc38 \ud835\udc38 \ud835\udc38 =\n) $ \u2019 (\n\ud835\udc43 \ud835\udc38 \ud835\udc38 \ud835\udc38\nAn easier probability to store and compute!\n$ \u2019 (\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nNetflix and Condition\n\ud835\udc3e: likes international emotional comedies\nChallenge: How\ndo we determine\n\ud835\udc3e? Stay tuned in\n6 weeks\u2019 time!\n\ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38\n( ) * +\n\ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 are \ud835\udc38 \ud835\udc38 \ud835\udc38 \ud835\udc38 are\n$ \u2019 ( ) $ \u2019 ( )\ndependent conditionally independent\ngiven \ud835\udc3e\nDependent events can be conditionally independent.\n(And vice versa: Independent events can be conditionally dependent.)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nRandom\nVariables\n11\nRandom variables are like typed variables\ne name\np\ny\nt v \ud835\udc34 is the number of Pokemon we\nal\nu\ne\nint a = 5; bring to our future battle.\n\ud835\udc34 \u2208 1, 2, \u2026 , 6\n\ud835\udc35 is the amount of money we get\ndouble b = 4.2;\nafter we win a battle.\n,\n\ud835\udc35 \u2208 \u211d\n\ud835\udc36 is 1 if we successfully beat the\nbit c = 1;\nElite Four. 0 otherwise.\n\ud835\udc36 \u2208 {0,1}\nRandom variables are like typed\nRandom\nCS variables variables (with uncertainty)\nvariables\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nRandom Variable\nA random variable is a real-valued function defined on a sample space.\nExperiment Outcome \ud835\udc4b = \ud835\udc58\n1. What is the value of \ud835\udc4b for the outcomes:\nExample:\n\u2022 (T,T,T)?\n\u2022 (H,H,T)?\n3 coins are flipped.\nLet \ud835\udc4b = # of heads. 2. What is the event (set of outcomes) where \ud835\udc4b = 2?\n\ud835\udc4b is a random variable.\n3. What is \ud835\udc43 \ud835\udc4b = 2 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nRandom Variable\nA random variable is a real-valued function defined on a sample space.\nExperiment Outcome \ud835\udc4b = \ud835\udc58\n1. What is the value of \ud835\udc4b for the outcomes:\nExample:\n\u2022 (T,T,T)?\n\u2022 (H,H,T)?\n3 coins are flipped.\nLet \ud835\udc4b = # of heads. 2. What is the event (set of outcomes) where \ud835\udc4b = 2?\n\ud835\udc4b is a random variable.\n3. What is \ud835\udc43 \ud835\udc4b = 2 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nRandom variables are NOT events!\nIt is confusing that random variables and events use the same notation.\n\u2022 Random variables \u2260 events.\n\u2022 We can define an event to be a particular assignment of a random\nvariable, or more generally, in terms of a random variable.\nExample:\n3 coins are flipped.\n\ud835\udc4b = 2 \ud835\udc43(\ud835\udc4b = 2)\nLet \ud835\udc4b = # of heads.\n\ud835\udc4b is a random variable.\nevent probability\n(number b/t 0 and 1)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nRandom variables are NOT events!\nIt is confusing that random variables and events use the same notation.\n\u2022 Random variables \u2260 events.\n\u2022 We can define an event to be a particular assignment of a random\nvariable, or more generally, in terms of a random variable.\n\ud835\udc4b = \ud835\udc65 Set of outcomes \ud835\udc43 \ud835\udc4b = \ud835\udc58\n\ud835\udc4b = \ud835\udfce {(T, T, T)} 1/8\nExample:\n\ud835\udc4b = \ud835\udfcf {(H, T, T), (T, H, T), 3/8\n(T, T, H)}\n3 coins are flipped.\n\ud835\udc4b = \ud835\udfd0 {(H, H, T), (H, T, H), 3/8\nLet \ud835\udc4b = # of heads. (T, H, H)}\n\ud835\udc4b is a random variable. \ud835\udc4b = \ud835\udfd1 {(H, H, H)} 1/8\n\ud835\udc4b \u2265 4 { } 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nPMF/CDF\n17\nSo far\n3 coins are flipped. Let \ud835\udc4b = # of heads. \ud835\udc4b is a random variable.\nOutcome\nExperiment \ud835\udc4b = ___ \ud835\udc43 \ud835\udc4b = ___\n(flip __ heads)\nCan we get a \"shorthand\" for\nthis last step?\nSeems like it might be useful!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nProbability Mass Function\n3 coins are flipped. Let \ud835\udc4b = # of heads. \ud835\udc4b is a random variable.\nparameter/input \ud835\udc58\nA function on \ud835\udc58 return value/output\n\ud835\udc43(\ud835\udc4b = \ud835\udc58)\nnumber between\nwith range [0,1]\n0 and 1\nWhat would be a useful function to define?\nThe probability of the event that a random variable \ud835\udc4b takes on the value \ud835\udc58!\nFor discrete random variables, this is a probability mass function.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nProbability Mass Function\n3 coins are flipped. Let \ud835\udc4b = # of heads. \ud835\udc4b is a random variable.\nparameter/input \ud835\udc58:\n2\na value of \ud835\udc4b\nA function on \ud835\udc58\n\ud835\udc43(\ud835\udc4b = 2)\n0.375\nwith range [0,1]\nreturn value/output:\nprobability of the event\n\ud835\udc4b = 2\nprobability mass function\ndef prob_x(n, k, p):\nn_ways = math.comb(n, k)\np_way = p ** k * (1 \u2013 p) ** (n - k)\nreturn n_ways * p_way\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nDiscrete RVs and Probability Mass Functions\nA random variable \ud835\udc4b is discrete if it can take on countably many values.\n\u2022 \ud835\udc4b = \ud835\udc65, where \ud835\udc65 \u2208 \ud835\udc65 , \ud835\udc65 , \ud835\udc65 , \u2026\n$ \u2019 (\nThe probability mass function (PMF) of a discrete random variable is\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 = \ud835\udc5d \ud835\udc65 = \ud835\udc5d (\ud835\udc65)\n4\nshorthand notation\n:\n\u2022 Probabilities must sum to 1: > \ud835\udc5d \ud835\udc65 = 1\n8\nThis last point is a good\n89$\nway to verify any PMF\nyou create is valid\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nPMF for a single 6-sided die\nLet \ud835\udc4b be a random variable that\nrepresents the result of a single\n1/6\ndice roll.\n\u2022 Support of \ud835\udc4b : 1, 2, 3, 4, 5, 6\n\u2022 Therefore, \ud835\udc4b is a discrete\nrandom variable.\n\u2022 PMF of X:\n0\n1/6 \ud835\udc65 \u2208 {1, \u2026 , 6} 1 2 3 4 5 6\n\ud835\udc5d \ud835\udc65 = B\n0 otherwise \ud835\udc4b = \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\nCumulative Distribution Functions\nFor a random variable \ud835\udc4b, the cumulative distribution function (CDF) is\ndefined as\n\ud835\udc39 \ud835\udc4e = \ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e , where \u2212 \u221e < \ud835\udc4e < \u221e\n?\nFor a discrete RV \ud835\udc4b, the CDF is:\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = > \ud835\udc5d(\ud835\udc65)\nall\n@AB\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nLet \ud835\udc4b be a random variable that\nrepresents the result of a single\ndice roll.\n1/6\n0 1 2 3 4 5 6\n\ud835\udc4b = \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\nCDF (cumulative\nCDFs as graphs \ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e\ndistribution function)\n\ud835\udc4e\n\ud835\udc39\nCDF of \ud835\udc4b\nPMF of \ud835\udc4b 5/6\n4/6 \ud835\udc43 \ud835\udc4b \u2264 6 = 1\n3/6\n2/6\n1/6\n\ud835\udc43 \ud835\udc4b \u2264 0 = 0\n\ud835\udc4b = \ud835\udc65\nExpectation\n25\nDiscrete random variables\nPMF\nExperiment\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 = \ud835\udc5d(\ud835\udc65)\noutcomes\nDiscrete CDF \ud835\udc39 \ud835\udc65\nDefinition\nRandom\nProperties\nVariable, \ud835\udc4b\nWithout performing the experiment:\n\u2022 The support tells us which values\nour random variable might produce\nSupport\n\u2022 Next up: How do we report the\n\"average\" value?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nExpectation\nThe expectation of a discrete random variable \ud835\udc4b is defined as:\n\ud835\udc38 \ud835\udc4b = 6 \ud835\udc5d \ud835\udc65 \u22c5 \ud835\udc65\n6:8 6 9:\n\u2022 Note: sum over all values of \ud835\udc4b = \ud835\udc65 that have non-zero probability.\n\u2022 Other names: mean, expected value, weighted average,\ncenter of mass, first moment\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nExpectation\n\ud835\udc38 \ud835\udc4b = E \ud835\udc5d \ud835\udc65 \u22c5 \ud835\udc65\nExpectation of a die roll\nof \ud835\udc4b\n!:# ! $%\nWhat is the expected value of a 6-sided die roll?\n1. Define random\n\ud835\udc4b = RV for value of roll\nvariables\n1/6 \ud835\udc65 \u2208 {1, \u2026 , 6}\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 = B\n0 otherwise\n2. Solve\n1 1 1 1 1 1 7\n\ud835\udc38 \ud835\udc4b = 1 + 2 + 3 + 4 + 5 + 6 =\n6 6 6 6 6 6 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nImportant properties of expectation\n1. Linearity:\n\u2022 Let \ud835\udc4b = 6-sided dice roll,\n\ud835\udc4c = 2\ud835\udc4b \u2212 1.\n\ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f\n\u2022 \ud835\udc38 \ud835\udc4b = 3.5\n\u2022 \ud835\udc38 \ud835\udc4c = 6\n2. Expectation of a sum = sum of expectation: Sum of two dice rolls:\n\u2022 Let \ud835\udc4b = roll of die 1\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\n\ud835\udc4c = roll of die 2\n\u2022 \ud835\udc38 \ud835\udc4b + \ud835\udc4c = 3.5 + 3.5 = 7\n3. Unconscious statistician:\n\ud835\udc38 \ud835\udc54 \ud835\udc4b = ) \ud835\udc54 \ud835\udc65 \ud835\udc5d(\ud835\udc65)\nThese properties let you avoid\ndefining difficult PMFs.\n$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nLinearity of Expectation proof \ud835\udc38 \ud835\udc4b = $ \ud835\udc5d \ud835\udc65 \u22c5\ud835\udc65\n!:# ! $%\n\ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f\nProof:\n\ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f = > \ud835\udc4e\ud835\udc65 + \ud835\udc4f \ud835\udc5d \ud835\udc65 = > \ud835\udc4e\ud835\udc65\ud835\udc5d \ud835\udc65 + \ud835\udc4f\ud835\udc5d \ud835\udc65\n@ @\n= \ud835\udc4e > \ud835\udc65\ud835\udc5d(\ud835\udc65) + \ud835\udc4f > \ud835\udc5d \ud835\udc65\n@ @\n= \ud835\udc4e \ud835\udc38 \ud835\udc4b + \ud835\udc4f \u22c5 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nExpectation of Sum intuition \ud835\udc38 \ud835\udc4b = $ \ud835\udc5d \ud835\udc65 \u22c5\ud835\udc65\n!:# ! $%\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c we\u2019ll prove this in a\nfew lectures\nIntuition \ud835\udc4b \ud835\udc4c \ud835\udc4b + \ud835\udc4c\nfor now: 3 6 9\n2 4 6\n6 12 18\n10 20 30\n-1 -2 -3\n0 0 0\n8 16 24\n) ) )\n1 1 1\nAverage: E\ud835\udc65 + E\ud835\udc66 = E \ud835\udc65 + \ud835\udc66\n& & & &\n\ud835\udc5b \ud835\udc5b \ud835\udc5b\n&\u2019( &\u2019( &\u2019(\n( ( (\n(28) + (56) = (84)\n/ / /\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nExpectation\n\ud835\udc38 \ud835\udc54 \ud835\udc4b = E\ud835\udc54 \ud835\udc65 \ud835\udc5d(\ud835\udc65)\nLOTUS proof\nof \ud835\udc54 \ud835\udc4b\n!\nLet \ud835\udc4c = \ud835\udc54(\ud835\udc4b), where \ud835\udc54 is a real-valued function.\n\ud835\udc38 \ud835\udc54 \ud835\udc4b = \ud835\udc38 \ud835\udc4c = > \ud835\udc66 \ud835\udc5d(\ud835\udc66 )\nK K\nK\n= ? \ud835\udc66 ? \ud835\udc5d(\ud835\udc65 )\n0 1\n0 1:3 4 5 7\n! \"\n= ? ? \ud835\udc66 \ud835\udc5d(\ud835\udc65 )\n0 1\n0 1:3 4 5 7\n! \"\n= ? ? \ud835\udc54(\ud835\udc65 ) \ud835\udc5d(\ud835\udc65 )\n1 1\nFor you to review\n0 1:3 4 5 7\n! \"\nso that you can\n= > \ud835\udc54(\ud835\udc65 ) \ud835\udc5d(\ud835\udc65 ) sleep tonight!\n8 8\nLisa Yan, Chris8 Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nExercises\n33\nA Whole New World with Random Variables\nEvent-driven probability Random Variables\n\u2022 Relate only binary events \u2022 Link multiple similar events\ntogether (\ud835\udc4b = 1, \ud835\udc4b = 2, \u2026 , \ud835\udc4b = 6)\n\u25e6 Either something happens (\ud835\udc38)\n\u25e6 or it doesn\u2019t happen (\ud835\udc38*)\n\u2022 Can only report probability \u2022 Can compute statistics: report the\n\"average\" outcome\n\u2022 Lots of combinatorics \u2022 Once we have the PMF (for\ndiscrete RVs), we can do regular\nmath\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nExample random variable\nConsider 5 flips of a coin which comes up heads with probability \ud835\udc5d.\nEach coin flip is an independent trial. Let \ud835\udc80 = # of heads on 5 flips.\n1. What is the support of \ud835\udc4c? In other words, what are the values that \ud835\udc4c can\ntake on with non-zero probability?\n2. Define the event \ud835\udc4c = 2. What is \ud835\udc43 \ud835\udc4c = 2 ?\n3. What is the PMF of \ud835\udc4c? In other words, what\nis \ud835\udc43 \ud835\udc4c = \ud835\udc58 , for \ud835\udc58 in the support of \ud835\udc4c?\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nExample random variable\nConsider 5 flips of a coin which comes up heads with probability \ud835\udc5d.\nEach coin flip is an independent trial. Let \ud835\udc80 = # of heads on 5 flips.\n1. What is the support of \ud835\udc4c? In other words, what are the values that \ud835\udc4c can\ntake on with non-zero probability?\n0, 1, 2, 3, 4, 5\n5\n\u2019 (\n2. Define the event \ud835\udc4c = 2. What is \ud835\udc43 \ud835\udc4c = 2 ? \ud835\udc43 \ud835\udc4c = 2 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n2\n3. What is the PMF of \ud835\udc4c? In other words, what\n5\nis \ud835\udc43 \ud835\udc4c = \ud835\udc58 , for \ud835\udc58 in the support of \ud835\udc4c?\nO *PO\n\ud835\udc43 \ud835\udc4c = \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nLying with statistics\nA school has 3 classes with 5, 10, and 150 students.\nWhat is the average class size?\n1. Interpretation #1 2. Interpretation #2\n\u2022 Randomly choose a class \u2022 Randomly choose a student\nwith equal probability. with equal probability.\n\u2022 \ud835\udc4b = size of chosen class \u2022 \ud835\udc4c = size of chosen class\n1 1 1 5 10 150\n\ud835\udc38 \ud835\udc4b = 5 + 10 + 150 \ud835\udc38 \ud835\udc4c = 5 + 10 + 150\n3 3 3 165 165 165\n165 22635\n= = 55 = \u2248 137\n3 165\nWhat alumni relations usually reports Average student perception of class size\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nExpectation\n\ud835\udc38 \ud835\udc54 \ud835\udc4b = E\ud835\udc54 \ud835\udc65 \ud835\udc5d(\ud835\udc65)\nBeing a statistician unconsciously\nof \ud835\udc54 \ud835\udc4b\n!\nLet \ud835\udc4b be a discrete random variable.\n$\n\u2022 \ud835\udc43 \ud835\udc4b = \ud835\udc65 = for \ud835\udc65 \u2208 {\u22121, 0, 1}\n(\nLet \ud835\udc4c = |\ud835\udc4b|. What is \ud835\udc38 \ud835\udc4c ?\n! ! !\nA. \u22c5 1 + \u22c5 0 + \u22c5 \u22121 = 0\n\" \" \"\nB. \ud835\udc38 \ud835\udc4c = \ud835\udc38 0 = 0\n! # #\nC. \u22c5 0 + \u22c5 1 =\n\" \" \"\n! ! ! #\nD. \u22c5 \u22121 + \u22c5 0 + 1 =\n\" \" \" \"\nE. C and D\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nExpectation\n\ud835\udc38 \ud835\udc54 \ud835\udc4b = E\ud835\udc54 \ud835\udc65 \ud835\udc5d(\ud835\udc65)\nBeing a statistician unconsciously\nof \ud835\udc54 \ud835\udc4b\n!\nLet \ud835\udc4b be a discrete random variable.\n$\n\u2022 \ud835\udc43 \ud835\udc4b = \ud835\udc65 = for \ud835\udc65 \u2208 {\u22121, 0, 1}\n(\nLet \ud835\udc4c = |\ud835\udc4b|. What is \ud835\udc38 \ud835\udc4c ?\n! ! !\nA. \u22c5 1 + \u22c5 0 + \u22c5 \u22121 = 0 \u274c\n\ud835\udc38 \ud835\udc4b\n\" \" \"\nB. \ud835\udc38 \ud835\udc4c = \ud835\udc38 0 = 0 \u274c \ud835\udc38 \ud835\udc38 \ud835\udc4b\n( )\n1. Find PMF of \ud835\udc4c: \ud835\udc5d 0 = , \ud835\udc5d 1 =\n! # # 8 8\nC. \u22c5 0 + \u22c5 1 = * *\n\" \" \" 2. Compute \ud835\udc38[\ud835\udc4c]\n! ! ! #\nD. \u22c5 \u22121 + \u22c5 0 + 1 = Use LOTUS by using PMF of X:\n\" \" \" \"\n1. \ud835\udc43 \ud835\udc4b = \ud835\udc65 \u22c5 \ud835\udc65\nE. C and D\n2. Sum up\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39 <END>"}
{"prompt": "Lecture notes from 04_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May2nd,2024\nContinuous Random Variables, Joint Distributions\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Reviewing the Basics\na. GivenaNormalRV \ud835\udc4b \u223c \ud835\udc41(\ud835\udf07,\ud835\udf0e2),howcanwecompute \ud835\udc43(\ud835\udc4b \u2264 \ud835\udc65) fromthestandard\nNormaldistributionZwithCDF \ud835\udf19?\nb. Whatisacontinuitycorrectionandwhenshouldweuseit?\nc. IfwehaveajointPMFfordiscreterandomvariables \ud835\udc5d \ud835\udc4b,\ud835\udc4c(\ud835\udc65,\ud835\udc66),howcanwecomputethe\nmarginalPMF \ud835\udc5d \ud835\udc4b(\ud835\udc65)?\n1.2 Independent Random Variables\na. WhatdistributiondoesthesumoftwoindependentbinomialRVs \ud835\udc4b +\ud835\udc4c have,where \ud835\udc4b \u223c\n\ud835\udc35\ud835\udc56\ud835\udc5b(\ud835\udc5b , \ud835\udc5d) and\ud835\udc4c \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(\ud835\udc5b , \ud835\udc5d)?Includeanyparameterswithyouranswer.\n1 2\nb. WhatdistributiondoesthesumoftwoindependentPoissonRVs \ud835\udc4b +\ud835\udc4c have,where \ud835\udc4b \u223c\nPoi(\ud835\udf06 ) and\ud835\udc4c \u223c Poi(\ud835\udf06 )?Includeanyparameterswithyouranswer.\n1 2\n2 Marguerite Gets Some Competition\nInthelate1880s,Stanfordbeganrunningahorseandtwelve-personbuggyservicefromtheStan-\nfordQuadtothetrainstationjustoffcampus.Thenameofthisshuttlingservicewaschosentobe\nMarguerite,whichwasthenameofthefavoritehorseofsomeStanfordbigwigofthetime.The\nhorse-and-carriageoperationwasretiredaround1910andreplacedwithelectricstreetcars,which\nthemselveswerereplacedwithbusesaround1930.Theservicehasgrownsubstantiallysince,and\nthebuseshavebeenupgradedseveraltimes.Theservice,however,hasretaineditsnamesincethe\nverybeginning.\nSeveralStanfordhorseenthusiastshaverecentlyrevivedthehorse-and-buggyservicetocompete\nwithMarguerite,andthey\u2019vegivenitthenameHildegard.Now,whenyouneedaridefromthe\nQuadtothetrainstation,youhavetwooptions!\nYouarriveattheQuad,headedtothetrainstation,andyou\u2019reequallyhappytotakeeitherofthe\ntwoindependentservices.Youarrivepreciselyat8:00am,whichisthetimethatbothservices\nstartfortheday.ThenumberofminutesyouneedtowaitforaMargueritebusismodeledbya\ndiscreteUniformrandomvariable \ud835\udc40 \u223c \ud835\udc48\ud835\udc5b\ud835\udc56(0,20),whereasthenumberofminutesyouneed\ntowaitforaHildegardhorse-and-buggyismodeledbyadiscretePoissonrandomvariable \ud835\udc3b \u223c\n\ud835\udc43\ud835\udc5c\ud835\udc56(10).(Yes,it\u2019stechnicallypossiblethatHildegardneverarrives.)\n\u20132\u2013\na. WhatistheprobabilitythatMargueriteandHildegardbotharriveat\ud835\udc61 = 6minutes?\nb. Whatistheconditionalprobabilitythat \ud835\udc3b < \ud835\udc40,given \ud835\udc40 = \ud835\udc5a\u2014thatis,whatis \ud835\udc43(\ud835\udc3b <\n\ud835\udc40|\ud835\udc40 = \ud835\udc5a)?Expressyouranswerasasum.\nc. Whatistheunconditionalprobabilitythat \ud835\udc3b < \ud835\udc40,i.e.,whatis \ud835\udc43(\ud835\udc3b < \ud835\udc40)?Expressyour\nanswerasadoublesumthatleveragesyouranswertopartb.\nd. WhatistheCDFofyourwaitingtimeforthefirstofthetwotoarrive?Youshouldleave\nyouranswerinsummationform.\n3 Burrow Smoke Detectors and Joint Probability Distributions\nBurrowLabshastakenonotherstartupsinthehomesafetyandsecurityspaceandhasrecently\nstartedmarketinganewsmokedetector.Burrow\u2019ssmokedetectorsrelyon\ud835\udc36\ud835\udc42 sensorsthat\n2\neventuallyfail,andthatfailuretimedictatestheaverageproductlifetimeofthesmokedetector.\nBurrowmanufacturesthreequartersofitssmokedetectorsincentralIdaho,andtherestareman-\nufacturedinsuburbanMaine.Anysinglesmokedetector\u2019sproductlifetimecanbemodeledasa\nExponentialrandomvariable.\nEachofthetwolocationssourcesits\ud835\udc36\ud835\udc42 sensorsfromdifferentsuppliers,sothesmokedetec-\n2\ntorsmanufacturedinMainehaveanaverageproductlifetimeof7yearsandthesmokedetectors\nmanufacturedinIdahohaveanaverageproductlifetimeof6years.Allsmokedetectorsaresold\nonline,soasidefromthefactthatasmokedetectoristhreetimesmorelikelytoshipfromthe\nIdahofacility,youcan\u2019ttellbylookingatasinglesmokedetectorwhereitwasmanufactured.\nLet\ud835\udc47 modeltheamountoftimethatpassesuntilthe\ud835\udc36\ud835\udc42 sensor(andthereforethesmokedetec-\n2\ntor)fails,andlet \ud835\udc40 beadiscreterandomvariablethattakesonthevalueof1forasmokedetec-\ntormanufacturedinMaine,and0otherwise.\na. Presentthecumulativedistributionandprobabilitydensityfunctionsfortherandomvari-\nable\ud835\udc47.BothyourCDFandyourPDFshouldbeanalyticfunctionson\ud835\udc61.\nb. ComputetheprobabilitythatasmokedetectorwasmanufacturedinMaine,giventhatit\nlastsmorethan15years.Ifneeded,youcankeepyouranswerintermsof \ud835\udc39 \ud835\udc47(15) or \ud835\udc53 \ud835\udc47(15)\nfrompart(a).However,anyconditionalexpressionoftheform \ud835\udc43(\u00b7|\u00b7) or \ud835\udc53(\u00b7|\u00b7) mustbe\nevaluated.\n4 Elections\nWewouldliketoseehowwecouldpredictanelectionbetweentwocandidatesinFrance(Aand\nB),givendatafrom10polls.Foreachofthe10polls,wereportbelowtheirsamplesize,how\nmanypeoplesaidtheywouldvoteforcandidateA,andhowmanypeoplesaidtheywouldvote\nforcandidateB.Notallpollsarecreatedequal,soforeachpollwealsoreportavalue\u201dweight\u201d\nwhichrepresentshowaccuratewebelievethepollwas.Thedataforthisproblemcanbefoundon\ntheclasswebsiteinpolls.csv:\n\u20133\u2013\na. First,assumethateachsampleineachpollisanindependentexperimentofwhetherornot\narandompersoninFrancewouldvoteforcandidateA(disregardweights).\n\u2022 CalculatetheprobabilitythatarandompersoninFrancevotesforcandidateA.\n\u2022 AssumeeachpersonvotesforcandidateAwiththeprobabilityyou\u2019vecalculatedand\notherwisevotesforcandidateB.IfthepopulationofFranceis64,888,792,whatisthe\nprobabilitythatcandidateAgetsmorethanhalfofthevotes?\nb. NateSilveratfivethirtyeightpioneeredanapproachcalledthe\u201dPollofPolls\u201dtopredict\nelections.ForeachcandidateAorB,wehavearandomvariable \ud835\udc46 \ud835\udc34 or \ud835\udc46 \ud835\udc35 whichrepresents\ntheirstrengthonelectionnight(likeELOscores).TheprobabilitythatAwinsis \ud835\udc43(\ud835\udc46 \ud835\udc34 >\n\ud835\udc46 \ud835\udc35).\n\u2022 Identifytheparametersfortherandomvariables \ud835\udc46 \ud835\udc34 and \ud835\udc46 \ud835\udc35.Both \ud835\udc46 \ud835\udc34 and \ud835\udc46 \ud835\udc35 arede-\nfinedtobenormalwiththefollowingparameters:\n\u2022 Wewillcalculate \ud835\udc43(\ud835\udc46 \ud835\udc34 > \ud835\udc46 \ud835\udc35) bysimulating100,000fakeelections.Ineachfakeelec-\ntion,wedrawarandomsampleforthestrengthofAfrom \ud835\udc46 \ud835\udc34 andarandomsample\nforthestrengthofBfrom \ud835\udc46 \ud835\udc35.If \ud835\udc46 \ud835\udc34 isgreaterthan \ud835\udc46 \ud835\udc35,candidateAwins.Whatdowe\nexpecttoseeifwesimulatesomanytimes?Whatdoweactuallysee?\n\u20134\u2013\nc. Whichmodel,theonefrom(a)orthemodelfrom(b)seemsmoreappropriate?Whymight\nthatbethecase?OnelectionnightcandidateAwins.Wasyourpredictionfrompart(b)\n\u201dcorrect\u201d? <END>"}
{"prompt": "Lecture notes from cs109_lec21_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 21: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nExponential RV and MLE 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nMystery RV and MLE 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nBeta Basics 2 / 2 pts\n3.1 Backpatching Betas from Expectations 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n3.2 Bootstrapping Beta 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 4\nThumbtacks 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Exponential RV and MLE\n1 Point\nSuppose that 8 batteries are needed to power an digital thermometer, and that\neach of the 8 batteries has a lifetime that's exponentially distributed, as with\nf(T i\u2223\u03bb) = \u03bbe\u2212\u03bbT i . The thermometer works brilliantly for a while, but stops\nworking after 112 days.\nWhat is the likelihood function, L(\u03bb)?\nL(\u03bb) = \u03bb\u220f8 e\u2212\u03bbT i\ni=1\nL(\u03bb) = \u03bb\u220f112 e\u2212\u03bbT i\ni=1\nL(\u03bb) = \u03bb8 \u220f i8\n=1\ne\u2212\u03bbT i\nL(\u03bb) = \u03bb112 \u220f8 e\u2212\u03bbT i\ni=1\nL(\u03bb) = \u03bb112 \u220f112 e\u2212\u03bbT i\ni=1\nQ2 Mystery RV and MLE\n1 Point\nConsider an iid sample of continuous random variables X 1, X 2, ..., X n with a\ndensity function of f(X\ni\n\u2223\u03b3) = 21\n\u03b3\ne\u2212\u2223X \u03b3i \u2223 .\nWhat is the maximum likelihood estimate of \u03b3, or \u03b3 MLE?\nHere, the RV is presumably influenced by a single parameter \u03b3.\nn\n\u03b3 MLE = \u2211 i=1 X i.\n\u03b3 MLE = X\u02c9 = n1 \u2211 in =1 X i.\n\u03b3\nMLE\n= n1 \u2223\u2211 in\n=1\nX\ni\n\u2223.\n\u03b3\nMLE\n= n1 \u2211 in\n=1\n\u2223X\ni\n\u2223.\nQ3 Beta Basics\n2 Points\nLet's make sure you're familiar with the Beta function!\nQ3.1 Backpatching Betas from Expectations\n1 Point\nWhich of the following RVs have E[X] = 0.5? Select all that apply.\nX \u223c Beta(1,1)\nX \u223c Beta(5,10)\nX \u223c Beta(100,100)\nX \u223c Beta(3,5)\nX \u223c Beta(7,1)\nQ3.2 Bootstrapping Beta\n1 Point\nWhich of the following is a uniform distribution between 0 and 1? Select all that\napply.\nX \u223c Beta(1,1)\nX \u223c Beta(0,0)\nX \u223c Beta(100,100)\nX \u223c Beta(3,5)\nX \u223c Beta(7,1)\nQ4 Thumbtacks\n1 Point\nIf you flip a thumbtack up into the air, it can either land on its base (with the\npoint sticking straight up) or it can rest on the point and a portion of its circular\nbase. You have a hunch that the probability the thumbtack lands on its base is\n0.2. You then toss the that thumbtack 18 times and see that it never lands on its\nbase. Which of the following RVs could model your posterior belief about of\nwhat the probability really is? Assume a Bayesian approach as introduced in\nlecture, and assume that the prior belief distribution is modeled as a Beta.\n\u0398 \u223c Beta(3,9)\n\u0398 \u223c Beta(3,18)\n\u0398 \u223c Beta(3,27)\n\u0398 \u223c Beta(21,27)\n\u0398 \u223c Beta(21,99) <END>"}
{"prompt": "Lecture notes from 26_deep_learning_annotated.txt\n\n###\n\n", "completion": "26: Intro to Deep\nLearning\nJerry Cain\nMay 31, 2024\nLecture Discussion on Ed\n1\nDeep Learning\n2\nInnovations in deep learning\nDeep learning and neural\nnetworks are cores theories and\ntechnologies behind the current AI\nrevolution.\nErrata:\n\u2022 Checkers is the last solved game (from game\ntheory, where perfect player outcomes can be\nfully predicted from any gameboard).\nhttps://en.wikipedia.org/wiki/Solved_game\n\u2022 The first machine learning algorithm defeated a\nworld champion in Chess in 1996.\nAlphaGO (2016) https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nComputers making art\nA Neural Algorithm of Artistic Style Google Deep Dream\nThe Next Rembrandt\nhttps://arxiv.org/abs/1508.06576 https://ai.googleblog.com/2015/06/in\nhttps://medium.com/@DutchDigital/the-\nceptionism-going-deeper-into-\nhttps://github.com/jcjohnson/neural-style\nnext-rembrandt-bringing-the-old-master-\nneural.html\nback-to-life-35dfb1653597\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nDetecting skin cancer\nEsteva, Andre, et al. \"Dermatologist-level classification of skin cancer with deep neural networks.\"\nNature 542.7639 (2017): 115-118.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nDeep learning\ndef Deep learning is def A neural network is,\nmaximum likelihood estimation at its core, many logistic\nwith neural networks. regression units stacked on top\nof each other and daisy-\nchained together.\nLOL\nYes.\n[1,0, \u2026 , 1] \ud835\udc66(, output > 0.5?\nPredict 1\n\ud835\udc99, input \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nLots of Logistic\n(regressions)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nLogistic Regression Model\n%\n!\"\n1\n\ud835\udc7f \ud835\udf03 + #\ud835\udf03 \ud835\udc4b 00 .. 68 \ud835\udc66\" = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f \ud835\udc4c) = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\n! \" \" 0.4\n0.2\n\"#$ 0 \" !\" #,%\n-10 -8 -6 -4 -2 0 2 4 6 8 10\n+\n\ud835\udc66\"\nLet\u2019s focus on the\nmodel up to \ud835\udc66\".\n\ud835\udc99\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nLogistic Regression Model\n%\n!\"\n1\n\ud835\udc7f \ud835\udf03 + #\ud835\udf03 \ud835\udc4b 00 .. 68 \ud835\udc66\" = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f \ud835\udc4c) = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\n! \" \" 0.4\n0.2\n\"#$ 0 \" !\" #,%\n-10 -8 -6 -4 -2 0 2 4 6 8 10\n+\n\ud835\udc66\"\nLet\u2019s focus on the\nmodel up to \ud835\udc66\".\n\ud835\udc99\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n\u2026\n\u03c3 > 0.5?\nOne neuron\n+\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\n\u2026\n= One logistic regression\n= \u03c3\n\ud835\udc66(\n\ud835\udc99\nBiological basis for neural networks\nA neuron\n\ud835\udc65\n$ \ud835\udf03\n!\nOne neuron =\n\ud835\udc65\n& \ud835\udf03\n\"\n\ud835\udc66\" one logistic\n\ud835\udf03\n\ud835\udc65 #\n\u2019\nregression\n\ud835\udf03\n\ud835\udc65 $\n(\nYour brain\n\ud835\udc65\n$\nNeural network =\n\ud835\udc65\n&\nmany logistic\n\ud835\udc65\n\u2019\nregressions\n\ud835\udc65\n(\n(or rather, someone else\u2019s brain)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nDigit recognition example\nInput image Input feature vector Output label\n\ud835\udc99(() = 0,0,0,0, \u2026 , 1,0,0,1, \u2026 , 0,0,1,0 \ud835\udc66 ( = 0\n\ud835\udc99(() = 0,0,1,1, \u2026 , 0,1,1,0, \u2026 , 0,1,0,0 \ud835\udc66 ( = 1\nWe make feature vectors from digitized pictures of numbers.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nLogistic Regression\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\n\u2026\n+ \u03c3\n\ud835\udc66(, output\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\n\ud835\udc99, input features\n(pixels, on/off)\nLogistic Regression\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\n\u2026\nindicates logistic\nregression connection\nNo.\n> 0.5?\nPredict 0\n\ud835\udc66(, output\n\u2705\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\n\ud835\udc99, input features\n(pixels, on/off)\nLogistic Regression\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\n\u2026\nindicates logistic\nregression connection\nYes.\n> 0.5?\nPredict 1\n\ud835\udc66(, output\n\u2705\n\ud835\udc99, input features\nLogistic Regression\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n\u2026\nindicates logistic\nregression connection\nYes.\n> 0.5?\nPredict 1\n\ud835\udc66(, output\n\u274c\nWhat can we do to increase\n\ud835\udc99, input features complexity of our model?\nTake two big ideas from Logistic Regression\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n\u2026\nReview\nBig idea #1 \ud835\udc43 \ud835\udc4c|\ud835\udc7f = \ud835\udc99\nModel conditional probability\n\ud835\udc66\" of class label given input\nindicates logistic\nregression connection\n\ud835\udc66(, output\nBig idea #2 \u03c3 \u03b8*\ud835\udc99\nNon-linear transform of multiple\nvalues into one value, using\nparameter \u03b8\n\ud835\udc99, input features\nIntroducing: The Neural network\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\n\u2026\nNo.\n> 0.5?\nPredict 0\n\ud835\udc66(, output\n\u2705\n\ud835\udc89, hidden\nlayer\n\ud835\udc99, input features\nNeural network\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n\u2026\nBig idea #1 \ud835\udc43 \ud835\udc4c|\ud835\udc7f = \ud835\udc99\nModel conditional probability\n\ud835\udc66\" of class label given input\nNo.\n> 0.5?\nPredict 0\n\ud835\udc66(, output\n\ud835\udc89, hidden\nlayer\n\ud835\udc99, input features\nFeed neurons into other neurons\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\n\u2026\nhidden\nneuron\n+ \u03c3\nNo.\n> 0.5?\nPredict 0\n*\nBig idea #2 \u03c3 \u03b8 \ud835\udc99\n\ud835\udc66(, output\nNon-linear transform of multiple\nvalues into one value, using\nparameter \u03b8\n\u2022 Neuron = logistic regression\n\ud835\udc89, hidden\nlayer\n\ud835\udc99, input features\nFeed neurons into other neurons\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\n\u2026\nNo.\nanother\n> 0.5?\nPredict 0\nhidden\n\ud835\udc66(, output\nneuron\n+ \u03c3\n\u2022 Neuron = logistic regression\n\ud835\udc89, hidden\n\u2022 Different parameters for\nlayer\n\ud835\udc99, input features every connection\nFeed neurons into other neurons\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\u2026\n|\ud835\udc89| logistic\nregression\nconnections\nNo.\n> 0.5?\nPredict 0\n\ud835\udc99 \u22c5 |\ud835\udc89| \ud835\udc66(, output\nparameters\n\u2022 Neuron = logistic regression\n\ud835\udc89, hidden\n\u2022 Different parameters for\nlayer\n\ud835\udc99, input features every connection\nFeed neurons into other neurons\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\u2026\n|\ud835\udc89| logistic\noutput\nregression\nneuron\nconnections\nNo.\n+ \u03c3\n> 0.5?\nPredict 0\n\ud835\udc99 \u22c5 |\ud835\udc89| \ud835\udc66(, output\nparameters\n\u2022 Neuron = logistic regression\n\ud835\udc89, hidden\n\u2022 Different parameters for\nlayer\n\ud835\udc99, input features every connection\nFeed neurons into other neurons\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n\u2026\n|\ud835\udc89| logistic 1 logistic\nregression regression\nconnections connection\nNo.\n> 0.5?\nPredict 0\n\ud835\udc99 \u22c5 |\ud835\udc89| |\ud835\udc89| \ud835\udc66(, output\nparameters parameters\n\u2022 Neuron = logistic regression\n\ud835\udc89, hidden\n\u2022 Different parameters for\nlayer\n\ud835\udc99, input features every connection\nWhy doesn\u2019t a linear model introduce \u201ccomplexity\u201d?\nNeural network:\n1.\n2.\nLinear network:\n1.\n2.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n\u2026\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n) * 1. 2.\n\u210e = \ud835\udf0e \ud835\udf03 \ud835\udc99\n\" \"\n*\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 \"#, output\n$, hidden\nlayer\n!, input features\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n*\n)\n\u210e = \ud835\udf03 \ud835\udc99\n\" \"\n*\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nWhy doesn\u2019t a linear model introduce \u201ccomplexity\u201d?\nNeural network:\n1.\n2.\nLinear network:\n1.\n2.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\n\u2026\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n) * 1. 2.\n\u210e = \ud835\udf0e \ud835\udf03 \ud835\udc99\n\" \"\n*\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 \"#, output\n$, hidden\nlayer\n!, input features\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n*\n)\n\u210e = \ud835\udf03 \ud835\udc99\n\" \" The linear model is effectively\n* a single logistic regression\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nwith \ud835\udc99 parameters.\nNeural Networks and Numeric Digit Recognition\nhttps://adamharley.com/nn_vis/\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nNeural networks\nA neural network (like logistic regression) gets intelligence from its\nparameters \ud835\udf03.\n\u2022 Learn parameters \ud835\udf03\nTraining\n\u2022 Find \ud835\udf03 that maximizes likelihood of\n&\u2019(\ntraining data (MLE)\nFor input feature vector \ud835\udc7f = \ud835\udc99:\nTesting/\n\u2022 Use parameters to compute \ud835\udc66( = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nPrediction \u2022 Classify instance as:\n1 \ud835\udc66( > 0.5\n-\n0 otherwise\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nNeural networks\nA neural network (like logistic regression) gets intelligence from its\nparameters \ud835\udf03.\n\u2022 Learn parameters \ud835\udf03\nTraining\n\u2022 Find \ud835\udf03 that maximizes likelihood of\n&\u2019(\ntraining data (MLE)\nHow do we learn the \ud835\udc99 \u22c5 \ud835\udc89 + |\ud835\udc89| parameters?\nGradient ascent + chain rule!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nTraining: Logistic Regression Review\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\" \ud83c\udf1f\n(\"%\n* (()\n\ud835\udc66\" = \ud835\udf0e \ud835\udf03 \ud835\udc99 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\n2. Compute gradient Find |\ud835\udc99| parameters\n3. Optimize initialize params\nrepeat many times:\ncompute gradient\nparams += \u03b7 * gradient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nTraining: Neural networks\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n2. Compute gradient\n3. Optimize\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\n1. Same output \ud835\udc66!, same log conditional likelihood\n/\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\n. .\n(\"%\n/\n( (\n\ud835\udc3f \ud835\udf03 = 9\ud835\udc43 \ud835\udc4c = \ud835\udc66 |\ud835\udc7f = \ud835\udc99 , \ud835\udf03\n(\"%\n/\n! ! %0! !\n( (\n= 9 \ud835\udc66\" 1 \u2212 \ud835\udc66\"\n(\"%\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n*\n) /\n\u210e = \ud835\udf0e \ud835\udf03 \ud835\udc99\n\" \"\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66(() log \ud835\udc66\" ( + 1 \u2212 \ud835\udc66(() log 1 \u2212 \ud835\udc66\" (\n(\"%\n*\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\n\u2026\nBinary class labels:\n\ud835\udc4c \u2208 0,1\n\"#, output\n$, hidden\nlayer\n!, input features\n(model is a little more complicated)\n/\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\n. .\n(\"%\nfor \ud835\udc57 = 1,\u2026 ,|\ud835\udc89|:\n*\n)\n\u210e = \ud835\udf0e \ud835\udf03 \ud835\udc99\n\" \"\n*\n\ud835\udc66, = \ud835\udf0e \ud835\udf03 ,+ \ud835\udc89 = \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\u2026\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\"\n\"#, output (\"%\n$, hidden\nlayer\n!, input features To optimize for\nlog conditional likelihood,\nwe now need to find:\ndimension \ud835\udc99\n\ud835\udc89 \u22c5 \ud835\udc99 + \ud835\udc89 parameters\ndimension \ud835\udc89\n2. Compute gradient\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\"\n(\"%\n* *\n\u210e = \ud835\udf0e \ud835\udf03\n4\n\ud835\udc99 for \ud835\udc57 = 1, \u2026 , |\ud835\udc89| \ud835\udc66\" = \ud835\udf0e \ud835\udf03\n!5\n\ud835\udc89\n3 3\n2. Compute gradient Take gradient with respect to all \ud835\udf03 parameters\n3. Optimize\nCalculus refresher #1: Calculus refresher #2:\nDerivative(sum) = Chain rule \ud83c\udf1f \ud83c\udf1f \ud83c\udf1f\nsum(derivative)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\n3. Optimize\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\"\n(\"%\n* *\n\u210e = \ud835\udf0e \ud835\udf03\n4\n\ud835\udc99 for \ud835\udc57 = 1, \u2026 , |\ud835\udc89| \ud835\udc66\" = \ud835\udf0e \ud835\udf03\n!5\n\ud835\udc89\n3 3\n2. Compute gradient Take gradient with respect to all \ud835\udf03 parameters\ninitialize params\n3. Optimize\nrepeat many times:\ncompute gradient\nparams += \u03b7 * gradient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nTraining a neural net\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\"\n(\"%\n* *\n\u210e = \ud835\udf0e \ud835\udf03\n4\n\ud835\udc99 for \ud835\udc57 = 1, \u2026 , |\ud835\udc89| \ud835\udc66\" = \ud835\udf0e \ud835\udf03\n!5\n\ud835\udc89\n3 3\nWait, did we just skip something difficult?\n2. Compute gradient Take gradient with respect to all \ud835\udf03 parameters\ninitialize params\n3. Optimize\nrepeat many times:\ncompute gradient\nparams += \u03b7 * gradient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\n2. Compute gradient via backpropagation\n/\n1. Optimization\n( (\n\ud835\udf03 = arg max 9\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n+,-\nproblem:\n. .\n(\"%\n/\n(() ( (() (\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = < \ud835\udc66 log \ud835\udc66\" + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udc66\"\n(\"%\n* *\n\u210e = \ud835\udf0e \ud835\udf03\n4\n\ud835\udc99 for \ud835\udc57 = 1, \u2026 , |\ud835\udc89| \ud835\udc66\" = \ud835\udf0e \ud835\udf03\n!5\n\ud835\udc89\n3 3\n2. Compute gradient Take gradient with respect to all \ud835\udf03 parameters\nLearn the tricks behind\n3. Optimize\nbackpropagation in\nCS229, CS231N, CS224N,\netc.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nBeyond the\nbasics\n37\nShared weights?\nIt turns out if you want to force some of your weights to be shared over\ndifferent neurons, the math isn\u2019t much harder.\nConvolution is an example of such weight-sharing and is used a lot in\ncomputer vision (Convolutional Neural Networks, CNN).\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nNeural networks with multiple layers\n\ud835\udc99 \ud835\udc82 \ud835\udc83 \ud835\udc84 \ud835\udc85 \ud835\udc86 \ud835\udc87 \ud835\udc9aJ \ud835\udc3f\ud835\udc3f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nNeurons learn features of the dataset\nNeurons in later layers will respond strongly to high-level\nfeatures of your training data.\nIf your training data is faces, you will get lots of face neurons.\nIf your training data\nis all of YouTube\u2026\n\u2026you get a cat\nneuron.\nOptimal stimulus found\nTop stimuli in test set\nby numerical optimization\nLe, et al., Building high-level features usingL lisaar Ygane, -Cshcrisa Pleiec uh, nMsehurapne Sravhaismei, dan dl eJearrry nCaining, C.S I1C09M, SLp ri2ng0 210224 40\nGoogLeNet (2015)\n1 Trillion Artificial Neurons\n(btw human brains have 1 billion neurons)\nMultiple,\nMulti class output\n22 layers deep!\nSzegedy et al., Going Deeper With ConvolutLiiosan Ysan., CChVrisP PRie c2h,0 M1eh5ran Sahami, and Jerry Cain, CS109, Spring 2024 41\nGood ML = Generalization\nOverfitting\nFitting the training data too well,\nsuch that we lose generality of\nmodel for predicting new data\nperfect fit, but bad more general fit + better\npredictor for new data predictor for new data\nDropout\nDuring training, randomly leave out\nsome neurons each training step.\nIt will make your network more robust.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nMaking decisions?\nNot everything is classification.\nDeep Reinforcement Learning\nInstead of having the output of\na model be a probability, you\nmake output an expectation.\nhttp://cs.stanford.edu/people/karpathy/convnetjs/demo/rldemo.html\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nDeep Reinforcement Learning\nhttp://cs.stanford.edu/people/karpathy\n/convnetjs/demo/rldemo.html\nDeep Mind Atari Games\nScore compared to best\nhuman\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44 <END>"}
{"prompt": "Lecture notes from cs109_lec12_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 12: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nIndependence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nSum of Binomials 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nSum of Poissons 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 4\nSum of Binomial and Poisson 2 / 2 pts\n4.1 Small Sum 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n4.2 Probability that sum is large 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Independence\n1 Point\nAssume you roll two fair dice and D is the outcome of the first die, D is the\n1 2\noutcome of the second die and S = D +D . Select all that are true.\n1 2\nP(D = 1,S = 7) = P(D = 1) \u22c5 P(S = 7)\n1 1\nP(D = 6,S = 6) = P(D = 6) \u22c5 P(S = 6)\n1 1\nRandom variables D and D are independent\n1 2\nRandom variables D and S are independent\n1\nEvents D = 1 and S = 7 are independent\n1\nQ2 Sum of Binomials\n1 Point\nLet X and Y be two independent random variables where\nX \u223c Bin(25,0.5) and Y \u223c Bin(50,0.5). Let Z = X + Y . What is the\ndistribution of Z?\nZ \u223c Bin(75,0.25)\nZ \u223c Bin(75,0.5)\nZ \u223c Bin(75,1.0)\nZ \u223c Bin(2500,0.25)\nQ3 Sum of Poissons\n1 Point\nLet X and Y be two independent random variables where X \u223c Poi(7) and\nY \u223c Poi(3). What is the distribution of X + Y ?\nX + Y \u223c Poi(10)\nX + Y \u223c Poi(21)\nX + Y \u223c Poi(4)\nQ4 Sum of Binomial and Poisson\n2 Points\nLet X and Y be two independent random variables where X \u223c Bin(5,0.5) and\nY \u223c Poi(1).\nQ4.1 Small Sum\n1 Point\nWhat is the exactly probability that X + Y \u2264 1? Express your answer to three\ndecimal places. Hint: Rely on Python and scipy to quickly compute the relevant\nprobabilities, as with:\n>>> from scipy.stats import poisson, binom\n>>> n, p, lamb = 5, 0.5, 1\n>>> poisson(lamb).pmf(0)\n0.36787944117144233\n>>> binom(n, p).pmf(1)\n0.15624999999999994\n>>>\n0.0805\nQ4.2 Probability that sum is large\n1 Point\nYou're interested in the exact probability, however small it might be, that X + Y\nis precisely 50. Recall that P(X + Y = 50) is calculated as the sum of many\nterms of the form P(X = k)P(Y = 50 \u2212 k). How many such terms\u2014each of\nthe form P(X = k)P(Y = 50 \u2212 k)\u2014contribute a nonzero amount to the\noverall probability?\n6 <END>"}
{"prompt": "Lecture notes from 25_logistic_regression_annotated.txt\n\n###\n\n", "completion": "25: Logistic Regression\nJerry Cain\nMay 29, 2024\nLecture Discussion on Ed\n1\nLinear to\nLogical:\nPreamble\n2\n1. Weighted sum Dot product: \ud835\udf03!\ud835\udc7f = \u2211% \ud835\udf03 \ud835\udc4b\n\"#$ \" \"\nRecall the linear regression model, where \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b and \ud835\udc4c \u2208 \u211d:\n! \" #\n#\n\ud835\udc54 \ud835\udc7f = \ud835\udf03 + , \ud835\udf03 \ud835\udc4b\n$ % %\n%&!\nHow would you rewrite this expression as a single dot product?\n\ud835\udc54 \ud835\udc7f = \ud835\udf03 \ud835\udc4b + \ud835\udf03 \ud835\udc4b + \ud835\udf03 \ud835\udc4b + \u22ef + \ud835\udf03 \ud835\udc4b Define \ud835\udc4b = 1\n$ $ ! ! \" \" # # !\n\u2019\n= \ud835\udf03 \ud835\udc7f New \ud835\udc7f = 1, \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\" # $\nPrepending \ud835\udc4b = 1 to each feature vector \ud835\udc7f\n!\nsimplifies matrix operations.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\n2. Sigmoid function \ud835\udf0e \ud835\udc67\n\ud835\udf0e \ud835\udc67\n\u2022 The sigmoid function:\n1\n1\n0.8\n\ud835\udf0e \ud835\udc67 =\n1 + \ud835\udc52!\"\n0.6\n0.4\n\u2022 Sigmoid squashes \ud835\udc67 to\n0.2\na number between 0 and 1.\n\ud835\udc67\n0\n-10 -8 -6 -4 -2 0 2 4 6 8 10\n\u2022 Recall definition of probability:\nA number between 0 and 1 that \ud835\udf48 \ud835\udc9b can represent\nexpresses a belief that something is true.\na probability.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\n3. Conditional likelihood function\nTraining data (\ud835\udc5b datapoints):\n\u2022 \ud835\udc99 % , \ud835\udc66 % drawn iid from a distribution \ud835\udc53 \ud835\udc7f = \ud835\udc99 % , \ud835\udc4c = \ud835\udc66 % |\ud835\udf03 = \ud835\udc53 \ud835\udc99 % , \ud835\udc66 % |\ud835\udf03\n0\nconditional likelihood\n/ /\n\ud835\udf03 = arg max 5 \ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03\n+,-\nof training data\n.\n/&!\n0\n/ /\n= arg max , log \ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 log conditional likelihood\n.\n/&!\n\u2022 MLE here is estimator that\n= arg max \ud835\udc3f\ud835\udc3f \ud835\udf03 maximizes conditional likelihood\n. \u2022 log conditional likelihood is also\nwritten as \ud835\udc3f\ud835\udc3f \ud835\udf03\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nLogistic\nRegression\n6\nPrediction models so far\nLinear Regression (Regression)\n%\n\ud835\udc7f \ud835\udf03 + 3\ud835\udf03 \ud835\udc4b \ud835\udc4c2 \u2705 \ud835\udc7f can be dependent\n! \" \"\n2\n\ud83e\udd37 Regression model (\ud835\udc4c \u2208 \u211d, not discrete)\n\"#$\n\ud835\udc4c2\n= \ud835\udf03 +\n\u2211$\n\ud835\udf03 \ud835\udc4b\n! &(\" & &\nNa\u00efve Bayes (Classification)\n\ud835\udc7f\n\u2705 Tractable with NB assumption, but\u2026\n2 2 2\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c \ud835\udc43 \ud835\udc7f, \ud835\udc4c\n\u26a0 Realistically, \ud835\udc4b features aren\u2019t always\n&\n\ud835\udc4c conditionally independent\n\ud835\udc4c2 = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f \ud83e\udd37 Actually models \ud835\udc43 \ud835\udc7f, \ud835\udc4c , not \ud835\udc43 \ud835\udc4c|\ud835\udc7f ?\n\u2019( !,\"\n= arg max \ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c\n\u2019( !,\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nLogistic Regression\n% sigmoid function\n\ud835\udc7f \ud835\udf03 ! + 3\ud835\udf03 \"\ud835\udc4b \" \ud835\udc67 1 \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f\n\ud835\udf0e \ud835\udc67 =\n1 + \ud835\udc52!\"\n\"#$\n#\nLogistic Regression Model: \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + , \ud835\udf03 \ud835\udc65\n$ % %\n%&!\n= =\nPredict \ud835\udc4c as the more likely \ud835\udc4c \ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c | \ud835\udc7f\ngiven our observation \ud835\udc7f = \ud835\udc99: 4& $,!\n#\n\u2022 Since \ud835\udc4c \u2208 0,1 , \ud835\udc43 \ud835\udc4c = 0|\ud835\udc7f = \ud835\udc99 = 1 \u2212 \ud835\udf0e \ud835\udf03 + \u2211 \ud835\udf03 \ud835\udc65\n$ %&! % %\n\u2022 Sigmoid function also known as logit function\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nLogistic Regression\n\ud835\udc99 = [0,1,1]\n0.81\n\ud835\udf03 parameter\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99\nconditional likelihood\n\ud835\udc7f\ninput features\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc65 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nLogistic Regression: Key Metaphor\n\ud835\udf03 parameter\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nLogistic Regression: Key Metaphor\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nLogistic Regression: Key Metaphor\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\n=\n\ud835\udc4c, output\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n\ud835\udc7f, input features\n&(\"\n0,1,1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nComponents of Logistic Regression\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n\ud835\udf03 weights ! & &\n&(\"\n(aka parameters)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nComponents of Logistic Regression\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx 3 \u2713 3 weighted sum\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nComponents of Logistic Regression\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nsquashing function\nx \u2713\n3 3\nbetween 0 and 1\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nComponents of Logistic Regression\nx \u2713\n0 0\nx \u2713\n1 1\n\ud835\udc67 \ud835\udf0e \ud835\udc67\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nprediction\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nDifferent predictions for different inputs\nx \u2713\n0 0\n7\nx \u2713 2 . 1 = 0 .\n1 1 =\n\ud835\udc67\n\ud835\udc67\n\ud835\udf0e\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n\ud835\udc7f, input features\n&(\"\n0,1,1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nDifferent predictions for different inputs\nx \u2713\n0 0\n3\nx 1 \u2713 1 \u2212 1 . 9 = 0 .\n= \ud835\udc67\n\ud835\udc67 \ud835\udf0e\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n\ud835\udc7f, input features\n&(\"\n0,0,1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nParameters affect prediction\nx \u2713\n0 0\n7\nx \u2713 2 . 1 = 0 .\n1 1 =\n\ud835\udc67\n\ud835\udc67\n\ud835\udf0e\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nParameters affect prediction\nx \u2713\n0 0\n4\nx 1 \u2713 1 \u2212 1 . 5 = 0 .\n= \ud835\udc67\n\ud835\udc67 \ud835\udf0e\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc99\nx +\n2 \u2713\n2\nx \u2713\n3 3\n$\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + B \ud835\udf03 \ud835\udc65\n! & &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nParameters affect prediction\n#\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 + , \ud835\udf03 \ud835\udc65\n$ % %\n%&!\n#\n\u2019\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e , \ud835\udf03 \ud835\udc65 = \ud835\udf0e \ud835\udf03 \ud835\udc99 where \ud835\udc65 = 1\n% % !\n%&$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nLogistic regression classifier\n=\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c|\ud835\udc7f\n4& $,!\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e\n\u2211#\n\ud835\udf03 \ud835\udc65 = \ud835\udf0e\n\ud835\udf03\u2019\n\ud835\udc99\n%&$ % %\nEstimate parameters\nTraining \ud835\udf03 = \ud835\udf03 , \ud835\udf03 , \ud835\udf03 , \u2026 , \ud835\udf03\nfrom training data $ ! \" #\nGiven an observation \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , predict\n! \" #\nTesting\n=\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c|\ud835\udc7f\n4& $,!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 2222\nTraining:\nThe big picture\n23\nLogistic regression classifier\n=\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c|\ud835\udc7f\n4& $,!\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e\n\u2211#\n\ud835\udf03 \ud835\udc65 = \ud835\udf0e\n\ud835\udf03\u2019\n\ud835\udc99\n%&$ % %\nEstimate parameters\nTraining \ud835\udf03 = \ud835\udf03 , \ud835\udf03 , \ud835\udf03 , \u2026 , \ud835\udf03\nfrom training data $ ! \" #\nChoose \ud835\udf03 that optimizes some objective:\n1. Determine objective function We are modeling \ud835\udc43 \ud835\udc4c|\ud835\udc4b\nGiven an observation \ud835\udc7f = \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , predict\n! \" #\n2. Find gradient with respect to each \ud835\udf03 directly, so we maximize the\nTesting\n=\n\ud835\udc4c = arg max \ud835\udc43 \ud835\udc4c|\ud835\udc4b\n3. Solve analytically by setting to 0, or solve conditional likelihood of\ncomputationally with gradient ascent 4& $,! training data.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 2244\nEstimating \ud835\udf03\n4\n1. Determine objective\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 % | \ud835\udc99 % , \ud835\udf03\n012\nfunction\n3\n%(\"\n2. Gradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a\n%\n3. Solve\ninitialize x\n\u2022 No analytical derivation of \ud835\udf03 \u2026\n+,- repeat many times:\n\u2022 \u2026but can still determine \ud835\udf03\ncompute gradient\n+,-\nvia gradient ascent!\nx += \u03b7 * gradient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\n1. Determine objective function\n4 $\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \u2211 \ud835\udf03 \ud835\udc65\n&(! & &\n\ud835\udf03\n012\n= arg max K\ud835\udc53 \ud835\udc66 % | \ud835\udc99 % , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n= \ud835\udf0e\n\ud835\udf035\n\ud835\udc99\n3 3\n%(\"\nFirst: Interpret Second: Write a differentiable\nconditional likelihood expression for log conditional\nwith Logistic Regression likelihood\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\n1. Determine objective function (interpret)\n4 $\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \u2211 \ud835\udf03 \ud835\udc65\n&(! & &\n\ud835\udf03\n012\n= arg max K\ud835\udc53 \ud835\udc66 % | \ud835\udc99 \ud835\udc8a , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n= \ud835\udf0e\n\ud835\udf035\n\ud835\udc99\n3 3\n%(\"\nSuppose you have \ud835\udc5b = 2 training datapoints: \ud835\udc99 \" , 1 , \ud835\udc99 # , 0\nConsider the following expressions for a given \ud835\udf03:\nA. \ud835\udf0e \ud835\udf035\ud835\udc99 \" \ud835\udf0e \ud835\udf035\ud835\udc99 # C. \ud835\udf0e \ud835\udf035 \ud835\udc99 \" 1 \u2212 \ud835\udf0e \ud835\udf035 \ud835\udc99 #\nB. 1 \u2212 \ud835\udf0e \ud835\udf035 \ud835\udc99 \" \ud835\udf0e \ud835\udf035 \ud835\udc99 # D. 1 \u2212 \ud835\udf0e \ud835\udf035 \ud835\udc99 \" 1 \u2212 \ud835\udf0e \ud835\udf035 \ud835\udc99 #\n1. Interpret the above expressions as probabilities.\n2. If we let \ud835\udf03 = \ud835\udf03 , which probability should be the highest?\n!\"#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\n1. Determine objective function (write)\n4 $\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \u2211 \ud835\udf03 \ud835\udc65\n&(! & &\n\ud835\udf03\n012\n= arg max K\ud835\udc53 \ud835\udc66 % | \ud835\udc99 % , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n= \ud835\udf0e\n\ud835\udf035\n\ud835\udc99\n3 3\n%(\"\n1. What is a differentiable\n\ud835\udf0e \ud835\udf03&\ud835\udc99 if \ud835\udc66 = 1\n\ud835\udc43 \ud835\udc4c = \ud835\udc66|\ud835\udc7f = \ud835\udc99 = <\nexpression for \ud835\udc43 \ud835\udc4c = \ud835\udc66| \ud835\udc7f = \ud835\udc99 ? 1 \u2212 \ud835\udf0e \ud835\udf03&\ud835\udc99 if \ud835\udc66 = 0\nRecall\nBernoulli\nMLE!\n(\n2. What is a differentiable expression\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = logE\ud835\udc53 \ud835\udc66 \u2019 | \ud835\udc99 \u2019 ,\ud835\udf03\nfor \ud835\udc3f\ud835\udc3f \ud835\udf03 , log conditional likelihood?\n\u2019#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n1. Determine objective function (write)\n4 $\n\ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \u2211 \ud835\udf03 \ud835\udc65\n&(! & &\n\ud835\udf03\n012\n= arg max K\ud835\udc53 \ud835\udc66 % | \ud835\udc99 % , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n= \ud835\udf0e\n\ud835\udf035\n\ud835\udc99\n3 3\n%(\"\n1. What is a differentiable\nexpression for \ud835\udc43 \ud835\udc4c = \ud835\udc66| \ud835\udc7f = \ud835\udc99 ?\n4 !G4\n\u2019 \u2019\n\ud835\udc43 \ud835\udc4c = \ud835\udc66|\ud835\udc7f = \ud835\udc99 = \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n2. What is a differentiable expression\nfor \ud835\udc3f\ud835\udc3f \ud835\udf03 , log conditional likelihood?\n4\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66(%) log \ud835\udf0e \ud835\udf035\ud835\udc99(%) + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udf0e \ud835\udf035\ud835\udc99(%)\n%(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n2. Find gradient with respect to \ud835\udf03\n4\n% %\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nOptimization 012\n3 3\n%(\"\nproblem: 4\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n%(\"\nGradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a:\n%\n4 \ud83e\udd84 presented here without proof, though it is \ud83e\udd84\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n(%) 5 (%) (%) a generalization of the gradient of a in the\n= B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n\ud835\udf15\ud835\udf03 & Y = \ud835\udc4e\ud835\udc4b + \ud835\udc4f + \ud835\udc4d derivation from last lecture\n&\n%(\"\nHow do we interpret the gradient\nLM\ncontribution of the \ud835\udc56 training datapoint?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\n2. Find gradient with respect to \ud835\udf03\n4\n% %\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nOptimization 012\n3 3\n%(\"\nproblem: 4\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n%(\"\nGradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a:\n%\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n(%)\n(%) 5 (%)\n= B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n\ud835\udf15\ud835\udf03 &\n&\n%(\"\nscale by j-th feature\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\n2. Find gradient with respect to \ud835\udf03\n4\n% %\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nOptimization 012\n3 3\n%(\"\nproblem: 4\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n%(\"\nGradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a:\n%\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n(%)\n(%) 5 (%)\n= B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n\ud835\udf15\ud835\udf03 &\n&\n%(\"\n1 or 0 \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f = \ud835\udc99 %\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n2. Find gradient with respect to \ud835\udf03\n4\n% %\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\nOptimization 012\n3 3\n%(\"\nproblem: 4\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n%(\"\nGradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a:\n%\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n(%)\n(%) 5 (%)\n= B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n\ud835\udf15\ud835\udf03 &\n&\n%(\"\nSuppose \ud835\udc66(\u2019) = 1 (the true class label for the \ud835\udc56+, datapoint):\n\u2022 If \ud835\udf0e \ud835\udf03&\ud835\udc99 \ud835\udc8a \u2265 0.5, correct\n\u2022 If \ud835\udf0e \ud835\udf03&\ud835\udc99 \ud835\udc8a < 0.5, incorrect \u00e0 change \ud835\udf03 more\n\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\n3. Solve\n4\n% %\n\ud835\udf03 = arg max K\ud835\udc53 \ud835\udc66 | \ud835\udc99 , \ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n1. Optimization 012\n3 3\n%(\"\nproblem: 4\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\n%(\"\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n2. Gradient wrt \ud835\udf03 , for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a: = B \ud835\udc66(%) \u2212 \ud835\udf0e \ud835\udf035\ud835\udc99(%) \ud835\udc65(%)\n%\n\ud835\udf15\ud835\udf03 &\n&\n%(\"\n3. Solve using gradient ascent!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nTraining:\nThe details\n35\nTraining: Gradient ascent step\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\n(%)\n= B \ud835\udc66(%) \u2212 \ud835\udf0e \ud835\udf035 \ud835\udc99(%) \ud835\udc65 for \ud835\udc57 = 0, 1, \u2026 , \ud835\udc5a\n\ud835\udf15\ud835\udf03 &\n&\n%(\"\nrepeat until convergence:\nfor all thetas:\nSTU\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\nXYZ STU\n\ud835\udf03 = \ud835\udf03 + \ud835\udf02 \u22c5\n% %\nSTU\n\ud835\udf15\ud835\udf03\n%\n0\nWhat does\nSTU (/) STU\u2019 (/) (/)\n= \ud835\udf03 + \ud835\udf02 \u22c5 , \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\nthis look like\n% %\nin code?\n/&!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nfor \ud835\udc57 = 0,1,\u2026,\ud835\udc5a:\nTraining: Gradient Ascent\n-\nGradient\n\ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m\n&\nrepeat until convergence:\ngradient[j] = 0 for 0 \u2264 j \u2264 m\n// TODO: your code here\n// compute all gradient[j]\u2019s\n// based on n training examples\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\ninner loop for \ud835\udc57 = 0,1,\u2026,\ud835\udc5a:\nTraining: Gradient Ascent\n-\nGradient\n\ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ncompute\nouter loop\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m\n&\nrepeat until convergence:\ngradient[j] = 0 for 0 \u2264 j \u2264 m\nfor each training example (\ud835\udc99,\ud835\udc66):\nfor each 0 \u2264 j \u2264 m:\n// update gradient[j] for\n// current (\ud835\udc99,\ud835\udc66) example\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\ninner loop for \ud835\udc57 = 0,1,\u2026,\ud835\udc5a:\nTraining: Gradient Ascent\n-\nGradient\n\ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ncompute\nouter loop\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m\n&\nrepeat until convergence:\ngradient[j] = 0 for 0 \u2264 j \u2264 m\nfor each training example (\ud835\udc99,\ud835\udc66):\nfor each 0 \u2264 j \u2264 m:\nSome important\n1\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65\ndetails\u2026\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\n-\nGradient\nTraining: Gradient Ascent \ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m \u2022 Finish computing\n&\ngradient with \ud835\udf03;<=\nrepeat until convergence:\nprior to any \ud835\udf03 update\ngradient[j] = 0 for 0 \u2264 j \u2264 m\nfor each training example (\ud835\udc99,\ud835\udc66):\nfor each 0 \u2264 j \u2264 m:\n1\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\n-\nGradient\nTraining: Gradient Ascent \ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m \u2022 Finish computing\n&\ngradient with \ud835\udf03;<=\nrepeat until convergence:\nprior to any \ud835\udf03 update\ngradient[j] = 0 for 0 \u2264 j \u2264 m\n\u2022 Learning rate \ud835\udf02 is a\nfor each training example (\ud835\udc99,\ud835\udc66): constant you set\nbefore training\nfor each 0 \u2264 j \u2264 m:\n1\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\n-\nGradient\nTraining: Gradient Ascent \ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m \u2022 Finish computing\n&\ngradient with \ud835\udf03;<=\nrepeat until convergence:\nprior to any \ud835\udf03 update\ngradient[j] = 0 for 0 \u2264 j \u2264 m\n\u2022 Learning rate \ud835\udf02 is a\nfor each training example (\ud835\udc99,\ud835\udc66): constant you set\nbefore training\nfor each 0 \u2264 j \u2264 m:\n\u2022 \ud835\udc65 is the \ud835\udc57>? feature of\n&\n1\ninput \ud835\udc99 = \ud835\udc65 , \u2026 , \ud835\udc65\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65 \" $\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\n-\nGradient\nTraining: Gradient Ascent \ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m \u2022 Finish computing\n&\ngradient with \ud835\udf03;<=\nrepeat until convergence:\nprior to any \ud835\udf03 update\ngradient[j] = 0 for 0 \u2264 j \u2264 m\n\u2022 Learning rate \ud835\udf02 is a\nfor each training example (\ud835\udc99,\ud835\udc66): constant you set\nbefore training\nfor each 0 \u2264 j \u2264 m:\n\u2022 \ud835\udc65 is the \ud835\udc57>? feature of\n&\n1\ninput \ud835\udc99 = \ud835\udc65 , \u2026 , \ud835\udc65\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65 \" $\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\u2022 Insert \ud835\udc65 = 1 before\n!\ntraining makes\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n& sigmoid of matrix\ncompact!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\n-\nGradient\nTraining: Gradient Ascent \ud835\udf03&\u2019( = \ud835\udf03)*+ +\ud835\udf02\u22c5) \ud835\udc66(,) \u2212\ud835\udf0e \ud835\udf03)*+! \ud835\udc99(,) \ud835\udc65(,)\nAscent Step \" \" \"\n,#$\ninitialize \ud835\udf03 = 0 for 0 \u2264 j \u2264 m \u2022 Finish computing\n&\ngradient with \ud835\udf03;<=\nrepeat until convergence:\nprior to any \ud835\udf03 update\ngradient[j] = 0 for 0 \u2264 j \u2264 m\n\u2022 Learning rate \ud835\udf02 is a\nfor each training example (\ud835\udc99,\ud835\udc66): constant you set\nbefore training\nfor each 0 \u2264 j \u2264 m:\n\u2022 \ud835\udc65 is the \ud835\udc57>? feature of\n&\n1\ninput \ud835\udc99 = \ud835\udc65 , \u2026 , \ud835\udc65\ngradient[j] += \ud835\udc66 \u2212 \ud835\udc65 \" $\n&\n1 +\n\ud835\udc5293!\ud835\udc99\n\u2022 Insert \ud835\udc65 = 1 before\n!\ntraining makes\n\ud835\udf03 += \u03b7 * gradient[j] for all 0 \u2264 j \u2264 m\n& sigmoid of matrix\n\ud83c\udf1f\ncompact!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nNa\u00efve Bayes vs Logistic Regression\n\ud835\udf03\n\ud835\udc7f\n!\"\n1\n\ud835\udc43[ \ud835\udc7f|\ud835\udc4c \ud835\udc43[ \ud835\udc4c [ 0.8\n\ud835\udc43 \ud835\udc7f,\ud835\udc4c \ud835\udc7f \ud835\udf03#\ud835\udc99 0.6 \ud835\udc43 \ud835\udc4c = 1|\ud835\udc7f\n0.4\n0.2\n\ud835\udc4c 0 \"\n-10 -8 -6 -4 -2 0 2 4 6 8 10\n\ud835\udc4c[ = arg max\ud835\udc43 \ud835\udc4c | \ud835\udc7f = arg max\ud835\udc43 \ud835\udc7f|\ud835\udc4c \ud835\udc43 \ud835\udc4c \ud835\udc4c[ = arg max\ud835\udc43 \ud835\udc4c|\ud835\udc7f\n.# !,$ .# !,$ .# !,$\nCompare/contrast:\n1. What distributions are we modeling?\n2. After learning our parameters, could we randomly generate a new datapoint \ud835\udc99, \ud835\udc66 ?\n3. Could we model a continuous \ud835\udc4b feature (e.g., \ud835\udc4b ~Normal, or \ud835\udc4b ~Unknown)?\n& & &\n4. Could we model a non-binary discrete \ud835\udc4b (e.g., \ud835\udc4b \u2208 1,2, \u2026 , 6 )?\n& &\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nTradeoffs: Na\u00efve Bayes Logistic Regression\n1. Modeling goal \ud835\udc43 \ud835\udc7f, \ud835\udc4c \ud835\udc43 \ud835\udc4c|\ud835\udc7f\n2. Generative or Generative: could use joint Discriminative: just tries to\ndistribution to generate new discriminate \ud835\udc66 = 0 vs \ud835\udc66 = 1\ndiscriminative?\npoints (\u26a0but you might not (\u274c cannot generate new points\nneed this extra effort) b/c no \ud835\udc43 \ud835\udc7f, \ud835\udc4c )\n3. Continuous \u26a0 Needs parametric form\ninput features (e.g., Gaussian) or\n\u2705 Yes, easily\ndiscretized buckets (for\nmultinomial features)\n\u26a0 Multi-valued discrete data\n4. Discrete \u2705 Yes, multi-value discrete hard (e.g., if \ud835\udc4b \u2208 {\ud835\udc34, \ud835\udc35, \ud835\udc36}, not\n%\ninput features data = multinomial \ud835\udc43 \ud835\udc4b |\ud835\udc4c necessarily good to encode as\n%\n1, 2, 3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nLinearly separable data\nLogistic Regression is trying to find\nthe line that separates data instances\nwhere \ud835\udc66 = 1 from those where \ud835\udc66 = 0:\n\u2019\n\ud835\udf03 \ud835\udc99 = 0\n\u2022 We call such data (or functions\ngenerating that data) linearly separable.\n!!\"\n0\n\u2022 Na\u00efve Bayes is linear too, because there is\none parameter for each feature\n$\n(and no parameters that involve multiple\n2 2\n\ud835\udc43 \ud835\udc7f|\ud835\udc4c = K\ud835\udc43 \ud835\udc4b |\ud835\udc4c\nfeatures). &\n&(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 47\nData is not always linearly separable\n\u2022 Not possible to draw a line that successfully separates all the\n\ud835\udc66 = 1 points (green) from the \ud835\udc66 = 0 points (red)\n\u2022 Despite this, Logistic Regression and Naive Bayes still often work well in\npractice\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\nExtra: Gradient\nDerivation\n49\nBackground: Calculus\nCalculus refresher #1:\n& &\n\ud835\udf15 \ud835\udf15\ud835\udc53 \ud835\udc65\nDerivative(sum) =\n#\n* \ud835\udc53 \ud835\udc65 = *\nsum(derivative) #\n\ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc65\n#$% #$%\nCalculus refresher #2: \ud835\udf15\ud835\udc53 \ud835\udc65 \ud835\udf15\ud835\udc53 \ud835\udc67 \ud835\udf15\ud835\udc67\nCalculus Chain Rule\nChain rule \ud83c\udf1f \ud83c\udf1f \ud83c\udf1f =\n\ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc67 \ud835\udf15\ud835\udc65\naka decomposition\n\ud835\udc53 \ud835\udc65 = \ud835\udc53 \ud835\udc67 \ud835\udc65\nof composed functions\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 50\nOur goal\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\nFind: where\n\ud835\udf15\ud835\udf03\n%\n4\nlog conditional\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\nlikelihood\n%(\"\nTwo \"pre-processing\" steps to prepare for chain rule\n1. Rewrite \ud835\udc3f\ud835\udc3f \ud835\udf03 with \ud835\udc66[\n2. Compute gradient of \ud835\udc66[\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 51\n1. Rewriting \ud835\udc3f\ud835\udc3f \ud835\udf03 with \ud835\udc66)\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03\nFind: where\n\ud835\udf15\ud835\udf03\n%\n4\nlog conditional\n(%) 5 (%) (%) 5 (%)\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66 log \ud835\udf0e \ud835\udf03 \ud835\udc99 + 1 \u2212 \ud835\udc66 log 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99\nlikelihood\n%(\"\n4\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = B \ud835\udc66(%) log \ud835\udc66[ % + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udc66[ % Let \ud835\udc66[ % = \ud835\udf0e \ud835\udf035 \ud835\udc99(%)\n%(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 52\n$\n2. Compute gradient of \ud835\udc66) = \ud835\udf0e \ud835\udf03 \ud835\udc99\nAside: sigmoid has a\nbeautiful derivative!\nSigmoid function: Derivative:\n1 \ud835\udc51\n\ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 1 \u2212 \ud835\udf0e \ud835\udc67\n1 + \ud835\udc529A \ud835\udc51\ud835\udc67\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 53\n$\n2. Compute gradient of \ud835\udc66) = \ud835\udf0e \ud835\udf03 \ud835\udc99\nSigmoid function: Derivative:\n1 \ud835\udc51\n\ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 1 \u2212 \ud835\udf0e \ud835\udc67\n1 + \ud835\udc529A \ud835\udc51\ud835\udc67\n\u2018 \u2018\n\u2019\nWhat is \ud835\udc66K = \ud835\udf0e \ud835\udf03 \ud835\udc99 ?\n\u2018. \u2018.\n6 6\nA. \ud835\udf0e \ud835\udc65 1 \u2212 \ud835\udf0e \ud835\udc65 \ud835\udc65\n% % %\n\u2019 \u2019\nB. \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc99\n\u2019 \u2019\nC. \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n%\n\u2019 \u2019\nD. \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n% %\nE. None/other\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 54\n$\n2. Compute gradient of \ud835\udc66) = \ud835\udf0e \ud835\udf03 \ud835\udc99\nSigmoid function: Derivative:\n1 \ud835\udc51\n\ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 = \ud835\udf0e \ud835\udc67 1 \u2212 \ud835\udf0e \ud835\udc67\n1 + \ud835\udc529A \ud835\udc51\ud835\udc67\n$\nWhat is \u2018 \ud835\udf0e \ud835\udf03\u2019 \ud835\udc99 ? Let \ud835\udc67 = \ud835\udf03\u2019 \ud835\udc99 = B \ud835\udf03 \ud835\udc65 .\nB B\n\u2018.\n6\nB(!\nA. \ud835\udf0e \ud835\udc65 1 \u2212 \ud835\udf0e \ud835\udc65 \ud835\udc65\n\ud835\udf15 \ud835\udf15 \ud835\udf15\ud835\udc67\n% % %\n\ud835\udf0e \ud835\udf03\u2019 \ud835\udc99 = \ud835\udf0e \ud835\udc67 \u22c5 (Chain Rule)\n\u2019 \u2019\nB. \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc99 \ud835\udf15\ud835\udf03 \ud835\udf15\ud835\udc67 \ud835\udf15\ud835\udf03\n% %\n\u2019 \u2019\nC. \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n%\n\u2019 \u2019\n\u2019 \u2019 = \ud835\udf0e \ud835\udf03 \ud835\udc99 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\nD. \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65 1 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n%\n% %\nE. None/other\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 55\nCompute gradient of log conditional likelihood\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\n= B \ud835\udc66(%) log \ud835\udc66[ % + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udc66[ % Let \ud835\udc66[ % = \ud835\udf0e \ud835\udf035 \ud835\udc99(%)\n\ud835\udf15\ud835\udf03 \ud835\udf15\ud835\udf03\n& &\n%(\"\n4\n%\n\ud835\udf15 \ud835\udf15\ud835\udc66[\n= B \ud835\udc66(%) log \ud835\udc66[ % + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udc66[ % \u22c5 (Chain Rule)\n\ud835\udf15\ud835\udc66[ % \ud835\udf15\ud835\udf03\n&\n%(\"\n4\n1 1\n(%) (%) % % % (calculus)\n= B \ud835\udc66 \u2212 1 \u2212 \ud835\udc66 \u22c5 \ud835\udc66[ 1 \u2212 \ud835\udc66[ \ud835\udc65\n\ud835\udc66[ % 1 \u2212 \ud835\udc66[ % &\n%(\"\n4 4\n(%) % (%) (%) 5 % (%) (simplify)\n= B \ud835\udc66 \u2212 \ud835\udc66[ \ud835\udc65 = B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n& &\n%(\" %(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 56\nCompute gradient of log conditional likelihood\n4\n\ud835\udf15\ud835\udc3f\ud835\udc3f \ud835\udf03 \ud835\udf15\n= B \ud835\udc66(%) log \ud835\udc66[ % + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udc66[ % Let \ud835\udc66[ % = \ud835\udf0e \ud835\udf035 \ud835\udc99(\ud835\udc8a)\n\ud835\udf15\ud835\udf03 \ud835\udf15\ud835\udf03\n& &\n%(\"\n4\n%\n\ud835\udf15 \ud835\udf15\ud835\udc66[\n= B \ud835\udc66(%) log \ud835\udc66[ % + 1 \u2212 \ud835\udc66(%) log 1 \u2212 \ud835\udc66[ % \u22c5 (Chain Rule)\n\ud835\udf15\ud835\udc66[ % \ud835\udf15\ud835\udf03\n&\n%(\"\n4\n1 1\n(%) (%) % % % (calculus)\n= B \ud835\udc66 \u2212 1 \u2212 \ud835\udc66 \u22c5 \ud835\udc66[ 1 \u2212 \ud835\udc66[ \ud835\udc65\n\ud835\udc66[ % 1 \u2212 \ud835\udc66[ % &\n%(\"\n4 4\n(%) % (%) (%) 5 % (%) \ud83c\udf89 (simplify)\n= B \ud835\udc66 \u2212 \ud835\udc66[ \ud835\udc65 = B \ud835\udc66 \u2212 \ud835\udf0e \ud835\udf03 \ud835\udc99 \ud835\udc65\n& &\n%(\" %(\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 57 <END>"}
{"prompt": "Lecture notes from cs109_lec06_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 6: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nRandom Variables: Definitions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nRandom Variables 3 / 3 pts\n2.1 Random Variables: Probability Mass Functions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 Random Variables: Cumulative Distribution Functions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.3 Random Variables: Expectation 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nExpected Number of Volleyball Games 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Random Variables: Definitions\n1 Point\nWhich of the following are random variables? Select all that apply.\nIf n coins are flipped, the number of coins that land heads.\nIf n coins are flipped, the probability that all coins land on heads.\nThe number of ways to order {A,B,C,D,E} so that A and B are not next to\neach other and C and D are not next to each other.\nA boolean which denotes whether it will rain today (1) or not (0).\nQ2 Random Variables\n3 Points\nLet X be a random variable whose support is {0, 1, 2}.\nQ2.1 Random Variables: Probability Mass Functions\n1 Point\nWhich of the following is a valid probability mass function for X? Assume that for\neach answer below, P(X = x) = 0 for all unspecified values of x.\nP(X = 0) = 0, P(X = 1) = 2, and P(X = 2) = 0.5\nP(X = 0) = 0.1, P(X = 1) = 0.8, and P(X = 2) = 0.1\nP(X = 0) = \u22120.1, P(X = 1) = 0.9, and P(X = 2) = 0.2\nP(X = 0) = 0.2, P(X = 1) = 0.6, and P(X = 2) = 0.11\nQ2.2 Random Variables: Cumulative Distribution Functions\n1 Point\nWhat is the CDF (Continuous Distribution Function), associated with the valid\nPMF you found in Q2.1?\nP(X < 0) = 0, P(X \u2264 0) = 0, P(X \u2264 1) = 2, P(X \u2264 2) = 0.5\nP(X < 0) = 0, P(X \u2264 0) = 0.1, P(X \u2264 1) = 0.9, P(X \u2264 2) = 1\nP(X < 0) = 0, P(X \u2264 0) = \u22120.1, P(X \u2265 1) = 0.8, P(X \u2264 2) = 1\nP(X < 0) = 0, P(X \u2264 0) = 0.2, P(X \u2264 1) = 0.8, P(X \u2264 2) = 0.91\nQ2.3 Random Variables: Expectation\n1 Point\nGiven the same PMF you found in Q2.1, what is the expectation, E[X]?\n(Remember expectation is defined as E[X] = \u2211 xP(x)) Hint: see if you can\nx\nuse symmetry to cut down on algebra!\n1\n0.5\n0.63\n1.34\nQ3 Expected Number of Volleyball Games\n1 Point\nTwo volleyball teams\u2014let's say Nebraska and Stanford, which according to one\npoll were the top two Division I teams last autumn\u2014play a best-of-seven match,\nand the match ends as soon as either team wins four games. Each game results\nin a win for one team and a loss for the other, so there are no ties or draws.\nAssume each team is equally likely to win each game, and that each game is\nindependent of all others. Compute the expected number of games played, and\nexpress your answer out to four decimal places.\n5.8125 <END>"}
{"prompt": "Lecture notes from Important Links.txt\n\n###\n\n", "completion": "Course Website (you can view schedule here)\n\nEd Forum (for real-time Q&A data from students, TAs, and instructors - need access via an authorized Stanford login, so ask Neetish Sharma) <END>"}
{"prompt": "Lecture notes from 08_poisson_and_more_annotated.txt\n\n###\n\n", "completion": "08: Poisson and More\nJerry Cain\nApril 17th, 2024\nLecture Discussion on Ed\n1\nPoisson\n2\nAlgorithmic ride sharing\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\nProbability of \ud835\udc58 requests from this area in the next 1 minute?\nSuppose we know: On average, \ud835\udf06 = 5 requests per minute\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nAlgorithmic ride sharing, approximately\nProbability of \ud835\udc58 requests from this area in the next 1 minute?\nOn average, \ud835\udf06 = 5 requests per minute\nBreak a minute down into 60 seconds:\n0 0 1 0 1 \u2026 0 0 0 0 1\n1 2 3 4 5 60\nAt each second:\n\ud835\udc4b ~ Bin \ud835\udc5b = 60, \ud835\udc5d = 5/60\n\u2022 Independent Bernoulli trial\n! \"#!\n\u2022 You get a request (1) or you don\u2019t (0). 60 5 5\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = 1 \u2212\nLet \ud835\udc4b = # of requests in minute. \ud835\udc58 60 60\n\ud835\udc38 \ud835\udc4b = \ud835\udf06 = 5 But what if there are two requests\nin the same second?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nAlgorithmic ride sharing, approximately\nProbability of \ud835\udc58 requests from this area in the next 1 minute?\nOn average, \ud835\udf06 = 5 requests per minute\nBreak a minute down into 60,000 milliseconds:\n\u2026\n1 60,000\nAt each millisecond:\n\ud835\udc4b ~ Bin \ud835\udc5b = 60000, \ud835\udc5d = \ud835\udf06/\ud835\udc5b\n\u2022 Independent Bernoulli trial\n! \"#!\n\u2022 You get a request (1) or you don\u2019t (0). \ud835\udc5b \ud835\udf06 \ud835\udf06\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = 1 \u2212\n\ud835\udc58\nLet \ud835\udc4b = # of requests in minute. \ud835\udc5b \ud835\udc5b\n\ud835\udc38 \ud835\udc4b = \ud835\udf06 = 5 But what if there are two requests\nin the same millisecond?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nAlgorithmic ride sharing, approximately\nProbability of \ud835\udc58 requests from this area in the next 1 minute?\nOn average, \ud835\udf06 = 5 requests per minute\nBreak a minute down into infinitely small buckets:\nomg so small\n1 \u221e\nFor each time bucket:\n\ud835\udc4b ~ Bin \ud835\udc5b, \ud835\udc5d = \ud835\udf06/\ud835\udc5b\n\u2022 Independent Bernoulli trial\n! \"#!\n\u2022 You get a request (1) or you don\u2019t (0). \ud835\udc5b \ud835\udf06 \ud835\udf06\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = lim 1 \u2212\n\ud835\udc58\nLet \ud835\udc4b = # of requests in minute. \"\u2192% \ud835\udc5b \ud835\udc5b\n\ud835\udc38 \ud835\udc4b = \ud835\udf06 = 5\nGnarly math incoming!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\n!\n\ud835\udf06\nBinomial in the limit lim 1 \u2212 = \ud835\udc52$%\n!\u2192# \ud835\udc5b\n\"\n\ud835\udc5b \ud835\udf06 ! \ud835\udf06 \"#! E x p a n d \ud835\udc5b! \ud835\udf06% 1 \u2212 l\n\ud835\udc5b\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = lim 1 \u2212\n= lim\n\ud835\udc58\n\"\u2192% \ud835\udc5b \ud835\udc5b \"\u2192$ \ud835\udc58!(\ud835\udc5b \u2212 \ud835\udc58)! \ud835\udc5b% l %\n1 \u2212\n\ud835\udc5b\nR e a r r a n g e \ud835\udc5b! \ud835\udf06% 1 \u2212 \ud835\udc5bl \" D ee xf p n o a nt e =u nr ta l\nl im\n\ud835\udc5b! \ud835\udf06% \ud835\udc52/0\n= lim\n\"\u2192$ \ud835\udc5b%(\ud835\udc5b \u2212 \ud835\udc58)! \ud835\udc58! l % \"\u2192$ \ud835\udc5b%(\ud835\udc5b \u2212 \ud835\udc58)! \ud835\udc58! l %\n1 \u2212\n1 \u2212 \ud835\udc5b\n\ud835\udc5b\nE x p a n d \ud835\udc5b \ud835\udc5b \u2212 1 \u22ef \ud835\udc5b \u2212 \ud835\udc58 + 1 \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udf06% \ud835\udc52/0\n= lim\n\"\u2192$ \ud835\udc5b% \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58! l %\n1 \u2212\nL i +m cit\na\nna cn ea ll y s i s \ud835\udc5b% \ud835\udf06% \ud835\udc52/0 S i m p lif y \ud835\udf06%\n/0\n\ud835\udc5b\n= lim = \ud835\udc52\n\"\u2192$ \ud835\udc5b% \ud835\udc58! 1 \ud835\udc58!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nAlgorithmic ride sharing\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\n\ud83d\ude4b\nProbability of \ud835\udc58 requests from this area in the next 1 minute?\nOn average, \ud835\udf06 = 5 requests per minute\n1\n\ud835\udf06 Poisson\n23\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc52\ndistribution\n\ud835\udc58!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nPoisson Random Variable\nConsider an experiment that lasts a fixed interval of time.\ndef A Poisson random variable \ud835\udc4b is the number of successes over the\nexperiment duration, assuming the time that each success occurs is\nindependent and the average # of requests over time is constant.\n1\nPMF \ud835\udf06\n\ud835\udc4b~Poi(\ud835\udf06) \ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5223\n\ud835\udc58!\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf06\nSupport: {0,1, 2, \u2026 } Variance Var \ud835\udc4b = \ud835\udf06\nExamples:\n\u2022 # earthquakes per year Yes, expectation == variance\n\u2022 # server hits per second for Poisson RV! More later!\n\u2022 # of emails per day\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\n\ud835\udf06#\nEarthquakes\n\ud835\udc5d \ud835\udc58 = \ud835\udc52!\"\n\ud835\udc58!\nThere are an average of 2.79 major earthquakes in the world each year,\nand major earthquakes occur independently.\nWhat is the probability of 3 major earthquakes happening next year?\n1. Define RVs\n0.3\n0.25\n0.2\n2. Solve\n0.15\n0.1\n0.05\n0\n0 1 2 3 4 5 6 7 8 9 10\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n)\ud835\udc58\n=\n\ud835\udc4b(\ud835\udc43\n\ud835\udc4b~Poi(\ud835\udf06)\n\ud835\udc38 \ud835\udc4b = \ud835\udf06\nNumber of earthquakes, \ud835\udc58\nOther Discrete\nRVs\n11\nGrid of random variables\nNumber of Time until\nsuccesses success\nBer(\ud835\udc5d)\nOne trial One success\n\ud835\udc5b = 1\nSeveral Several\nBin(\ud835\udc5b, \ud835\udc5d)\ntrials successes\nInterval Interval of time to\nPoi(\ud835\udf06)\n(next week)\nof time first success\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nGeometric RV\nConsider an experiment: independent trials of Ber(\ud835\udc5d) random variables.\ndef A Geometric random variable \ud835\udc4b is the # of trials until the first success.\n12<\nPMF \ud835\udc43 \ud835\udc4b = \ud835\udc58 = 1 \u2212 \ud835\udc5d \ud835\udc5d\n\ud835\udc4b~Geo(\ud835\udc5d)\n3\n\ud835\udc38 \ud835\udc4b =\nExpectation\n4\n3#4\nVariance Var \ud835\udc4b =\nSupport: {1, 2, \u2026 }\n4!\nExamples:\n\u2022 Flipping a coin (\ud835\udc43 heads = \ud835\udc5d) until first heads appears\n\u2022 Generate bits with \ud835\udc43 bit = 1 = \ud835\udc5d until first 1 generated\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nNegative Binomial RV\nConsider an experiment: independent trials of Ber(\ud835\udc5d) random variables.\ndef A Negative Binomial random variable \ud835\udc4b is the # of trials until\n\ud835\udc5f successes.\n\ud835\udc58 \u2212 1\nPMF\n!#5 5\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = 1 \u2212 \ud835\udc5d \ud835\udc5d\n\ud835\udc4b~NegBin(\ud835\udc5f, \ud835\udc5d)\n\ud835\udc5f \u2212 1\n5\n\ud835\udc38 \ud835\udc4b =\nExpectation\n4\n5 3#4\nVariance\nVar \ud835\udc4b =\nSupport: {\ud835\udc5f, \ud835\udc5f + 1, \u2026 }\n4!\nExamples:\n\u2022 Flipping a coin until \ud835\udc5f45 heads appears\n\u2022 # of strings to hash into table until bucket 1 has \ud835\udc5f entries\nGeo \ud835\udc5d = NegBin(1, \ud835\udc5d)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nGrid of random variables\nNumber of Time until\nsuccesses success\nBer(\ud835\udc5d) Geo(\ud835\udc5d)\nOne trial One success\n\ud835\udc5b = 1 \ud835\udc5f = 1\nSeveral Several\nBin(\ud835\udc5b, \ud835\udc5d) NegBin(\ud835\udc5f, \ud835\udc5d)\ntrials successes\nInterval Interval of time to\nPoi(\ud835\udf06)\n(this Friday)\nof time first success\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nCatching Pokemon\nWild Pokemon are captured by throwing Pokeballs at them.\n\u2022 Each ball has probability p = 0.1 of capturing the Pokemon.\n\u2022 Each ball is an independent trial.\nWhat is the probability that you catch the Pokemon on the 5th try?\n1. Define events/ 2. Solve\nRVs & state goal\nA. \ud835\udc4b~Bin 5, 0.1\n\ud835\udc4b~some distribution B. \ud835\udc4b~Poi 0.5\nC. \ud835\udc4b~NegBin 5, 0.1\nWant: \ud835\udc43 \ud835\udc4b = 5\nD. \ud835\udc4b~NegBin 1, 0.1\nE. \ud835\udc4b~Geo 0.1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nCatching Pokemon \ud835\udc4b~Geo(\ud835\udc5d) \ud835\udc5d \ud835\udc58 = 1 \u2212 \ud835\udc5d #!$\ud835\udc5d\nWild Pokemon are captured by throwing Pokeballs at them.\n\u2022 Each ball has probability p = 0.1 of capturing the Pokemon.\n\u2022 Each ball is an independent trial.\nWhat is the probability that you catch the Pokemon on the 5th try?\n1. Define events/ 2. Solve\nRVs & state goal\nA. \ud835\udc4b~Bin 5, 0.1\n\ud835\udc4b~some distribution B. \ud835\udc4b~Poi 0.5\nC. \ud835\udc4b~NegBin 5, 0.1\nWant: \ud835\udc43 \ud835\udc4b = 5\nD. \ud835\udc4b~NegBin 1, 0.1\nE. \ud835\udc4b~Geo 0.1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nExercises\nThe hardest part of is almost always deciding what\nyou\u2019re modeling and what random variable to use.\n18\nChoose from: C. Poi \ud835\udf06\nKickboxing with RVs\nA. Ber \ud835\udc5d D. Geo \ud835\udc5d\nB. Bin \ud835\udc5b, \ud835\udc5d E. NegBin \ud835\udc5f, \ud835\udc5d\nHow might you model the following?\n1. # of snapchats you receive in a day\n2. # of children born to the same parents\nuntil the first one with green eyes\n3. If stock went up (1) or down (0) in a day\n4. # of probability problems you try until you\nget 5 correct (if you are randomly correct)\n5. # of years between now and 2050 with\nmore than 6 Atlantic hurricanes\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nChoose from: C. Poi \ud835\udf06\nKickboxing with RVs\nA. Ber \ud835\udc5d D. Geo \ud835\udc5d\nB. Bin \ud835\udc5b, \ud835\udc5d E. NegBin \ud835\udc5f, \ud835\udc5d\nHow might you model the following?\n1. # of snapchats you receive in a day C. Poi \ud835\udf06\n2. # of children born to the same parents D. Geo \ud835\udc5d or E. NegBin 1, \ud835\udc5d\nuntil the first one with green eyes\n3. If stock went up (1) or down (0) in a day A. Ber \ud835\udc5d or B. Bin 1, \ud835\udc5d\n4. # of probability problems you try until you E. NegBin \ud835\udc5f = 5, \ud835\udc5d\nget 5 correct (if you are randomly correct)\n5. # of years between now and 2050 with B. Bin \ud835\udc5b = 27, \ud835\udc5d , where\nmore than 6 Atlantic hurricanes \ud835\udc5d = \ud835\udc43 \u2265 6 hurricanes in a year\nNote: These exercises are designed to build intuition; in a calculated from C. Poi \ud835\udf06\nproblem statement, you\u2019ll generally be given more detail.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nPoisson Random Variable Review\n1\nPMF \ud835\udf06\n\ud835\udc4b~Poi(\ud835\udf06) \ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5223\n\ud835\udc58!\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf06\nSupport: {0,1, 2, \u2026 } Variance Var \ud835\udc4b = \ud835\udf06\nIn CS109, a Poisson RV \ud835\udc4b~Poi(\ud835\udf06) most often models\n1. # of successes in a fixed interval of time, where successes are independent\n\ud835\udf06 = \ud835\udc38[\ud835\udc4b], average success/interval\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\ud835\udc4b~Poi(\ud835\udf06)\n\ud835\udf06#\n1. Web server load\n\ud835\udc5d \ud835\udc58 = \ud835\udc52!\"\n\ud835\udc38 \ud835\udc4b = \ud835\udf06 \ud835\udc58!\nConsider requests to a web server in 1 second.\n\u2022 In the past, server load averages 2 hits/second, where requests arrive independently.\n\u2022 Let \ud835\udc4b = # requests the server receives in a second.\nWhat is \ud835\udc43 \ud835\udc4b < 5 ?\nDefine RVs Solve\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nPoisson Random Variable\n1\nPMF \ud835\udf06\n\ud835\udc4b~Poi(\ud835\udf06) \ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5223\n\ud835\udc58!\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf06\nSupport: {0,1, 2, \u2026 } Variance Var \ud835\udc4b = \ud835\udf06\nIn CS109, a Poisson RV \ud835\udc4b~Poi(\ud835\udf06) most often models\n1. # of successes in a fixed time interval, where successes are\nindependent\n\ud835\udf06 = \ud835\udc38[\ud835\udc4b], average success/interval\n2. Approximation of \ud835\udc4c~Bin(\ud835\udc5b, \ud835\udc5d) where \ud835\udc5b is large and \ud835\udc5d is small.\n\ud835\udf06 = \ud835\udc38 \ud835\udc4c = \ud835\udc5b\ud835\udc5d\nApproximation works well even when trials not entirely independent.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n2. DNA\nAll the movies, images,\nemails and other digital\ndata from more than\n600 smartphones\n(10,000 GB) can be\nstored in the faint pink\nsmear of DNA at the end\nof this test tube.\nWhat is the probability\nthat DNA storage stays\nuncorrupted?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n2. DNA\nWhat is the probability that DNA storage stays uncorrupted?\n\u2022 In DNA (and real networks), we store large strings.\n\u2022 Let string length be long, e.g., \ud835\udc5b \u2248 106\n\u2022 Probability of corruption of each base pair is very small, e.g., \ud835\udc5d = 10/7\n\u2022 Let \ud835\udc4b = # of corruptions.\nWhat is P(DNA storage is uncorrupted) = \ud835\udc43 \ud835\udc4b = 0 ?\n1. Approach 1: 2. Approach 2:\n8 #9 8 #9\n\ud835\udc4b~Bin \ud835\udc5b = 10 , \ud835\udc5d = 10 \ud835\udc4b~Poi \ud835\udf06 = 10 \u22c5 10 = 0.01\n% 9\n\ud835\udc5b \ud835\udf06 0.01\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d% 1 \u2212 \ud835\udc5d \"/% \ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc52/0 = \ud835\udc52/9.9:\n\ud835\udc58\n\ud835\udc58! 0!\n106\n/7\u22c59 /7 :9!/9 =\n\ud835\udc52/9.9:\n= 10 1 \u2212 10\nunwieldy!\n0\na good\n\u2248 0.990049829 \u2248 0.990049834\napproximation!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nWhen is a Poisson approximation appropriate?\n! \"#!\n\ud835\udc5b \ud835\udf06 \ud835\udf06 Under which conditions will\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = lim 1 \u2212 = \u22ef\n\ud835\udc58 \ud835\udc5b \ud835\udc5b \ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) behave like\n\"\u2192%\nD ee xf\np\nn\no\na nt eu nr ta l\n\ud835\udc5b!\n\ud835\udf06% \ud835\udc52/0\nPoi(\ud835\udf06), where \ud835\udf06 = \ud835\udc5b\ud835\udc5d?\n= lim\nA. Large \ud835\udc5b, large \ud835\udc5d\n\"\u2192$ \ud835\udc5b%(\ud835\udc5b \u2212 \ud835\udc58)! \ud835\udc58! l %\n1 \u2212 B. Small \ud835\udc5b, small \ud835\udc5d\n\ud835\udc5b\nC. Large \ud835\udc5b, small \ud835\udc5d\nE x p a n d \ud835\udc5b \ud835\udc5b \u2212 1 \u22ef \ud835\udc5b \u2212 \ud835\udc58 + 1 \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udf06% \ud835\udc52/0\nD. Small \ud835\udc5b, large \ud835\udc5d\n= lim\n\"\u2192$ \ud835\udc5b% \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58! l % E. Other\n1 \u2212\n\ud835\udc5b\nm it\na n a l y s i s\n\ud835\udc5b% \ud835\udf06% \ud835\udc52/0\nL i\n= lim\n\"\u2192$ \ud835\udc5b% \ud835\udc58! 1\nm p\nlif y\n%\nS i \ud835\udf06\n/0\n= \ud835\udc52\n\ud835\udc58!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nPoisson approximation\nPoisson approximates Binomial 0.3\nwhen \ud835\udc5b is large, \ud835\udc5d is small, and\n0.25\n\ud835\udf06 = \ud835\udc5b\ud835\udc5d is \"moderate\u201d.\n0.2\nDifferent interpretations of 0.15\n\"moderate\":\n0.1\n\u2022 \ud835\udc5b > 20 and \ud835\udc5d < 0.05\n0.05\n\u2022 \ud835\udc5b > 100 and \ud835\udc5d < 0.1\n0\n0 1 2 3 4 5 6 7 8 9 10\nPoisson is Binomial in the limit:\n\u2022 \ud835\udf06 = \ud835\udc5b\ud835\udc5d, where \ud835\udc5b \u2192 \u221e, \ud835\udc5d \u2192 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\n)\ud835\udc58\n=\n\ud835\udc4b(\ud835\udc43\n\ud835\udc4b~Poi(\ud835\udf06) \ud835\udc4c~Bin(\ud835\udc5b,\ud835\udc5d)\n\ud835\udc38 \ud835\udc4b = \ud835\udf06 \ud835\udc38 \ud835\udc4c = \ud835\udc5b\ud835\udc5d\nBin(10,0.3)\nBin(100,0.03)\nBin(1000,0.003)\nPoi(3)\n\ud835\udc4b = \ud835\udc58\nPoisson Random Variable\nConsider an experiment that lasts a fixed interval of time.\ndef A Poisson random variable \ud835\udc4b is the number of occurrences over the\nexperiment duration.\n1\nPMF \ud835\udf06\n\ud835\udc4b~Poi(\ud835\udf06) \ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5223\n\ud835\udc58!\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf06\nSupport: {0,1, 2, \u2026 } Variance Var \ud835\udc4b = \ud835\udf06\nExamples:\n\u2022 # earthquakes per year\n\u2022 # server hits per second Time to show intuition for why\n\u2022 # of emails per day expectation == variance!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nProperties of Poi(\ud835\udf06) with the Poisson paradigm\nRecall the Binomial:\nExpectation \ud835\udc38 \ud835\udc4c = \ud835\udc5b\ud835\udc5d\n\ud835\udc4c~Bin(\ud835\udc5b, \ud835\udc5d)\nVariance Var \ud835\udc4c = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nConsider \ud835\udc4b~Poi(\ud835\udf06), where \ud835\udf06 = \ud835\udc5b\ud835\udc5d (\ud835\udc5b \u2192 \u221e, \ud835\udc5d \u2192 0):\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf06\n\ud835\udc4b~Poi(\ud835\udf06)\nVariance Var \ud835\udc4b = \ud835\udf06\nProof:\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d = \ud835\udf06\nVar \ud835\udc4b = \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d \u2192 \ud835\udf06 1 \u2212 0 = \ud835\udf06\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nPoisson Approximation, approximately\nPoisson can still provide a good approximation of the Binomial,\neven when assumptions are \"mildly\" violated.\nYou still can apply the Poisson approximation when:\n\u2022 \"Successes\" in trials are almost, but not entirely independent\ne.g., # entries in each bucket in large hash table.\n\u2022 Probability of \"success\" in each trial varies (slightly),\nlike a small relative change in a very small p\ne.g., average # requests to web server/sec may fluctuate\nslightly due to load on network or time of day\nWe won\u2019t explore this too much, but we\nwant you to know about it anyway.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nCan these Binomial RVs be approximated?\n0.1\nPoisson approximates Binomial\n0.05\nwhen \ud835\udc5b is large, \ud835\udc5d is small, and\n\ud835\udf06 = \ud835\udc5b\ud835\udc5d is \"moderate\". 0\n0 10 20 30 40 50 60 70 80 90\nDifferent interpretations of\n\"moderate\":\n\u2022 \ud835\udc5b > 20 and \ud835\udc5d < 0.05\n\u2022 \ud835\udc5b > 100 and \ud835\udc5d < 0.1\nPoisson is Binomial in the limit:\n\u2022 \ud835\udf06 = \ud835\udc5b\ud835\udc5d, where \ud835\udc5b \u2192 \u221e, \ud835\udc5d \u2192 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\n)#\n=\n\"(!\nBin(100,0.5)\n0.3\n0.2\n0.1\n0\n0 10 20 30 40 50 60 70 80 90\n)#\n=\n\"(!\nBin(100,0.04)\n0.3\n0.2\n0.1\n0\n0 10 20 30 40 50 60 70 80 90\n)#\n=\n\"(!\nBin(100,0.96)\nCan these Binomial RVs be approximated?\n0.1\n0.05\n0\n0 10 20 30 40 50 60 70 80 90\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n)\ud835\udc58\n=\n\ud835\udc4b(\ud835\udc43\nBin(100,0.5)\nPoi(50)\n0.3\n0.2\n0.1\n0\n0 10 20 30 40 50 60 70 80 90\n)\ud835\udc58\n=\n\ud835\udc4b(\ud835\udc43\nBin(100,0.04)\nPoi(4)\n0.3\n0.2\n0.1\n0\n0 10 20 30 40 50 60 70 80 90\n)\ud835\udc58\n=\n\ud835\udc4b(\ud835\udc43\nPoisson approximates Binomial\nwhen \ud835\udc5b is large, \ud835\udc5d is small, and\n\ud835\udf06 = \ud835\udc5b\ud835\udc5d is \"moderate\".\nDifferent interpretations of\n\u201cmoderate\u201d:\n\u2022 \ud835\udc5b > 20 and \ud835\udc5d < 0.05\n\u2022 \ud835\udc5b > 100 and \ud835\udc5d < 0.1\nPoisson is Binomial in the limit:\nBin(100,0.96) Poi(4)\nCan approximate\nBin(100,1-0.96)\n\u2022 \ud835\udf06 = \ud835\udc5b\ud835\udc5d, where \ud835\udc5b \u2192 \u221e, \ud835\udc5d \u2192 0 <END>"}
{"prompt": "Lecture notes from 04_section_soln.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May2nd,2024\nContinuous Random Variables, Joint Distributions\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Reviewing the Basics\na. GivenaNormalRV \ud835\udc4b \u223c \ud835\udc41(\ud835\udf07,\ud835\udf0e2),howcanwecompute \ud835\udc43(\ud835\udc4b \u2264 \ud835\udc65) fromthestandard\nNormaldistributionZwithCDF \ud835\udf19?\nb. Whatisacontinuitycorrectionandwhenshouldweuseit?\nc. IfwehaveajointPMFfordiscreterandomvariables \ud835\udc5d \ud835\udc4b,\ud835\udc4c(\ud835\udc65,\ud835\udc66),howcanwecomputethe\nmarginalPMF \ud835\udc5d \ud835\udc4b(\ud835\udc65)?\na. First,weapplyalineartransformationtoarriveat\u03a6((\ud835\udc65 \u2212 \ud835\udf07)/\ud835\udf0e).Wethenlookup\nthevaluewe\u2019vecomputedintheStandardNormalTable(orwerelyonPythonto\ncomputetheprobabilityforus).\nb. ContinuitycorrectionisusedwhenaNormaldistributionisusedtoapproximatea\nBinomial.SinceaNormaliscontinuousandBinomialisdiscrete,wehavetousea\ncontinuitycorrectiontodiscretizetheNormal.Thecontinuitycorrectionmakesitso\nthatthenormalvariableisevaluatedfrom+or-0.5incrementsfromthedesired \ud835\udc58\nvalue.\nc. Themarginaldistributionis \ud835\udc5d \ud835\udc4b(\ud835\udc65) = (cid:205)\n\ud835\udc66\n\ud835\udc5d \ud835\udc4b,\ud835\udc4c(\ud835\udc65,\ud835\udc66)\n1.2 Independent Random Variables\na. WhatdistributiondoesthesumoftwoindependentbinomialRVs \ud835\udc4b +\ud835\udc4c have,where \ud835\udc4b \u223c\n\ud835\udc35\ud835\udc56\ud835\udc5b(\ud835\udc5b , \ud835\udc5d) and\ud835\udc4c \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(\ud835\udc5b , \ud835\udc5d)?Includeanyparameterswithyouranswer.\n1 2\nb. WhatdistributiondoesthesumoftwoindependentPoissonRVs \ud835\udc4b +\ud835\udc4c have,where \ud835\udc4b \u223c\nPoi(\ud835\udf06 ) and\ud835\udc4c \u223c Poi(\ud835\udf06 )?Includeanyparameterswithyouranswer.\n1 2\na. Binomial: \ud835\udc4b +\ud835\udc4c \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(\ud835\udc5b +\ud835\udc5b , \ud835\udc5d)\n1 2\nb. Poisson: \ud835\udc4b +\ud835\udc4c \u223c Poi(\ud835\udf06 +\ud835\udf06 )\n1 2\n\u20132\u2013\n2 Marguerite Gets Some Competition\nInthelate1880s,Stanfordbeganrunningahorseandtwelve-personbuggyservicefromtheStan-\nfordQuadtothetrainstationjustoffcampus.Thenameofthisshuttlingservicewaschosentobe\nMarguerite,whichwasthenameofthefavoritehorseofsomeStanfordbigwigofthetime.The\nhorse-and-carriageoperationwasretiredaround1910andreplacedwithelectricstreetcars,which\nthemselveswerereplacedwithbusesaround1930.Theservicehasgrownsubstantiallysince,and\nthebuseshavebeenupgradedseveraltimes.Theservice,however,hasretaineditsnamesincethe\nverybeginning.\nSeveralStanfordhorseenthusiastshaverecentlyrevivedthehorse-and-buggyservicetocompete\nwithMarguerite,andthey\u2019vegivenitthenameHildegard.Now,whenyouneedaridefromthe\nQuadtothetrainstation,youhavetwooptions!\nYouarriveattheQuad,headedtothetrainstation,andyou\u2019reequallyhappytotakeeitherofthe\ntwoindependentservices.Youarrivepreciselyat8:00am,whichisthetimethatbothservices\nstartfortheday.ThenumberofminutesyouneedtowaitforaMargueritebusismodeledbya\ndiscreteUniformrandomvariable \ud835\udc40 \u223c \ud835\udc48\ud835\udc5b\ud835\udc56(0,20),whereasthenumberofminutesyouneed\ntowaitforaHildegardhorse-and-buggyismodeledbyadiscretePoissonrandomvariable \ud835\udc3b \u223c\n\ud835\udc43\ud835\udc5c\ud835\udc56(10).(Yes,it\u2019stechnicallypossiblethatHildegardneverarrives.)\na. WhatistheprobabilitythatMargueriteandHildegardbotharriveat\ud835\udc61 = 6minutes?\nWecanrepresenttheeventsthattheMargueriteandHildegardarriveat\ud835\udc61 = 6minutesas\n\ud835\udc40 = 6and \ud835\udc3b = 6,respectively.Write\n\ud835\udc43(\ud835\udc40 = 6,\ud835\udc3b = 6) = \ud835\udc43(\ud835\udc40 = 6)\ud835\udc43(\ud835\udc3b = 6) (\ud835\udc40 \u22a5 \ud835\udc3b)\n1 106\ud835\udc52\u221210\n= \u00b7 .\n21 6!\nb. Whatistheconditionalprobabilitythat \ud835\udc3b < \ud835\udc40,given \ud835\udc40 = \ud835\udc5a\u2014thatis,whatis \ud835\udc43(\ud835\udc3b <\n\ud835\udc40|\ud835\udc40 = \ud835\udc5a)?Expressyouranswerasasum.\nWewerelookingforsomethingalongthelinesofthis:\n\ud835\udc43(\ud835\udc3b < \ud835\udc40|\ud835\udc40 = \ud835\udc5a) = \ud835\udc43(\ud835\udc3b < \ud835\udc5a) (specifyingvalueof \ud835\udc40)\n\ud835\udc5a\u22121\n\u2211\ufe01\n= \ud835\udc43(\ud835\udc3b = \u210e)\n\u210e=0\n\ud835\udc5a \u2211\ufe01\u22121 10\u210e\ud835\udc52\u221210\n= .\n\u210e!\n\u210e=0\nc. Whatistheunconditionalprobabilitythat \ud835\udc3b < \ud835\udc40,i.e.,whatis \ud835\udc43(\ud835\udc3b < \ud835\udc40)?Expressyour\nanswerasadoublesumthatleveragesyouranswertopartb.\n\u20133\u2013\nWewerelookingforsomethinglikethis:\n\u2211\ufe01\n\ud835\udc43(\ud835\udc3b < \ud835\udc40) = \ud835\udc43(\ud835\udc3b < \ud835\udc40,\ud835\udc40 = \ud835\udc5a) (LawofTotalProbability)\n\ud835\udc5a\n\u2211\ufe01\n= \ud835\udc43(\ud835\udc3b < \ud835\udc40|\ud835\udc40 = \ud835\udc5a)\ud835\udc43(\ud835\udc40 = \ud835\udc5a) (ChainRule)\n\ud835\udc5a\n20\n\u2211\ufe01 1\n= \u00b7 \ud835\udc43(\ud835\udc3b < \ud835\udc40|\ud835\udc40 = \ud835\udc5a)\n21\n\ud835\udc5a=0\n1\n\u2211\ufe0120 \ud835\udc5a \u2211\ufe01\u22121 10\u210e\ud835\udc52\u221210\n= (frompartb)\n21 \u210e!\n\ud835\udc5a=0 \u210e=0\nd. WhatistheCDFofyourwaitingtimeforthefirstofthetwotoarrive?Youshouldleave\nyouranswerinsummationform.\nLet \ud835\udc46 betherandomvariablerepresentingyourwaitingtimeforthefirstofthetwotoar-\nrive.Thenwehave \ud835\udc46 = min{\ud835\udc40,\ud835\udc3b},andaccordinglythat \ud835\udc46 \u2208 {0,1,...,20}.Letting \ud835\udc39 \ud835\udc46 be\ntheCDFof \ud835\udc46 and \ud835\udc60 \u2208 {0,1,...,20},write\n\ud835\udc39 \ud835\udc46(\ud835\udc60) = \ud835\udc43(\ud835\udc46 \u2264 \ud835\udc60) (definitionofCDF)\n= \ud835\udc43(min{\ud835\udc40,\ud835\udc3b} \u2264 \ud835\udc60) (definitionof \ud835\udc46)\n= \ud835\udc43(\ud835\udc40 \u2264 \ud835\udc60\u222a\ud835\udc3b \u2264 \ud835\udc60)\n(cid:18) (cid:19)\n= 1\u2212 \ud835\udc43 (cid:0)\ud835\udc40 \u2264 \ud835\udc60\u222a\ud835\udc3b \u2264 \ud835\udc60(cid:1)\ud835\udc36\n= 1\u2212 \ud835\udc43(\ud835\udc40 > \ud835\udc60,\ud835\udc3b > \ud835\udc60) (DeMorgan\u2019sLaw)\n= 1\u2212 \ud835\udc43(\ud835\udc40 > \ud835\udc60)\ud835\udc43(\ud835\udc3b > \ud835\udc60) (\ud835\udc40 \u22a5 \ud835\udc3b)\n(cid:18) 20 (cid:19)(cid:18) \u221e (cid:19)\n\u2211\ufe01 \u2211\ufe01\n= 1\u2212 \ud835\udc43(\ud835\udc40 = \ud835\udc5a) \ud835\udc43(\ud835\udc3b = \u210e)\n\ud835\udc5a=\ud835\udc60+1 \u210e=\ud835\udc60+1\n(cid:18) \u2211\ufe0120\n1\n(cid:19)(cid:18) \u2211\ufe01\u221e 10\u210e\ud835\udc52\u221210(cid:19)\n= 1\u2212\n21 \u210e!\n\ud835\udc5a=\ud835\udc60+1 \u210e=\ud835\udc60+1\n(cid:18) 20\u2212\ud835\udc60(cid:19)(cid:18) \u2211\ufe01\ud835\udc60 10\u210e\ud835\udc52\u221210(cid:19)\n= 1\u2212 1\u2212 .\n21 \u210e!\n\u210e=0\n3 Burrow Smoke Detectors and Joint Probability Distributions\nBurrowLabshastakenonotherstartupsinthehomesafetyandsecurityspaceandhasrecently\nstartedmarketinganewsmokedetector.Burrow\u2019ssmokedetectorsrelyon\ud835\udc36\ud835\udc42 sensorsthat\n2\neventuallyfail,andthatfailuretimedictatestheaverageproductlifetimeofthesmokedetector.\n\u20134\u2013\nBurrowmanufacturesthreequartersofitssmokedetectorsincentralIdaho,andtherestareman-\nufacturedinsuburbanMaine.Anysinglesmokedetector\u2019sproductlifetimecanbemodeledasa\nExponentialrandomvariable.\nEachofthetwolocationssourcesits\ud835\udc36\ud835\udc42 sensorsfromdifferentsuppliers,sothesmokedetec-\n2\ntorsmanufacturedinMainehaveanaverageproductlifetimeof7yearsandthesmokedetectors\nmanufacturedinIdahohaveanaverageproductlifetimeof6years.Allsmokedetectorsaresold\nonline,soasidefromthefactthatasmokedetectoristhreetimesmorelikelytoshipfromthe\nIdahofacility,youcan\u2019ttellbylookingatasinglesmokedetectorwhereitwasmanufactured.\nLet\ud835\udc47 modeltheamountoftimethatpassesuntilthe\ud835\udc36\ud835\udc42 sensor(andthereforethesmokedetec-\n2\ntor)fails,andlet \ud835\udc40 beadiscreterandomvariablethattakesonthevalueof1forasmokedetec-\ntormanufacturedinMaine,and0otherwise.\na. Presentthecumulativedistributionandprobabilitydensityfunctionsfortherandomvari-\nable\ud835\udc47.BothyourCDFandyourPDFshouldbeanalyticfunctionson\ud835\udc61.\nTheLawofTotalProbabilityappliestoallprobabilities,includingcumulativeonesrele-\nvanttocontinuousdistributions.Thatmeansthat:\n\ud835\udc39 \ud835\udc47(\ud835\udc61) = \ud835\udc43(\ud835\udc47 \u2264 \ud835\udc61) = \ud835\udc43(\ud835\udc47 \u2264 \ud835\udc61|\ud835\udc40 = 1) \u00b7 \ud835\udc43(\ud835\udc40 = 1) + \ud835\udc43(\ud835\udc47 \u2264 \ud835\udc61|\ud835\udc40 = 0) \u00b7 \ud835\udc43(\ud835\udc40 = 0)\n1 3\n=\n(1\u2212\ud835\udc52\u2212\ud835\udc61/7)\n\u00b7 +\n(1\u2212\ud835\udc52\u2212\ud835\udc61/6)\n\u00b7\n4 4\n1 3\n= 1\u2212\n\ud835\udc52\u2212\ud835\udc61/7\n\u2212\n\ud835\udc52\u2212\ud835\udc61/6\n4 4\n1 3\n\ud835\udc53 \ud835\udc47(\ud835\udc61) = \ud835\udc39 \ud835\udc47\u2032(\ud835\udc61) = \ud835\udc52\u2212\ud835\udc61/7 + \ud835\udc52\u2212\ud835\udc61/6\n28 24\nOfcourse,thesearealldefinedfornon-negativevaluesof\ud835\udc61.\nb. ComputetheprobabilitythatasmokedetectorwasmanufacturedinMaine,giventhatit\nlastsmorethan15years.Ifneeded,youcankeepyouranswerintermsof \ud835\udc39 \ud835\udc47(15) or \ud835\udc53 \ud835\udc47(15)\nfrompart(a).However,anyconditionalexpressionoftheform \ud835\udc43(\u00b7|\u00b7) or \ud835\udc53(\u00b7|\u00b7) mustbe\nevaluated.\nWeonceagainrelyonahybridformofBayes\u2019sTheorem,althoughthistimetheprobabili-\ntiesrequireweintegrateanaccumulationofprobabilitydensitiesonTfortgreaterthan15\n\u20135\u2013\nhours.\n\ud835\udc43(\ud835\udc47 > 15|\ud835\udc40 = 1)\ud835\udc43(\ud835\udc40 = 1)\n\ud835\udc43(\ud835\udc40 = 1|\ud835\udc47 > 15) =\n\ud835\udc43(\ud835\udc47 > 15)\n1 1\u2212 \ud835\udc43(\ud835\udc47 \u2264 15|\ud835\udc40 = 1)\n= \u2217\n4 1\u2212 \ud835\udc43(\ud835\udc47 \u2264 15)\n1 1\u2212 (1\u2212\ud835\udc52\u221215/7)\n= \u2217\n4 1\u2212 \ud835\udc39 \ud835\udc47(15)\n1 \ud835\udc52\u221215/7\n= \u2217\n4 1\u2212 \ud835\udc39 \ud835\udc47(15)\n= 0.32268\n4 Elections\nWewouldliketoseehowwecouldpredictanelectionbetweentwocandidatesinFrance(Aand\nB),givendatafrom10polls.Foreachofthe10polls,wereportbelowtheirsamplesize,how\nmanypeoplesaidtheywouldvoteforcandidateA,andhowmanypeoplesaidtheywouldvote\nforcandidateB.Notallpollsarecreatedequal,soforeachpollwealsoreportavalue\u201dweight\u201d\nwhichrepresentshowaccuratewebelievethepollwas.Thedataforthisproblemcanbefoundon\ntheclasswebsiteinpolls.csv:\na. First,assumethateachsampleineachpollisanindependentexperimentofwhetherornot\narandompersoninFrancewouldvoteforcandidateA(disregardweights).\n\u2022 CalculatetheprobabilitythatarandompersoninFrancevotesforcandidateA.\n\u2022 AssumeeachpersonvotesforcandidateAwiththeprobabilityyou\u2019vecalculatedand\notherwisevotesforcandidateB.IfthepopulationofFranceis64,888,792,whatisthe\nprobabilitythatcandidateAgetsmorethanhalfofthevotes?\n\u20136\u2013\nb. NateSilveratfivethirtyeightpioneeredanapproachcalledthe\u201dPollofPolls\u201dtopredict\nelections.ForeachcandidateAorB,wehavearandomvariable \ud835\udc46 \ud835\udc34 or \ud835\udc46 \ud835\udc35 whichrepresents\ntheirstrengthonelectionnight(likeELOscores).TheprobabilitythatAwinsis \ud835\udc43(\ud835\udc46 \ud835\udc34 >\n\ud835\udc46 \ud835\udc35).\n\u2022 Identifytheparametersfortherandomvariables \ud835\udc46 \ud835\udc34 and \ud835\udc46 \ud835\udc35.Both \ud835\udc46 \ud835\udc34 and \ud835\udc46 \ud835\udc35 arede-\nfinedtobenormalwiththefollowingparameters:\n\u2022 Wewillcalculate \ud835\udc43(\ud835\udc46 \ud835\udc34 > \ud835\udc46 \ud835\udc35) bysimulating100,000fakeelections.Ineachfakeelec-\ntion,wedrawarandomsampleforthestrengthofAfrom \ud835\udc46 \ud835\udc34 andarandomsample\nforthestrengthofBfrom \ud835\udc46 \ud835\udc35.If \ud835\udc46 \ud835\udc34 isgreaterthan \ud835\udc46 \ud835\udc35,candidateAwins.Whatdowe\nexpecttoseeifwesimulatesomanytimes?Whatdoweactuallysee?\nc. Whichmodel,theonefrom(a)orthemodelfrom(b)seemsmoreappropriate?Whymight\nthatbethecase?OnelectionnightcandidateAwins.Wasyourpredictionfrompart(b)\n\u201dcorrect\u201d?\na. \ud835\udc43(randompersonvotesforA) = \ud835\udc63\ud835\udc5c\ud835\udc61\ud835\udc52\ud835\udc60\ud835\udc53\ud835\udc5c\ud835\udc5f\ud835\udc34 = 4881 = 0.655\n\ud835\udc61\ud835\udc5c\ud835\udc61\ud835\udc4e\ud835\udc59\ud835\udc63\ud835\udc5c\ud835\udc61\ud835\udc52\ud835\udc60 7453\nNow,letXbethenumberofvotesforcandidateA.WeassumethatX\n\u02dc\ud835\udc35\ud835\udc56\ud835\udc5b(64888792,0.655).\n\u2022 Sincenissolarge,wecanapproximateXusinganormalY\u02dc\ud835\udc41(\ud835\udc5b\ud835\udc5d,\ud835\udc5b\ud835\udc5d(1\u2212 \ud835\udc5d)).\n\u2022 \ud835\udf07 = \ud835\udc5b\ud835\udc5d = 42502158.76,Variance= \ud835\udc5b\ud835\udc5d(1\u2212 \ud835\udc5d) = 14663244.77StdDev=3829.26\n\u2022 Votestowin= 64888792 = 32444396\n2\n\u2022 \ud835\udc43(Agetsenoughvotes) = \ud835\udc43(\ud835\udc4b > 32444396) \u2248 \ud835\udc43(\ud835\udc4c > 32444396.5) = 1.00\nb. \ud835\udc46 \ud835\udc34 \u02dc\ud835\udc41(5.324,16.436)\n\ud835\udc46\n\ud835\udc35\n\u02dc\ud835\udc41(2.926,16.436)\n\ud835\udc43(\ud835\udc46\n\ud835\udc34\n> \ud835\udc46 \ud835\udc35) \u2248 0.66\nWecanfigurethisoutthroughsimulationbydrawingfrom \ud835\udc46 \ud835\udc34 and \ud835\udc46 \ud835\udc35 100,000timesand\nseeinghowoftenthe \ud835\udc46 \ud835\udc34 valueisgreaterthanthe \ud835\udc46 \ud835\udc35 value.Laterinthequarter,when\nwelearntheconvolutionofindependentGaussians,youwillbeabletofigurethisout\nmathematically,withoutsampling.\nc. Algorithm(a)makesveryfewassumptions,andsimplicitycanbeuseful,butitdoes\nassumethateachvoterisindependent,whichwedefinitelyknowisn\u2019tthecaseinreal\n\u20137\u2013\nelections.Algorithm(b)allowsustomodelbias(usingtheweightsweincorporated),and\ndoesn\u2019tthinkofeachvoterasnecessarilyindependent. <END>"}
{"prompt": "Lecture notes from netflix-readme.txt\n\n###\n\n", "completion": "Task:\nYour task is to predict if a user would rate Love Actually with 5 five stars based on their ratings for the 19 other movies. \n\nValues:\nEach row in the train and test set represents one user. Each column represents one movie. All users in the dataset rated all movies in the dataset. Each entry in this dataset is binary. A value of 1 indicates a rating of 5 stars. A value of 0 indicates a rating of 1, 2, 3 or 4 stars. \n\nColumn meaning:\nEach column represents ratings for a particular movie.\n\nPrediction:\nThe variable you are predicting is the binary value for the user's rating of the movie Love Actually.\n\nCredit:\nThis dataset is based on data originally made for the \"Netflix Prize\". The Netflix Prize data was initially retracted because of concerns over user privacy. Reed Hastings, the CEO of Netflix, gave the official thumbs up for CS109 to release this anonymized subsample of data. Thanks to Matt Chen for his help in getting the Netflix Prize data. <END>"}
{"prompt": "Lecture notes from cs109_cheat_cheat.txt\n\n###\n\n", "completion": "CS109 LaTeX Cheat Sheet\nCreated by Derek Chong for CS109 during Spring 2020.\nThis cheat sheet assumes you have done an introductory tutorial and have a basic level of\ngeneral knowledge. It focuses on giving you a quick reference for language features you will\nencounter in CS109, in order to make your life easier when working on problem sets.\nFrequently-Used Markup\nBuilding Blocks\n\\geq \\leq\n\\neq \\approx\n\\sim \\Rightarrow\n\\sqrt{42} \\infty\n\\lambda \\mu, \\sigma\n\\Phi(0) \\Sigma\n\\theta \\bar{X}, \\hat{X}\nA,B,\\dots,Z 1,2,\\cdots,n\n\\verb|my_function() \\frac{42 \\textrm{\n| units} \\times 42\n\\textrm{ units}}{42\n\\textrm{ units}\n\\times 42 \\textrm{\nunits}}\n\\sum_{i=0}^{n} \\prod_{i=0}^{n}\n\\frac{a}{b} \\frac{a}{b}\nProbability\nP(A \\cap B) P(A \\cup B)\n\\binom{n}{k} P(A_1|B^C)\nP(\\textrm{text } | P(\\textrm{cond}\n\\textrm{ text}) \\leq 5.0)\n\\frac{P(\\textrm{a } \\frac{P(\\textrm{a }\n| \\textrm{ b}) | \\textrm{ b})\n\\times \\times\nP(\\textrm{b})}{P(\\t P(\\textrm{b})}{P(\\t\nextrm{a})} extrm{a } |\n\\textrm{\nb})P(\\textrm{b}) +\nP(\\textrm{a } |\n\\textrm{\nb}^C)P(\\textrm{b}^C\n)}\nRandom Variables\nX \\sim X \\sim\n\\textrm{Ber}(p) \\textrm{Bin}(n,p)\nX \\sim X \\sim\n\\textrm{Poi}(\\lambd \\textrm{Exp}(\\lambd\na=0) a=0)\nX \\sim \\theta \\sim\n\\mathcal{N}(\\mu = \\textrm{Beta}(a,b)\n0, \\sigma^2 = 1)\nCalculus\n\\int_{-1}^{1} x^2 - \\left[ x -\n2x + 1 dx \\frac{1}{2}x^2\n\\right]_{-1}^1\n\\iint_{0<y<x<1} \\left. \\frac{2}{3}y\n\\frac{x}{y} dy dx - \\frac{3}{4}y^2\n\\right|_{-1}^{x}\nVariance and Covariance\n\\textrm{Var}(X) \\textrm{Cov}(X,Y)\n\\begin{bmatrix} a & \\rho\nb \\\\ c & d\n\\end{bmatrix}\n\nUseful Structures\nGroups of Equations\n\\begin{align*} chunks can be used to organise multiple lines of equations.\n\u200b\n\\begin{align*}\nP(X=x|Y=1,W=P_1)\n&= \\frac{P(X=x,Y=1 |\nW=P_1)}{P(Y=1|W=P_1)} \\\\\n&= P(X=x|W=P_1) \\\\\n&= \\binom{5}{x}(0.1)^x(0.9)^{5-x} \\\\\nP(X=x|Y=1,W=P_2)\n&= \\frac{P(X=x,Y=1 |\nW=P_2)}{P(Y=1|W=P_2)} \\\\\n&= P(X=x|W=P_2) \\\\\n&= \\binom{5}{x}(0.1)^x(0.9)^{5-x}\n\\end{align*}\nVenn Diagrams\nYou may have to install the venndiagram package (and include \\usepackage{venndiagram})\n\u200b \u200b \u200b \u200b\n\\begin{venndiagram3sets}[labelA={Foo},labelB={Bar},labelC\n={Baz},\nlabelOnlyA={1},labelOnlyB={2},labelOnlyC={3},\nlabelOnlyAB={4},labelOnlyAC={5},labelOnlyBC={6},labelABC=\n{7},\nlabelNotABC={8}]\n\\begin{center}\n\\begin{venndiagram3sets}[labelA={Foo},labelB={Bar},labelC\n={Baz},\nlabelOnlyA={1},labelOnlyB={2},labelOnlyC={3},\nlabelOnlyAB={4},labelOnlyAC={5},labelOnlyBC={6},labelABC=\n{7},labelNotABC={8},shade={yellow}]\n\\fillOnlyB\\end{venndiagram3sets}\n\\end{center}\n\\begin{center}\n\\begin{venndiagram2sets}[labelA={Foo},labelB={Bar},\nlabelOnlyA={$x$},labelOnlyB={$z$}, labelAB={$y$},\nshade={white}]\n\\fillAll\n\\end{venndiagram2sets}\n\\end{center}\nFull package documentation is available here:\nhttps://ctan.math.illinois.edu/macros/latex/contrib/venndiagram/venndiagram.pdf\nPlotting Graphs\n\\begin{tikzpicture}\n\\begin{axis}[\naxis lines = center,\nxlabel = {$p$},\n]\n\\addplot [domain=-0.05:1.5, samples=100,\ncolor=blue]{x};\n\\addlegendentry{$p$}\n\\addplot [domain=-0.05:1.5, samples=100,\ncolor=red]{x*x};\n\\addlegendentry{$q = p^2$}\n\\end{axis}\n\\end{tikzpicture}\nProbability Trees\n\\tikzstyle{level 1}=[level distance=3.5cm, sibling\ndistance=3cm]\n\\tikzstyle{level 2}=[level distance=3.5cm, sibling\ndistance=3.3cm]\n\\tikzstyle{bag} = [text width=4em, text centered]\n\\tikzstyle{end} = [circle, minimum width=3pt,fill, inner\nsep=0pt]\n\\begin{tikzpicture}[grow=right]\n\\node[bag] {Foo}\nchild {\nnode[bag] {Bar}\nchild {\nnode[end, label=right:{Baz}] {}\nedge from parent\nnode[above] {$X$}\nnode[below] {$x$}\n}\nchild {\nnode[end, label=right:{Xyzzy}] {}\nedge from parent\nnode[above] {$X$}\nnode[below] {$x$}\n}\nedge from parent\nnode[above] {$X$}\nnode[below] {$x$}\n}\nchild {\nnode[end, label=right:{Quux}] {}\nedge from parent\nnode[above] {$X$}\nnode[below] {$x$}\n};\n\\end{tikzpicture}\nTables\n\\setlength{\\tabcolsep}{0.75em} % horizontal padding\n\\def\\arraystretch{1.25} % vertical padding\n\\begin{tabular}{ |c|c|c|c|c|c| }\n\\hline\nFoo & $0$ & $1$ & $2$ & $3$ & $4$ \\\\\n\\hline\nBar & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ \\\\\n\\hline\nBaz & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ \\\\\n\\hline\nQuux & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ & $0.0000$ \\\\\n\\hline\nXyzzy & $0.00\\%$ & $0.00\\%$ & $0.00\\%$ & $0.00\\%$ & $0.00\\%$ \\\\\n\\hline\n\\end{tabular}\nPython Code\nThis code requires you to install the pythonhiglight package and include\n\u200b \u200b\n\\usepackage{pythonhighlight} in your header.\n\u200b\nhttps://github.com/olivierverdier/python-latex-highlighting\n\\begin{python}\nsome_var = 42 # example comment\nfor n in range(5):\nprint(\"Hello world!\")\n\\end{python}\nGeneral Tips\n\u25cf Local LaTeX: Running LaTeX locally can help you learn faster than Overleaf - a shorter\n\u200b\nfeedback loop is really helpful!\n\u25cf Wolfram Alpha: You can paste LaTeX snippets directly into Wolfram Alpha and most of\n\u200b\nthe time it'll understand them correctly and do something useful.\n\u25cb You can even add Wolfram Alpha as a custom search engine in Chrome. This\nlets you type \"w [your LaTeX equation]\" into your location bar, and it'll take you\nstraight to the answer in Wolfram. Just go to this link, and add this as an entry.\n\u200b \u200b \u200b \u200b \u200b \u200b\n\u25cf Half-LaTeX environments: Using a half-LaTeX environment like MS Word, Powerpoint,\n\u200b\nor Google Docs with the Auto-LaTeX Equations Addon is super useful while you\u2019re doing\n\u200b \u200b\nyour rough work.\n\u25cb Save up snippets for typesetting and test them in Wolfram Alpha as you go!\n\u25cb Auto-LaTeX may throw an error if you\u2019re signed into >1 Google Account at once\n\u25cb MS Office LaTeX support was added in 2016, is not yet available on macOS\n\u25cf Keyboard shortcuts:\n\u200b\n\u25cb On TeXShop, you can type \\bali and press Esc twice, and it'll set up a\n\\begin{align*} block. Or \\b[xyz] for any \\begin{xyz} block.\n\u25cb It can be nice to define custom shortcuts for things you find yourself typing\nfrequently, such as \\textrm{} or Bayes\u2019 Theorem.\n\u200b \u200b\n\u25cf Expectations: You don\u2019t have to use any of the above structures if you don\u2019t want to!\n\u200b\nThe teaching team will accept and grade PSets in any format you submit.\n\u25cf Motivation: Strong LaTeX skills will make you more effective in all future courses. Goals\n\u200b \u200b \u200b \u200b <END>"}
{"prompt": "Lecture notes from 02_combinatorics_annotated.txt\n\n###\n\n", "completion": "02: Combinatorics\nJerry Cain\nApril 3rd, 2024\nLecture Discussion on Ed\n1\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct Some\n(distinguishable) distinct\n\ud835\udc5b!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 2\nGeneral approach to counting permutations\nWhen there are \ud835\udc5b objects such that\n\ud835\udc5b are the same (indistinguishable or indistinct), and\n!\n\ud835\udc5b are the same, and\n\"\n\u2026\n\ud835\udc5b are the same,\n#\nThe number of unique orderings (permutations) is\n\ud835\udc5b!\n.\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b !\n# $ %\nFor each group of indistinct objects,\ndivide by the overcounted permutations.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nOrder \ud835\udc5b semi- \ud835\udc5b!\nSort semi-distinct objects\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many permutations?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nOrder \ud835\udc5b semi- \ud835\udc5b!\nStrings\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many letter orderings are possible for the following strings?\nKIKIIRIAFIN\n1.\nEFFERVESCENCE\n2.\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nOrder \ud835\udc5b semi- \ud835\udc5b!\nStrings\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many letter orderings are possible for the following strings?\n!!!\nKIKIIRIAFIN = = 166,320\n1.\n#!$!\n!%!\n= = 12,972,960\nEFFERVESCENCE\n2.\n$!#!$!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nOrder \ud835\udc5b semi- \ud835\udc5b!\nUnique 6-digit passcodes with four smudges\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of four distinct numbers?\nTwo mutually exclusive scenarios:\n\u2022 One digit repeated three times, other three repeated once\n\u2022 Two digits repeated twice, other two repeated once\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nOrder \ud835\udc5b semi- \ud835\udc5b!\nUnique 6-digit passcodes with four smudges\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of four distinct numbers?\nTwo mutually exclusive scenarios:\n\u2022 One digit repeated three times, other three repeated once\n\u2022 Two digits repeated twice, other two repeated once\n$!\nfirst scenario: \ud835\udc5b = 4 \u2019 = 480\n!\n&!\n$!\nsecond scenario: \ud835\udc5b = 6 \u2019 = 1080\n\"\n\"!\"!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nOrder \ud835\udc5b semi- \ud835\udc5b!\nUnique 6-digit passcodes with four smudges\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of four distinct numbers?\nTwo mutually exclusive scenarios:\n\u2022 One digit repeated three times, other three repeated once\n\u2022 Two digits repeated twice, other two repeated once\n$!\nfirst scenario: \ud835\udc5b = 4 \u2019 = 480\n!\n&!\n$!\nsecond scenario: \ud835\udc5b = 6 \u2019 = 1080\n\"\n\"!\"!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nOrder \ud835\udc5b semi- \ud835\udc5b!\nUnique 6-digit passcodes with four smudges\ndistinct objects \ud835\udc5b !\ud835\udc5b !\u22ef\ud835\udc5b !\n! \" #\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of four distinct numbers?\nTwo mutually exclusive scenarios:\n\u2022 One digit repeated three times, other three repeated once\n\u2022 Two digits repeated twice, other two repeated once\n$!\nfirst scenario: \ud835\udc5b = 4 \u2019 = 480\n!\n&! 1560 such\npasscodes\n$!\nsecond scenario: \ud835\udc5b = 6 \u2019 = 1080\n\"\n\"!\"!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct Some\n(distinguishable) distinct\n\ud835\udc5b!\n\ud835\udc5b!\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b !\n\" # $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nCombinations I\n12\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct\nDistinct Some\n(distinguishable) distinct\n\ud835\udc5b!\n\ud835\udc5b!\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b !\n\" # $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\nConsider the following\ngenerative process\u2026\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n1 2 3 4 5 6 7 8 9 10\n11 12 13 14 15 16 17 18 19 20\n1. \ud835\udc5b people\nget in line\n\ud835\udc5b! ways\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n1 2 3 4 5 6 7 8 9 10\n11 12 13 14 15 16 17 18 19 20\n1. \ud835\udc5b people 2. Put first \ud835\udc58\nget in line in cake room\n\ud835\udc5b! ways 1 way\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n6 7 8 9 10 11 12 13\n14 15 16 17 18 19 20\n1. \ud835\udc5b people 2. Put first \ud835\udc58\nget in line in cake room\n\ud835\udc5b! ways 1 way\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n6 7 8 9 10 11 12 13\n14 15 16 17 18 19 20\n1. \ud835\udc5b people 2. Put first \ud835\udc58 3. Allow cake\ngroup to mingle\nget in line in cake room\n\ud835\udc58! different permutations\n\ud835\udc5b! ways 1 way all considered the same\ngroup of children\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n6 7 8 9 10 11 12 13\n14 15 16 17 18 19 20\n1. \ud835\udc5b people 2. Put first \ud835\udc58 3. Allow cake 4. Allow non-cake\nget in line in cake room group to mingle group to mingle\n\ud835\udc58! different permutations\n\ud835\udc5b! ways 1 way all considered the same\ngroup of children\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nCombinations with cake\nThere are \ud835\udc5b = 20 people.\nHow many ways can we choose \ud835\udc58 = 5 people to get cake?\n1. \ud835\udc5b people 2. Put first \ud835\udc58 3. Allow cake 4. Allow non-cake\nget in line in cake room group to mingle group to mingle\n\ud835\udc58! different permutations \ud835\udc5b \u2212 \ud835\udc58 ! different\n\ud835\udc5b! ways 1 way all considered the same permutations all lead to\ngroup of children the same group of children\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nCombinations\nA combination is an unordered selection of \ud835\udc58 objects\nfrom a set of \ud835\udc5b distinct objects.\nThe number of ways of making this selection is\n\ud835\udc5b! 1 1 \ud835\udc5b\n= \ud835\udc5b! \u00d7 1 \u00d7 \u00d7 =\n\ud835\udc58! \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58! \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58\n4. Overcounted:\nany ordering\n1.Order \ud835\udc5b 3.Overcounted:\nof unchosen\n2.Take first \ud835\udc58\ndistinct any ordering of\nas chosen group is\nobjects chosen group is\nsame choice\nsame choice\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nCombinations\nA combination is an unordered selection of \ud835\udc58 objects\nfrom a set of \ud835\udc5b distinct objects.\nThe number of ways of making this selection is\n\ud835\udc5b\n\ud835\udc5b! 1 1 \ud835\udc5b\nBinomial\n= \ud835\udc5b! \u00d7 1 \u00d7 \u00d7 =\n\ud835\udc58! \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58! \ud835\udc5b \u2212 \ud835\udc58 ! \ud835\udc58\ud835\udc58 coefficient\n! !\n=\nNote:\n!\"# #\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\ud835\udc5b\nChoose \ud835\udc58 of\nProbability textbooks\n\ud835\udc5b distinct objects \ud835\udc58\nProb Is Fun: Piech\nHow many ways are there to choose a subset of 3\nAvoid Prob:\nShankar\nfrom a set of 6 distinct books? By saying subset, Woof: Doris\nwe assume order doesn\u2019t matter.\nIntro\nProb:\nRoss, 10th\nEdition\nniaC .esneS sekaM borP\nIntro Prob: Ross, 9th Edition\n6 6!\n= = 20 ways\n3 3! 3!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nCombinations II\n24\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct\nDistinct Some\n(distinguishable) distinct\n1 group \ud835\udc5f groups\n\ud835\udc5b! \ud835\udc5b\n\ud835\udc5b!\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b ! \ud835\udc58\n\" # $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nGeneral approach to combinations\nThe number of ways to choose \ud835\udc5f groups of \ud835\udc5b distinct objects such that\nFor all \ud835\udc56 = 1, \u2026 , \ud835\udc5f, group \ud835\udc56 has size \ud835\udc5b , and\n*\n#\n\u2211 \ud835\udc5b = \ud835\udc5b (all objects are assigned), is\n*+! *\n\ud835\udc5b! \ud835\udc5b\n=\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b ! \ud835\udc5b , \ud835\udc5b , \u22ef , \ud835\udc5b\n# $ % # $ %\nMultinomial coefficient\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\n\ud835\udc5b\nChoose \ud835\udc58 of \ud835\udc5b distinct objects\nDatacenters\ninto \ud835\udc5f groups of size \ud835\udc5b ,\u2026\ud835\udc5b \ud835\udc5b ,\ud835\udc5b ,\u22ef,\ud835\udc5b\n! \" ! \" #\nDatacenter # machines\n13 different computers are to be allocated to\nA 6\n3 datacenters as shown in the table:\nB 4\nHow many different divisions are possible?\nC 3\n!\"\nA. = 60,060\n#,%,\"\n!\" $ \"\nB. = 60,060\n# % \"\nC. 6 \u22c5 1001 \u22c5 10 = 60,060\nD. A and B\nE. All of the above\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\n\ud835\udc5b\nChoose \ud835\udc58 of \ud835\udc5b distinct objects\nDatacenters\ninto \ud835\udc5f groups of size \ud835\udc5b ,\u2026\ud835\udc5b \ud835\udc5b ,\ud835\udc5b ,\u22ef,\ud835\udc5b\n! \" ! \" #\nDatacenter # machines\n13 different computers are to be allocated to\nA 6\n3 datacenters as shown in the table:\nB 4\nHow many different divisions are possible?\nC 3\n!\"\nA. = 60,060\n#,%,\"\n!\" $ \"\nB. = 60,060\n# % \"\nC. 6 \u22c5 1001 \u22c5 10 = 60,060\nD. A and B\nE. All of the above\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n\ud835\udc5b\nChoose \ud835\udc58 of \ud835\udc5b distinct objects\nDatacenters\ninto \ud835\udc5f groups of size \ud835\udc5b ,\u2026\ud835\udc5b \ud835\udc5b ,\ud835\udc5b ,\u22ef,\ud835\udc5b\n! \" ! \" #\nDatacenter # machines\n13 different computers are to be allocated to\nA 6\n3 datacenters as shown in the table:\nB 4\nHow many different divisions are possible?\nC 3\n!\"\nA. = 60,060\n#,%,\"\nStrategy: Combinations into 3 groups\nGroup 1 (datacenter A): \ud835\udc5b = 6\n\"\nGroup 2 (datacenter B): \ud835\udc5b = 4\n#\nGroup 3 (datacenter C): \ud835\udc5b = 3\n*\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n\ud835\udc5b\nChoose \ud835\udc58 of \ud835\udc5b distinct objects\nDatacenters\ninto \ud835\udc5f groups of size \ud835\udc5b ,\u2026\ud835\udc5b \ud835\udc5b ,\ud835\udc5b ,\u22ef,\ud835\udc5b\n! \" ! \" #\nDatacenter # machines\n13 different computers are to be allocated to\nA 6\n3 datacenters as shown in the table:\nB 4\nHow many different divisions are possible?\nC 3\n!\" !\" $ \"\nA. = 60,060 B. = 60,060\n#,%,\" # % \"\nStrategy: Combinations into 3 groups Strategy: Product rule with 3 steps\n$%\n1. Choose 6 computers for A\nGroup 1 (datacenter A): \ud835\udc5b = 6 &\n\"\n\u2019\n2. Choose 4 computers for B\nGroup 2 (datacenter B): \ud835\udc5b = 4 (\n# %\n3. Choose 3 computers for C\n%\nGroup 3 (datacenter C): \ud835\udc5b = 3\n*\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\n\ud835\udc5b\nChoose \ud835\udc58 of \ud835\udc5b distinct objects\nDatacenters\ninto \ud835\udc5f groups of size \ud835\udc5b ,\u2026\ud835\udc5b \ud835\udc5b ,\ud835\udc5b ,\u22ef,\ud835\udc5b\n! \" ! \" #\nDatacenter # machines\n13 different computers are to be allocated to\nA 6\n3 datacenters as shown in the table:\nB 4\nHow many different divisions are possible?\nC 3\n!\" !\" $ \"\nA. = 60,060 B. = 60,060\n#,%,\" # % \"\nStrategy: Combinations into 3 groups Strategy: Product rule with 3 steps\n$%\n1. Choose 6 computers for A\nGroup 1 (datacenter A): \ud835\udc5b = 6 &\n\"\n\u2019\n2. Choose 4 computers for B\nGroup 2 (datacenter B): \ud835\udc5b = 4 (\n# %\n3. Choose 3 computers for C\n%\nGroup 3 (datacenter C): \ud835\udc5b = 3\n*\nYour approach will determine if you use\nbinomial/multinomial coefficients or factorials.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\n\ud835\udc5b\nChoose \ud835\udc58 of\nProbability textbooks\n\ud835\udc5b distinct objects \ud835\udc58\n1. How many ways are there to choose 3 books 6 6!\n= = 20 ways\nfrom a set of 6 distinct books?\n3 3! 3!\n2. Two are by the same author. What if we don\u2019t want to choose both?\n! ! ! %\nA. \u2212 = 5 ways D. \u2212 = 16\n\" # \" &\n!!\nB. = 10\nE. Both C and D\n\"!\"!#!\n% %\nC. 2 \u22c5 + = 16\nF. Something else\n# \"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\ud835\udc5b\nChoose \ud835\udc58 of\nProbability textbooks\n\ud835\udc5b distinct objects \ud835\udc58\n1. How many ways are there to choose 3 books 6 6!\n= = 20 ways\nfrom a set of 6 distinct books?\n3 3! 3!\n2. Two are by the same author. What if we don\u2019t want to choose both?\nStrategy 1: Sum Rule\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\n\ud835\udc5b\nChoose \ud835\udc58 of\nProbability textbooks\n\ud835\udc5b distinct objects \ud835\udc58\n1. How many ways are there to choose 3 books 6 6!\n= = 20 ways\nfrom a set of 6 distinct books?\n3 3! 3!\n2. Two are by the same author. What if we don\u2019t want to choose both?\nStrategy 2: \"Forbidden method\"\nForbidden method: It is\nsometimes easier to exclude\ninvalid cases than to account\nfor all valid cases.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nBuckets and The\nDivider Method\n35\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct\nDistinct Some\n(distinguishable) distinct Distinct Indistinct\n1 group \ud835\udc5f groups\n\ud835\udc5b! \ud835\udc5b \ud835\udc5b\n\ud835\udc5b!\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b ! \ud835\udc58 \ud835\udc5b , \ud835\udc5b , \u22ef , \ud835\udc5b\n\" # $ \" # $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nBalls and urns Hash tables and distinct strings\nHow many ways are there to hash \ud835\udc5b distinct strings to \ud835\udc5f buckets?\nSteps:\n1. Bucket 1st string\nssdfsskdfsd fooandbaz\n2. Bucket 2nd string\nboba\n\u2026\nviridian city\n\ud835\udc5b. Bucket \ud835\udc5bth string\n\u2026\n/\n\ud835\udc5f outcomes\n1 2 r\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct\nDistinct Some\n(distinguishable) distinct Distinct Indistinct\n1 group \ud835\udc5f groups\n\ud835\udc5b! \ud835\udc5b \ud835\udc5b\n+\n\ud835\udc5b! \ud835\udc5f\n\ud835\udc5b ! \ud835\udc5b ! \u22ef \ud835\udc5b ! \ud835\udc58 \ud835\udc5b , \ud835\udc5b , \u22ef , \ud835\udc5b\n\" # $ \" # $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nServers and indistinct requests\nHow many ways are there to distribute \ud835\udc5b indistinct web requests to \ud835\udc5f servers?\nrequest request Goal\nServer 1 has \ud835\udc65 requests,\n!\nrequest request\nServer 2 has \ud835\udc65 requests,\n\"\n\u2026\nServer \ud835\udc5f has \ud835\udc65 requests (the rest)\n#\n\u2026\n1 2 r\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nBicycle helmet sales\nHow many ways can we assign \ud835\udc5b = 5 indistinct children to \ud835\udc5f = 4 distinct\nbicycle helmet styles?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nBicycle helmet sales\n1 possible assignment outcome:\nGoal Order \ud835\udc5b indistinct objects and \ud835\udc5f \u2212 1 indistinct dividers.\nConsider the\nfollowing\ngenerative\nprocess\u2026\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nThe divider method: A generative proof\nHow many ways can we assign \ud835\udc5b = 5 indistinct children to \ud835\udc5f = 4 distinct\nbicycle helmet styles?\nGoal Order \ud835\udc5b indistinct objects and \ud835\udc5f \u2212 1 indistinct dividers.\n01.. Make objects and dividers distinct\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nThe divider method: A generative proof\nHow many ways can we assign \ud835\udc5b = 5 indistinct children to \ud835\udc5f = 4 distinct\nbicycle helmet styles?\nGoal Order \ud835\udc5b indistinct objects and \ud835\udc5f \u2212 1 indistinct dividers.\n01.. Make objects and dividers distinct\n1. Order \ud835\udc5b distinct\nobjects and \ud835\udc5f \u2212 1\ndistinct dividers\n\ud835\udc5b + \ud835\udc5f \u2212 1 !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nThe divider method: A generative proof\nHow many ways can we assign \ud835\udc5b = 5 indistinct children to \ud835\udc5f = 4 distinct\nbicycle helmet styles?\nGoal Order \ud835\udc5b indistinct objects and \ud835\udc5f \u2212 1 indistinct dividers.\n01.. Make objects and dividers distinct\n1. Order \ud835\udc5b distinct 2. Make \ud835\udc5b objects\nobjects and \ud835\udc5f \u2212 1 indistinct\ndistinct dividers\n1\n\ud835\udc5b + \ud835\udc5f \u2212 1 !\n\ud835\udc5b!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nThe divider method: A generative proof\nHow many ways can we assign \ud835\udc5b = 5 indistinct children to \ud835\udc5f = 4 distinct\nbicycle helmet styles?\nGoal Order \ud835\udc5b indistinct objects and \ud835\udc5f \u2212 1 indistinct dividers.\n01.. Make objects and dividers distinct\n1. Order \ud835\udc5b distinct 2. Make \ud835\udc5b objects 3. Make \ud835\udc5f \u2212 1 dividers\nobjects and \ud835\udc5f \u2212 1 indistinct indistinct\ndistinct dividers\n1 1\n\ud835\udc5b + \ud835\udc5f \u2212 1 !\n\ud835\udc5b! \ud835\udc5f \u2212 1 !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nThe divider method\nThe number of ways to distribute \ud835\udc5b indistinct objects into \ud835\udc5f buckets is\nequivalent to the number of ways to permute \ud835\udc5b + \ud835\udc5f \u2212 1 objects such that\n\ud835\udc5b are indistinct objects, and\n\ud835\udc5f \u2212 1 are indistinct dividers:\n& &\nTotal = (\ud835\udc5b + \ud835\udc5f \u2212 1)! \u00d7 \u00d7\n!! (\"& !\n\ud835\udc5b + \ud835\udc5f \u2212 1\n=\noutcomes\n\ud835\udc5f \u2212 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nDivider method \ud835\udc5b + \ud835\udc5f \u2212 1\nVenture capitalists\n(\ud835\udc5b indistinct objects, \ud835\udc5f buckets)\n\ud835\udc5f \u2212 1\nYou have $10 million to invest in 4 companies (in units of $1 million).\n1. How many ways can you fully allocate your $10 million?\n2. What if you want to invest at least $3 million in company 1?\n3. What if you don\u2019t have to invest all your money?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 47\nDivider method \ud835\udc5b + \ud835\udc5f \u2212 1\nVenture capitalists. #1\n(\ud835\udc5b indistinct objects, \ud835\udc5f buckets)\n\ud835\udc5f \u2212 1\nYou have $10 million to invest in 4 companies (in units of $1 million).\n1. How many ways can you fully allocate your $10 million?\nSet up Solve\n\ud835\udc65 + \ud835\udc65 + \ud835\udc65 + \ud835\udc65 = 10\n! \" & 3\n\ud835\udc65 : amount invested in company \ud835\udc56\n,\n\ud835\udc65 \u2265 0\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\nDivider method \ud835\udc5b + \ud835\udc5f \u2212 1\nVenture capitalists. #2\n(\ud835\udc5b indistinct objects, \ud835\udc5f buckets)\n\ud835\udc5f \u2212 1\nYou have $10 million to invest in 4 companies (in units of $1 million).\n1. How many ways can you fully allocate your $10 million?\n2. What if you want to invest at least $3 million in company 1?\nSet up Solve\n\ud835\udc65 + \ud835\udc65 + \ud835\udc65 + \ud835\udc65 = 10\n! \" & 3\n\ud835\udc65 : amount invested in company \ud835\udc56\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 49\nDivider method \ud835\udc5b + \ud835\udc5f \u2212 1\nVenture capitalists. #3\n(\ud835\udc5b indistinct objects, \ud835\udc5f buckets)\n\ud835\udc5f \u2212 1\nYou have $10 million to invest in 4 companies (in units of $1 million).\n1. How many ways can you fully allocate your $10 million?\n2. What if you want to invest at least $3 million in company 1?\n3. What if you don\u2019t have to invest all your money?\nSet up \u26a0 Solve\n\ud835\udc65 + \ud835\udc65 + \ud835\udc65 + \ud835\udc65 \u2264 10\n! \" & 3\n\ud835\udc65 : amount invested in company \ud835\udc56\n,\n\ud835\udc65 \u2265 0\n,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 50\nSummary of Combinatorics\nCounting tasks on \ud835\udc5b objects\nSort objects Choose \ud835\udc58 objects Put objects in \ud835\udc5f\n(permutations) (combinations) buckets\nDistinct\nDistinct Some\n(distinguishable) distinct Distinct Indistinct\n1 group \ud835\udc5f groups\n\u2022 determine if objects are distinct\n\u2022 use product rule if several steps\n\u2022 use inclusion-exclusion if different cases\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 51\nCombinatorial\nProofs\n52\nCombinatorial Proofs\nA combinatorial proof\u2014sometimes called a story proof\u2014is a proof that counts the same thing in\ntwo different ways, forgoing any tedious algebra.\nCombinatorial proofs aren\u2019t as formal as CS103 proofs, but they still need to convince the\nreader something is true in an absolute sense.\n) )\nAn algebraic proof of, say, = is straightforward if you just write combinations in terms\n* ) , *\nof factorials.\n) )\nA combinatorial proof makes an identity like = easier to believe and understand\n* ) , *\nintuitively.\nCombinatorial Proof:\nConsider choosing a set of k CS109 CAs from a total of n applicants. We know that there are\n)\nsuch possibilities. Another way to choose the k CS109 CAs is to disqualify n \u2013 k\n*\n)\napplicants. There are ways to choose which n \u2013 k don\u2019t get the job. Specifying who is on\n),* ) )\nCS109 course staff is the same as specifying who isn\u2019t. That means that and must\n* ),*\nbe counting the same thing.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 53\nCombinatorial Proofs\nLet\u2019s provide another combinatorial proof, this time proving that\n) ,$ )\n\ud835\udc5b = \ud835\udc58\n*,$ *\nThis is easy to prove algebraically (provided k and n are positive integers, with \ud835\udc58 \u2264 \ud835\udc5b). A\ncombinatorial/story proof, however, is more compelling!\nCombinatorial Proof:\nConsider n candidates for college admission, where k candidates can be accepted, and\nprecisely one of the k is selected for a full scholarship. We can first choose the lucky recipient\nof the full scholarship and then select an additional k \u2013 1 applicants from the remaining n \u2013 1\napplicants to round out the set of admits. Or we can select which k applicants are accepted\nand then choose which of those k gets the full ride.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 54 <END>"}
{"prompt": "Lecture notes from 06_section_soln_clt.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May16,2024\nContinuous Joint Distributions, Central Limit Theorem\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Food for Thought\nKarelthedogeatsanunpredictableamountoffood.Everyday,thedogisequallylikelytoeat\nbetweenacontinuousamountintherange100to300g.HowmuchKareleatsisindependentofall\notherdays.Youonlyhave6.5kgoffoodforthenext30days.Whatistheprobabilitythat6.5kg\nwillbeenoughforthenext30days?\nThe distribution of the sum is given by the central limit theorem. Let \ud835\udc4b \ud835\udc56 \u223c Uni(100,300)\nwhere \ud835\udc38[\ud835\udc4b \ud835\udc56] = 200and\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b \ud835\udc56) = 1 (200)2 \u2248 3333.\n12\n\u2211\ufe01\n\ud835\udc4c = \ud835\udc4b \ud835\udc56\n\ud835\udc56\nLet\u2019sapproximate\ud835\udc4c withanormalR.V.\n\u223c N(6000,316.2122)\n\ud835\udc43(\ud835\udc4c < 6500)\n(cid:18)\ud835\udc4c\n\u22126000\n6500\u22126000(cid:19)\n\ud835\udc43 <\n316.212 316.212\nLet \ud835\udc4c\u22126000 = \ud835\udc4d \u223c N(0,1)\n316.212\n(cid:18) (cid:19)\n6500\u22126000\n\ud835\udc43 \ud835\udc4d <\n316.212\n\ud835\udc43(\ud835\udc4d < 1.58)\n\u03a6(1.58)\n\u20132\u2013\n1.2 Sample and Population Mean\nComputingthesamplemeanissimilartothepopulationmean:sumallavailablepointsanddivide\nbythenumberofpoints.However,samplevarianceisslightlydifferentfrompopulationvariance.\n1. Considertheequationforpopulationvariance,andananalogousequationforsample\nvariance.\n\ud835\udc41\n1 \u2211\ufe01\n\ud835\udf0e2 = (\ud835\udc65 \ud835\udc56 \u2212 \ud835\udf07)2\n\ud835\udc41\n\ud835\udc56=1\n\ud835\udc5b\n1 \u2211\ufe01\n\ud835\udc462 \ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 = \ud835\udc5b (\ud835\udc4b \ud835\udc56 \u2212 \ud835\udc4b\u00af)2\n\ud835\udc56=1\n\ud835\udc462 isarandomvariabletoestimatetheconstant \ud835\udf0e2.Becauseitisbiased,\n\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\n\ud835\udc38[\ud835\udc462 ] \u2260 \ud835\udf0e2.Is \ud835\udc38[\ud835\udc462 ] greaterorlessthan \ud835\udf0e2?\n\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\n2. ConsideranalternativeRandomVariable, \ud835\udc462 (knownsimplyas \ud835\udc462 inclass).The\n\ud835\udc62\ud835\udc5b\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\ntechniqueofun-biasingvarianceisknownasBessel\u2019scorrection.Writethe \ud835\udc462\n\ud835\udc62\ud835\udc5b\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\nequation.\na. \ud835\udc38[\ud835\udc462 ] < \ud835\udf0e2. The intuition is that the spread of a sample of points is generally\nbiased\nsmallerthanthespreadofallthepointsconsideredtogether.Thisbecomesmoreclear\nwhenweconsidertheunbiasedversionandhowitmakestheexpressionevaluatetoa\nlargernumber.\nb. \ud835\udc46 u2\nnbiased\n= \ud835\udc462 = \ud835\udc5b\u22121\n1\n(cid:205) \ud835\udc56\ud835\udc5b =1(\ud835\udc4b \ud835\udc56 \u2212 \ud835\udc4b\u00af)2\n2 Problems\n2.1 Sum of Two Exponentials\nConsidertwoindependentrandomvariables \ud835\udc4b and\ud835\udc4c,eachExponentialswithdifferent\nparameters\u2014specifically,let \ud835\udc4b \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) and\ud835\udc4c \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1).Assuming\ud835\udc47 = \ud835\udc4b +\ud835\udc4c,deriveand\n2 3\npresenttheprobabilitydensityfunction \ud835\udc53 \ud835\udc47(\ud835\udc61) byevaluatingtherelevantconvolution.Onceyou\narriveatyour \ud835\udc53 \ud835\udc47(\ud835\udc61),verifyyouranswerbycalculating \ud835\udc53 \ud835\udc47(2) outtothreedecimalplaces.\nIf we let \ud835\udc4b and\ud835\udc4c be continuous random variables with probability density functions \ud835\udc53 \ud835\udc4b(\ud835\udc61)\nand \ud835\udc53 \ud835\udc4c(\ud835\udc61),thentheprobabilitydensityfunctionand \ud835\udc53 \ud835\udc47(\ud835\udc61) of\ud835\udc47 = \ud835\udc4b+\ud835\udc4c istheconvolutionof\n\ud835\udc53 \ud835\udc4b(\ud835\udc61) and \ud835\udc53 \ud835\udc4c(\ud835\udc61)\u2014thatis:\n\u222b \u221e\n\ud835\udc53 \ud835\udc47(\ud835\udc61) = \ud835\udc53 \ud835\udc4b(\ud835\udc65)\ud835\udc53 \ud835\udc4c(\ud835\udc61 \u2212\ud835\udc65)\ud835\udc51\ud835\udc65\n\u2212\u221e\nInthecaseofthisproblem,both \ud835\udc4b and\ud835\udc4c areExponentialswithsupportsofallnonnegative\nreal numbers, so the bounds of the integral can be compressed to include just those values\n\u20133\u2013\nwhere both \ud835\udc65 and \ud835\udc61 \u2212\ud835\udc65 are greater than 0 (which is [0,\ud835\udc61]). Of course, the density function\nforageneralExponentialis \ud835\udc53 \ud835\udc4b(\ud835\udc65) = \ud835\udf06\ud835\udc52\u2212\ud835\udf06\ud835\udc65 ,sotheconvolutiontobeevaluatedshouldbe:\n\u222b \ud835\udc61\n\ud835\udc53 \ud835\udc47(\ud835\udc61) = \ud835\udc53 \ud835\udc4b(\ud835\udc65)\ud835\udc53 \ud835\udc4c(\ud835\udc61 \u2212\ud835\udc65)\ud835\udc51\ud835\udc65\n0\n\u222b \ud835\udc61\n1 1\n=\n\ud835\udc52\u22121 2\ud835\udc65\n\u00b7\n\ud835\udc52\u22121 3(\ud835\udc61\u2212\ud835\udc65)\ud835\udc51\ud835\udc65\n2 3\n0\n\u222b \ud835\udc61\n1\n=\n\ud835\udc52\u22121 3\ud835\udc61 \ud835\udc52\u22121 6\ud835\udc65\ud835\udc51\ud835\udc65\n6\n0\n(cid:12)\ud835\udc61\n= \u2212\ud835\udc52\u2212 31\ud835\udc61\ud835\udc52\u22121 6\ud835\udc65(cid:12)\n(cid:12)\n0\n=\n\ud835\udc52\u22121 3\ud835\udc61 (1\u2212\ud835\udc52\u22121 6\ud835\udc61\n)\n=\n\ud835\udc52\u22121 3\ud835\udc61 \u2212\ud835\udc52\u22121 2\ud835\udc61\nThat\u2019stheprobabilitydensityfunctionofinterest,anditsvalueat\ud835\udc61 = 2is \ud835\udc53 \ud835\udc47(2) = 0.145537.\n2.2 Grading Exams\nJacobandKathleenareplanningtogradeProblem1onyourWeek7exam,andthey\u2019lleachgrade\ntheirhalfindependentlyoftheother.Jacobtakes \ud835\udc4b \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) hourstofinishhishalfwhile\n3\nKathleentakes\ud835\udc4c \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) hourstofinishhishalf.\n4\na. FindtheCDFof \ud835\udc4b/\ud835\udc4c,whichistheratiooftheirgradingcompletiontimes.\nThe random variable of interest is the ratio \ud835\udc4b/\ud835\udc4c, so the CDF, \ud835\udc39(\ud835\udc5f), in this case would be\n\ud835\udc43(\ud835\udc4b < \ud835\udc5f), where\ud835\udc5f stands for ratio and ranges from 0 to \u221e. Rearranging, we are interested\n\ud835\udc4c\n\u20134\u2013\nincomputing \ud835\udc43(\ud835\udc4b < \ud835\udc5f\ud835\udc4c),whichcanbecomputedintermsofthePDFsfor \ud835\udc4b and\ud835\udc4c:\n\ud835\udc4b\n\ud835\udc39(\ud835\udc5f) = \ud835\udc43( < \ud835\udc5f) = \ud835\udc43(\ud835\udc4b < \ud835\udc5f\ud835\udc4c)\n\ud835\udc4c\n\u222b \u221e\u222b \ud835\udc5f\ud835\udc66\n1\n=\n\ud835\udc52\u22121 3\ud835\udc65\ud835\udc52\u22121 4\ud835\udc66\ud835\udc51\ud835\udc65\ud835\udc51\ud835\udc66\n12\n0 0\n1 \u222b \u221e \u222b \ud835\udc5f\ud835\udc66\n=\n\ud835\udc52\u22121 4\ud835\udc66 \ud835\udc52\u22121 3\ud835\udc65\ud835\udc51\ud835\udc65\ud835\udc51\ud835\udc66\n12\n0 0\n1 \u222b \u221e (cid:16) (cid:17)(cid:12)\ud835\udc5f\ud835\udc66\n= \u2212\n4 0\n\ud835\udc52\u22121 4\ud835\udc66 \ud835\udc52\u2212 31\ud835\udc65 (cid:12)\n(cid:12) 0\n\ud835\udc51\ud835\udc66\n1 \u222b \u221e (cid:16) (cid:17)\n= \u2212 \ud835\udc52\u22121 4\ud835\udc66 \ud835\udc52\u2212 31\ud835\udc5f\ud835\udc66 \u22121 \ud835\udc51\ud835\udc66\n4\n0\n1 \u222b \u221e 1 \u222b \u221e\n=\n\ud835\udc52\u22121 4\ud835\udc66\ud835\udc51\ud835\udc66\n\u2212\n\ud835\udc52\u2212(1 3\ud835\udc5f+1 4)\ud835\udc66\ud835\udc51\ud835\udc66\n4 4\n0 0\n1 (cid:12)\u221e\n= 1+ 1\ud835\udc5f4\n+\n1\ud835\udc52\u2212(1 3\ud835\udc5f+1 4)\ud835\udc66(cid:12)\n(cid:12)\n0\n3 4\n1 1\ud835\udc5f + 1 1\n= 1\u2212 4 = 3 4 \u2212 4\n1\ud835\udc5f + 1 1\ud835\udc5f + 1 1\ud835\udc5f + 1\n3 4 3 4 3 4\n1\ud835\udc5f\n= 3\n1\ud835\udc5f + 1\n3 4\nFor those question why that first of two integrals vanished to 1, note that the integrand is\njustthePDFofExpo(\ud835\udf06 = 1)!\n4\nIncidentally, we can compute the probability density function from the CDF by dif-\nferentiatingwithrespectto\ud835\udc5f:\n\ud835\udc51\ud835\udc39(\ud835\udc5f)\n\ud835\udc53(\ud835\udc5f) =\n\ud835\udc51\ud835\udc5f\n\ud835\udc51 1\ud835\udc5f\n= 3\n\ud835\udc51\ud835\udc5f 1\ud835\udc5f + 1\n3 4\n1\n=\n12(1\ud835\udc5f + 1)2\n3 4\nb. WhatistheprobabilitythatKathleenfinishesbeforeJacobdoes?\nIn comparison, that is delightfully straightforward, because we get to plug \ud835\udc5f = 1 into our\nresult from part a. \ud835\udc43(\ud835\udc4b < \ud835\udc4c) = 1 \u00b7 12 = 4. That, however, is the probability that Jacob\n3 7 7\nfinishing before Kathleen, and we want to opposite. Therefore, the probability of interest\n\u20135\u2013\nis really 3. Given the expected completion times of 3 and 4 hours for Jacob and Kathleen,\n7\nrespectively,thisseemsright.\n2.3 Central Limit Theorem and Sampling Calisthenics\na. Let \ud835\udc4b , \ud835\udc4b , \ud835\udc4b ,..., \ud835\udc4b beiid\u2014thatis,independentandidenticallydistributed\u2014suchthat\n1 2 3 1000\n\ud835\udc4b \ud835\udc56 \u223c NegBin(\ud835\udc5f = 10, \ud835\udc5d = 0.5),andlet\ud835\udc4a = \ud835\udc4b 1 + \ud835\udc4b 2 +...+ \ud835\udc4b 1000.AccordingtotheCentral\nLimitTheorem,whatdistributiondoes\ud835\udc4a assume,andwhatareitsparameters?\nThis is classic Central Limit Theorem where the distribution of the sum is a Gaussian with\nmean1000\ud835\udc38[\ud835\udc4b \ud835\udc56] andvariance1000\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b \ud835\udc56).TheformulasforaNegativeBinomial\u2019smean\nandvariancearewell-definedandarecomputedas:\n\ud835\udc5f 10\n\ud835\udc38[\ud835\udc4b \ud835\udc56] = = = 20\n\ud835\udc5d 0.5\n\ud835\udc5f(1\u2212 \ud835\udc5d) 10\u00b70.5\n\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b \ud835\udc56) = = = 20\n\ud835\udc5d2 0.52\nHow neat is it that the mean and variance are the same? This all means that \ud835\udc4a \u223c\nN(20000,20000).\nb. Define \ud835\udc4b\u00af = 101\n00\n(cid:205) \ud835\udc561 =0 100 \ud835\udc4b \ud835\udc56 tobethesamplemeanofour1000iidsamples.Whatisthe\nstandarddeviationoftherandomvariable \ud835\udc4b\u00af?\nThe Central Limit Theorem has a lot to say about the distribution of sample means as well.\nIn particular, for this problem, \ud835\udc4b\u00af \u223c N(\ud835\udc38[\ud835\udc4b \ud835\udc56],\ud835\udc49\ud835\udc4e\ud835\udc5f[\ud835\udc4b \ud835\udc56] ). That\u2019s more than we\u2019re asking\u2014all\n1000\nIneedfromyouisthat\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b \ud835\udc56) = 20 = 0.02.\n1000\nc. Youcomputethevarianceofyour1000samples, \ud835\udc4b , \ud835\udc4b , \ud835\udc4b ,..., \ud835\udc4b accordingtothe\n1 2 3 1000\ntraditionaldefinitionofvariance\u2014i.e. 101\n00\n(cid:205) \ud835\udc561 =0 100 (\ud835\udc4b \ud835\udc56 \u2212 \ud835\udc4b\u00af)2.Doyouexpectthisvarianceto,\nmoreoftenthannot,belarger,equalto,orsmallerthanthevarianceofNegBin(10,0.5).\nExplainyouranswer.\nHerethepopulationvarianceis20,sinceweknowthepopulationdistributionistheNegative\nBinomial.Recallthattheunbiasedsamplevariancedividesthesumofthedifferencessquared\nby\ud835\udc5b\u22121,or999.Thetraditionallycomputedvariancedividesbyaslightlylargernumberof\n1000, so we expect the traditionally computed variance to, more often than not, be a little\ntoolow.\nd. ThenumberofsamplesneededfortheCentralLimitTheoremtoapplyisgenerally\nunderstoodtobe30ormore.However,theCentralLimitTheoremworkswellforaneven\nsmallernumberofsampleswhen \ud835\udc4b \ud835\udc56 \u223c Bin(10,0.5) thanisdoeswhen\n\ud835\udc4b\n\ud835\udc56\n\u223c NegBin(10,0.5).Brieflyexplainwhy.\n\u20136\u2013\nThe simple answer is that \ud835\udc4b \ud835\udc56 \u223c Bin(10,0.5) is symmetric, so there are no asymmetries\nto overcome as you add samples together. In fact, you can view, say, 3 Bin(10,0.5) as 30\nBer(0.5).\ne. Recallthatsamplingtheoryallowsareasonablylargesampletostandinforthetrue\npopulationdistribution.Whenresamplingfromthesampleforbootstrappingpurposes,we\ngenerallydosowithreplacement.Whywithreplacementinsteadof without?\nWe sample with replacement because we treat the original set of samples as a probability\nmass function. If we were to sample without replacement, we\u2019re incapable of creating\nresamples of a size larger than the original sample, and when the size of the resample is\nclosetothesizeoftheoriginal,eachresamplewouldessentiallybeareplicaoftheoriginal. <END>"}
{"prompt": "Lecture notes from cs109_lec17_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 17: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n2 / 2 pts\nQuestion 1\nQuestion 1 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nRatios of probabilities 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Question 1\n1 Point\nSuppose we have two independent normal random variables, X and Y . Let\nX \u223c N(\u03bc = 2,\u03c32 = 10) and Y \u223c N(\u03bc = 4,\u03c32 = 1). How is X + Y\ndistributed?\nX + Y \u223c N(2, 10 + 1)\nX + Y \u223c N(2,11)\nX + Y \u223c N(3,5.5)\nX + Y \u223c N(6,11)\nX + Y \u223c Poi( 10 + 1)\nQ2 Ratios of probabilities\n1 Point\nLet X \u223c Exp(\u03bb) with PDF given by f(x). How much more likely is P(X = 3)\ncompared to P(X = 30)?\nf(3)\nf(30)\nf(1)\nf(10)\nf(30)\nf(3)\nf(10)\nf(1)\nundefined, since P(X = 3) = 0 and P(X = 30) = 0\n1 since P(X = 3) = P(X = 30) = 0 <END>"}
{"prompt": "Lecture notes from cs109_lec03_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 3: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nCombinatorics III 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nEvent Spaces: Dice 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nCounting and Probability: Poker Hands 2 / 2 pts\n3.1 Counting: Poker Hands 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n3.2 Probability: Poker Hands 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Combinatorics III\n1 Point\nHow many solutions are there to the equation x + x + x = 10, given the\n1 2 3\nconstraint that all x i need to be positive integers? Express your answer as a\nsimple integer.\n36\nQ2 Event Spaces: Dice\n1 Point\nSuppose you roll two dice. Which of the following definitions of events E and F\nare mutually exclusive? Select all that apply.\nE: you roll exactly 1 one, F: you roll exactly 1 two\nE: you roll exactly 1 one, F: you roll exactly 2 twos\nE: dice 1 outcome is even, F: dice 2 outcome is odd\nE: dice 1 outcome is even, F: dice 1 outcome is odd\nQ3 Counting and Probability: Poker Hands\n2 Points\nQ3.1 Counting: Poker Hands\n1 Point\nA 52-card deck has 4 suits (Diamond/Club/Heart/Spade), each with 13 ranks (Ace,\n2, 3, \u2026, 9, 10, Jack, Queen, King). How many unordered 5-card hands would result\nin a three of a kind in poker using a standard 52-card deck? A three of a kind\noccurs when the cards have ranks a, a, a, b, c, where a, b and c are all distinct.\nExample unordered three-of-a-kind hand: (Jack Club, Jack Spade, Jack Heart, 9\nHeart, 10 Heart).\n13 \u22c5 (4 ) \u22c5 (12 ) \u22c5 42 = 54,912\n3 2\n13 \u22c5 (4 ) \u22c5 (48 ) = 58,656\n3 2\n13 \u22c5 12 \u22c5 11 \u22c5 10 \u22c5 9 = 154,440\n12\n13 \u22c5 ( ) = 858\n2\nQ3.2 Probability: Poker Hands\n1 Point\nIf you are dealt 5 cards from a 52-card deck, what is the probability of getting a\nthree of a kind? Please provide a decimal answer (e.g. 0.0034), with a leading\nzero.\n0.0211 <END>"}
{"prompt": "Lecture notes from 08_section_soln.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May30,2024\nMaximum A Posteriori and Na\u00a8\u0131ve Bayes Solution\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Maximum A Posteriori\na. Intuitively,whatisMAP?Whatproblemisittryingtosolve?HowdoesitdifferfromMLE?\nb. Givena6-sideddie(possiblyunfair),yourollthedie \ud835\udc41 timesandobservethecountsfor\neachofthe6outcomesas \ud835\udc5b ,...,\ud835\udc5b .Whatisthemaximumaposterioriestimateofthis\n1 6\ndistribution,usingLaplacesmoothing?Recallthatthedierollsthemselvesfollowa\nmultinomialdistribution.\na. From the course notes: The paradigm of MAP is that we should choose the value for\nour parameters that is the most likely given the data. At first blush this might seem\nthesameasMLE;however,rememberthatMLEchoosesthevalueofparametersthat\nmakesthedatamostlikely.OneofthedisadvantagesofMLEisthatitbestexplains\ndata we have seen and makes no attempt to generalize to unseen data. In MAP, we\nincorporatepriorbeliefaboutourparameters,andthenweupdateourposteriorbelief\noftheparametersbasedonthedatawehaveseen.\nb. Using a prior which represents one imagined observation of each outcome is called\n\u201cLaplacesmoothing\u201danditguaranteesthatnoneofyourprobabilitiesare0or1.The\nLaplaceestimateforaMultinomialRVis \ud835\udc5d \ud835\udc56 = \ud835\udc5b \ud835\udc41\ud835\udc56 ++ 61 for\ud835\udc56 = 1,...,6.\n1.2 Naive Bayes Review\nRecalltheclassificationsetting:wehavedatavectorsoftheform \ud835\udc4b = (\ud835\udc4b 1,...,\ud835\udc4b \ud835\udc5a) andwewant\ntopredictalabel\ud835\udc4c \u2208 {0,1}.\na. RecallinNaiveBayes,givenadatapoint\ud835\udc65,wecompute \ud835\udc43(\ud835\udc4c = 1|\ud835\udc4b = \ud835\udc65) andpredict\ud835\udc4c = 1\nprovidedthisquantityis \u2265 0.5,andotherwisewepredict\ud835\udc4c = 0.Decompose\n\ud835\udc43(\ud835\udc4c = 1|\ud835\udc4b = \ud835\udc65) intosmallerterms,andstatewheretheNaiveBayesassumptionisused.\nb. Supposewearegivenexamplevectorswithlabelsprovided.Giveaformulatoestimate\n(usingmaximumlikelihood)eachquantity \ud835\udc43(\ud835\udc4b \ud835\udc56 = \ud835\udc65 \ud835\udc56|\ud835\udc4c = \ud835\udc66) above,for\ud835\udc56 \u2208 {1,...,\ud835\udc5a} and\n\ud835\udc66 \u2208 {0,1}.Youcanassumethereisafunctioncountwhichtakesinanynumberofboolean\nconditionsandreturnsacountoverthedataofthenumberofexamplesinwhichtheyare\ntrue.Forexample,count(\ud835\udc4b = 2,\ud835\udc4b = 7) returnsthenumberofexampleswhere \ud835\udc4b = 2and\n3 5 3\n\ud835\udc4b = 7.\n5\n\u20132\u2013\na.\n\ud835\udc43(\ud835\udc4c =1)\ud835\udc43(\ud835\udc4b=\ud835\udc65|\ud835\udc4c =1)\n\ud835\udc43(\ud835\udc4c =1|\ud835\udc4b=\ud835\udc65)= (Bayes+LTP)\n\ud835\udc43(\ud835\udc4c =1)\ud835\udc43(\ud835\udc4b=\ud835\udc65|\ud835\udc4c =1)+\ud835\udc43(\ud835\udc4c =0)\ud835\udc43(\ud835\udc4b=\ud835\udc65|\ud835\udc4c =0)\n= \ud835\udc43(\ud835\udc4c =1)(cid:206) \ud835\udc56\ud835\udc5a =1\ud835\udc43(\ud835\udc43 \ud835\udc4b( \ud835\udc56\ud835\udc4c == \ud835\udc65\ud835\udc561 |) \ud835\udc4c(cid:206) =\ud835\udc56\ud835\udc5a = 11 )\ud835\udc43 +( \ud835\udc43\ud835\udc4b (\ud835\udc56 \ud835\udc4c= =\ud835\udc65\ud835\udc56 0| )\ud835\udc4c (cid:206)= \ud835\udc56\ud835\udc5a =1 1) \ud835\udc43(\ud835\udc4b\ud835\udc56=\ud835\udc65\ud835\udc56|\ud835\udc4c =0) (NBAssumption)\ncount(\ud835\udc4b \ud835\udc56 = \ud835\udc65 \ud835\udc56,\ud835\udc4c = \ud835\udc66)\nb. \ud835\udc43(\ud835\udc4b \ud835\udc56 = \ud835\udc65 \ud835\udc56|\ud835\udc4c = \ud835\udc66) =\ncount(\ud835\udc4c = \ud835\udc66)\n2 Problems\n2.1 Why Boba Cares About MAP\nYoudon\u2019tunderstandwhythere\u2019snobobaplacewithinwalkingdistancearoundcampus,soyou\ndecidetostartone.Inordertoestimatetheamountofingredientsneededandthetimeyouwill\nspendinthebusiness(youstillneedtostudy),youwanttoestimatehowmanyordersyouwill\nreceiveperhour.AftertakingCS109,youareprettyconfidentthatincomingorderscanbe\nconsideredasindependenteventsandtheprocesscanbemodeledwithaPoisson.\nNowthequestionis-whatisthe\ud835\udf06 parameterofthePoisson?Inthefirsthourofyoursoftopening,\nyouarevisitedby4curiousstudents,eachofwhommadeanorder.Youhaveapriorbeliefthat\n\ud835\udc53(\u039b = \ud835\udf06) = \ud835\udc3e \u00b7\ud835\udf06 \u00b7\ud835\udc52\u2212\ud835\udf06 2.WhatistheMLEestimate?Whatisinferenceof\ud835\udf06 giventheobservation?\nWhatistheMaximumaPosteriori(MAP)estimateof\ud835\udf06?Throughyourprocesstrytoidentify\nwhatisapoint-estimate,andwhatisadistribution.\nTo find the MLE, we start from finding the likelihood function (i.e. joint probability of\nobservedevents)andfindthe\ud835\udf06 thatmaximizesthelikelihoodfunction.\n\ud835\udf064 \u00b7\ud835\udc52\u2212\ud835\udf06\n\ud835\udc3f(\ud835\udf06) =\n4!\n\ud835\udc3f\ud835\udc3f(\ud835\udf06) = 4log(\ud835\udf06) \u2212\ud835\udf06\u2212log(4!)\n\ud835\udf15\ud835\udc3f\ud835\udc3f 4\n= \u22121\n\ud835\udf15\ud835\udf06 \ud835\udf06\nSet \ud835\udf15\ud835\udc3f\ud835\udc3f to0andsolvefor\ud835\udf06.\n\ud835\udf15\ud835\udf06\n\ud835\udf06 = 4\nInferenceof\ud835\udf06 giventheobservation:\n\ud835\udc43(\ud835\udc4b = 4|\ud835\udf06) \u00b7 \ud835\udc53(\ud835\udf06)\n\ud835\udc53(\ud835\udf06|\ud835\udc4b = 4) =\n\ud835\udc43(\ud835\udc4b = 4)\nMAP estimate of \ud835\udf06: we find the \ud835\udf06 that maximizes the inference given the observation, i.e.\n\u20133\u2013\nwewanttosolve:\n\ud835\udc43(\ud835\udc4b = 4|\ud835\udf06) \u00b7 \ud835\udc53(\ud835\udf06)\nargmax \ud835\udc53(\ud835\udf06|\ud835\udc4b = 4) = argmax\n\ud835\udf06 \ud835\udf06\n\ud835\udc43(\ud835\udc4b = 4)\n= argmax\ud835\udc43(\ud835\udc4b = 4|\ud835\udf06) \u00b7 \ud835\udc53(\ud835\udf06)\n\ud835\udf06\n\ud835\udf064 \u00b7\ud835\udc52\u2212\ud835\udf06\n= argmax \u00b7\ud835\udc3e \u00b7\ud835\udf06\n\u00b7\ud835\udc52\u2212\ud835\udf06\n2\n\ud835\udf06 4!\nTakelog.\n\ud835\udf064 \u00b7\ud835\udc52\u2212\ud835\udf06 \ud835\udf06\n\ud835\udc59\ud835\udc5c\ud835\udc54( \u00b7\ud835\udc3e \u00b7\ud835\udf06\n\u00b7\ud835\udc52\u2212\ud835\udf06\n2) = 4\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udf06) \u2212\ud835\udf06+1+\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udc3e) +\ud835\udc59\ud835\udc5c\ud835\udc54(\ud835\udf06) \u2212\n4! 2\nDifferentiatewithrespectto\ud835\udf06,setto0andsolve.\n5 1\n\u22121\u2212 = 0\n\ud835\udf06 2\n10\n\ud835\udf06 =\n3\n2.2 Multiclass Bayes\nInthisproblemwearegoingtoexplorehowtowriteNaiveBayesformultipleoutputclasses.We\nwanttopredictasingleoutputvariableYwhichrepresentshowauserfeelsaboutabook.Unlike\ninyourhomework,theoutputvariableYcantakeononeofthefour valuesintheset\n{Like,Love,Haha,Sad}.Wewillbaseourpredictionsoffofthreebinaryfeaturevariables\n\ud835\udc4b 1,\ud835\udc4b 2, and \ud835\udc4b 3 whichareindicatorsoftheuser\u2019staste.Allvalues \ud835\udc4b \ud835\udc56 \u2208 {0,1}.\nWehaveaccesstoadatasetwith10,000users.Eachuserinthedatasethasavaluefor \ud835\udc4b ,\ud835\udc4b ,\ud835\udc4b\n1 2 3\nand\ud835\udc4c.Youcanuseaspecialquerymethodcountthatreturnsthenumberofusersinthedataset\nwiththegivenequalityconstraints(andonlyequalityconstraints).Herearesomeexampleusages\nof count:\ncount(\ud835\udc4b = 1,\ud835\udc4c = Haha) returnsthenumberofuserswhere \ud835\udc4b = 1and\ud835\udc4c = Haha.\n1 1\ncount(\ud835\udc4c = Love) returnsthenumberofuserswhere\ud835\udc4c = Love.\ncount(\ud835\udc4b = 0,\ud835\udc4b = 0) returnsthenumberofuserswhere \ud835\udc4b = 0,and \ud835\udc4b = 0.\n1 3 1 3\nYouaregivenanewuserwith \ud835\udc4b = 1, \ud835\udc4b = 1, \ud835\udc4b = 0.Whatisthebestpredictionforhowtheuser\n1 2 3\nwillfeelaboutthebook(\ud835\udc4c)?Youmayleaveyouranswerintermsofanargmaxfunction.You\nshouldexplainhowyouwouldcalculateallprobabilitiesusedinyourexpression.UseLaplace\nestimationwhencalculatingprobabilities.\nWecanmaketheNaiveBayesassumptionofindependenceandsimplifyargmaxof \ud835\udc43(\ud835\udc4c|X)\nto get an expression for \ud835\udc4c\u02c6, the predicted output value, and evaluate it using the provided\n\u20134\u2013\ncountfunction.\n\ud835\udc43(\ud835\udc4b = 1,\ud835\udc4b = 1,\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66)\ud835\udc43(\ud835\udc4c = \ud835\udc66)\n\ud835\udc4c\u02c6 = argmax 1 2 3\n\ud835\udc66 \ud835\udc43(\ud835\udc4b 1 = 1,\ud835\udc4b 2 = 1,\ud835\udc4b 3 = 0)\n= argmax \ud835\udc43(\ud835\udc4b = 1,\ud835\udc4b = 1,\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66)\ud835\udc43(\ud835\udc4c = \ud835\udc66)\n1 2 3\n\ud835\udc66\n= argmax \ud835\udc43(\ud835\udc4b = 1|\ud835\udc4c = \ud835\udc66)\ud835\udc43(\ud835\udc4b = 1|\ud835\udc4c = \ud835\udc66)\ud835\udc43(\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66)\ud835\udc43(\ud835\udc4c = \ud835\udc66),where:\n1 2 3\n\ud835\udc66\n\ud835\udc43(\ud835\udc4b = 1|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 1,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n1 1\n\ud835\udc43(\ud835\udc4b = 1|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 1,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n2 2\n\ud835\udc43(\ud835\udc4b = 1|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 1,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n3 3\n\ud835\udc43(\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 0,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n1 1\n\ud835\udc43(\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 0,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n2 2\n\ud835\udc43(\ud835\udc4b = 0|\ud835\udc4c = \ud835\udc66) = [count(\ud835\udc4b = 0,\ud835\udc4c = \ud835\udc66) +1]/[count(\ud835\udc4c = \ud835\udc66) +2]\n3 3\n\ud835\udc43(\ud835\udc4c = \ud835\udc66) = count(\ud835\udc4c = \ud835\udc66)/10,000\n2.3 Gaussian Na\u00a8\u0131ve Bayes\nTheversionofNa\u00a8\u0131veBayesthatweusedinclassworkedgreatwhenthefeaturevalueswereall\nbinary.Ifinsteadtheyarecontinuous,wearegoingtohavetorethinkhowweestimateofthe\nprobabilityofthe\ud835\udc56thfeaturegiventhelabel, \ud835\udc43(\ud835\udc4b \ud835\udc56|\ud835\udc4c).Theubiquitoussolutionistomakethe\nGaussianInputAssumptionthat:\nIf\ud835\udc4c = 0,then \ud835\udc4b \ud835\udc56 \u223c \ud835\udc41(\ud835\udf07 \ud835\udc56,0,\ud835\udf0e \ud835\udc562 ,0)\nIf\ud835\udc4c = 1,then \ud835\udc4b \ud835\udc56 \u223c \ud835\udc41(\ud835\udf07 \ud835\udc56,1,\ud835\udf0e \ud835\udc562 ,1)\nForeachfeature,thereare4parameters(meanandvarianceforbothclasslabels).Thereisafinal\nparameter, \ud835\udc5d,whichistheestimateof \ud835\udc43(\ud835\udc4c = 1).Assumethatyouhavetrainedondatawithtwo\ninputfeaturesandhavealreadyestimatedall9parametervalues,includingthat \ud835\udc5d = 0.6:\nFeature\ud835\udc56 \ud835\udf07\n\ud835\udc56,0\n\ud835\udf07\n\ud835\udc56,1\n\ud835\udf0e \ud835\udc562\n,0\n\ud835\udf0e \ud835\udc562\n,1\n1 5 0 1 1\n2 0 3 1 4\nWriteaninequalitytopredictwhether\ud835\udc4c = 1forinput [\ud835\udc4b = 5,\ud835\udc4b = 3].UsetheNa\u00a8\u0131veBayes\n1 2\nassumptionandtheGaussianInputAssumption.Yourexpressionshouldbeintermsofthe\nlearnedparameters(eitherusingnumbersorsymbolsisfine).\n\u20135\u2013\nFundamentally, you need to compute two probabilities: \ud835\udc43(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 0) and\n1 2\n\ud835\udc43(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 1) and then predict\ud835\udc4c\u02c6 to be whichever of 0 and 1 leads to a higher\n1 2\njointprobability.However,whensomeoftheinputvariablesarecontinuous,theprobability\nthosecontinuousvaluestakesonanyspecificvalueis0.\nHowever, you can still compute and compare probability densities, as with:\n\ud835\udc53(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 0) and \ud835\udc53(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 1). The Na\u00a8\u0131ve Bayes as-\n1 2 1 2\nsumptionallowsustorewritethosedensitiesas:\n\ud835\udc53(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 0) = \ud835\udc53(\ud835\udc4b = 5|\ud835\udc4c = 0) \u00b7 \ud835\udc53(\ud835\udc4b = 3|\ud835\udc4c = 0) \u00b7 \ud835\udc43(\ud835\udc4c = 0)\n1 2 1 2\nand\n\ud835\udc53(\ud835\udc4b = 5,\ud835\udc4b = 3,\ud835\udc4c = 1) = \ud835\udc53(\ud835\udc4b = 5|\ud835\udc4c = 1) \u00b7 \ud835\udc53(\ud835\udc4b = 3|\ud835\udc4c = 1) \u00b7 \ud835\udc43(\ud835\udc4c = 1)\n1 2 1 2\nWhen the input variables are specifically guided by Gaussians with the learned paramaters\npresentedabove,weultimatelypredict\ud835\udc4c\u02c6 = 0if\n1 1 1\n\u221a \ud835\udc52\u22121 2(5\u2212 15)2 \u00b7 \u221a \ud835\udc52\u22121 2(3\u2212 10)2 \u00b70.4 = \ud835\udc52\u22129 2\n2\ud835\udf0b 2\ud835\udf0b 5\ud835\udf0b\nisgreaterthan\n1 1 3\n\u221a \ud835\udc52\u22121 2(5\u2212 10)2 \u00b7 \u221a \ud835\udc52\u22121 2(3\u2212 43)2 \u00b70.6 = \ud835\udc52\u22122 25\n2\ud835\udf0b 2\ud835\udf0b 10\ud835\udf0b\nandotherwisepredict\ud835\udc4c\u02c6 = 1.\n3 Ethics and Beta Distribution\nWhiletherewon\u2019tbeanyethicsmaterialonthefinalexam,we\u2019reincludingaproblemthatwillnot\nonlyexercisesomeprobability,buthopefullyprovokeyoutothinkabouttheimpactthat\nprobability-anddata-drivendecisionshaveonsociety.\nTheEconomistusedabetadistributiontoforecastresultsforthe2020U.S.presidentialelection.1\n1Gelman,A.,&Heidemanns,M.(2020).Howtheeconomistpresidentialforecastworks.TheEconomist.\n\u20136\u2013\nFigure1:UpdatedpredictionofDemocraticvoteshareis\u201dPosterior\u201dprediction.\n1. Whyisthebetadistributionappropriateformodelingapresidentialelection?\n2. ReadthepollingreportpublishedbyTheEconomist.Whatshouldbeconsideredwhen\nusingthismodelandreleasingitselectionpredictions?\n1. Severalfeaturesofthebetadistributionmapontoelectionmodeling:\n\u2022 The beta requires number of successes and number of failures as parameters,\nThese are easy to acquire for elections since they are the counts of the target\ncandidatepollingpositivelyvs.negatively.\n\u2022 The beta distribution can be used to model quantities representing fractions or\npercentages, since it is a continuous random variable with a support of [0,1].\nElectionoutcomesaretypicallyreportedintermsofpercentagevoteshare,which\nnaturallylendsitselftoabeta.\n\u2022 Electionresultsarehighlyvariableandbetasallowustoincorporateuncertainty!\n\u2022 Election predictions require priors and new data, especially as the election day\napproaches. In the Economist\u2019s model, the expected distribution of potential\nvotesharesineachstatewasusedastheprior,andthestatepollsthattrickledin\nduringthecourseofthecampaignwerethe\u201dnewdata\u201d.\n2. Possibleanswers:\nLimitations\n\u2022 Thebetaapproachisbadatmodelingmultipartysystemsbecausesuccess/failure\ncan\u2019tsplitupvotesharespercandidateunlessitisatwo-partysystem.\n\u2022 Randomdriftcausesuncertaintyaroundthecurrentpollingaverage.\n\u2022 Instatesthatareheavilypolledlateintherace,themodelwillpaylittleattention\ntoitspriorforecast;conversely,itwillemphasisethepriorearlyintheraceorin\nthinly-polledstates.\n\u20137\u2013\n\u2022 Differentmethodsofturnoutprojectioncanproduceabias.\n\u2022 Partisan non-response bias: The probability that a poll respondent will agree\nto participate in a survey varies in response to media coverage. When there is\nunusually bad news about a candidate, their supporters are not in the mood to\ntell pollsters what they think \u2013 even though their ultimate voting intention has\nnotchanged.Thiscausestheothercandidate\u2019svotesharetobeover-represented\ninpolls.\nEthicalConsiderations\n\u2022 Pollresultsinfluencehowpeoplewillvote.Whenthepublicbelievesacandidate\nisextremelylikelytowin,somepeoplearelesslikelytovote.Thisiswhysome\nanalyststhinkelectionpollsshouldbecoveredusingmarginsoferrorratherthan\nspeculativewinprobabilities.\n\u2022 Pollresultsactasafeedbackmechanismthataffectparties\u2019policychoices. <END>"}
{"prompt": "Lecture notes from cs109_lec14_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 14: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\n\uf040 View or edit group\nTotal Points\n4 / 4 pts\nQuestion 1\nImplications of Independence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nImplications of Dependence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nConditional Expectation and Rolls of a Single Die 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 4\nConditional Variance and Rolls of a Single Die 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Implications of Independence\n1 Point\nSuppose X and Y are independent. Which of the following is true? Check all that\napply.\nE[XY ] = E[X]E[Y ]\nE[X + Y ] = E[X] + E[Y ]\nV ar(X + Y ) = V ar(X) + V ar(Y )\nQ2 Implications of Dependence\n1 Point\nSuppose X and Y are dependent. Which of the following is true for all X and Y\nthat are dependent? Check all that apply.\nE[XY ] = E[X]E[Y ]\nE[X + Y ] = E[X] + E[Y ]\nV ar(X + Y ) = V ar(X) + V ar(Y )\nQ3 Conditional Expectation and Rolls of a Single Die\n1 Point\nConsider an experiment where you repeatedly roll a single fair die until you get a\n4. Let X be the number of rolls needed until you get that 4 (e.g. X = 7 if the\nseventh roll produces the first 4), and let Y count the number of 3's you see\nalong the way. What is E[Y \u2223X = x]?\nx\n6\n1 + x\n6\nx\n1 +\n5\n1(x \u2212 1)\n5\n1(x + 1)\n5\n1(x \u2212 1)\n6\n1(x + 1)\n6\nQ4 Conditional Variance and Rolls of a Single Die\n1 Point\nLeveraging the same experiment used in Question 3, the conditional variance is\ngiven by V ar(Y \u2223X = x) = k(x \u2212 1). What is the value of k?\nThe answer is a real number between 0 and 1, which you should enter it as a\ndecimal to two significant digits.\n0.16 <END>"}
{"prompt": "Lecture notes from cs109_lec15_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 15: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n2 / 2 pts\nQuestion 1\nBayesian Networks 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nBayesian Inference 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Bayesian Networks\n1 Point\nSelect all that are true of Bayesian networks.\nThey model the conditional dependences of random variables as edges in\na graph, where the nodes represent the random variables.\n\u2192\nIf A and B are nodes in a Bayesian network with an edge A B, then B is\nconditionally dependent on A.\nThey are useful for solving inference questions.\n\u2192 \u2192\nIf A and B share a parent C (with edges C A and C B), then then A\nand B are conditionally independent.\nQ2 Bayesian Inference\n1 Point\nHow do Bayesian networks help us answer inference questions?\nThey allow us to avoid the calculation of the entire joint probability table\nof all variables.\nThey help us more easily track conditional dependencies, which are\nessential for evaluating conditional probabilities.\nThey increase computation time of conditional probabilities.\nWe can implement algorithms that take advantage of the Bayesian\nnetworks to solve inference problems. <END>"}
{"prompt": "Lecture notes from cs109_lec10_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 10: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nStanford Student Heights 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nMeal Plan Dollars 3 / 3 pts\n2.1 Meal Plan Dollars: Expectation 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 Meal Plan Dollars: Variance 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.3 Meal Plan Dollars: Linear Combinations of Gaussians 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Stanford Student Heights\n1 Point\nAssume the heights of all Stanford students are normally distributed with mean\n175 cm and variance 16 cm2 . Restated, if X is the height of a random Stanford\nstudent, X \u223c N(\u03bc = 175,\u03c32 = 16).\nApproximately what percentage of Stanford student heights would fall within\none standard deviation of the mean, i.e., in the interval [171, 179]?\n90%\n50%\n68%\n20%\nQ2 Meal Plan Dollars\n3 Points\nNow, consider that Stanford starts instituting a plan where the number of meal\nplan dollars a student receives each quarter is Y = 3X + 1400, where X is the\nheight (in cm) of the student and follows the distribution in Question 1. (Yes, this\nis a contrived scenario and the university does not actually do this. At least yet!)\nQ2.1 Meal Plan Dollars: Expectation\n1 Point\nIf you are a Stanford student, what is the expected number of meal plan dollars\nyou receive in a quarter?\n1925\nQ2.2 Meal Plan Dollars: Variance\n1 Point\nIf you are a Stanford student, what is the variance of the meal plan dollars you\nreceive in a quarter?\n144\nQ2.3 Meal Plan Dollars: Linear Combinations of Gaussians\n1 Point\nWhat is the probability that you receive more than $1937 in meal dollars in a\nquarter?\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20 <END>"}
{"prompt": "Lecture notes from 12_independent_rvs_annotated.txt\n\n###\n\n", "completion": "12: Independent RVs\nJerry Cain\nApril 26th, 2024\nLecture Discussion on Ed\n1\nSums of\nindependent\nBinomial RVs\n2\nIndependent discrete RVs\nRecall the definition of independent\n\ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39\nevents \ud835\udc38 and \ud835\udc39:\nTwo discrete random variables \ud835\udc4b and \ud835\udc4c are independent if:\nfor all \ud835\udc65, \ud835\udc66:\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 = \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc43 \ud835\udc4c = \ud835\udc66\nDifferent notation,\n\ud835\udc5d \ud835\udc65, \ud835\udc66 = \ud835\udc5d \ud835\udc65 \ud835\udc5d \ud835\udc66\n!,# ! #\nsame idea:\n\u2022 Intuitively: knowing value of \ud835\udc4b tells us nothing about\nthe distribution of \ud835\udc4c (and vice versa)\n\u2022 If two variables are not independent, they are termed dependent.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nSum of independent Binomials\n\ud835\udc4b~Bin(\ud835\udc5b , \ud835\udc5d)\n!\n\ud835\udc4b + \ud835\udc4c ~Bin(\ud835\udc5b + \ud835\udc5b , \ud835\udc5d)\n\ud835\udc4c~Bin(\ud835\udc5b , \ud835\udc5d)\n! \"\n\"\n\ud835\udc4b, \ud835\udc4c independent\nIntuition:\n\u2022 Each trial in \ud835\udc4b and \ud835\udc4c is independent and has same success probability \ud835\udc5d\n\u2022 Define \ud835\udc4d =# successes in \ud835\udc5b + \ud835\udc5b independent trials, each with success\n! \"\nprobability \ud835\udc5d. \ud835\udc4d~Bin \ud835\udc5b + \ud835\udc5b , \ud835\udc5d and \ud835\udc4d = \ud835\udc4b + \ud835\udc4c as well.\n! \"\nHolds in general case:\n\u2019 \u2019\nIf only it were\n\ud835\udc4b ~Bin(\ud835\udc5b , \ud835\udc5d) + \ud835\udc4b ~Bin(+ \ud835\udc5b , \ud835\udc5d)\n# # $ $ always so simple\n\ud835\udc4b independent for \ud835\udc56 = 1, \u2026 , \ud835\udc5b\n# $%& $%&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nCoin flips\nFlip a coin with probability \ud835\udc5d of heads a total of \ud835\udc5b + \ud835\udc5a times.\nLet \ud835\udc4b = number of heads in first \ud835\udc5b flips. \ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d)\n\ud835\udc4c = number of heads in next \ud835\udc5a flips. \ud835\udc4c~Bin \ud835\udc5a, \ud835\udc5d\n\ud835\udc4d = total number of heads in \ud835\udc5b + \ud835\udc5a flips.\n1. Are \ud835\udc4b and \ud835\udc4d independent?\n2. Are \ud835\udc4b and \ud835\udc4c independent?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nCoin flips\nFlip a coin with probability \ud835\udc5d of heads a total of \ud835\udc5b + \ud835\udc5a times.\nLet \ud835\udc4b = number of heads in first \ud835\udc5b flips. \ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d)\n\ud835\udc4c = number of heads in next \ud835\udc5a flips. \ud835\udc4c~Bin(\ud835\udc5a, \ud835\udc5d)\n\ud835\udc4d = total number of heads in \ud835\udc5b + \ud835\udc5a flips.\n1. Are \ud835\udc4b and \ud835\udc4d independent? \u274c Counterexample: What if \ud835\udc4d = 0?\n2. Are \ud835\udc4b and \ud835\udc4c independent? \u2705\n# of mutually exclusive \ud835\udc5b \ud835\udc5a\n\u2236\nfirst \ud835\udc5b flips have \ud835\udc65 heads outcomes in event \ud835\udc65 \ud835\udc66\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 = \ud835\udc43\nand next \ud835\udc5a flips have \ud835\udc66 heads \ud835\udc43 each outcome\n\ud835\udc5b \ud835\udc5a = \ud835\udc5d! 1 \u2212 \ud835\udc5d \"#!\ud835\udc5d$ 1 \u2212 \ud835\udc5d %#$\n$ %&$ \u2019 (&\u2019\n= \ud835\udc5d 1 \u2212 \ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc65 \ud835\udc66\nThis probability (found through\ncounting) is the product of the\n= \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc43 \ud835\udc4c = \ud835\udc66\nmarginal PMFs.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nConvolution:\nSum of\nindependent\nPoisson RVs\n7\nConvolution: Sum of independent random variables\nFor any discrete random variables \ud835\udc4b and \ud835\udc4c:\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = + \ud835\udc43 \ud835\udc4b = \ud835\udc58, \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\n3\nIn particular, for independent discrete random variables \ud835\udc4b and \ud835\udc4c:\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = + \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\n3\nthe convolution of \ud835\udc5d and \ud835\udc5d\n) *\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nInsight into convolution\nFor independent discrete random variables \ud835\udc4b and \ud835\udc4c:\nthe convolution\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = \u2019 \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\nof \ud835\udc5d and \ud835\udc5d\n) *\n!\nSuppose \ud835\udc4b and \ud835\udc4c are independent, both with support 0, 1, \u2026 , \ud835\udc5b, \u2026 :\n\ud835\udc4b\n0 1 2 \u2026 \ud835\udc5b \ud835\udc5b + 1 \u2026\n\u2022 \u2714: event where \ud835\udc4b + \ud835\udc4c = \ud835\udc5b\n0\n\u2714\n\u2022 Each event has probability:\n\u2026\n\u2026\n\ud835\udc43 \ud835\udc4b = \ud835\udc58, \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\n\ud835\udc5b \u2212 2 \u2714\n= \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\n\ud835\udc4c \ud835\udc5b \u2212 1\n\u2714\n(because \ud835\udc4b,\ud835\udc4c are independent)\n\ud835\udc5b\n\u2714 \u2022 \ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = sum of\n\ud835\udc5b + 1\nmutually exclusive events\n\u2026\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nSum of 2 dice rolls\n6/36\n5/36\n4/36\n3/36\n2/36\n1/36\n0\n2 3 4 5 6 7 8 9 10 11 12\n% + ' = )\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n)\n=\n'\n+\n%\n.\nThe distribution of a sum of\n2 dice rolls is a convolution\nof 2 PMFs.\nExample:\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = 4 =\n\ud835\udc43 \ud835\udc4b = 1 \ud835\udc43 \ud835\udc4c = 3\n+ \ud835\udc43 \ud835\udc4b = 2 \ud835\udc43 \ud835\udc4c = 2\n+ \ud835\udc43 \ud835\udc4b = 3 \ud835\udc43 \ud835\udc4c = 1\nSum of 10 dice rolls (fun preview)\n0.08\nThe distribution of a sum of\n0.06\n10 dice rolls is a convolution\n0.04\n10 PMFs.\n0.02\n0\n10 20 30 40 50 60\n\ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b = \ud835\udc5b\n! \" !3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n\ud835\udc5b\n=\n\ud835\udc4b\n+\n\u22ef\n+\n\ud835\udc4b\n+\n\ud835\udc4b\n\ud835\udc43\n3!\n\"\n!\nLooks kinda Normal\u2026???\n(more on this in a few weeks)\nSum of independent Poissons\n\ud835\udc4b~Poi \ud835\udf06 , \ud835\udc4c~Poi \ud835\udf06\n! \" \ud835\udc4b + \ud835\udc4c ~Poi(\ud835\udf06 + \ud835\udf06 )\n! \"\n\ud835\udc4b, \ud835\udc4c independent\nProof (just for reference):\n\ud835\udc4b and \ud835\udc4c independent,\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = \ud835\udc5b = ; \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = \ud835\udc5b \u2212 \ud835\udc58\nconvolution\n4\n% %\n4 %&4 4 %&4\n\ud835\udf06 \ud835\udf06 \ud835\udf06 \ud835\udf06\n! \" ! \"\n= ; \ud835\udc52&6 ! \ud835\udc52&6 \" = \ud835\udc52&(6 !86 \") ; PMF of Poisson RVs\n\ud835\udc58! (\ud835\udc5b \u2212 \ud835\udc58)! \ud835\udc58! (\ud835\udc5b \u2212 \ud835\udc58)!\n453 453\n%\nBinomial Theorem:\n& 6 86 & 6 86\n\ud835\udc52 ! \" \ud835\udc5b! \ud835\udc52 ! \"\n!\n4 %&4 %\n= ; \ud835\udf06 \ud835\udf06 = \ud835\udf06 + \ud835\udf06 \ud835\udc5b\n\ud835\udc5b! \ud835\udc58! (\ud835\udc5b \u2212 \ud835\udc58)! ! \" \ud835\udc5b! ! \" \ud835\udc4e + \ud835\udc4f ! = = \ud835\udc4e\"\ud835\udc4f!%\"\n\ud835\udc58\n453\n\"#$\nPoi \ud835\udf06 + \ud835\udf06\n! \"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nSum of independent Poissons\n\ud835\udc4b~Poi \ud835\udf06 , \ud835\udc4c~Poi \ud835\udf06\n! \" \ud835\udc4b + \ud835\udc4c ~Poi(\ud835\udf06 + \ud835\udf06 )\n! \"\n\ud835\udc4b, \ud835\udc4c independent\n\u2022 \ud835\udc5b servers with independent number of requests/minute\n\u2022 Server \ud835\udc56\u2019s requests each minute can be modeled as \ud835\udc4b ~Poi \ud835\udf06\n\" \"\nWhat is the probability that the total number of web requests received at all\nservers in the next minute exceeds 10?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nExercises\n14\nIndependent questions\n1. Let \ud835\udc4b~Bin 30, 0.01 and \ud835\udc4c~Bin 50, 0.02 be independent RVs.\n\u2022 How do we compute \ud835\udc43 \ud835\udc4b + \ud835\udc4c = 2 using a Poisson approximation?\n\u2022 How do we compute \ud835\udc43 \ud835\udc4b + \ud835\udc4c = 2 exactly?\n2. Let \ud835\udc41 = # of requests to a web server per day. Suppose \ud835\udc41~Poi \ud835\udf06 .\n\u2022 Each request independently comes from a human (prob. \ud835\udc5d), or bot (1 \u2212 \ud835\udc5d).\n\u2022 Let \ud835\udc4b be # of human requests/day, and \ud835\udc4c be # of bot requests/day.\nAre \ud835\udc4b and \ud835\udc4c independent? What are their marginal PMFs?\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n1. Approximating the sum of independent Binomial RVs\nLet \ud835\udc4b~Bin 30, 0.01 and \ud835\udc4c~Bin 50, 0.02 be independent RVs.\n\u2022 How do we compute \ud835\udc43 \ud835\udc4b + \ud835\udc4c = 2 using a Poisson approximation?\n\u2022 How do we compute \ud835\udc43 \ud835\udc4b + \ud835\udc4c = 2 exactly?\n\"\n\ud835\udc43 \ud835\udc4b + \ud835\udc4c = 2 = ; \ud835\udc43 \ud835\udc4b = \ud835\udc58 \ud835\udc43 \ud835\udc4c = 2 \u2212 \ud835\udc58\n453\n)\n30 50\n= : 0.01& 0.99 *(#& 0.02)#&0.98+(#()#&)\u2248 0.2327\n\ud835\udc58 2 \u2212 \ud835\udc58\n&\u2019(\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n2. Web server requests\nLet \ud835\udc41 = # of requests to a web server per day. Suppose \ud835\udc41~Poi \ud835\udf06 .\n\u2022 Each request independently comes from a human (prob. \ud835\udc5d), or bot (1 \u2212 \ud835\udc5d).\n\u2022 Let \ud835\udc4b be # of human requests/day, and \ud835\udc4c be # of bot requests/day.\nAre \ud835\udc4b and \ud835\udc4c independent? What are their marginal PMFs?\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 = \ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 \ud835\udc41 = \ud835\udc65 + \ud835\udc66 \ud835\udc43 \ud835\udc41 = \ud835\udc65 + \ud835\udc66 Law of Total\nProbability\n+\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 \ud835\udc41 \u2260 \ud835\udc65 + \ud835\udc66 \ud835\udc43 \ud835\udc41 \u2260 \ud835\udc65 + \ud835\udc66\n= \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc41 = \ud835\udc65 + \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66| \ud835\udc4b = \ud835\udc65, \ud835\udc41 = \ud835\udc65 + \ud835\udc66 \ud835\udc43 \ud835\udc41 = \ud835\udc65 + \ud835\udc66 Chain Rule\n$8\u2019\n\ud835\udf06\n\ud835\udc65 + \ud835\udc66 Given \ud835\udc41 = \ud835\udc65 + \ud835\udc66 indep. trials,\n$ \u2019 &6\n= \ud835\udc5d 1 \u2212 \ud835\udc5d \u22c5 1 \u22c5 \ud835\udc52\n\ud835\udc65 \ud835\udc65 + \ud835\udc66 ! \ud835\udc4b|\ud835\udc41 = \ud835\udc65 + \ud835\udc66~Bin \ud835\udc65 + \ud835\udc66,\ud835\udc5d\n$ $\n\ud835\udc65 + \ud835\udc66 ! \ud835\udf06\ud835\udc5d # \ud835\udf06 1 \u2212 \ud835\udc5d \ud835\udf06\ud835\udc5d # \ud835\udf06 1 \u2212 \ud835\udc5d\n= \ud835\udc52!\" = \ud835\udc52!\"% \u22c5 \ud835\udc52!\" &!%\n\ud835\udc65! \ud835\udc66! \ud835\udc65 + \ud835\udc66 ! \ud835\udc65! \ud835\udc66!\nYes, \ud835\udc4b and \ud835\udc4c are\nwhere \ud835\udc4b~Poi \ud835\udf06\ud835\udc5d ,\ud835\udc4c~Poi \ud835\udf06 1 \u2212 \ud835\udc5d\n= \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc43 \ud835\udc4c = \ud835\udc66 independent!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nExpectation of\nCommon RVs\n18\nLinearity of Expectation: Important\n\u2019\nExpectation is a linear mathematical operation. If \ud835\udc4b = \u2211 \ud835\udc4b :\n$%& $\n8 8\n\ud835\udc38 \ud835\udc4b = \ud835\udc38 . \ud835\udc4b = . \ud835\udc38 \ud835\udc4b\n6 6\n67! 67!\n\u2022 Even if you don\u2019t know the distribution of \ud835\udc4b (e.g., because the joint\ndistribution of \ud835\udc4b , \u2026 , \ud835\udc4b is unknown), you can still compute\n& \u2019\nexpectation of \ud835\udc4b.\nMost common use cases:\n%\n\u2022 Problem-solving key: \u2022 \ud835\udc38 \ud835\udc4b easy to calculate\n#\n\ud835\udc4b = ; \ud835\udc4b\nDefine \ud835\udc4b such that # \u2022 Sum of dependent RVs\n$\n#5!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nExpectations of common RVs: Binomial Review\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) # of successes in \ud835\udc5b independent trials\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nwith probability of success \ud835\udc5d\nRecall: Bin 1, \ud835\udc5d = Ber \ud835\udc5d\n8\n\ud835\udc4b = . \ud835\udc4b\n6\n67!\n% % %\nLet \ud835\udc4b = \ud835\udc56th trial is heads\n. \ud835\udc38 \ud835\udc4b = \ud835\udc38 ; \ud835\udc4b = ; \ud835\udc38 \ud835\udc4b = ; \ud835\udc5d = \ud835\udc5b\ud835\udc5d\n# #\n\ud835\udc4b ~Ber \ud835\udc5d ,\ud835\udc38 \ud835\udc4b = \ud835\udc5d\n. .\n#5! #5! #5!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nExpectations of common RVs: Negative Binomial\nE # of independent trials with probability\n\ud835\udc4c~NegBin(\ud835\udc5f, \ud835\udc5d) \ud835\udc38 \ud835\udc4c =\nF of success \ud835\udc5d until \ud835\udc5f successes\nRecall: NegBin 1, \ud835\udc5d = Geo \ud835\udc5d\n?\n1. How should we define \ud835\udc4c ?\n$\n\ud835\udc4c = . \ud835\udc4c\n6\n2. How many terms are in our summation?\n67!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nExpectations of common RVs: Negative Binomial\nE # of independent trials with probability\n\ud835\udc4c~NegBin(\ud835\udc5f, \ud835\udc5d) \ud835\udc38 \ud835\udc4c =\nF of success \ud835\udc5d until \ud835\udc5f successes\nRecall: NegBin 1, \ud835\udc5d = Geo \ud835\udc5d\n?:\n\ud835\udc4c = . \ud835\udc4c\n6\n67!\nLet \ud835\udc4c = # trials to get \ud835\udc56th success (after\n. ? ? ?\n1 \ud835\udc5f\n\ud835\udc56 \u2212 1 th success)\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 ; \ud835\udc4c = ; \ud835\udc38 \ud835\udc4c = ; =\n/ # #\n\ud835\udc4c~Geo \ud835\udc5d ,\ud835\udc38 \ud835\udc4c = \ud835\udc5d \ud835\udc5d\n. .\n0 #5! #5! #5!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22 <END>"}
{"prompt": "Lecture notes from 03_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 April25,2024\nSection 3: Named Random Variables\nBefore you leave lab, make sure you click here so that you\u2019re marked as having attended. The CA\nleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\n1 Gender Composition of Discussion Sections\nAmassiveonlineStanfordclasshassectionswith10studentseach.Eachstudentinourpopulation\nhas a 50% chance of identifying as female, 47% chance of identifying as male and 3% chance of\nidentifying as non-binary. Even though students are assigned randomly to sections, a few sections\nenduphavingaveryunevendistributionjustbychance.Youshouldassumethatthepopulationof\nstudents is so large that the percentages of students who identify as male / female / non-binary are\nunchanged,evenifyouselectstudentswithoutreplacement.\na. Definearandomvariableforthenumberofpeopleinasectionwhoidentifyasmale.\nb. What is the expectation and standard deviation of number of students who identify as male\ninasinglesection?\nc. Write an expression for the exact probability that a section is skewed. We defined skewed to\nbethatthesectionhas0,1,9or10peoplewhoidentifyasmale.\nd. The course has 1,200 sections. Approximate the probability that 30 or more sections will be\nskewed.\n2 Better Evaluation of Eye Disease\nWhen a patient has eye inflammation, eye doctors \u201dgrade\u201d the inflammation. When \u201dgrading\u201d\ninflammation they randomly look at a single 1 millimeter by 1 millimeter square in the patient\u2019s\neyeandcounthowmany\u201dcells\u201dtheysee.\nThere is uncertainty in these counts. If the true average number of cells for a given patient\u2019s eye is\n6, the doctor could get a different count (say 4, or 5, or 7) just by chance. As of 2021, modern eye\nmedicine does not have a sense of uncertainty for their inflammation grades! In this problem we\nare going to change that. At the same time we are going to learn about poisson distributions over\nspace.\na. Explain, as if teaching, why the number of cells observed in a 1x1 square is governed by\na poisson process. Make sure to explain how a binomial distribution could approximate the\ncount of cells. Explain what \ud835\udf06 means in this context. Note: for a given person\u2019s eye, the\npresenceofacellinalocationisindependentofthepresenceofacellinanotherlocation.\nb. For a given patient the true average rate of cells is 5 cells per 1x1 sample. What is the\nprobabilitythatinasingle1x1samplethedoctorcounts4cells?\n\u20132\u2013\nFigure 1: A 1x1mm sample used for inflammation grading. Inflammation is graded by counting\ncellsinarandomlychosen1mmby1mmsquare.Thissamplehas5cells.\n3 Continuous Random Variables\nLet \ud835\udc4b beacontinuousrandomvariablewiththefollowingprobabilitydensityfunction:\n(cid:26) \ud835\udc50(\ud835\udc52\ud835\udc65\u22121 +\ud835\udc52\u2212\ud835\udc65) if0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc4b(\ud835\udc65) =\n0 otherwise\na. Findthevalueof \ud835\udc50 thatmakes \ud835\udc53 \ud835\udc4b avalidprobabilitydistribution.\nb. Whatis \ud835\udc43(\ud835\udc4b < 0.75)?Whatis \ud835\udc43(\ud835\udc4b < \ud835\udc65)?\n4 Website Visits\nYouhaveawebsitewhereonlyonevisitorcanbeonthesiteatatime,butthereisaninfinitequeue\nof visitors, so that immediately after a visitor leaves, a new visitor will come onto the website. On\naverage,visitorsleaveyourwebsiteafter5minutes.Assumethatthelengthofstayisexponentially\ndistributed.Wewillcalculatewhatistheprobabilitythatauserstaysmorethan10minutes.\na. Usingtherandomvariable \ud835\udc4b definedasabove,whatistheprobabilitythatauserstayslonger\nthan10mins?(i.e, \ud835\udc4b > 10).\nb. Using the random variable\ud835\udc4c, defined as the number of users who leave your website over a\n10-minuteinterval,whatistheprobabilitythatauserstayslongerthan10mins? <END>"}
{"prompt": "Lecture notes from 27_ai_and_ethics.txt\n\n###\n\n", "completion": "27: AI and Ethics\nJerry Cain\nJune 3, 2024\nLecture Discussion on Ed\n1\n2\nWe live in a time with\nreal work to be done\nh\ng n\ni o\nh\ni\nt b\no a e\nt\nh t\ns\nt uc e\na l\ne\nr\nt\ns d h\ne e How can we begin to c\na\nc r\ny e\nc\nt\na li use ML to help?\na\nu\nq\nsmart grids\ncriminal justice reform\n1\nhttps://www.nytimes.com/interac\ntive/2021/09/03/climate/bitcoi 3\nn-carbon-footprint-electricity.html\nhttps://www.bbc.com/portuguese/noticias/2009/12/091225_videoyoutubegd\nhttps://petapixel.com/2010/01/22/racist-camera-phenomenon-explained-almost/\n2\nhttps://www.cjr.org/the_media_today/facebook-un-myanmar-genocide.php\nhttps://www.nytimes.com/2018/10/15/technology/myanmar-facebook-genocide.html\nLearning Goals\n1. Understand limits in\nfairness through\nunawareness\n2. Know two ways to\nmeasure fairness\n3. Know some techniques\nto mitigate fairness\nissues\n5\n\"\u2026 [T]o call attention to\nthe privacy risks, he\n[Michal Kosinski of\nStanford\u2019s GSB] decided\nto show that it was\n\"Presented with photos\npossible to use facial\nof gay men and straight\nrecognition analysis to\nmen, a computer\ndetect something\nprogram was able to\nintimate, something\ndetermine which of the\n'people should have full\ntwo was gay with 81\nrights to keep private.'\"\npercent accuracy,\naccording to Dr. Kosinski\nand co-author Yilun\nhttps://www.nytimes.com/2017/10/09/science/stanford-sexual-orientation-study.html\nWang\u2019s paper.\"\n'\"the algorithmic equivalent of a 13-year-old bully\"' \"Indeed, few of the claims made by researchers or companies hyping its\npotential have been replicated, said Clare Garvie of Georgetown University\u2019s\nCenter on Privacy and Technology.\nOther learning goal: how to be a scientist\n'At the very best, it\u2019s a highly inaccurate science,' she said of promises to\nwhile working on controversial topics predict criminal behavior, intelligence and other character traits from faces.\n'At its very worst, this is racism by algorithm.'\"\n6\n'\"We\u2019re at the beginning of a broader societal\ntransformation,\" said Brian Christian, a\ncomputer scientist and the author of... a\nbook about the ethical concerns surrounding\nA.I. systems. \"There\u2019s going to be a bigger\nquestion here for businesses, but in the\nimmediate term, for the education system,\nwhat is the future of homework?\u201d\u2019\n\"OpenAI, the company behind ChatGPT,\ndeclined to comment for this column.\"\nhttps://www.nytimes.com/2022/12/21/technology/personaltech/how-to-use-chatgpt-ethically.html\nhttps://www.nytimes.com/2023/03/14/technology/openai-new-gpt4.html\n7\nPhilosophy and Ethics Ask Very Good Questions of CS\nHere are a few questions and concepts worth discussing:\n\u2022 What is a protected demographic?\n\u2022 What is distributive harm? What is quality-of-service harm?\n\u2022 What is fairness? How can various definitions of fairness be made core\nto machine learning?\nimage sources\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 8\nLogistics Regression Is That Linear Separator\n\u2022 Logistic regression computes some line that separates instances where\n\ud835\udc66 = 1 from those where \ud835\udc66 = 0.\nT\n\u2713 x = 0\n\u2713 x + \u2713 x + + \u2713 x = 0\n0 0 1 1 m m\n\u00b7 \u00b7 \u00b7\nx\n2\nx\n1\n\u2022 We call such data (or the functions generating the data) linearly\nseparable.\n\u2022 Na\u00efve Bayes is linear as well, since the different features are assumed to\nbe conditionally independent.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 9\nFrameworks of Harm\nQuality-of-service harm Distributive harm Existential harms\nOccurs when a system Occurs when AI systems Occurs when AI gravely\ndoes not work as well for withhold opportunities, alters the course of all\none person as it does for resources, or information humankind\nanother\nExamples: Examples: Examples:\n\u00d8 generative art \u00d8 hiring \u00d8 democracy\n\u00d8 facial recognition \u00d8 lending \u00d8 climate\n\u00d8 document search \u00d8 college admissions \u00d8 genocide\n\u00d8 product recommendation \u00d8 salary and benefits \u00d8 AI supremacy\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 1100\nUnder-sampling, Lack of Data, Poorly Curated Datasets\nInitial explanations for AI-driven harm:\n\u2022 On both gender and race, majority groups are generally overrepresented\nin image databases.\n\u2022 Most images in some widely used databases: white faces.\n\u2022 Faces In The Wild database was 83.5% white and 77.5% male.\n\u2022 Machine learning may ignore or deemphasize features of minority\ngroups.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 1111\nIntentional Improvements in Face Datasets in 2018\nResearch and activism by Joy Buolamwini, Timnit Gebru, and many\nothers has led to more representative datasets already.\n\"The Gender Shades project pilots an\nintersectional approach to inclusive\nproduct testing for AI\"\nStanford PhD 2017\n- Gender Shades\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 1122\nAlgorithmic Discrimination: The Case of St. George\u2019s Hospital\nOffer spots to\napprox. 425\nInterview (so 70% of\napprox. 625 interviewees\n2,500 (so \u00be are accepted)\napplicants to rejected)\nthe medical In 1979, Vice Dean Dr.\nGeoffrey Franglen\nschool\ncompletes a classification\nalgorithm to do the job\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 1133\nTimeline of a Biased Algorithm\n1982: Dr. Franglen Internal review Commission finds that\nargues that 90-95% of questions why name and place of\nclassifications agree applicants are being birth are used to dock\nwith the verdict of weighted by factors like points from female and\nhuman assessors on name and place of \"Non-Caucasian\"\nthe selection panel birth applicants\n1982: Algorithm 1986: two St. George\u2019s\ntrained on historical lecturers report\ndata from St. George\u2019s findings to UK\nscreens all applications Commission for Racial\nEquality\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 14\nAlgorithmic Discrimination: The Case of St. George\u2019s Hospital\n1. Codifying misogyny and racism\nPrevious admissions process was biased against\nThis biased result\nfemale applicants and applicants of color. Simply\nwas predictable. learning from the data will replicate and perpetuate\nthe past bias.\n2. Improper use of sensitive features.\nAt least 60\nAlgorithm relied on data like name and place of birth\npeople unfairly\nthat provide no information about the merit of the\nrejected each applicant and are highly correlated with sensitive\ncategories like race and gender.\nyear.\n3. Can be biased without intention to be evil\nEven if you didn\u2019t mean to make a biased algorithm,\nthat doesn\u2019t mean it isn\u2019t biased.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 1155\nTwo Philosophical Views of Fairness\nProcedural Fairness: Distributive Fairness:\nFocuses on the decision- Focuses on the decision-\nmaking or classification making or classification\nprocess, ensures that the outcome, ensures that the\nalgorithm does not rely on distribution of good and bad\nunfair features. outcomes is equitable.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 16\nThree Formal\nDefinitions of Fairness\nFairness through Unawareness\nFairness through Awareness: Independence\nFairness through Awareness: Separation\n17\nFairness through Unawareness\nMotivating idea: \"The way to stop discrimination on the basis of race is to\nstop discriminating on the basis of race\" \u2013 Chief Justice Roberts\nNote: Fairness through unawareness of some federally protected\ncategories\u2014that is, a subset of sensitive features\u2014is legally required in\ndomains like lending.\nHow to do it:\n1. Exclude sensitive feature (race, gender, age, etc.) from your dataset\n2. Also exclude proxies to the sensitive feature (name, zip code)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 18\nProtected Demographics\nProtected Groups\nProtected groups under EEO are race, color, national origin,\nreligion, age (40 or older), sex (including pregnancy, sexual\norientation, or gender identity), physical or mental disability,\nand reprisal.\nEqual Employment\nOpportunity, US\nSimilarly defined for housing, loans, etc.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 19\nCase Study: Facebook Ads & Job/Housing Recommendations\nFacebook creates \"Lookalike\" March 2019: As part of\nfeature for advertisers: settlement, Facebook agrees\nupload a \"source list\" and not to use \"age, gender,\nfind users with \"common relationship status, religious\nqualities\" to target ads for views, school, political views,\ngoods and services, including interested in, or zip code\" in\nhousing and jobs creating lookalike audience\nMarch 2018: National Fair\nHousing Alliance (NFHA) &\nother civil rights groups sue\nFacebook over violations of\nthe Fair Housing Act\nhttps://techscience.org/a/2021101901\nhttps://www.technologyreview.com/2019/04/05/1175/facebook-algorithm-discriminates-ai-bias\nhttps://arxiv.org/pdf/1912.07579.pdf\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 20\nFacebook Input Lookalikes\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 21\nLookalike Special Ad (no gender)\nNew Special Ad\nAudiences Still\nBiased\ngender: equally biased\nage: almost as biased\nrace: more difficult to measure\ngiven the tools provided\nbut still biased\npolitics: less biased\nhttps://sapiezynski.com/papers/sapiezynski2019algorithms.pdf\n22\nTwo Philosophic Values of Fairness\nProcedural Fairness: Distributive Fairness:\nFocuses on the decision- Focuses on the decision-\nmaking or classification making or classification\nprocess, ensures that the outcome, ensures that the\nalgorithm does not rely on distribution of good and bad\nunfair features. outcomes is equitable.\nFairness through unawareness\n(Facebook example shows this isn\u2019t always effective)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024\n23\nFairness Through Awareness Terms\nD: protected demographic\nG: guess of your model (aka y hat)\nT: the true value (aka y)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 24\nDistributive Fairness #1: Parity\nD: protected demographic\nG: guess of your model (aka y hat)\nT: the true value (aka y)\nP(G = 1 | D = 1) = P(G = 1 | D = 0)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 25\nDistributive Fairness #2: Calibration\nD: protected demographic\nG: guess of your model (aka y hat)\nT: the true value (aka y)\nP(G = T | D = 1) = P(G = T | D = 0)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 26\nDistributive Fairness #2: Calibration (Relaxed)\nD: protected demographic\nG: guess of your model (aka y hat)\nT: the true value (aka y)\nwhere epsilon = 0.2\nUS legal standard: \"disparate impact\" also known as the 80% rule.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 27\nWhat does fairness through awareness fail to\ncapture?\n\u2022 If the classifier is worse at identifying\ncandidates (e.g., for an experimental surgery)\nin a minority group, the candidates selected\nDisparate\nmight experience worse outcomes, leading to\nQuality & Self-\nfuture bias\nFulfilling\n\u2022 Quality-of-service disparity might lead to an\nProphecies\nallocation disparity\n\u2022 Dwork et. al. (including Omer Reingold of\nStanford) call this a \"self-fulfilling prophecy\".\nhttps://dl.acm.org/doi/10.1145/2090236.2090255\n28\nAdvanced Idea: Adversarial Learning [aka: train bias out]\n\"Recidivism prediction scores are used across the\nUSA to determine sentencing and supervision for\nhundreds of thousands of inmates. One such\ngenerator of recidivism prediction scores is\nNorthpointe's Correctional Offender Management\nProfiling for Alternative Sanctions (COMPAS)\nscore, used in states like California and Florida,\nwhich past research has shown to be biased\nagainst black inmates according to certain\nmeasures of fairness. To counteract this racial\nbias, we present an adversarially-trained neural\nStanford seniors at the network that predicts recidivism and is trained to\nremove racial bias.\"\ntime they published it\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 29\nCOMPAS: Predicting Recidivism\nx\ndata about an\ninmate: their zip\ncode, past argmax P (y x)\n|\ncrimes, etc.\ny= 0,1\n{ }\ny\u02c6 = 0\nprediction whether\nthey will commit a\ncrime again\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 30\nCan We Train Out Bias?\nModel 1: Prediction Model 2: Extract Demographic\nx\ny\u02c6 = 0 Demographic\nModel 1 should Model 2 should\nbe accurate be inaccurate\n*note in the paper these were neural nets\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 31\nCan We Train Out Bias?\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 32\nstnioP\negatnecreP\n0.8\n0.7\n0.6\n0.5\n0.4\n0.3\n0.2\n0.1\n0\nstnioP\negatnecreP\nCOMPAS: Correctional Offender Management Profiling for Alternative Sanctions\nBefore: COMPAS is Biased After: Gaps are reduced\nAccuracy Parity Gap\nAccuracy Parity Gap\nCalibration Gap\nCalibration Gap\n160,000,000,000,000\nhashes per second\nClimate change and bitcoin\naren\u2019t a significant part of\nethics within Stanford CS yet.\nIt isn\u2019t too hard to see the trend\nWe will most almost certainly hit 2x CO2 before 2060, and then blow past it.\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 34\nEasy to Know Impacts Will Be Harsh\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 35\nImpacts are Here\nCyclone Idai\nImpacted over 3M people\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024\nIt is hard to feel like you can do anything\u2026\n\"I am just going\nto wait and see\nwhat happens\"\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 37\nWhat Can We Do?: Push for some change\nIndividual Community Nation State\nScale\nIs this our sweet spot?\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 38\nWhat Can We Do? Reduce CS \"Pump\" of Proof of Work\n160,000,000,000,000\nHashes per second\nEthereum\u2019s Response?\n\"Ethereum switched on its proof-\nof-stake mechanism in 2022\nbecause it is more secure, less\nenergy-intensive, and better for\nimplementing new scaling\nsolutions compared to the\nprevious proof-of-work\narchitecture.\"\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024\nWhat Can We Do? Advocate for a Clean Grid in CA\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024\nBuild?\nTech-For-Good Startups\nRecently Started By Stanford\nGraduates\n\u2022 Recidiviz (Clementine Jacoby)\n\u2022 Edlyft (Arnelle Ansong)\n\u2022 Develop For Good (Mary Zhu)\nLisa Yan, Chris Piech, Mehran Sahami, Katie Creel, and Jerry Cain, CS109, Spring 2024 <END>"}
{"prompt": "Lecture notes from 04_cond_bayes_annotated.txt\n\n###\n\n", "completion": "04: Conditional\nProbability and Bayes\nJerry Cain\nApril 8th, 2024\nLecture Discussion on Ed\n1\nConditional\nProbability\n2\nDice, our misunderstood friends\nRoll two, fair 6-sided dice,\nyielding values \ud835\udc37 and \ud835\udc37 .\n! \"\nLet \ud835\udc38 be event: \ud835\udc37 + \ud835\udc37 = 4. Let \ud835\udc39 be event: \ud835\udc37 = 2.\n! \" !\nWhat is \ud835\udc43 \ud835\udc38 ? What is \ud835\udc43 \ud835\udc38, knowing \ud835\udc39 already observed ?\n\ud835\udc46 = 36\n\ud835\udc38 = 1,3 , 2, 2 , 3,1\n\ud835\udc43 \ud835\udc38 = 3/36 = 1/12\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nConditional Probability\nThe conditional probability of \ud835\udc38 given \ud835\udc39 is the probability that \ud835\udc38 occurs\ngiven that F has already occurred. This is known as conditioning on F.\nWritten as: \ud835\udc43(\ud835\udc38|\ud835\udc39)\nMeans: \"\ud835\udc43 \ud835\udc38, knowing \ud835\udc39 already observed \"\nSample space \u00e0 all possible outcomes in \ud835\udc39\nEvent \u00e0 all possible outcomes in \ud835\udc38 \u2229 \ud835\udc39\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nConditional Probability, equally likely outcomes\nThe conditional probability of \ud835\udc38 given \ud835\udc39 is the probability that \ud835\udc38 occurs\ngiven that F has already occurred. This is known as conditioning on F.\nWith equally likely outcomes:\n# of outcomes in E consistent with F |\ud835\udc38 \u2229 \ud835\udc39| |\ud835\udc38 \u2229 \ud835\udc39|\n\ud835\udc43 \ud835\udc38 \ud835\udc39 = = =\n# of outcomes in S consistent with F |\ud835\udc46 \u2229 \ud835\udc39| |\ud835\udc39|\n|\ud835\udc38\ud835\udc39|\n\ud835\udc43 \ud835\udc38 \ud835\udc39 = 8\n|\ud835\udc39| \ud835\udc43 \ud835\udc38 = \u2248 0.16\n50\n3\n\ud835\udc43 \ud835\udc38 \ud835\udc39 = \u2248 0.21\n14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\n\ud835\udc38\ud835\udc39 Equally likely\nSlicing up the spam\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\noutcomes\n|\ud835\udc39|\n24 emails are sent, 6 each to 4 users.\n\u2022 10 of the 24 emails are spam.\n\u2022 All possible outcomes are equally likely.\nLet \ud835\udc38 = user 1 receives Let \ud835\udc39 = user 2 receives Let \ud835\udc3a = user 3 receives\n3 spam emails. 6 spam emails. 5 spam emails.\nWhat is \ud835\udc43 \ud835\udc38 ? What is \ud835\udc43 \ud835\udc38|\ud835\udc39 ? What is \ud835\udc43 \ud835\udc3a|\ud835\udc39 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\n\ud835\udc38\ud835\udc39 Equally likely\nSlicing up the spam\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\noutcomes\n|\ud835\udc39|\n24 emails are sent, 6 each to 4 users.\n\u2022 10 of the 24 emails are spam.\n\u2022 All possible outcomes are equally likely.\nLet \ud835\udc38 = user 1 receives Let \ud835\udc39 = user 2 receives Let \ud835\udc3a = user 3 receives\n3 spam emails. 6 spam emails. 5 spam emails.\nWhat is \ud835\udc43 \ud835\udc38 ? What is \ud835\udc43 \ud835\udc38|\ud835\udc39 ? What is \ud835\udc43 \ud835\udc3a|\ud835\udc39 ?\n\u26a0 % !%\n!# !% % !%\n( !\n$ $ $ $ \ud835\udc43 \ud835\udc3a|\ud835\udc39 =\n\ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc38|\ud835\udc39 =\n!\u2019\n\"% !\u2019\n&\n& &\n= 0\n\u2248 0.3245 \u2248 0.0784\nNo way to choose 5 spam from\n4 remaining spam emails!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nConditional probability in general\nGeneral definition of conditional probability:\n\ud835\udc43 \ud835\udc38\ud835\udc39\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\n\ud835\udc43(\ud835\udc39)\nThe Chain Rule (aka Product rule):\n\ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc38 \ud835\udc39\nThese properties hold even when\noutcomes are not equally likely.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nand Learn\n\ud835\udc43 \ud835\udc38\ud835\udc39 Definition of\nNetflix and Learn\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\nCond. Probability\n\ud835\udc43(\ud835\udc39)\nLet \ud835\udc38 = a user watches Life is Beautiful.\nWhat is \ud835\udc43 \ud835\udc38 ?\n\u274c Equally likely outcomes? \ud835\udc46 = {watch, not watch}\n\ud835\udc38 = {watch}\n\ud835\udc43 \ud835\udc38 = 1/2 ?\n# people who have watched movie\n)(-)\n\u2705 \ud835\udc43 \ud835\udc38 = lim \u2248\n# people on Netflix\n)\u2192+ )\n= 10,234,231 / 50,923,123 \u2248 0.20\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\n\ud835\udc43 \ud835\udc38\ud835\udc39 Definition of\nNetflix and Learn\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\nCond. Probability\n\ud835\udc43(\ud835\udc39)\nLet \ud835\udc38 be the event that a user watches the given movie.\n\ud835\udc43 \ud835\udc38 = 0.19 \ud835\udc43 \ud835\udc38 = 0.32 \ud835\udc43 \ud835\udc38 = 0.20 \ud835\udc43 \ud835\udc38 = 0.09 \ud835\udc43 \ud835\udc38 = 0.20\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n\ud835\udc43 \ud835\udc38\ud835\udc39 Definition of\nNetflix and Learn\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\nCond. Probability\n\ud835\udc43(\ud835\udc39)\nLet \ud835\udc38 = a user watches Life is Beautiful.\nLet \ud835\udc39 = a user watches Amelie.\nWhat is the probability that a user watches\nLife is Beautiful, given they watched Amelie?\n\ud835\udc43 \ud835\udc38|\ud835\udc39\n# people who have watched both\n\ud835\udc43 \ud835\udc38\ud835\udc39\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = = # people on Netflix\n# people who have watched Amelie\n\ud835\udc43(\ud835\udc39)\n# people on Netflix\n# people who have watched both\n=\n# people who have watched Amelie\n\u2248 0.42\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\n\ud835\udc43 \ud835\udc38\ud835\udc39 Definition of\nNetflix and Learn\n\ud835\udc43 \ud835\udc38|\ud835\udc39 =\nCond. Probability\n\ud835\udc43(\ud835\udc39)\nLet \ud835\udc38 be the event that a user watches the given movie.\nLet \ud835\udc39 be the event that the same user watches Amelie.\n\ud835\udc43 \ud835\udc38 = 0.19 \ud835\udc43 \ud835\udc38 = 0.32 \ud835\udc43 \ud835\udc38 = 0.20 \ud835\udc43 \ud835\udc38 = 0.09 \ud835\udc43 \ud835\udc38 = 0.20\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.14 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.35 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.20 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.72 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.42\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nLaw of Total\nProbability\n14\nToday\u2019s tasks\n\ud835\udc43 \ud835\udc38\ud835\udc39\nChain rule Definition of\n(Product rule) conditional probability\n\ud835\udc43 \ud835\udc38|\ud835\udc39\nLaw of Total\nProbability\n\ud835\udc43 \ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nLaw of Total Probability\nThm Let \ud835\udc39 be an event where \ud835\udc43 \ud835\udc39 > 0. For any event \ud835\udc38,\n! !\n\ud835\udc43(\ud835\udc38) = \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39\nProof\n1. \ud835\udc39, \ud835\udc39(are disjoint such that \ud835\udc39 \u222a \ud835\udc39( = S Def. of complement\n(\n2. \ud835\udc38 = \ud835\udc38\ud835\udc39 \u222a (\ud835\udc38\ud835\udc39 ) (see diagram)\n3. \ud835\udc43(\ud835\udc38) = \ud835\udc43 \ud835\udc38\ud835\udc39 + \ud835\udc43(\ud835\udc38\ud835\udc39( ) Additivity axiom\n4. \ud835\udc43(\ud835\udc38) = \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38|\ud835\udc39( \ud835\udc43 \ud835\udc39( Chain rule (product rule)\nNote: disjoint sets are, by definition, mutually exclusive events\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nGeneral Law of Total Probability\nThm For mutually exclusive events \ud835\udc39 , \ud835\udc39 , \u2026, \ud835\udc39\n! \" )\nsuch that \ud835\udc39 \u222a \ud835\udc39 \u222a \u22ef \u222a \ud835\udc39 = \ud835\udc46,\n! \" )\n)\n\ud835\udc43(\ud835\udc38) = A \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39\n/ /\n/0!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nLaw of Total\nFinding \ud835\udc43 \ud835\udc38 from \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38|\ud835\udc39! \ud835\udc43 \ud835\udc39!\nProbability\n\u2022 Flip a fair coin.\n\u2022 If heads: roll a fair 6-sided die.\n\u2022 Else: roll a fair 3-sided die.\nYou win if you roll a 6. What is P(winning)?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nLaw of Total\nFinding \ud835\udc43 \ud835\udc38 from \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38|\ud835\udc39! \ud835\udc43 \ud835\udc39!\nProbability\n\u2022 Flip a fair coin.\n\u2022 If heads: roll a fair 6-sided die.\n\u2022 Else: roll a fair 3-sided die.\nYou win if you roll a 6. What is P(winning)?\n1. Define events 2. Identify known 3. Solve\n& state goal probabilities\nLet: \ud835\udc38: win, \ud835\udc39: flip heads \ud835\udc43 win|H = \ud835\udc43 \ud835\udc38|\ud835\udc39 = 1/6 \ud835\udc43 \ud835\udc38 = 1/6 1/2\nWant: \ud835\udc43 win \ud835\udc43 H = \ud835\udc43 \ud835\udc39 = 1/2\n+ 0 1/2\n= \ud835\udc43 \ud835\udc38 \ud835\udc43 win|T = \ud835\udc43 \ud835\udc38|\ud835\udc39( = 0\n1\n(\n\ud835\udc43 T = \ud835\udc43 \ud835\udc39 = 1 \u2212 1/2 = \u2248 0.083\n12\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nBayes\u2019 Theorem I\n20\nToday\u2019s tasks\n\ud835\udc43 \ud835\udc38\ud835\udc39\nChain rule Definition of\n(Product rule) conditional probability\n\ud835\udc43 \ud835\udc38|\ud835\udc39\nRev. Thomas Bayes (~1701-1761):\nBritish mathematician and Presbyterian minister\nLaw of Total Bayes\u2019\nProbability Theorem\n\ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nDetecting spam email\nBut what is the probability that a mystery\nWe can easily calculate how many\nemail containing \"Dear\" is spam?\nexisting spam emails contain \"Dear\":\nSpam Spam\n\ud835\udc43 \ud835\udc38 \ud835\udc39 = \ud835\udc43 \" D ear\" & \ud835\udc43 \ud835\udc39 \ud835\udc38 = \ud835\udc43 &\"D ear\"\nemail email\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nBayes\u2019 Theorem \ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39|\ud835\udc38\nThm For any events \ud835\udc38 and \ud835\udc39 where \ud835\udc43 \ud835\udc38 > 0 and \ud835\udc43 \ud835\udc39 > 0,\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38\nProof\n2 steps!\nExpanded form:\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!)\nProof\n1 more step!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nDetecting spam email\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 60% of all email in 2016 is spam.\n\u2022 20% of spam has the word \"Dear\"\n\u2022 1% of non-spam (aka ham) has the word \"Dear\"\nYou get an email with the word \"Dear\" in it.\nWhat is the probability that the email is spam?\n1. Define events 2. Identify known 3. Solve\n& state goal probabilities\nLet: \ud835\udc38: \"Dear\", \ud835\udc39: spam\nWant: \ud835\udc43 spam|\"Dear\"\n= \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nBayes\u2019 Theorem terminology\n\u2022 60% of all email in 2016 is spam. \ud835\udc43 \ud835\udc39\n\u2022 20% of spam has the word \"Dear\" \ud835\udc43 \ud835\udc38|\ud835\udc39\n\u2022 1% of non-spam (aka ham) has the word \"Dear\" \ud835\udc43 \ud835\udc38|\ud835\udc39(\nYou get an email with the word \"Dear\" in it.\nWhat is the probability that the email is spam? Want: \ud835\udc43 \ud835\udc39|\ud835\udc38\nlikelihood prior\nposterior \ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38\nnormalization constant\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nBayes\u2019 Theorem II\n26\nThis class going forward\nLast week Today and for most of this course\nEqually likely Events not always equally likely\nevents\n\ud835\udc43 \ud835\udc38 = Evidence | \ud835\udc39 = Fact\n(collected from data)\n\ud835\udc38 given some evidence\nBayes\u2019\n\ud835\udc43\nhas been observed\n\ud835\udc43 \ud835\udc39 = Fact | \ud835\udc38 = Evidence\n(categorize\n\ud835\udc43 \ud835\udc38 \u2229 \ud835\udc39 \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39\na new datapoint)\n(counting, combinatorics)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nBayes\u2019 Theorem Review\nposterior likelihood prior\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38\nMathematically:\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \u2192 \ud835\udc43 \ud835\udc39|\ud835\udc38\nReal-life application:\nGiven new evidence \ud835\udc38, update belief of fact \ud835\udc39\nPrior belief \u2192 Posterior belief\n\ud835\udc43 \ud835\udc39 \u2192 \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nZika, an autoimmune disease\nZiika Forest, Uganda Rhesus monkeys\nhttps://www.nytimes.com/2016/04/06/world/africa/ugand\na-zika-forest-mosquitoes.html\nIf a test returns positive,\nwhat is the likelihood\nyou have the disease?\nA disease spread through mosquito bites.\nGenerally, no symptoms, but can cause paralysis in very,\nvery rare cases. During pregnancy: may cause birth\ndefects. Very serious news story in 2015/2016.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nTaking tests: Confusion matrix\nTake\ntest\nFact, \ud835\udc39 Has disease Evidence, \ud835\udc38 Test positive\nor \ud835\udc39( No disease or \ud835\udc38( Test negative\nFact\n1\n\ud835\udc39, disease + \ud835\udc39 , disease \u2013\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\necnedivE\nIf a test returns positive,\nTrue positive False positive what is the likelihood\n\ud835\udc38, Test +\n1\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 you have the disease?\nFalse negative True negative\n\ud835\udc38!, Test \u2013\n1 1 1\n\ud835\udc43 \ud835\udc38 |\ud835\udc39 \ud835\udc43 \ud835\udc38 |\ud835\udc39\nTaking tests: Confusion matrix\nTake\ntest\nFact, \ud835\udc39 Has disease Evidence, \ud835\udc38 Test positive\nor \ud835\udc39( No disease or \ud835\udc38( Test negative\nFact\n1\n\ud835\udc39, disease + \ud835\udc39 , disease \u2013\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\necnedivE\nIf a test returns positive,\nTrue positive False positive what is the likelihood\n\ud835\udc38, Test +\n1\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 you have the disease?\nFalse negative True negative\n\ud835\udc38!, Test \u2013\n1 1 1\n\ud835\udc43 \ud835\udc38 |\ud835\udc39 \ud835\udc43 \ud835\udc38 |\ud835\udc39\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nZika Testing\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 A test is 98% effective at detecting Zika (\"true positive\").\n\u2022 However, the test has a \"false positive\" rate of 1%.\n\u2022 0.5% of the US population has Zika.\nWhat is the likelihood you have Zika if you test positive?\nWhy would you expect this number?\n1. Define events\n& state goal\nLet: \ud835\udc38 = you test positive\n\ud835\udc39 = you actually have\nthe disease\nWant:\nP(disease | test+)\n= \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nZika Testing\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 A test is 98% effective at detecting Zika (\"true positive\").\n\u2022 However, the test has a \"false positive\" rate of 1%.\n\u2022 0.5% of the US population has Zika.\nWhat is the likelihood you have Zika if you test positive?\nWhy would you expect this number?\n1. Define events 2. Identify known 3. Solve\n& state goal probabilities\nLet: \ud835\udc38 = you test positive\n\ud835\udc39 = you actually have\nthe disease\nWant:\nP(disease | test+)\n= \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nBayes\u2019 Theorem intuition\nAll People\nOriginal question:\nWhat is the likelihood\nyou have Zika if you\nPeople who test positive\ntest positive for the\ndisease?\nPeople with Zika\nThe space\nof facts\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nBayes\u2019 Theorem intuition\nAll People\nOriginal question:\nWhat is the likelihood\nyou have Zika if you\nPeople who test positive\ntest positive for the\ndisease?\nInterpret\nPeople with Zika\nInterpretation:\nOf the people who test\npositive, how many actually\nThe space\nhave Zika?\nof facts\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nBayes\u2019 Theorem intuition\nPeople who test positive\nOriginal question:\nWhat is the likelihood\ne\nv\nyou have Zika if you\ns\niti\no\np\ntest positive for the s t\ne a\ndisease? w h o\nt\ne Z i\nk\ne a\nv\np l h\ne\no\nn\n\u2019t\nP o\nd\nInterpret u t\nb\nInterpretation: People who test\nOf the people who test positive and have Zika\npositive, how many actually\nThe space of facts,\nhave Zika?\nconditioned on a positive test result\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nUpdate your beliefs with Bayes\u2019 Theorem\n\ud835\udc38 = you test positive for Zika\n\ud835\udc39 = you have the disease\nWith these test\nI have a 0.5%\nresults, I now have a\nTake test,\nchance of having\nresults positive 33% chance of having\nZika.\nZika!!!\n\u26a0\n\ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nWhy it\u2019s still good to get tested\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 A test is 98% effective at detecting Zika (\u201ctrue positive\u201d).\n\u2022 However, the test has a \u201cfalse positive\u201d rate of 1%.\n\u2022 0.5% of the US population has Zika.\nLet: \ud835\udc38 = you test positive\n\ud835\udc39, disease + \ud835\udc39(, disease \u2013\n\ud835\udc39 = you actually have\n\ud835\udc38, Test + True positive False positive\nthe disease\n(\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.98 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.01\n(\nLet: \ud835\udc38 = you test negative\nfor Zika with this test.\n1\nWhat is \ud835\udc43 \ud835\udc39|\ud835\udc38 ?\n(ruminating)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nWhy it\u2019s still good to get tested\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 A test is 98% effective at detecting Zika (\u201ctrue positive\u201d).\n\u2022 However, the test has a \u201cfalse positive\u201d rate of 1%.\n\u2022 0.5% of the US population has Zika.\nLet: \ud835\udc38 = you test positive\n\ud835\udc39, disease + \ud835\udc39(, disease \u2013\n\ud835\udc39 = you actually have\n\ud835\udc38, Test + True positive False positive\nthe disease\n(\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.98 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.01\n(\nLet: \ud835\udc38 = you test negative\nfor Zika with this test.\n1\nWhat is \ud835\udc43 \ud835\udc39|\ud835\udc38 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\n\ud835\udc43 \ud835\udc38 \ud835\udc39 \ud835\udc43 \ud835\udc39 Bayes\u2019\nWhy it\u2019s still good to get tested\n\ud835\udc43 \ud835\udc39 \ud835\udc38 =\n\ud835\udc43 \ud835\udc38|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38 \ud835\udc39! \ud835\udc43(\ud835\udc39!) Theorem\n\u2022 A test is 98% effective at detecting Zika (\"true positive\").\n\u2022 However, the test has a \"false positive\" rate of 1%.\n\u2022 0.5% of the US population has Zika.\nLet: \ud835\udc38 = you test positive\n\ud835\udc39, disease + \ud835\udc39(, disease \u2013\n\ud835\udc39 = you actually have\n\ud835\udc38, Test + True positive False positive\nthe disease\n(\n\ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.98 \ud835\udc43 \ud835\udc38|\ud835\udc39 = 0.01\n(\nLet: \ud835\udc38 = you test negative\nfor Zika with this test. \ud835\udc38(, Test \u2013 False negative True negative\n( ( (\n1 \ud835\udc43 \ud835\udc38 |\ud835\udc39 = 0.02 \ud835\udc43 \ud835\udc38 |\ud835\udc39 = 0.99\nWhat is \ud835\udc43 \ud835\udc39|\ud835\udc38 ?\n\ud835\udc43 \ud835\udc38! \ud835\udc39 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc38! =\n\ud835\udc43 \ud835\udc38!|\ud835\udc39 \ud835\udc43 \ud835\udc39 + \ud835\udc43 \ud835\udc38! \ud835\udc39! \ud835\udc43(\ud835\udc39!)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nWhy it\u2019s still good to get tested\n\ud835\udc38 = you test positive for Zika\nWith these test\n\ud835\udc39 = you actually have the disease\nresults, I now have a\n\ud835\udc38( = you test negative for Zika 33% chance of\ns\nt, having Zika!!!\ne e\nT a\nk\ne\nt\np o\nsitiv\n\u26a0\ns\nu\nlt\ne s \ud835\udc43 \ud835\udc39|\ud835\udc38\nr\nI have a 0.5%\nchance of having\nWith these test results,\nZika disease.\nTake\ntest,\nresults\nnegative\nI now have a 0.01%\nchance of having Zika\ndisease!!!\n\ud835\udc43 \ud835\udc39 \u2705\n1\n\ud835\udc43 \ud835\udc39|\ud835\udc38\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41 <END>"}
{"prompt": "Lecture notes from 10_normal_gaussian_annotated.txt\n\n###\n\n", "completion": "10: Normal Distributions\nJerry Cain\nApril 22nd, 2024\nLecture Discussion on Ed\n1\nNormal\nRandom\nVariables\n2\nNormal Random Variable\ndef A Normal random variable \ud835\udc4b is defined as follows:\n1\n! !\n! \"!# /%&\n\ud835\udc53 \ud835\udc65 = \ud835\udc52\nPDF\n!\n\ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e )\n\ud835\udf0e 2\ud835\udf0b\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udf07\nSupport: \u2212\u221e, \u221e\nVariance Var \ud835\udc4b = \ud835\udf0e%\nOther names: Gaussian random variable 0.5 !\n0.4\nmean\nvariance 0.3\n! 0.2\n\ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e )\n0.1\n0\n-3 -2 -1 0 1 2 3\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\n\ud835\udc65\n\ud835\udc53\nCarl Friedrich Gauss\nCarl Friedrich Gauss (1777-1855) was a remarkably influential\nGerman mathematician.\njust wow!\nDid not invent Normal distribution but rather popularized it.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nWhy the Normal?\n\u2022 Common for natural phenomena:\nheight, weight, etc.\n\u2022 Most noise in the world is Normal\n\u2022 Often results from the sum of many\nrandom variables\nThat\u2019s what they\n\u2022 Sample means are distributed normally want you to believe\u2026\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nWhy the Normal?\n\u2022 Common for natural phenomena:\nActually log-normal\nheight, weight, etc.\n\u2022 Most noise in the world is Normal Just an assumption\n\u2022 Often results from the sum of many\nOnly if equally weighted\nrandom variables\n(okay this one is true, we\u2019ll see\n\u2022 Sample means are distributed normally\nthis in 3 weeks)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nOkay, so why the Normal?\nPart of CS109 learning goals:\n\u2022 Translate a problem statement into a random variable\nIn other words: model real life situations with probability distributions\nHow do you model student heights?\n\u2022 Suppose you have data from one classroom.\n0.25\nFits perfectly!\n0.2\nBut what about in\n0.15\n0.1 another classroom?\n0.05\n0\n00 \u2026\u2026 4444 4488 5522 5566 6600 6644 \u2026\u2026 9900\nvalue\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nOkay, so why the Normal?\nPart of CS109 learning goals:\n\u2022 Translate a problem statement into a random variable\nIn other words: model real life situations with probability distributions\nHow do you model student heights?\n\u2022 Suppose you have data from one classroom.\n0.25\n\u2022 Same mean/var\n0.2\n\u2022 Generalizes well\n0.15\n0.1\n0.05\n0\nA Gaussian maximizes entropy for a\n00 \u2026\u2026 4444 4488 5522 5566 6600 6644 \u2026\u2026 9900\nvalue given mean and variance.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nWhy the Normal?\n\u2022 Common for natural phenomena:\nActually log-normal d\no\nheight, weight, etc. o\nt\ns\nr\ne\nd\nn\nu\n\u2022 Most noise in the world is Normal Just an assumption\nl\nl\ne\nw\ns\n\u2019\nt\ni\n\u2022 Often results from the su m of many\ne\ns Only if equally weighted\nu\nrandom variables\na\nc\ne\nb\n(okay this one is true, we\u2019ll see\n\u2022 Sample means are distributed normally\nthis in 3 weeks)\nStay critical of how to model real-\nworld phenomena.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nAnatomy of a beautiful equation\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e .\nThe PDF of \ud835\udc4b is defined as:\nsymmetric\n!\n1 $ \" %\naround \ud835\udf07\n\"\n\ud835\udc53 \ud835\udc65 = \ud835\udc52 !&!\n\ud835\udf0e 2\ud835\udf0b variance \ud835\udf0e#\nmanages spread\nexponential\nnormalizing constant tail\n0.5 !\n0.4\n0.3\n0.2\n0.1\n0\n-3 -2 -1 0 1 2 3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 \ud835\udc65 10\n\ud835\udc65\n\ud835\udc53\nNormal Random Variable\nmean variance\n!\n\ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e )\nMatch PDF to distribution:\n1\n1. \ud835\udca9 0, 1 0.9 !A.( 0,1)\n0.8 !B.(0,0.2)\n0.7\n!C.(0,5)\n2. \ud835\udca9(\u22122, 0.5)\n0.6\n!D.(-2,0.5)\n0.5\n0.4\n3. \ud835\udca9 0, 5\n0.3\n0.2\n4. \ud835\udca9(0, 0.2) 0.1\n0\n-5 -4 -3 -2 -1 0 1 2 3 4 5\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n\ud835\udc65\n\ud835\udc53\nGetting to class\nYou spend some minutes, \ud835\udc4b, traveling\nbetween classes.\n\u2022 Average time spent: \ud835\udf07 = 4 minutes\n\u2022 Variance of time spent: \ud835\udf0e% = 2 minutes2\nSuppose \ud835\udc4b is normally distributed. What is the\nprobability you spend \u2265 6 minutes traveling?\n%\n\ud835\udc4b~\ud835\udca9(\ud835\udf07 = 4, \ud835\udf0e = 2)\n( ( 1 \" !* !\n!\n\ud835\udc43 \ud835\udc4b \u2265 6 = 9 \ud835\udc53(\ud835\udc65)\ud835\udc51\ud835\udc65 = 9 \ud835\udc52 * \ud835\udc51\ud835\udc65\n2 \ud835\udf0b\n\u2019 \u2019\nLove and Anger in the\n(tell Jerry if you solve this analytically and we\u2019ll be famous together) Same Formula\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nComputing probabilities with Normal RVs\n%\nFor a Normal RV \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e , its CDF has no closed form.\nCannot be\n\u26a0\n( +\n1 * & +\n& solved\n\ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 = - \ud835\udc52 ,-+ \ud835\udc51\ud835\udc66\nanalytically\n\ud835\udf0e 2\ud835\udf0b\n&\u2019\nHowever, we can solve for probabilities numerically using a function \u03a6:\n\ud835\udc65 \u2212 \ud835\udf07 To get here, we\u2019ll first\n\ud835\udc39 \ud835\udc65 = \u03a6\nneed to know some\n\ud835\udf0e\nproperties of Normal RVs.\nCDF of A function that has been\n\ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# solved numerically\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nNormal RV:\nProperties\n14\nProperties of Normal RVs\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e with CDF \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 .\n1. Linear transformations of Normal RVs are also Normal RVs.\n\" \"\nIf \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, then \ud835\udc4c~\ud835\udca9(\ud835\udc4e\ud835\udf07 + \ud835\udc4f, \ud835\udc4e \ud835\udf0e ).\n2. The PDF of a Normal RV is symmetric about the mean \ud835\udf07.\n\ud835\udc39 \ud835\udf07 \u2212 \ud835\udc65 = 1 \u2212 \ud835\udc39 \ud835\udf07 + \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n1. Linear transformations of Normal RVs\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e with CDF \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 .\nLinear transformations of X are also Normal.\n\" \"\nIf \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, then \ud835\udc4c~\ud835\udca9 \ud835\udc4e\ud835\udf07 + \ud835\udc4f, \ud835\udc4e \ud835\udf0e\nProof:\n\u2022 \ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f = \ud835\udc4e\ud835\udf07 + \ud835\udc4f Linearity of Expectation\n\u2022 Var \ud835\udc4c = Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e% Var \ud835\udc4b = \ud835\udc4e% \ud835\udf0e% Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e#Var \ud835\udc4b\nProof in Ross,\n\u2022 \ud835\udc4c is also Normal\n10th ed (Section 5.4)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n2. Symmetry of Normal RVs\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e with CDF \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 .\nThe PDF of a Normal RV is symmetric about the mean \ud835\udf07.\n\ud835\udc39 \ud835\udf07 \u2212 \ud835\udc65 = 1 \u2212 \ud835\udc39 \ud835\udf07 + \ud835\udc65\n! \u2212 # ! + #\n-3 -2 -1 0 1 2 3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\n)\ud835\udc65(\ud835\udc53\n\ud835\udf07 \ud835\udc65\nUsing symmetry of the Normal RV\n\u2212\" +\"\n-3 -2 -1 0 1 2 \ud835\udc673\nA. \ud835\udc39 \ud835\udc67\n1. \ud835\udc43 \ud835\udc4d \u2264 \ud835\udc67 = \ud835\udc39 \ud835\udc67\nB. 1 \u2212 \ud835\udc39(\ud835\udc67)\n2. \ud835\udc43 \ud835\udc4d < \ud835\udc67\n3. \ud835\udc43 \ud835\udc4d \u2265 \ud835\udc67 C. \ud835\udc39 \ud835\udc67 \u2212 \ud835\udc39(\ud835\udc66)\n4. \ud835\udc43 \ud835\udc4d \u2264 \u2212\ud835\udc67\n5. \ud835\udc43 \ud835\udc4d \u2265 \u2212\ud835\udc67\n6. \ud835\udc43(\ud835\udc66 < \ud835\udc4d < \ud835\udc67)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n)\ud835\udc67(\ud835\udc53\n\ud835\udc39 \ud835\udf07 \u2212 \ud835\udc65 = 1 \u2212 \ud835\udc39 \ud835\udf07 + \ud835\udc65\nLet \ud835\udc4d~\ud835\udca9 0,1 with CDF \ud835\udc43 \ud835\udc4d \u2264 \ud835\udc67 = \ud835\udc39 \ud835\udc67 .\nSuppose we only knew numeric values\nfor \ud835\udc39 \ud835\udc67 and \ud835\udc39 \ud835\udc66 , for some \ud835\udc66, \ud835\udc67 \u2265 0.\n\ud835\udf07 = 0\nHow do we compute the following probabilities?\nUsing symmetry of the Normal RV\n\u2212\" +\"\n-3 -2 -1 0 1 2 \ud835\udc673\nA. \ud835\udc39 \ud835\udc67\n1. \ud835\udc43 \ud835\udc4d \u2264 \ud835\udc67 = \ud835\udc39 \ud835\udc67\nB. 1 \u2212 \ud835\udc39(\ud835\udc67)\n2. \ud835\udc43 \ud835\udc4d < \ud835\udc67 = \ud835\udc39 \ud835\udc67\n3. \ud835\udc43 \ud835\udc4d \u2265 \ud835\udc67 = 1 \u2212 \ud835\udc39(\ud835\udc67) C. \ud835\udc39 \ud835\udc67 \u2212 \ud835\udc39(\ud835\udc66)\n4. \ud835\udc43 \ud835\udc4d \u2264 \u2212\ud835\udc67 = 1 \u2212 \ud835\udc39(\ud835\udc67)\nSymmetry is particularly useful when\n5. \ud835\udc43 \ud835\udc4d \u2265 \u2212\ud835\udc67 = \ud835\udc39 \ud835\udc67\ncomputing probabilities of zero-mean\n6. \ud835\udc43(\ud835\udc66 < \ud835\udc4d < \ud835\udc67) = \ud835\udc39 \ud835\udc67 \u2212 \ud835\udc39(\ud835\udc66) Normal RVs.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\n)\ud835\udc67(\ud835\udc53\n\ud835\udc39 \ud835\udf07 \u2212 \ud835\udc65 = 1 \u2212 \ud835\udc39 \ud835\udf07 + \ud835\udc65\nLet \ud835\udc4d~\ud835\udca9 0,1 with CDF \ud835\udc43 \ud835\udc4d \u2264 \ud835\udc67 = \ud835\udc39 \ud835\udc67 .\nSuppose we only knew numeric values\nfor \ud835\udc39 \ud835\udc67 and \ud835\udc39 \ud835\udc66 , for some \ud835\udc66, \ud835\udc67 \u2265 0.\n\ud835\udf07 = 0\nHow do we compute the following probabilities?\nNormal RV:\nComputing\nprobability\n20\nComputing probabilities with Normal RVs\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e .\nTo compute the CDF, \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 :\n\u2022 We cannot analytically solve the integral, as it has no closed form.\n\u2022 \u2026 but we can solve numerically using a function \u03a6:\n\ud835\udc65 \u2212 \ud835\udf07\n\ud835\udc39 \ud835\udc65 = \u03a6\n\ud835\udf0e\nCDF of the\nStandard Normal, \ud835\udc4d\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nStandard Normal RV, \ud835\udc4d\nThe Standard Normal random variable \ud835\udc4d is defined as follows:\nExpectation \ud835\udc38 \ud835\udc4d = \ud835\udf07 = 0\n\ud835\udc4d~\ud835\udca9(0, 1)\nVariance %\nVar \ud835\udc4d = \ud835\udf0e = 1\nNote: not a new distribution; just\na special case of the Normal\nOther names: Unit Normal\n\ud835\udc43 \ud835\udc4d \u2264 \ud835\udc67 = \u03a6(\ud835\udc67)\nCDF of \ud835\udc4d defined as:\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n\u03a6 has been numerically computed\nStandardNormalTable \ud835\udc43 \ud835\udc4d \u2264 1.31 = \u03a6(1.31)\nAnentryinthetableistheareaunderthecurvetotheleftof z, P Z z = \u03a6 z .\n( \u2264 ) ( )\n0.5\n! = 1.31\n0.4\nZ 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09\n0.3\n0.0 0.5000 0.5040 0.5080 0.5120 0.5160 0.5199 0.5239 0.5279 0.5319 0.5359\n0.1 0.5398 0.5438 0.5478 0.5517 0.5557 0.5596 0.5636 0.5675 0.5714 0.5753\n0.2\n0.2 0.5793 0.5832 0.5871 0.5910 0.5948 0.5987 0.6026 0.6064 0.6103 0.6141\n0.3 0.6179 0.6217 0.6255 0.6293 0.6331 0.6368 0.6406 0.6443 00.6.1480 0.6517\n0.4 0.6554 0.6591 0.6628 0.6664 0.6700 0.6736 0.6772 0.6808 0.6844 0.6879\n0.5 0.6915 0.6950 0.6985 0.7019 0.7054 0.7088 0.7123 0.7157 0.70190 0.7224\n0.6 0.7257 0.7291 0.7324 0.7357 0.7389 0.7422 0.7454 0.7486 0.7517-30.7549 -2 -1 0 1 2 3\n0.7 0.7580 0.7611 0.7642 0.7673 0.7703 0.7734 0.7764 0.7793 0.7823 0.7852\n0.8 0.7881 0.7910 0.7939 0.7967 0.7995 0.8023 0.8051 0.8078 0.8106 0.8133\n0.9 0.8159 0.8186 0.8212 0.8238 0.8264 0.8289 0.8315 0.8340 0.8365 0.8389\n1.0 0.8413 0.8438 0.8461 0.8485 0.8508 0.8531 0.8554 0.8577 0.8599 0.8621\n1.1 0.8643 0.8665 0.8686 0.8708 0.8729 0.8749 0.8770 0.8790 0.8810 0.8830\n1.2 0.8849 0.8869 0.8888 0.8906 0.8925 0.8943 0.8962 0.8980 0.8997 0.9015\n1.3 0.9032 0.9049 0.9066 0.9082 0.9099 0.9115 0.9131 0.9147 0.9162 0.9177\n1.4 0.9192 0.9207 0.9222 0.9236 0.9251 0.9265 0.9279 0.9292 0.9306 0.9319\n1.5 0.9332 0.9345 0.9357 0.9370 0.9382 0.9394 0.9406 0.9418 0.9429 0.9441\n1.6 0.9452 0.9463 0.9474 0.9484 0.9495Lisa 0Y.a9n5, C0h5ris P0ie.9ch5, 1M5ehra0n. 9Sa5h2a5mi, a0n.d9 5Je3rr5y Cai0n.,9 C5S41509, Spring 2024 23\n1.7 0.9554 0.9564 0.9573 0.9582 0.9591 0.9599 0.9608 0.9616 0.9625 0.9633\n1.8 0.9641 0.9649 0.9656 0.9664 0.9671 0.9678 0.9686 0.9693 0.9699 0.9706\n1.9 0.9713 0.9719 0.9726 0.9732 0.9738 0.9744 0.9750 0.9756 0.9761 0.9767\n2.0 0.9772 0.9778 0.9783 0.9788 0.9793 0.9798 0.9803 0.9808 0.9812 0.9817\n2.1 0.9821 0.9826 0.9830 0.9834 0.9838 0.9842 0.9846 0.9850 0.9854 0.9857\n2.2 0.9861 0.9864 0.9868 0.9871 0.9875 0.9878 0.9881 0.9884 0.9887 0.9890\n2.3 0.9893 0.9896 0.9898 0.9901 0.9904 0.9906 0.9909 0.9911 0.9913 0.9916\n2.4 0.9918 0.9920 0.9922 0.9925 0.9927 0.9929 0.9931 0.9932 0.9934 0.9936\n2.5 0.9938 0.9940 0.9941 0.9943 0.9945 0.9946 0.9948 0.9949 0.9951 0.9952\n2.6 0.9953 0.9955 0.9956 0.9957 0.9959 0.9960 0.9961 0.9962 0.9963 0.9964\n2.7 0.9965 0.9966 0.9967 0.9968 0.9969 0.9970 0.9971 0.9972 0.9973 0.9974\n2.8 0.9974 0.9975 0.9976 0.9977 0.9977 0.9978 0.9979 0.9979 0.9980 0.9981\n2.9 0.9981 0.9982 0.9982 0.9983 0.9984 0.9984 0.9985 0.9985 0.9986 0.9986\n3.0 0.9987 0.9987 0.9987 0.9988 0.9988 0.9989 0.9989 0.9989 0.9990 0.9990\n3.1 0.9990 0.9991 0.9991 0.9991 0.9992 0.9992 0.9992 0.9992 0.9993 0.9993\n3.2 0.9993 0.9993 0.9994 0.9994 0.9994 0.9994 0.9994 0.9995 0.9995 0.9995\n3.3 0.9995 0.9995 0.9995 0.9996 0.9996 0.9996 0.9996 0.9996 0.9996 0.9997\n3.4 0.9997 0.9997 0.9997 0.9997 0.9997 0.9997 0.9997 0.9997 0.9997 0.9998\n3.5 0.9998 0.9998 0.9998 0.9998 0.9998 0.9998 0.9998 0.9998 0.9998 0.9998\n\ud835\udc67\n\ud835\udc53 \u03a6(\ud835\udc67)\n\ud835\udc67\nStandard Normal Table only has\nprobabilities \u03a6(\ud835\udc67) for \ud835\udc67 \u2265 0.\nHistory fact: Standard Normal Table\nThe first Standard Normal Table was\ncomputed by Christian Kramp, French\nastronomer (1760\u20131826), in Analyse\ndes R\u00e9fractions Astronomiques et\nTerrestres, 1799\nUsed a Taylor series expansion to the\nthird power\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nProbabilities for a general Normal RV\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e . To compute the CDF \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 ,\nwe use \u03a6, the CDF for the Standard Normal \ud835\udc4d~\ud835\udca9(0, 1):\n\ud835\udc65 \u2212 \ud835\udf07\n\ud835\udc39 \ud835\udc65 = \u03a6\n\ud835\udf0e\nProof:\n\ud835\udc39 \ud835\udc65 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 Definition of CDF\n\ud835\udc4b \u2212 \ud835\udf07 \ud835\udc65 \u2212 \ud835\udf07\n= \ud835\udc43 \ud835\udc4b \u2212 \ud835\udf07 \u2264 \ud835\udc65 \u2212 \ud835\udf07 = \ud835\udc43 \u2264 Algebra + \ud835\udf0e > 0\n\ud835\udf0e \ud835\udf0e\n\ud835\udc65 \u2212 \ud835\udf07 $%& ( &\n\u2022 = \ud835\udc4b \u2212 is a linear transform of \ud835\udc4b.\n= \ud835\udc43 \ud835\udc4d \u2264 \u2019 \u2019 \u2019\n\ud835\udf0e ( & (\n\u2022 This is distributed as \ud835\udca9 \ud835\udf07 \u2212 , \ud835\udf0e# =\ud835\udca9 0,1\n\u2019 \u2019 \u2019!\n\ud835\udc65 \u2212 \ud835\udf07\n$%&\n= \u03a6 \u2022 In other words, = \ud835\udc4d~\ud835\udca9 0,1 with CDF \u03a6.\n\u2019\n\ud835\udf0e\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nProbabilities for a general Normal RV\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e . To compute the CDF \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 ,\nwe use \u03a6, the CDF for the Standard Normal \ud835\udc4d~\ud835\udca9(0, 1):\n\ud835\udc65 \u2212 \ud835\udf07\n\ud835\udc39 \ud835\udc65 = \u03a6\n\ud835\udf0e\nProof:\n\ud835\udc39 \ud835\udc65 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 Definition of CDF\n\ud835\udc4b \u2212 \ud835\udf07 \ud835\udc65 \u2212 \ud835\udf07\n= \ud835\udc43 \ud835\udc4b \u2212 \ud835\udf07 \u2264 \ud835\udc65 \u2212 \ud835\udf07 = \ud835\udc43 \u2264 Algebra + \ud835\udf0e > 0\n\ud835\udf0e \ud835\udf0e\n\ud835\udc65 \u2212 \ud835\udf07 $%& ( &\n\u2022 = \ud835\udc4b \u2212 is a linear transform of \ud835\udc4b.\n= \ud835\udc43 \ud835\udc4d \u2264 \u2019 \u2019 \u2019\n\ud835\udf0e ( & (\n\u2022 This is distributed as \ud835\udca9 \ud835\udf07 \u2212 , \ud835\udf0e# =\ud835\udca9 0,1\n1. Compute \ud835\udc67 = \ud835\udc65 \u2212 \ud835\udf07 /\u2019\ud835\udf0e. \u2019 \u2019!\n\ud835\udc65 \u2212 \ud835\udf07\n$%&\n= \u03a6 \u2022 I2n. oLtohoekr uwpo r\u03a6ds,\ud835\udc67 in S=ta\ud835\udc4dn~da\ud835\udca9rd 0N,1ormwiathl tCaDblFe .\u03a6.\n\u2019\n\ud835\udf0e\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nCampus bikes\nYou spend some minutes, \ud835\udc4b, traveling between classes.\n\u2022 Average time spent: \ud835\udf07 = 4 minutes\n\u2022 Variance of time spent: \ud835\udf0e# = 2 minutes2\nSuppose \ud835\udc4b is normally distributed. What is the probability\nyou spend \u2265 6 minutes traveling?\n(\n\u00d7\n\ud835\udc4b~\ud835\udca9(\ud835\udf07 = 4, \ud835\udf0e% = 2) \ud835\udc43 \ud835\udc4b \u2265 6 = 9 \ud835\udc53(\ud835\udc65)\ud835\udc51\ud835\udc65 (no analytic solution)\n\u2019\n\"!#\n1. Compute \ud835\udc67 = 2. Look up \u03a6(\ud835\udc67) in table\n&\n\ud835\udc43 \ud835\udc4b \u2265 6 = 1 \u2212 \ud835\udc39 (6)\n\" 1 \u2212 \u03a6 1.41\n6 \u2212 4\n\u2248 1 \u2212 0.9207\n= 1 \u2212 \u03a6\n2 = 0.0793\n\u2248 1 \u2212 \u03a6 1.41\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nIs there an easier way? (yes)\n%\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e . What is \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 = \ud835\udc39 \ud835\udc65 ?\n\u2022 Use Python\nfrom scipy import stats SciPy reference:\nX = stats.norm(mu, std) https://docs.scipy.org/doc/scipy/refere\nnce/generated/scipy.stats.norm.html\nX.cdf(x)\nI'm not sure why Python decided to parameterize around the\nstats.norm\nstandard deviation instead of the variance, but it did. J\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nExercises\n29\nGet your Gaussian On\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07 = 3, \ud835\udf0e% = 16 . Std deviation \ud835\udf0e = 4. \u2022 If \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# , then\n)%&\n1. \ud835\udc43 \ud835\udc4b > 0 \ud835\udc39 \ud835\udc65 = \u03a6\n\u2019\n\u2022 Symmetry of the PDF of\nNormal RV implies\n\u03a6 \u2212\ud835\udc67 = 1 \u2212 \u03a6 \ud835\udc67\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nGet your Gaussian On\n,\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07 = 3, \ud835\udf0e = 16 . \u2022 If \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# , then\n)%&\nNote standard deviation \ud835\udf0e = 4. \ud835\udc39 \ud835\udc65 = \u03a6\n\u2019\n\u2022 Symmetry of the PDF of\nHow would you write each of the below\nNormal RV implies\nprobabilities as a function of the\n\u03a6 \u2212\ud835\udc67 = 1 \u2212 \u03a6 \ud835\udc67\nstandard normal CDF, \u03a6?\n1. \ud835\udc43 \ud835\udc4b > 0\n2. \ud835\udc43 2 < \ud835\udc4b < 5\n3. \ud835\udc43 \ud835\udc4b \u2212 3 > 6\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nGet your Gaussian On\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07 = 3, \ud835\udf0e% = 16 . Std deviation \ud835\udf0e = 4. \u2022 If \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# , then\n)%&\n1. \ud835\udc43 \ud835\udc4b > 0 \ud835\udc39 \ud835\udc65 = \u03a6\n\u2019\n\u2022 Symmetry of the PDF of\n2. \ud835\udc43 2 < \ud835\udc4b < 5\nNormal RV implies\n\u03a6 \u2212\ud835\udc67 = 1 \u2212 \u03a6 \ud835\udc67\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nGet your Gaussian On\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07 = 3, \ud835\udf0e% = 16 . Std deviation \ud835\udf0e = 4. \u2022 If \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# , then\n)%&\n1. \ud835\udc43 \ud835\udc4b > 0 \ud835\udc39 \ud835\udc65 = \u03a6\n\u2019\n\u2022 Symmetry of the PDF of\n2. \ud835\udc43 2 < \ud835\udc4b < 5\nNormal RV implies\n3. \ud835\udc43 \ud835\udc4b \u2212 3 > 6\n\u03a6 \u2212\ud835\udc65 = 1 \u2212 \u03a6 \ud835\udc65\n\"!# Look up \u03a6(z) in table\nCompute \ud835\udc67 =\n&\n\ud835\udc43 \ud835\udc4b < \u22123 + \ud835\udc43 \ud835\udc4b > 9\n= \ud835\udc39 \u22123 + 1 \u2212 \ud835\udc39 9\n\u22123 \u2212 3 9 \u2212 3\n= \u03a6 + 1 \u2212 \u03a6\n4 4\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nGet your Gaussian On\nLet \ud835\udc4b~\ud835\udca9 \ud835\udf07 = 3, \ud835\udf0e% = 16 . Std deviation \ud835\udf0e = 4. \u2022 If \ud835\udc4b~\ud835\udca9 \ud835\udf07, \ud835\udf0e# , then\n)%&\n1. \ud835\udc43 \ud835\udc4b > 0 \ud835\udc39 \ud835\udc65 = \u03a6\n\u2019\n\u2022 Symmetry of the PDF of\n2. \ud835\udc43 2 < \ud835\udc4b < 5\nNormal RV implies\n3. \ud835\udc43 \ud835\udc4b \u2212 3 > 6\n\u03a6 \u2212\ud835\udc65 = 1 \u2212 \u03a6 \ud835\udc65\n\"!# Look up \u03a6(z) in table\nCompute z =\n&\n3 3\n\ud835\udc43 \ud835\udc4b < \u22123 + \ud835\udc43 \ud835\udc4b > 9\n= \u03a6 \u2212 + 1 \u2212 \u03a6\n2 2\n= \ud835\udc39 \u22123 + 1 \u2212 \ud835\udc39 9\n3\n= 2 1 \u2212 \u03a6\n\u22123 \u2212 3 9 \u2212 3 2\n= \u03a6 + 1 \u2212 \u03a6\n4 4\n\u2248 0.1337\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nNoisy Wires\nSend a voltage of 2 V or \u22122 V on 0.5\n! = 0.5\nwire (to denote 1 and 0, respectively). 0.4\n0.3\n\u2022 \ud835\udc4b = voltage sent (2 or \u22122)\n0.2 Send 0 Send 1\n\u2022 \ud835\udc4c = noise, \ud835\udc4c~\ud835\udca9 0, 1\n& = \u22122 & = 2\n0.1\n\u2022 \ud835\udc45 = \ud835\udc4b + \ud835\udc4c voltage received.\n0\nDecode: 1 if \ud835\udc45 \u2265 0.5 -5 -4 -3 -2 -1 0 1 2 3 4 5\n0 otherwise.\n1. What is P(decoding error | original bit is 1)?\ni.e., we sent 1, but we decoded as 0?\n2. What is P(decoding error | original bit is 0)?\nThese probabilities are unequal. Why might this be useful?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\n)\ud835\udc5f(\n\ud835\udc39\n*\n\ud835\udc45 = \ud835\udc5f\nNoisy Wires\nSend a voltage of 2 V or \u22122 V on 0.5\n! = 0.5\nwire (to denote 1 and 0, respectively). 0.4\n0.3\n\u2022 \ud835\udc4b = voltage sent (2 or \u22122)\n0.2 Send 0 Send 1\n\u2022 \ud835\udc4c = noise, \ud835\udc4c~\ud835\udca9 0, 1\n& = \u22122 & = 2\n0.1\n\u2022 \ud835\udc45 = \ud835\udc4b + \ud835\udc4c voltage received.\n0\nDecode: 1 if \ud835\udc45 \u2265 0.5 -5 -4 -3 -2 -1 0 1 2 3 4 5\n0 otherwise.\n1. What is P(decoding error | original bit is 1)?\ni.e., we sent 1, but we decoded as 0?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\n)\ud835\udc5f(\n\ud835\udc39\n*\n\ud835\udc45 = \ud835\udc5f\n\ud835\udc43 \ud835\udc45 < 0.5| \ud835\udc4b = 2 = \ud835\udc43 2 + \ud835\udc4c < 0.5 = \ud835\udc43 \ud835\udc4c < \u22121.5 Y is Standard Normal\n= \u03a6 \u22121.5 = 1 \u2212 \u03a6 1.5 \u2248 0.0668\nNoisy Wires\nSend a voltage of 2 V or \u22122 V on 0.5\n! = 0.5\nwire (to denote 1 and 0, respectively). 0.4\n0.3\n\u2022 \ud835\udc4b = voltage sent (2 or \u22122)\n0.2 Send 0 Send 1\n\u2022 \ud835\udc4c = noise, \ud835\udc4c~\ud835\udca9 0, 1\n& = \u22122 & = 2\n0.1\n\u2022 \ud835\udc45 = \ud835\udc4b + \ud835\udc4c voltage received.\n0\nDecode: 1 if \ud835\udc45 \u2265 0.5 -5 -4 -3 -2 -1 0 1 2 3 4 5\n0 otherwise.\n1. What is P(decoding error | original bit is 1)?\ni.e., we sent 1, but we decoded as 0?\n2. What is P(decoding error | original bit is 0)?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\n)\ud835\udc5f(\n\ud835\udc39\n*\n\ud835\udc45 = \ud835\udc5f\n0.0668\n\ud835\udc43 \ud835\udc45 \u2265 0.5| \ud835\udc4b = \u22122 = \ud835\udc43 \u22122 + \ud835\udc4c \u2265 0.5 = \ud835\udc43 \ud835\udc4c \u2265 2.5 \u2248 0.0062\nAsymmetric decoding probability: We would like to avoid\nmistaking a 0 for 1. Errors the other way are tolerable.\nSampling with\nthe Normal RV\n38\nELO ratings\nWhat is the probability that the Warriors win?\nMore generally: How can you model zero-sum\ngames?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nELO ratings\nWarriors \ud835\udc34 ~\ud835\udca9 \ud835\udc46 = 1657, 200#\nEach team has an ELO score \ud835\udc46, +\n0.0025\ncalculated based on its \ud835\udf07=1657\n0.002\npast performance.\n0.0015\n\u2022 Each game, a team has\nArpad Elo\n0.001\n%\nability \ud835\udc34~\ud835\udca9 \ud835\udc46, 200 .\n0.0005\n\u2022 The team with the higher 0\n1000 1500 2000 2500\nsampled ability wins.\nOpponents \ud835\udc34 ~\ud835\udca9 \ud835\udc46 = 1470, 200#\n,\nWhat is the probability\n0.0025\nthat Warriors win \ud835\udf07=1470\n0.002\nthis game?\n0.0015\n0.001\nWant: \ud835\udc43 Warriors win = \ud835\udc43 \ud835\udc34 > \ud835\udc34\n7 8 0.0005\n0\n1000 1500 2000 2500\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nELO ratings\n\"\nWarriors ! ~# $ = 1657, 200\nWant: \ud835\udc43 Warriors win = \ud835\udc43 \ud835\udc34 > \ud835\udc34 !\n7 8\n0.0025\n!=1657\nfrom scipy import stats 0.002\nWARRIORS_ELO = 1657\n0.0015\nOPPONENT_ELO = 1470\n0.001\nSTDEV = 200\n0.0005\nNTRIALS = 10000\n0\n1000 1500 2000 2500\nnSuccess = 0\nfor i in range(NTRIALS): Opponents ! ~# $ = 1470, 200\"\n#\nw = stats.norm.rvs(WARRIORS_ELO, STDEV)\n0.0025\no = stats.norm.rvs(OPPONENT_ELO, STDEV) !=1470\n0.002\nif w > o: nSuccess += 1\n0.0015\n0.001\nprint(\"Warriors sampled win fraction\",\nfloat(nSuccess) / NTRIALS) 0.0005\n0\n\u2248 0.7488, calculated by sampling\n1000 1500 2000 2500\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nIs there a better way?\n\ud835\udc43 \ud835\udc34 > \ud835\udc34\n! \"\n\u2022 This is a probability of an event involving\nactual depiction of someone understanding\ntwo continuous random variables!\njoint continuous random variables\n\u2022 We\u2019ll solve this problem analytically in less than two weeks\u2019 time.\nBig goal for next lecture: Events involving two discrete random variables.\nStay tuned!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42 <END>"}
{"prompt": "Lecture notes from heart-readme.txt\n\n###\n\n", "completion": "Task:\nYour task is to assist a doctor in predicting whether or not a patient has heart disease (specifically myocardial perfusion diagnosis). Your prediction will be based on partial diagnosis made on images of different parts of the heart.\n\nValues:\nA heart is scanned and pictures of 2D images are generated for five different parts of the heart:\nArea A: Near the heart's apex (4 ROIs)\nArea B: In middle of the \"LV\" (5 ROIs)\nArea C: Near the heart base (5 ROIs)\nArea D: In the center of the LV cavity for horizontal long axis view (4 ROIs)\nArea E: In the center of the LV cavity for vertical long axis view (4 ROIs)\nThere are 4 or 5 regions of interest (ROIs) in each image. \n\nA cardiologist makes a partial diagnoses for each of the 22 Regions of Interest (ROIs). These partial diagnosis were mechanical to generate and could be performed by a trained nurse. 0 is a negative diagnosis (healthy), 1 is a positive diagnosis (unhealthy).  \n\nColumn meaning:\nEach column represents a partial diagnosis by a cardiologist for a particular ROI:\nColumn index, Area.ROI \n1, A.1\n2, A.2\n3, A.3\n4, A.4\n5, B.1\n6, B.2\n7, B.3\n8, B.4\n9, B.5\n10, C.1\n11, C.2\n12, C.3\n13, C.4\n14, C.5\n15, D.1\n16, D.2\n17, D.3\n18, D.4\n19, E.1\n20, E.2\n21, E.3\n22, E.4\nSee figure 3 in the paper \"Knowledge discovery approach to automated cardiac SPECT diagnosis\" by Kurgan et Al for a visual.\n\nPrediction:\nThe variable you are predicting is the overall diagnosis of heart disease. The labels were generated by a team of cardiologists based on detailed analysis of each case.\n\nCredit:\nThis dataset was collected by Kurgan et al and is hosted by the UCI Machine Learning Repository:\nhttp://archive.ics.uci.edu/ml/datasets/SPECT+Heart\n\n <END>"}
{"prompt": "Lecture notes from 07_bernoulli_binomial_annotated.txt\n\n###\n\n", "completion": "07: Variance,\nBernoulli, Binomial\nJerry Cain\nApril 15th, 2024\nLecture Discussion on Ed\n1\nVariance\n2\nAverage temperatures\nStanford, CA Washington, DC\n\ud835\udc38 high = 68\u00b0F \ud835\udc38 high = 67\u00b0F\n\ud835\udc38 low = 52\u00b0F \ud835\udc38 low = 51\u00b0F\nIs \ud835\udc38 \ud835\udc4b enough? Does is capture everything?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nAverage temperatures\nStanford, CA Washington, DC\n\ud835\udc38 high = 68\u00b0F \ud835\udc38 high = 67\u00b0F\n\ud835\udc38 low = 52\u00b0F \ud835\udc38 low = 51\u00b0F\n0.4 0.4\n0.3 0.3\n0.2 0.2\n0.1 0.1\n0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\nStanford high temps Washington high temps\n68\u00b0F 67\u00b0F\n35 50 65 80 90 35 50 65 80 90\nNormalized histograms are approximations of probability mass functions, i.e., PMFs.\nVariance = measure of \"spread\"\nConsider the following three distributions (PMFs):\n\u2022 Expectation: \ud835\udc38 \ud835\udc4b = 3 for all distributions\n\u2022 But the shape and spread across distributions are very different!\n\u2022 Variance, Var \ud835\udc4b : a formal quantification of spread\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nVariance\nThe variance of a random variable \ud835\udc4b with mean \ud835\udc38 \ud835\udc4b = \ud835\udf07 is\n(\nVar \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07\n!\n\u2022 Also written as: \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b\n\u2022 Note: Var(X) \u2265 0\n\u2022 Other names: 2nd central moment, or square of the standard deviation\nVar \ud835\udc4b Units of \ud835\udc4b!\ndef standard deviation SD \ud835\udc4b = Var \ud835\udc4b Units of \ud835\udc4b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nVariance\nVariance of Stanford weather Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b !\nof \ud835\udc4b\nStanford, CA\n\ud835\udc38 high = 68\u00b0F\n\ud835\udc38 low = 52\u00b0F\n0.4\n0.3\n0.2\n0.1\n0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\n!\n\ud835\udc4b \ud835\udc4b \u2212 \ud835\udf07\n57\u00b0F 121 (\u00b0F)2\nStanford high temps\n71\u00b0F 9 (\u00b0F)2\n75\u00b0F 49 (\u00b0F)2\n\ud835\udc38 \ud835\udc4b = \ud835\udf07 = 68\u00b0F\n69\u00b0F 1 (\u00b0F)2\n\u2026 \u2026\nVariance \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07 ! = 39 (\u00b0F)2\n35 50 65 80 90 Standard deviation = 6.2\u00b0F\nComparing variance\nStanford, CA Washington, DC\n\ud835\udc38 high = 68\u00b0F \ud835\udc38 high = 67\u00b0F\n0.4 0.4\n0.3 0.3\n0.2 0.2\n0.1 0.1\n0 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc65\n=\n\ud835\udc4b\n\ud835\udc43\nVariance\nVar \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b !\nof \ud835\udc4b\nStanford high temps Washington high temps\n68\u00b0F 67\u00b0F\n35 50 65 80 90 35 50 65 80 90\nVar \ud835\udc4b = 39 \u00b0F ! Var \ud835\udc4b = 248 \u00b0F !\nProperties of\nVariance\n9\nProperties of variance\n!\nDefinition Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b !\nUnits of \ud835\udc4b\ndef standard deviation SD \ud835\udc4b = Var \ud835\udc4b\nUnits of \ud835\udc4b\n! !\nProperty 1 Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b\n!\nProperty 2 Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e Var \ud835\udc4b\n\u2022 Property 1 is often easier to manipulate than the original definition\n\u2022 Unlike expectation, variance is not linear\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nProperties of variance\n!\nDefinition Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b !\nUnits of \ud835\udc4b\ndef standard deviation SD \ud835\udc4b = Var \ud835\udc4b\nUnits of \ud835\udc4b\n! !\nProperty 1 Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b\n!\nProperty 2 Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e Var \ud835\udc4b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nVar \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b ! Variance\nComputing variance, a proof\n= \ud835\udc38 \ud835\udc4b! \u2212 \ud835\udc38 \ud835\udc4b ! of \ud835\udc4b\n! !\nVar \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07\nLet \ud835\udc38 \ud835\udc4b = \ud835\udf07\n!\n= , \ud835\udc65 \u2212 \ud835\udf07 \ud835\udc5d \ud835\udc65\n\"\n! !\n= , \ud835\udc65 \u2212 2\ud835\udf07\ud835\udc65 + \ud835\udf07 \ud835\udc5d \ud835\udc65\n\"\n! !\n= , \ud835\udc65 \ud835\udc5d \ud835\udc65 \u2212 2\ud835\udf07 , \ud835\udc65\ud835\udc5d \ud835\udc65 + \ud835\udf07 , \ud835\udc5d \ud835\udc65\nEveryone,\n\" \" \"\nplease ! !\n= \ud835\udc38 \ud835\udc4b \u2212 2\ud835\udf07\ud835\udc38 \ud835\udc4b + \ud835\udf07\n\u22c5 1\nwelcome the\n! ! !\nsecond = \ud835\udc38 \ud835\udc4b \u2212 2\ud835\udf07 + \ud835\udf07\nmoment!\n! !\n= \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07\n! !\n= \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nVar \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b ! Variance\nVariance of a 6-sided die\n= \ud835\udc38 \ud835\udc4b! \u2212 \ud835\udc38 \ud835\udc4b ! of \ud835\udc4b\nLet Y = outcome of a single die roll. Recall \ud835\udc38 \ud835\udc4c = 7/2 .\nCalculate the variance of Y.\n1. Approach #1: Definition 2. Approach #2: A property\nn t\nm e\nm o\n! ! 2 n d 1\n1 7 1 7\n! ! ! ! ! ! !\n\ud835\udc38 \ud835\udc4c = 1 + 2 + 3 + 4 + 5 + 6\nVar \ud835\udc4c = 1 \u2212 + 2 \u2212\n6\n6 2 6 2\n! ! = 91/6\n1 7 1 7\n+ 3 \u2212 + 4 \u2212\n6 2 6 2\n! !\n1 7 1 7\n+ 5 \u2212 + 6 \u2212\n6 2 6 2 ! ! !\nVar \ud835\udc4c = E \ud835\udc4c \u2212 E Y = 91/6 \u2212 7/2\n= 35/12 = 35/12\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nProperties of variance\n!\nDefinition Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b !\nUnits of \ud835\udc4b\ndef standard deviation SD \ud835\udc4b = Var \ud835\udc4b Units of \ud835\udc4b\n! !\nProperty 1 Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b\n!\nProperty 2 Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e Var \ud835\udc4b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nProperty 2: A proof\n!\nProperty 2 Var \ud835\udc4e\ud835\udc4b + \ud835\udc4f = \ud835\udc4e Var \ud835\udc4b\nVar \ud835\udc4e\ud835\udc4b + \ud835\udc4f\nProof:\n= \ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n!\n\u2212 \ud835\udc38 \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n!\nProperty 1\n= \ud835\udc38\n\ud835\udc4e! \ud835\udc4b!\n+ 2\ud835\udc4e\ud835\udc4f\ud835\udc4b +\n\ud835\udc4f!\n\u2212 \ud835\udc4e\ud835\udc38 \ud835\udc4b + \ud835\udc4f\n!\nFactoring/\nLinearity of\n=\n\ud835\udc4e!\n\ud835\udc38\n\ud835\udc4b!\n+ 2\ud835\udc4e\ud835\udc4f\ud835\udc38 \ud835\udc4b +\n\ud835\udc4f!\n\u2212\n\ud835\udc4e!\n\ud835\udc38[\ud835\udc4b]\n!\n+ 2\ud835\udc4e\ud835\udc4f\ud835\udc38[\ud835\udc4b] +\n\ud835\udc4f!\nExpectation\n=\n\ud835\udc4e!\n\ud835\udc38\n\ud835\udc4b!\n\u2212\n\ud835\udc4e!\n\ud835\udc38[\ud835\udc4b]\n!\n=\n\ud835\udc4e!\n\ud835\udc38\n\ud835\udc4b!\n\u2212 \ud835\udc38[\ud835\udc4b]\n!\n=\n\ud835\udc4e!Var\n\ud835\udc4b Property 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nOther Moments of Interest\nSkewness: Sometimes referred to as the 3rd central moment and\n)\ncomputed as \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b , skewness provides a\nmeasure of whether a probability distribution is\nsymmetric or asymmetric.\nKurtosis: Sometimes referred to as the 4th central moment and\n*\ncomputed as \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b , kurtosis provides a\nmeasure of how concentrated the distribution is. Some\ndistributions are so dispersed they don\u2019t have finite\nvariances or means.\n[image source]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nBernoulli RV\n17\nBernoulli Random Variable\nConsider an experiment with two outcomes: \"success\" and \"failure\".\ndef A Bernoulli random variable \ud835\udc4b maps \"success\" to 1 and \"failure\" to 0.\nOther names: indicator random variable, Boolean random variable\nPMF \ud835\udc43 \ud835\udc4b = 1 = \ud835\udc5d 1 = \ud835\udc5d\n\ud835\udc4b~Ber(\ud835\udc5d)\n\ud835\udc43 \ud835\udc4b = 0 = \ud835\udc5d 0 = 1 \u2212 \ud835\udc5d\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udc5d\nSupport: {0,1} Variance Var \ud835\udc4b = \ud835\udc5d(1 \u2212 \ud835\udc5d)\nExamples:\n\u2022 Coin flip\n\u2022 Random binary digit\n\u2022 Whether Doris barks\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\n\ud835\udc4b~Ber(\ud835\udc5d) \ud835\udc5d 1 = \ud835\udc5d\n\"\nDefining Bernoulli RVs\n\ud835\udc38 \ud835\udc4b = \ud835\udc5d \ud835\udc5d 0 = 1 \u2212 \ud835\udc5d\n\"\nRun a program Serve an ad. Roll two dice.\n\u2022 Crashes w.p. \ud835\udc5d \u2022 User clicks w.p. 0.2 \u2022 Success: roll a 10\n\u2022 Works w.p. 1 \u2212 \ud835\udc5d \u2022 Ignores otherwise \u2022 Failure: anything else\nLet \ud835\udc4b: 1 if crash Let \ud835\udc4b: 1 if clicked Let \ud835\udc4b : 1 if success\n\ud835\udc4b~Ber(\ud835\udc5d) \ud835\udc4b~Ber(___) \ud835\udc4b~Ber(___)\n\ud835\udc43 \ud835\udc4b = 1 = \ud835\udc5d \ud835\udc43 \ud835\udc4b = 1 = ___\n\ud835\udc38 \ud835\udc4b = ___\n\ud835\udc43 \ud835\udc4b = 0 = 1 \u2212 \ud835\udc5d \ud835\udc43 \ud835\udc4b = 0 = ___\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nBinomial RV\n20\nBinomial Random Variable\nConsider an experiment: \ud835\udc5b independent Ber(\ud835\udc5d) trials.\ndef A Binomial random variable \ud835\udc4b counts the successes across \ud835\udc5b trials.\nPMF \ud835\udc58 = 0, 1, \u2026 , \ud835\udc5b:\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) \ud835\udc5b\n! \"#!\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nSupport: {0,1, \u2026 , \ud835\udc5b} Var \ud835\udc4b = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nVariance\nExamples:\n\u2022 # heads in n coin flips\n\u2022 # of 1\u2019s in randomly generated length n bit string\n\u2022 # of disk drives crashed in 1000 computer cluster\n(assuming disks crash independently)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nReiterating notation\n1. The random \ud835\udc4b ~ Bin(\ud835\udc5b, \ud835\udc5d)\nvariable\n2. is distributed 4. with parameters\n3. Binomial\nas a\nThe parameters of a Binomial random variable:\n\u2022 \ud835\udc5b: number of independent trials\n\u2022 \ud835\udc5d: probability of success on each trial\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nReiterating notation\n\ud835\udc4b ~ Bin(\ud835\udc5b, \ud835\udc5d)\nIf \ud835\udc4b is a binomial with parameters \ud835\udc5b and \ud835\udc5d, the PMF of \ud835\udc4b is\n\ud835\udc5b\n( )*(\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nProbability that \ud835\udc4b\nProbability Mass Function for a Binomial\ntakes on the value \ud835\udc58\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n\ud835\udc5b\nThree coin flips \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nThree fair (with \ud835\udc5d = 0.5) coins are flipped.\n\u2022 \ud835\udc4b is number of heads\n\u2022 \ud835\udc4b~Bin 3, 0.5\nCompute the following event probabilities:\n\ud835\udc43 \ud835\udc4b = 0\n\ud835\udc43 \ud835\udc4b = 1\n\ud835\udc43 \ud835\udc4b = 2\n\ud835\udc43 \ud835\udc4b = 3\nP(event)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n\ud835\udc5b\nThree coin flips \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nThree fair (with \ud835\udc5d = 0.5) coins are flipped.\n\u2022 \ud835\udc4b is number of heads\n\u2022 \ud835\udc4b~Bin 3, 0.5\nCompute the following event probabilities:\n3 &\n= \ud835\udc5d 0 =\n\ud835\udc5d$\n1 \u2212 \ud835\udc5d\n%\n=\n\ud835\udc43 \ud835\udc4b = 0\n0 \u2019\n3 %\n& !\n\ud835\udc43 \ud835\udc4b = 1 = \ud835\udc5d 1 = \ud835\udc5d 1 \u2212 \ud835\udc5d =\n1 \u2019\n3 %\n\ud835\udc43 \ud835\udc4b = 2 = \ud835\udc5d 2 =\n\ud835\udc5d!\n1 \u2212 \ud835\udc5d\n&\n=\n2 \u2019\n3 &\n\ud835\udc43 \ud835\udc4b = 3 = \ud835\udc5d 3 =\n\ud835\udc5d%\n1 \u2212 \ud835\udc5d\n$\n=\n3 \u2019\nP(event)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nBinomial Random Variable\nConsider an experiment: \ud835\udc5b independent trials of Ber(\ud835\udc5d) random variables.\ndef A Binomial random variable \ud835\udc4b is the number of successes in \ud835\udc5b trials.\nPMF \ud835\udc58 = 0, 1, \u2026 , \ud835\udc5b:\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) \ud835\udc5b\n! \"#!\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nRange: {0,1, \u2026 , \ud835\udc5b} Var \ud835\udc4b = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nVariance\nExamples:\n\u2022 # heads in n coin flips\n\u2022 # of 1\u2019s in randomly generated length n bit string\n\u2022 # of disk drives crashed in 1000 computer cluster\n(assuming disks crash independently)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nBinomial RV is sum of Bernoulli RVs\nBernoulli\n\u2022 \ud835\udc4b~Ber(\ud835\udc5d)\nBinomial\n\u2022 \ud835\udc4c~Bin \ud835\udc5b, \ud835\udc5d\n+\n\u2022 The sum of \ud835\udc5b independent\nBernoulli RVs\n+\n*\n+\n\ud835\udc4c = , \ud835\udc4b , \ud835\udc4b ~Ber(\ud835\udc5d)\n( (\n()&\nBer \ud835\udc5d = Bin(1, \ud835\udc5d)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nBinomial Random Variable\nConsider an experiment: \ud835\udc5b independent trials of Ber(\ud835\udc5d) random variables.\ndef A Binomial random variable \ud835\udc4b is the number of successes in \ud835\udc5b trials.\nPMF \ud835\udc58 = 0, 1, \u2026 , \ud835\udc5b:\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) \ud835\udc5b\n! \"#!\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nRange: {0,1, \u2026 , \ud835\udc5b} Var \ud835\udc4b = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nVariance\nExamples:\n\u2022 # heads in n coin flips\n\u2022 # of 1\u2019s in randomly generated length n bit string\n\u2022 # of disk drives crashed in 1000 computer cluster\n(assuming disks crash independently)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nBinomial Random Variable\nConsider an experiment: \ud835\udc5b independent trials of Ber(\ud835\udc5d) random variables.\ndef A Binomial random variable \ud835\udc4b is the number of successes in \ud835\udc5b trials.\nPMF \ud835\udc58 = 0, 1, \u2026 , \ud835\udc5b:\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d) \ud835\udc5b\n! \"#!\n\ud835\udc43 \ud835\udc4b = \ud835\udc58 = \ud835\udc5d \ud835\udc58 = \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\nExpectation \ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\nRange: {0,1, \u2026 , \ud835\udc5b} Var \ud835\udc4b = \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d)\nVariance\nWe\u2019ll prove\nExamples:\nthis later in\n\u2022 # heads in n coin flips\nthe course.\n\u2022 # of 1\u2019s in randomly generated length n bit string\n\u2022 # of disk drives crashed in 1000 computer cluster\n(assuming disks crash independently)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nExercises\n30\nStatistics: Expectation and variance\n1. a. Let \ud835\udc4b = the outcome of a fair 24-sided\ndie roll. What is \ud835\udc38 \ud835\udc4b ?\nb. Let \ud835\udc4c = the sum of seven rolls of a fair\n24-sided die. What is \ud835\udc38 \ud835\udc4c ?\n2. Let \ud835\udc4d = # of tails on 10 flips of a\nbiased coin, with p = 0.71. What is \ud835\udc38 \ud835\udc4d ?\n3. Compare the variances of\n\ud835\udc35 ~Ber 0.0 , \ud835\udc35 ~Ber 0.1 ,\n4 5\n\ud835\udc35 ~Ber 0.5 , and \ud835\udc35 ~Ber(0.9).\n! )\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nIf you can identify common RVs, just look up\nStatistics: Expectation and variance\nstatistics instead of rederiving from scratch.\n1. a. Let \ud835\udc4b = the outcome of a fair 24-sided\ndie roll. What is \ud835\udc38 \ud835\udc4b ?\nb. Let \ud835\udc4c = the sum of seven rolls of a fair\n24-sided die. What is \ud835\udc38 \ud835\udc4c ?\n2. Let \ud835\udc4d = # of tails on 10 flips of a\nbiased coin, with p = 0.71. What is \ud835\udc38 \ud835\udc4d ?\n3. Compare the variances of\n\ud835\udc35 ~Ber 0.0 , \ud835\udc35 ~Ber 0.1 ,\n4 5\n\ud835\udc35 ~Ber 0.5 , and \ud835\udc35 ~Ber(0.9).\n! )\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\n\ud835\udc5b\nVisualizing Binomial PMFs\n\ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc56 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nA. 0.3 B.\n0.3\n0.2\n0.2\n0.1 0.1\n0 0\n0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10\n\ud835\udc58\nC. D.\n0.3 0.3\nMatch the distribution\n0.2 0.2\nof \ud835\udc4b to the graph:\n0.1 0.1\n1. Bin 10, 0.5\n0 0\n2. Bin 10, 0.3\n0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10\n3. Bin 10, 0.7\n4. Bin 5, 0.5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\nVisualizing Binomial PMFs\nA. 0.3 B.\n0.3\n0.2\n0.2\n0.1 0.1\n0 0\n0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10\n\ud835\udc58\nC. D.\n0.3 0.3\nMatch the distribution\n0.2 0.2\nof \ud835\udc4b to the graph:\n0.1 0.1\n1. Bin 10, 0.5\n0 0\n2. Bin 10, 0.3\n0 1 2 3 4 5 6 7 8 9 10 0 1 2 3 4 5 6 7 8 9 10\n3. Bin 10, 0.7\n4. Bin 5, 0.5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc58\n\ud835\udc58\n=\n\ud835\udc4b\n\ud835\udc43\n\ud835\udc38 \ud835\udc4b = \ud835\udc5b\ud835\udc5d\n\ud835\udc5b\n\ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc56 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nGalton Board\nhttp://cs109.stanford.edu/demos/galton.html\n0 1 2 3 4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\n\ud835\udc5b\nGalton Board \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nWhen a marble hits a pin, it has an equal\nchance of going left or right.\nLet \ud835\udc35 = the bucket index a ball drops into.\nWhat is the distribution of \ud835\udc35?\n\ud835\udc5b = 5\n(Interpret: If \ud835\udc35 is a common\nrandom variable, report it,\notherwise report PMF)\n0 1 2 3 4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\n\ud835\udc5b\nGalton Board \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nWhen a marble hits a pin, it has an equal\nchance of going left or right.\nLet \ud835\udc35 = the bucket index a ball drops into.\nWhat is the distribution of \ud835\udc35?\n\ud835\udc5b = 5\n\u2022 Each pin is an independent trial\n\u2022 One decision made for level \ud835\udc56 = 1, 2, . . , 5\n\u2022 Consider a Bernoulli RV with success \ud835\udc45 if\n(\nball went right on level \ud835\udc56\n\u2022 Bucket index \ud835\udc35 = # times ball went right\n\ud835\udc35~Bin(\ud835\udc5b = 5, \ud835\udc5d = 0.5)\n0 1 2 3 4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\n\ud835\udc5b\nGalton Board \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\nWhen a marble hits a pin, it has an equal\nchance of going left or right.\nLet \ud835\udc35 = the bucket index a ball drops into.\n\ud835\udc35 is distributed as a Binomial RV,\n\ud835\udc5b = 5\n\ud835\udc35~Bin(\ud835\udc5b = 5, \ud835\udc5d = 0.5)\n5\n\ud835\udc43 \ud835\udc35 = 0 =\n0.50\n\u2248 0.03\n0\n5\n0\n\ud835\udc43 \ud835\udc35 = 1 = 0.5 \u2248 0.16\n1\n5\n\ud835\udc43 \ud835\udc35 = 2 =\n0.50\n\u2248 0.31\n2\n0 1 2 3 4 5\nPMF of Binomial RV!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\n\ud835\udc5b\nGenetics and NBA Finals \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d) \ud835\udc5d \ud835\udc58 = \ud835\udc5d# 1 \u2212 \ud835\udc5d $%#\n\ud835\udc58\n1. Each parent has 2 genes per trait (e.g., eye color).\n\u2022 Child inherits 1 gene from each parent with equal likelihood.\n\u2022 Brown eyes are \"dominant\", blue eyes are \"recessive\":\n\u2022 Child has brown eyes if either or both genes for brown eyes are inherited.\n\u2022 Child has blue eyes otherwise (i.e., child inherits two genes for blue eyes)\n\u2022 Assume parents each have 1 gene for blue eyes and 1 gene for brown eyes.\nTwo parents have 4 children. What is P(exactly 3 children have brown eyes)?\n2. Let\u2019s speculate that the Boston Celtics will play the Oklahoma City\nThunder in a 7-game series during the 2024 NBA finals this June.\n\u2022 The Celtics have a probability of 81% of winning each game, independently.\n\u2022 A team wins if they win at least 4 games (we\u2019ll assume they play all 7 games).\nWhat is P(Celtics winning)?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nGenetic inheritance\n1. Each parent has 2 genes per trait (e.g., eye color).\n\u2022 Child inherits 1 gene from each parent with equal likelihood.\n\u2022 Brown eyes are \"dominant\", blue eyes are \"recessive\":\n\u2022 Child has brown eyes if either or both genes for brown eyes are inherited.\n\u2022 Child has blue eyes otherwise (i.e., child inherits two genes for blue eyes)\n\u2022 Assume parents each have 1 gene for blue eyes and 1 gene for brown eyes.\nTwo parents have 4 children. What is P(exactly 3 children have brown eyes)?\nBig Q: Fixed parameter or random variable?\nParameters What is common among all\noutcomes of our experiment?\nRandom variable What differentiates our event\nfrom the rest of the sample\nspace?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nGenetic inheritance\n1. Each parent has 2 genes per trait (e.g., eye color).\n\u2022 Child inherits 1 gene from each parent with equal likelihood.\n\u2022 Brown eyes are \"dominant\", blue eyes are \"recessive\":\n\u2022 Child has brown eyes if either or both genes for brown eyes are inherited.\n\u2022 Child has blue eyes otherwise (i.e., child inherits two genes for blue eyes)\n\u2022 Assume parents each have 1 gene for blue eyes and 1 gene for brown eyes.\nTwo parents have 4 children. What is P(exactly 3 children have brown eyes)?\n1. Define events/ 2. Identify known 3. Solve\nRVs & state goal probabilities\n\ud835\udc4b: # brown-eyed children,\n\ud835\udc4b~Bin(4, \ud835\udc5d)\n\ud835\udc5d: \ud835\udc43 brown\u2212eyed child\nWant: \ud835\udc43 \ud835\udc4b = 3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nNBA Finals\n2. Let\u2019s speculate that the Boston Celtics will play the Oklahoma City\nThunder in a 7-game series during the 2024 NBA finals this June.\n\u2022 The Celtics have a probability of 58% of\nwinning each game, independently.\n\u2022 A team wins if they win at least 4 games (we\u2019ll assume they play all 7 games). What\nis P(Celtics winning)?\n1. Define events/ 2. Solve\nRVs & state goal\n3 3\n7\n1 341\n\ud835\udc43 \ud835\udc4b \u2265 4 = , \ud835\udc43 \ud835\udc4b = \ud835\udc58 = , 0.81 0.19\n\ud835\udc4b: # games Celtics win\n\ud835\udc58\n\ud835\udc4b~Bin(7, 0.81) 1)2 1)2\nWant: \ud835\udc43 \ud835\udc4b \u2265 4\nCool Probability Fact: this is identical to the probability of winning\nif we define winning to be that to to first win 4 games\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42 <END>"}
{"prompt": "Lecture notes from cs109_lec13_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 13: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nLinearity of Expectation 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nCovariance 2 / 2 pts\n2.1 Independent RVs 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 Dependent RVs 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nZero Covariance 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Linearity of Expectation\n1 Point\nLinearity of Expectation\u2014that is, expectation of a sum is the same as the sum of\nexpectations\u2014holds when:\nThere is independence\nThere is mutual exclusivity\nIn general\nQ2 Covariance\n2 Points\nQ2.1 Independent RVs\n1 Point\nSuppose X and Y are independent random variables. What does this tell us\nabout their covariance?\nIt is 0\nIt is 1\nIt is 0.5\nIt tells us nothing about their covariance\nQ2.2 Dependent RVs\n1 Point\nSuppose X and Y are dependent random variables. Which of the following are\ntrue?\nCov(X,Y ) = E[X \u2212 E[X]] \u22c5 E[Y \u2212 E[Y ]]\nCov(X,Y ) = E[XY ] \u2212 E[X]E[Y ]\nE[X + Y ] = E[X] + E[Y ]\nVar(X + Y ) = Var(X) + Var(Y )\nVar(X + Y ) = Var(X) + 2Cov(X,Y ) + Var(Y )\nQ3 Zero Covariance\n1 Point\nSuppose we know that for Stanford students that their height and weight are\nboth random but their covariance is zero. Can we then conclude that it must be\ntrue that height and weight are independent for Stanford students?\nYes\nNo <END>"}
{"prompt": "Lecture notes from ancestry-readme.txt\n\n###\n\n", "completion": "Task:\nYour task is to predict the ethnicity of a person who has sent in their DNA based on Single Nucleotide Polymorphisms (SNPs).\n\nValues:\nThis dataset contains the genetic variation found in people sampled by the 1000 Genomes Project which sequenced the DNA from different ethnic groups around the world. Each input vector represents the DNA at specific locations in the genome for one individual. There are 20 binary input features. 0 indicates that the user's DNA at the given location matches the human reference genome. 1 indicates that the user's DNA does not match the human reference genome. The output class value represents the super population (ethnicity) of each individual. The super populations contained in this dataset are East Asian or Ad Mixed American, encoded in binary. The training data set contains 283 data vectors, and the testing data set contains 184 data vectors.\n\nColumn meaning:\nEach column represents a particular location in the human genome. 0 indicates that the user's DNA at the given location matches the human reference genome. 1 indicates that the user's DNA does not match the human reference genome. Though the particular locations in DNA may have semantic meanings -- for this task all you know is that each column is a distinct nucleotide index.\n\nPrediction:\nThe variable you are predicting is the super population of the user.\n\nCredit:\nThanks to Jim Notwell and Gill Bejerano who is a professor in Computer Science and Genetics \n\n <END>"}
{"prompt": "Lecture notes from cs109_lec02_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 2: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nCounting 2 / 2 pts\n1.1 Counting: Minimal Constraints 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Counting: Added Constraints 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nCombinatorics I 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nCombinatorics II 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Counting\n2 Points\nThere are 5 CS109 students (Emnet, Vanessa, Anthony, Mara, and Meygan) in line\nfor office hours.\nQ1.1 Counting: Minimal Constraints\n1 Point\nHow many ways can the five students be ordered in line, from front to back?\n5\n55 = 3125\n4 \u22c5 3 \u22c5 2 \u22c5 1 = 24\n2 \u22c5 (4 \u22c5 3 \u22c5 2 \u22c5 1) = 48\n5 \u22c5 4 \u22c5 3 \u22c5 2 \u22c5 1 = 120\n6 \u22c5 5 \u22c5 4 \u22c5 3 \u22c5 2 \u22c5 1 = 720\n5 \u22c5 200 = 1000\nQ1.2 Counting: Added Constraints\n1 Point\nHow many ways can they be ordered if Emnet and Mara insist on being next to\neach other in line?\n5 \u22c5 4 \u22c5 3 \u22c5 2 \u22c5 1 = 120\n6 \u22c5 5 \u22c5 4 \u22c5 3 \u22c5 2 \u22c5 1! = 720\n4 \u22c5 3 \u22c5 2 \u22c5 1 = 24\n2 \u22c5 (4 \u22c5 3 \u22c5 2 \u22c5 1) = 48\n5\u22c54\u22c53\u22c52\u22c51 = 60\n2\nQ2 Combinatorics I\n1 Point\nHow many ways are there to split a dozen people into 3 teams, where one team\nhas 2 people, and the other two teams have 5 people each? Restated, how many\nways can you partition 12 distinct items into three subsets of size 2, 5, and 5.\nNote that the order of the two size-5 subsets doesn't matter!, i.e. A partition of\n{1,2,3,4,5,6,7,8,9,10,11,12} into {1,2}, {3,4,5,6,7}, and\n{8,9,10,11,12} is the same partition as {1,2}, {8,9,10,11,12}, and\n{3,4,5,6,7}, so it should only be counted once.\nExpress your answer as a simple integer.\n8316\nQ3 Combinatorics II\n1 Point\nHow many ways are there to split a dozen people into 6 teams of two people\neach? Express your answer as a simple integer. Hint: Avoid overcounting just as\nyou did for Question 2.\n10395 <END>"}
{"prompt": "Lecture notes from simple-readme.txt\n\n###\n\n", "completion": "Task:\nThis is a toy dataset. You may find it helpful for testing your code. You should be able to predict the test dataset (which is identical to the train dataset) with 100% accuracy.\n\nValues:\nThe values are all binary. \n\nColumn meaning:\nN/A\n\nPrediction:\nN/A\n\nCredit:\nThis dataset was developed by Mehran Sahami\n\n <END>"}
{"prompt": "Lecture notes from cs109_lec18_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 18: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nDefinition: iid 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nSum of IID Poisson RVs 2 / 2 pts\n2.1 (no title) 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 (no title) 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nSum of Continuous Uniforms 2 / 2 pts\n3.1 Sum of Uniforms 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n3.2 Approximate Probability 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Definition: iid\n1 Point\nAre X 1, X 2, ... X n independent and identically distributed (iid) with the following\ndistributions? Select all that apply.\nX \u223c Poi(\u03bb)\ni\nX \u223c Ber(p )\ni i\nLet X i be an indicator variable which takes a 1 if it is raining on the i'th\nday of the year\nImagine you toss a normal 6-sided die n times. Let X i be the outcome of\nthe i'th die toss.\nQ2 Sum of IID Poisson RVs\n2 Points\nLet X 1, X 2, ... X 10 be iid RV with X i \u223c Poi(10). Select all that apply.\nQ2.1\n1 Point\n10\nWhat is the distribution of their sum, \u2211 X ?\ni=1 i\nN(100, 100)\nPoi(100)\nPoi(10)\nBinomial(100000, 0.001)\nQ2.2\n1 Point\nWhat is P(\u2211 i1 =0 1 X i \u2264 110), approximately or exactly? Select all that apply.\n\u03a6(110.5\u2212100) = \u03a6(1.05) = 0.8531\n10\n\u03a6(110\u2212100) = \u03a6(1) = 0.841\n10\n\u2211110 100ie\u2212100\n= 0.8529\ni=0 i!\nQ3 Sum of Continuous Uniforms\n2 Points\nLet X 1, X 2, X 3, ..., X 95, and X 96 all be iid such that X i \u223c Uni(0,1), and let\n96\nX = \u2211 X . Recall that the mean and variance of a single continuous\nk=1 k\nUni(a,b)\nare\na+b\nand\n(a\u2212b)2\n, respectively.\n2 12\nQ3.1 Sum of Uniforms\n1 Point\nThe Central Limit Theorem tells us that X is distributed as something very close\nto a Gaussian. What is the sum of the mean and variance of this Gaussian? Enter\nyour answer to the nearest integer.\n56\nQ3.2 Approximate Probability\n1 Point\nWhat is the approximate probability that X < 64. Enter your answer to three\ndecimal places.\nHint: you can make an educated guess without bothering to do the math. We'll\nshow you the math after you enter the correct value.\n1.000 <END>"}
{"prompt": "Lecture notes from 06_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May16,2024\nContinuous Joint Distributions, Central Limit Theorem\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Food for Thought\nKarelthedogeatsanunpredictableamountoffood.Everyday,thedogisequallylikelytoeat\nbetweenacontinuousamountintherange100to300g.HowmuchKareleatsisindependentofall\notherdays.Youonlyhave6.5kgoffoodforthenext30days.Whatistheprobabilitythat6.5kg\nwillbeenoughforthenext30days?\n1.2 Sample and Population Mean\nComputingthesamplemeanissimilartothepopulationmean:sumallavailablepointsanddivide\nbythenumberofpoints.However,samplevarianceisslightlydifferentfrompopulationvariance.\n1. Considertheequationforpopulationvariance,andananalogousequationforsample\nvariance.\n\ud835\udc41\n1 \u2211\ufe01\n\ud835\udf0e2 = (\ud835\udc65 \ud835\udc56 \u2212 \ud835\udf07)2\n\ud835\udc41\n\ud835\udc56=1\n\ud835\udc5b\n1 \u2211\ufe01\n\ud835\udc462 \ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 = \ud835\udc5b (\ud835\udc4b \ud835\udc56 \u2212 \ud835\udc4b\u00af)2\n\ud835\udc56=1\n\ud835\udc462 isarandomvariabletoestimatetheconstant \ud835\udf0e2.Becauseitisbiased,\n\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\n\ud835\udc38[\ud835\udc462 ] \u2260 \ud835\udf0e2.Is \ud835\udc38[\ud835\udc462 ] greaterorlessthan \ud835\udf0e2?\n\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51 \ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\n2. ConsideranalternativeRandomVariable, \ud835\udc462 (knownsimplyas \ud835\udc462 inclass).The\n\ud835\udc62\ud835\udc5b\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\ntechniqueofun-biasingvarianceisknownasBessel\u2019scorrection.Writethe \ud835\udc462\n\ud835\udc62\ud835\udc5b\ud835\udc4f\ud835\udc56\ud835\udc4e\ud835\udc60\ud835\udc52\ud835\udc51\nequation.\n2 Problems\n2.1 Sum of Two Exponentials\nConsidertwoindependentrandomvariables \ud835\udc4b and\ud835\udc4c,eachExponentialswithdifferent\nparameters\u2014specifically,let \ud835\udc4b \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) and\ud835\udc4c \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1).Assuming\ud835\udc47 = \ud835\udc4b +\ud835\udc4c,deriveand\n2 3\npresenttheprobabilitydensityfunction \ud835\udc53 \ud835\udc47(\ud835\udc61) byevaluatingtherelevantconvolution.Onceyou\narriveatyour \ud835\udc53 \ud835\udc47(\ud835\udc61),verifyyouranswerbycalculating \ud835\udc53 \ud835\udc47(2) outtothreedecimalplaces.\n\u20132\u2013\n2.2 Grading Exams\nJacobandKathleenareplanningtogradeProblem1onyourWeek7exam,andthey\u2019lleachgrade\ntheirhalfindependentlyoftheother.Jacobtakes \ud835\udc4b \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) hourstofinishhishalfwhile\n3\nKathleentakes\ud835\udc4c \u223c \ud835\udc38\ud835\udc65\ud835\udc5d(1) hourstofinishhishalf.\n4\na. FindtheCDFof \ud835\udc4b/\ud835\udc4c,whichistheratiooftheirgradingcompletiontimes.\nb. WhatistheprobabilitythatKathleenfinishesbeforeJacobdoes?\n2.3 Central Limit Theorem and Sampling Calisthenics\na. Let \ud835\udc4b , \ud835\udc4b , \ud835\udc4b ,..., \ud835\udc4b beiid\u2014thatis,independentandidenticallydistributed\u2014suchthat\n1 2 3 1000\n\ud835\udc4b \ud835\udc56 \u223c NegBin(\ud835\udc5f = 10, \ud835\udc5d = 0.5),andlet\ud835\udc4a = \ud835\udc4b 1 + \ud835\udc4b 2 +...+ \ud835\udc4b 1000.AccordingtotheCentral\nLimitTheorem,whatdistributiondoes\ud835\udc4a assume,andwhatareitsparameters?\nb. Define \ud835\udc4b\u00af = 101\n00\n(cid:205) \ud835\udc561 =0 100 \ud835\udc4b \ud835\udc56 tobethesamplemeanofour1000iidsamples.Whatisthe\nstandarddeviationoftherandomvariable \ud835\udc4b\u00af?\nc. Youcomputethevarianceofyour1000samples, \ud835\udc4b , \ud835\udc4b , \ud835\udc4b ,..., \ud835\udc4b accordingtothe\n1 2 3 1000\ntraditionaldefinitionofvariance\u2014i.e. 101\n00\n(cid:205) \ud835\udc561 =0 100 (\ud835\udc4b \ud835\udc56 \u2212 \ud835\udc4b\u00af)2.Doyouexpectthisvarianceto,\nmoreoftenthannot,belarger,equalto,orsmallerthanthevarianceofNegBin(10,0.5).\nExplainyouranswer.\nd. ThenumberofsamplesneededfortheCentralLimitTheoremtoapplyisgenerally\nunderstoodtobe30ormore.However,theCentralLimitTheoremworkswellforaneven\nsmallernumberofsampleswhen \ud835\udc4b \ud835\udc56 \u223c Bin(10,0.5) thanisdoeswhen\n\ud835\udc4b\n\ud835\udc56\n\u223c NegBin(10,0.5).Brieflyexplainwhy.\ne. Recallthatsamplingtheoryallowsareasonablylargesampletostandinforthetrue\npopulationdistribution.Whenresamplingfromthesampleforbootstrappingpurposes,we\ngenerallydosowithreplacement.Whywithreplacementinsteadof without? <END>"}
{"prompt": "Lecture notes from cs109_lec16_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 16: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nJoint Continuous X and Y 4 / 4 pts\n1.1 Finding the full PDF 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Probabilities 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.3 Inferences 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.4 Further Constraint 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nExpected Distance 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Joint Continuous X and Y\n4 Points\nSuppose X and Y are jointly continuous random variables with joint PDF\nf X,Y(x,y) = cxy where 0 \u2264 x,y \u2264 1.\nQ1.1 Finding the full PDF\n1 Point\nWhat is the value for constant c? Your answer should be a whole integer.\n4\nQ1.2 Probabilities\n1 Point\nFor your value of c, what is P(X \u2264 Y )?\nDepends on c\n0.5\n0\n1\nQ1.3 Inferences\n1 Point\nFrom above, which of the following statements can we infer to be true?\nX and Y are independent\nX and Y are correlated\nWe can infer nothing\nQ1.4 Further Constraint\n1 Point\nSuppose now we learn some more information about the relationship between X\nand Y and update the joint PDF f X,Y(x,y) = 8xy where 0 \u2264 x \u2264 y \u2264 1.\nWhich of the following statements can we infer to be true?\nX and Y are independent\nX and Y are dependent\nQ2 Expected Distance\n1 Point\nAssume that X and Y are each Uni(0,1) random variables, so that the joint\nPDF is simply f(x,y) = 1 for 0 < x,y < 1.\nWhat is the expected value of the distance between them? Restated, what is\nE[abs(Y \u2212 X)]? Express your answer to three decimal places.\n0.333 <END>"}
{"prompt": "Lecture notes from 03_section_soln.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 April25,2024\nSection 3: Named Random Variables\nBefore you leave lab, make sure you click here so that you\u2019re marked as having attended. The CA\nleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\n1 Gender Composition of Discussion Sections\nAmassiveonlineStanfordclasshassectionswith10studentseach.Eachstudentinourpopulation\nhas a 50% chance of identifying as female, 47% chance of identifying as male and 3% chance of\nidentifying as non-binary. Even though students are assigned randomly to sections, a few sections\nenduphavingaveryunevendistributionjustbychance.Youshouldassumethatthepopulationof\nstudents is so large that the percentages of students who identify as male / female / non-binary are\nunchanged,evenifyouselectstudentswithoutreplacement.\na. Definearandomvariableforthenumberofpeopleinasectionwhoidentifyasmale.\nLet \ud835\udc4b denotethenumberofpeopleinasectionwhoidentifyasmale.\n\ud835\udc4b \u223c Bin(\ud835\udc5b = 10, \ud835\udc5d = 0.47)\nb. What is the expectation and standard deviation of number of students who identify as male\ninasinglesection?\n\ud835\udc38[\ud835\udc4b] = \ud835\udc5b\u00b7 \ud835\udc5d = 10\u00b70.47 = 4.7\n\u221a\n\u221a\ufe01 \u221a\ufe01\nStd(\ud835\udc4b) = Var(\ud835\udc4b) = \ud835\udc5b\u00b7 \ud835\udc5d \u00b7 (1\u2212 \ud835\udc5d) = 10\u00b70.47\u00b70.53 \u2248 1.58\nc. Write an expression for the exact probability that a section is skewed. We defined skewed to\nbethatthesectionhas0,1,9or10peoplewhoidentifyasmale.\nRecallthat \ud835\udc5d = 0.47.\n\ud835\udc43(skewed) = \ud835\udc43(\ud835\udc4b = 0) + \ud835\udc43(\ud835\udc4b = 1) + \ud835\udc43(\ud835\udc4b = 9) + \ud835\udc43(\ud835\udc4b = 10)\n(cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19) (cid:18) (cid:19)\n10 10 10 10\n= (1\u2212 \ud835\udc5d)10 + \ud835\udc5d(1\u2212 \ud835\udc5d)9 + \ud835\udc5d9(1\u2212 \ud835\udc5d) + \ud835\udc5d10\n0 1 9 10\n\u2248 0.024\n$ python3\n>>> import scipy.stats as st\n\u20132\u2013\n>>> import numpy as np\n>>> st.binom(10, 0.47).pmf(np.array([0,1,9,10])).sum()\n0.023715146414928143\nd. The course has 1,200 sections. Approximate the probability that 30 or more sections will be\nskewed.\nThe exact probability of number of skewed sections is \ud835\udc46 \u223c Bin(\ud835\udc5b = 1200, \ud835\udc5d = 0.024). To\nsimplify the math, we can approximate the number of skewed sections using a Poisson\napproximation.Let\ud835\udc4c bethePoissonapproximationof \ud835\udc46.\n\ud835\udc4c \u223c Poi(\ud835\udf06 = 28.8) since \ud835\udc5b\ud835\udc5d = 1200\u00b70.024 = 28.8.\n\ud835\udc43(\ud835\udc4c \u2265 30) = 1\u2212 \ud835\udc43(\ud835\udc4c < 30)\n29\n\u2211\ufe01\n= 1\u2212 \ud835\udc43(\ud835\udc4c = \ud835\udc58)\n\ud835\udc58=0\n\u2248 0.436\n$ python3\n>>> import scipy.stats as st\n>>> import numpy as np\n>>> lamb = 28.8\n>>> 1 - st.poisson(lamb).pmf(range(0, 30)).sum()\n0.43605869062536795\n2 Better Evaluation of Eye Disease\nWhen a patient has eye inflammation, eye doctors \u201dgrade\u201d the inflammation. When \u201dgrading\u201d\ninflammation they randomly look at a single 1 millimeter by 1 millimeter square in the patient\u2019s\neyeandcounthowmany\u201dcells\u201dtheysee.\nThere is uncertainty in these counts. If the true average number of cells for a given patient\u2019s eye is\n6, the doctor could get a different count (say 4, or 5, or 7) just by chance. As of 2021, modern eye\nmedicine does not have a sense of uncertainty for their inflammation grades! In this problem we\nare going to change that. At the same time we are going to learn about poisson distributions over\nspace.\na. Explain, as if teaching, why the number of cells observed in a 1x1 square is governed by\na poisson process. Make sure to explain how a binomial distribution could approximate the\n\u20133\u2013\nFigure 1: A 1x1mm sample used for inflammation grading. Inflammation is graded by counting\ncellsinarandomlychosen1mmby1mmsquare.Thissamplehas5cells.\ncount of cells. Explain what \ud835\udf06 means in this context. Note: for a given person\u2019s eye, the\npresenceofacellinalocationisindependentofthepresenceofacellinanotherlocation.\nWe can approximate a distribution for the count by discretizing the square into a fixed\nnumber of equal sized buckets. Each bucket either has a cell or not. Therefore, the count\nof cells in the 1x1 square is a sum of Bernoulli random variables with equal \ud835\udc5d, and as\nsuch can be modeled as a binomial random variable. This is an approximation because it\ndoesn\u2019t allow for two cells in one bucket. Just like with time, if we make the size of each\nbucket infinitely small, this limitation goes away and we converge on the true distribution\nof counts. The binomial in the limit, i.e. a binomial as \ud835\udc5b \u2192 \u221e, is truly represented by a\nPoisson random variable. In this context, \ud835\udf06 represents the average number of cells per 1\u00d71\nsample.SeeFigure2.\nFigure 2: \ud835\udc4b is counts of events in discrete buckets. In the limit, as \ud835\udc5b (number of buckets) \u2192 \u221e, \ud835\udc4b\nbecomesaPoisson.\nb. For a given patient the true average rate of cells is 5 cells per 1x1 sample. What is the\nprobabilitythatinasingle1x1samplethedoctorcounts4cells?\n\u20134\u2013\nLet \ud835\udc4b denote the number of cells in the 1x1 sample. We note that \ud835\udc4b \u223c \ud835\udc43\ud835\udc5c\ud835\udc56(5). We want to\nfind \ud835\udc43(\ud835\udc4b = 4).\n54\ud835\udc52\u22125\n\ud835\udc43(\ud835\udc4b = 4) = \u2248 0.175\n4!\nInadditiontoprovidinganexpressionabove,\npleasecomputeanumericanswer: 0.175\n3 Continuous Random Variables\nLet \ud835\udc4b beacontinuousrandomvariablewiththefollowingprobabilitydensityfunction:\n(cid:26) \ud835\udc50(\ud835\udc52\ud835\udc65\u22121 +\ud835\udc52\u2212\ud835\udc65) if0 \u2264 \ud835\udc65 \u2264 1\n\ud835\udc53 \ud835\udc4b(\ud835\udc65) =\n0 otherwise\na. Findthevalueof \ud835\udc50 thatmakes \ud835\udc53 \ud835\udc4b avalidprobabilitydistribution.\nWeneed\u222b \u221e \ud835\udc53 \ud835\udc4b(\ud835\udc65)\ud835\udc51\ud835\udc65 = 1ifthisistobeavalidprobabilitydensityfunction!\n\u2212\u221e\n\u222b \u221e \u222b 1\n\ud835\udc53 \ud835\udc4b(\ud835\udc65)\ud835\udc51\ud835\udc65 = \ud835\udc50(\ud835\udc52\ud835\udc65\u22121 +\ud835\udc52\u2212\ud835\udc65 )\ud835\udc51\ud835\udc65\n\u2212\u221e 0\n1 = \ud835\udc50 (cid:2)\ud835\udc52\ud835\udc65\u22121 \u2212\ud835\udc52\u2212\ud835\udc65(cid:3)1\n\ud835\udc65=0\n1 = \ud835\udc50(\ud835\udc521\u22121 \u2212\ud835\udc52\u22121 \u2212 (\ud835\udc520\u22121 \u2212\ud835\udc52\u22120))\n1 1\n\ud835\udc50 = =\n1\u2212\ud835\udc52\u22121 \u2212 (\ud835\udc52\u22121 \u22121) 2\u2212 2\n\ud835\udc52\nb. Whatis \ud835\udc43(\ud835\udc4b < 0.75)?Whatis \ud835\udc43(\ud835\udc4b < \ud835\udc65)?\n\u222b 0.75\n\ud835\udc43(\ud835\udc4b < 0.75) = \ud835\udc50(\ud835\udc52\ud835\udc65\u22121 +\ud835\udc52\u2212\ud835\udc65 )\ud835\udc51\ud835\udc65\n0\n= \ud835\udc50 (cid:2)\ud835\udc52\ud835\udc65\u22121 \u2212\ud835\udc52\u2212\ud835\udc65(cid:3)0.75\n\ud835\udc65=0\n(cid:16) (cid:17)\n= \ud835\udc50 (\ud835\udc520.75\u22121 \u2212\ud835\udc52\u22120.75) \u2212 (\ud835\udc520\u22121 \u2212\ud835\udc52\u22120)\n\u222b \ud835\udc65\n\ud835\udc43(\ud835\udc4b < \ud835\udc65) = \ud835\udc50(\ud835\udc52\ud835\udc66\u22121 +\ud835\udc52\u2212\ud835\udc66 )\ud835\udc51\ud835\udc66\n0\n= \ud835\udc50 (cid:2)\ud835\udc52\ud835\udc66\u22121 \u2212\ud835\udc52\u2212\ud835\udc66(cid:3)\ud835\udc65\n\ud835\udc65=0\n(cid:16) (cid:17)\n= \ud835\udc50 (\ud835\udc52\ud835\udc65\u22121 \u2212\ud835\udc52\u2212\ud835\udc65 ) \u2212 (\ud835\udc520\u22121 \u2212\ud835\udc52\u22120)\n\u20135\u2013\n4 Website Visits\nYouhaveawebsitewhereonlyonevisitorcanbeonthesiteatatime,butthereisaninfinitequeue\nof visitors, so that immediately after a visitor leaves, a new visitor will come onto the website. On\naverage,visitorsleaveyourwebsiteafter5minutes.Assumethatthelengthofstayisexponentially\ndistributed.Wewillcalculatewhatistheprobabilitythatauserstaysmorethan10minutes.\na. Usingtherandomvariable \ud835\udc4b definedasabove,whatistheprobabilitythatauserstayslonger\nthan10mins?(i.e, \ud835\udc4b > 10).\n\ud835\udc43(\ud835\udc4b > 10) = 1\u2212 \ud835\udc39 \ud835\udc4b(10) = 1\u2212 (1\u2212\ud835\udc52\u221210\ud835\udf06 ) = \ud835\udc52\u22122 \u2248 0.1353\nb. Using the random variable\ud835\udc4c, defined as the number of users who leave your website over a\n10-minuteinterval,whatistheprobabilitythatauserstayslongerthan10mins?\nIf this problem doesn\u2019t convince you that the Poisson and Exponential RVs are coupled,\nthenI\u2019mnotsurewhatwill!Asdefinedabove, \ud835\udc4b \u223c Exp(\ud835\udf06 = 1).\n5\nAlternatively, we have that \ud835\udc4c is the number of users leaving on the website in the\nnext 10 minutes. The average number of users leaving is 2 users per 10 minutes.\n\ud835\udc4c \u223c Poi(\ud835\udf06 = 2).\n20\ud835\udc52\u22122\n\ud835\udc43(\ud835\udc4c = 0) =\n0!\n= \ud835\udc52\u22122 \u2248 0.1353 <END>"}
{"prompt": "Lecture notes from cs109_lec09_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 9: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n3 / 3 pts\nQuestion 1\nContinuous Distributions 2 / 2 pts\n1.1 Continuous Distributions: Specific Outcome 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Continuous Distributions: Expectation 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nMore Continuous Distributions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Continuous Distributions\n2 Points\nA continuous variable X is distributed according to the probability density\nfunction (PDF): f(x) = 1 for 1 \u2264 x \u2264 3, and f(x) = 0 otherwise. Notice that\n2\nX \u223c Uni(1,3).\nQ1.1 Continuous Distributions: Specific Outcome\n1 Point\nWhat is the probability that X = 1?\nf(1)\n\u222b1 f(x)dx = 1\n0 2\n0\nnot enough info\nQ1.2 Continuous Distributions: Expectation\n1 Point\nWhat is the expectation of X, E[X]?\n\u221e\n\u222b f(x)dx = 1\n\u2212\u221e\n\u221e\n\u222b xf(x)dx = 2\n\u2212\u221e\nf(2) = 1\n2\nf(1) + f(3) = 1\nQ2 More Continuous Distributions\n1 Point\nLet Y \u223c Uni(0,10), with PDF f(x). Which of the following are correct (select all\nthat apply).\nP(Y \u2264 2) = 1\n5\nP(4 \u2264 Y \u2264 5) = P(9 \u2264 Y \u2264 10)\nf(5) = 1\n10\nE[Y ] = 5\nE[Y ] = 10 <END>"}
{"prompt": "Lecture notes from 14_conditional_expectation_annotated.txt\n\n###\n\n", "completion": "14: Conditional\nExpectation\nJerry Cain\nMay 1st, 2024\nLecture Discussion on Ed\nDiscrete\nconditional\ndistributions\n2\nDiscrete conditional distributions\nRecall the definition of the conditional probability of event \ud835\udc38 given event \ud835\udc39:\n\ud835\udc43 \ud835\udc38\ud835\udc39\n\ud835\udc43 \ud835\udc38 \ud835\udc39 =\n\ud835\udc43 \ud835\udc39\nFor discrete random variables \ud835\udc4b and \ud835\udc4c, the conditional PMF of \ud835\udc4b given \ud835\udc4c is\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 =\n\ud835\udc43 \ud835\udc4c = \ud835\udc66\n\ud835\udc5d \ud835\udc65, \ud835\udc66\n!,#\n\ud835\udc5d \ud835\udc65|\ud835\udc66 =\nDifferent notation,\n!|#\n\ud835\udc5d \ud835\udc66\nsame idea: #\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nDiscrete probabilities of CS109\nJoint PMF\nEach student responds with:\n\ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3\nYear \ud835\udc4c\n\ud835\udc47 = \u22121 .06 .01 .01\n\u2022 1: Freshmen and Sophomores\n\ud835\udc47 = 0 .29 .14 .09\n\u2022 2: Juniors and Seniors\n\ud835\udc47 = 1 .30 .08 .02\n\u2022 3: Graduate Students and SCPD\n\ud835\udc43 \ud835\udc4c = 2, \ud835\udc47 = 1\nMood \ud835\udc47:\n\u2022 \u22121: \ud83d\ude15\n\u2022 \u22120: \ud83d\ude10\n\u2022 \u22121: \ud83e\udd70\nJoint PMFs sum to 1.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nDiscrete probabilities of CS109\nJoint PMF\nThe below are conditional probability\n\ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3\ntables for conditional PMFs\n\ud835\udc47 = \u22121 .06 .01 .01\n(A) \ud835\udc43 \ud835\udc4c = \ud835\udc66|\ud835\udc47 = \ud835\udc61 and (B) \ud835\udc43 \ud835\udc47 = \ud835\udc61|\ud835\udc4c = \ud835\udc66 .\n\ud835\udc47 = 0 .29 .14 .09\n1. Which is which?\n\ud835\udc47 = 1 .30 .08 .02\n2. What\u2019s the missing probability?\n\ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3 \ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3\n\ud835\udc47 = \u22121 .09 .04 .08 \ud835\udc47 = \u22121 .75 .125 ?\n\ud835\udc47 = 0 .45 .61 .75 \ud835\udc47 = 0 .56 .27 .17\n\ud835\udc47 = 1 .46 .35 .17 \ud835\udc47 = 1 .75 .2 .05\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nDiscrete probabilities of CS109\nJoint PMF\nThe below are conditional probability\n\ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3\ntables for conditional PMFs\n\ud835\udc47 = \u22121 .06 .01 .01\n(A) \ud835\udc43 \ud835\udc4c = \ud835\udc66|\ud835\udc47 = \ud835\udc61 and (B) \ud835\udc43 \ud835\udc47 = \ud835\udc61|\ud835\udc4c = \ud835\udc66 .\n\ud835\udc47 = 0 .29 .14 .09\n1. Which is which?\n\ud835\udc47 = 1 .30 .08 .02\n2. What\u2019s the missing probability?\n(B) \ud835\udc43 \ud835\udc47 = \ud835\udc61|\ud835\udc4c = \ud835\udc66 (A) \ud835\udc43 \ud835\udc4c = \ud835\udc66|\ud835\udc47 = \ud835\udc61\n\ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3 \ud835\udc4c = 1 \ud835\udc4c = 2 \ud835\udc4c = 3\n\ud835\udc47 = \u22121 .09 .04 .08 \ud835\udc47 = \u22121 .75 .125 .1?25 1-.75-.125\n\ud835\udc47 = 0 .45 .61 .75 \ud835\udc47 = 0 .56 .27 .17\n\ud835\udc47 = 1 .46 .35 .17 \ud835\udc47 = 1 .75 .2 .05\n.30/(.06+.29+.30) Conditional PMFs also sum to 1 conditioned on\ndifferent events!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\n\ud835\udc43 \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\nQuick check \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 =\n\ud835\udc43 \ud835\udc4c = \ud835\udc66\nNumber or function? True or false?\n1. \ud835\udc43 \ud835\udc4b = 2 \ud835\udc4c = 5 5.\n) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = 5 = 1\n!\n2. \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = 5 6. ) \ud835\udc43 \ud835\udc4b = 2|\ud835\udc4c = \ud835\udc66 = 1\n\"\n) ) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 = 1\n3. \ud835\udc43 \ud835\udc4b = 2 \ud835\udc4c = \ud835\udc66 7.\n! \"\n) ) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66 = 1\n4. \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 8.\n! \"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\n\ud835\udc43 \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66\nQuick check \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 =\n\ud835\udc43 \ud835\udc4c = \ud835\udc66\nNumber or function? True or false?\n1. \ud835\udc43 \ud835\udc4b = 2 \ud835\udc4c = 5 5.\n) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = 5 = 1 true\nnumber !\n2. \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = 5 6. ) \ud835\udc43 \ud835\udc4b = 2|\ud835\udc4c = \ud835\udc66 = 1 false\n\"\n1-D function\n) ) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 = 1 false\n3. \ud835\udc43 \ud835\udc4b = 2 \ud835\udc4c = \ud835\udc66 7.\n! \"\n1-D function\n) ) \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66 = 1 true\n4. \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc4c = \ud835\udc66 8.\n! \"\n2-D function\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nConditional\nExpectation\n9\nConditional expectation\nRecall the the conditional PMF of \ud835\udc4b given \ud835\udc4c = \ud835\udc66:\n\ud835\udc5d \ud835\udc65, \ud835\udc66\n!,#\n\ud835\udc5d \ud835\udc65|\ud835\udc66 = \ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 =\n!|#\n\ud835\udc5d \ud835\udc66\n#\nThe conditional expectation of \ud835\udc4b given \ud835\udc4c = \ud835\udc66 is\n\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = 3 \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 = 3 \ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66\n\"|$\n! !\n\u2022 Note that \ud835\udc38 \ud835\udc4b is a well-defined statistic even when \ud835\udc4b is one of many random\nvariables in a multivariate distribution: \ud835\udc38 \ud835\udc4b = \u2211 \u2211 \ud835\udc65\ud835\udc5d \ud835\udc65, \ud835\udc66\n! \" #,%\n\u2022 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 is the average value of \ud835\udc4b when \ud835\udc4c is constrained to take on a specific\nvalue of \ud835\udc66: \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = \u2211 \ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66\n! #,%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nIt\u2019s been so long, our dice friends \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = ,\ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66\n\"|$\n!\n\u2022 Roll two 6-sided dice.\n\u2022 Let roll 1 be \ud835\udc37 , roll 2 be \ud835\udc37 .\n% &\n\u2022 Let \ud835\udc46 = value of \ud835\udc37 + \ud835\udc37 .\n% &\n1. What is \ud835\udc38 \ud835\udc46|\ud835\udc37 = 6 ?\n\ud835\udc38 \ud835\udc46|\ud835\udc37 = 6 = ) \ud835\udc65\ud835\udc43 \ud835\udc46 = \ud835\udc65|\ud835\udc37 = 6\n&\n/ /\n!\n1\n= 7 + 8 + 9 + 10 + 11 + 12\n6\n57\n= = 9.5\n6\nIntuitively: 6 + \ud835\udc38 \ud835\udc37 = 6 + 3.5 = 9.5 We\u2019ll prove in a moment\n0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nProperties of conditional expectation\n1. LOTUS:\n\ud835\udc38 \ud835\udc54 \ud835\udc4b |\ud835\udc4c = \ud835\udc66 = ) \ud835\udc54 \ud835\udc65 \ud835\udc5d (\ud835\udc65|\ud835\udc66)\n#|%\n!\n2. Linearity of conditional expectation:\n3 3\n\ud835\udc38 ) \ud835\udc4b | \ud835\udc4c = \ud835\udc66 = ) \ud835\udc38 \ud835\udc4b |\ud835\udc4c = \ud835\udc66\n1 1\n120 120\n3. Law of total expectation (in, like, three slides)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nIt\u2019s been so long, our dice friends \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = ,\ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66\n\"|$\n!\n\u2022 Roll two 6-sided dice.\n\u2022 Let roll 1 be \ud835\udc37 , roll 2 be \ud835\udc37 .\n% &\n\u2022 Let \ud835\udc46 = value of \ud835\udc37 + \ud835\udc37 .\n% &\n57\n1. What is \ud835\udc38 \ud835\udc46|\ud835\udc37 = 6 ? = 9.5\n&\n6\n2. What is \ud835\udc38 \ud835\udc46|\ud835\udc37 ?\n&\nA. A function of \ud835\udc46\nB. A function of \ud835\udc37\n&\nC. A number\n3. Give an expression\nfor \ud835\udc38 \ud835\udc46|\ud835\udc37 .\n&\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nIt\u2019s been so long, our dice friends \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = ,\ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66\n\"|$\n!\n\u2022 Roll two 6-sided dice.\n\u2022 Let roll 1 be \ud835\udc37 , roll 2 be \ud835\udc37 .\n% &\n\u2022 Let \ud835\udc46 = value of \ud835\udc37 + \ud835\udc37 .\n% &\n57\n1. What is \ud835\udc38 \ud835\udc46|\ud835\udc37 = 6 ? = 9.5\n&\n6\n2. What is \ud835\udc38 \ud835\udc46|\ud835\udc37 ?\n&\n\ud835\udc38 \ud835\udc46|\ud835\udc37 = \ud835\udc51 = \ud835\udc38 \ud835\udc37 + \ud835\udc51 |\ud835\udc37 = \ud835\udc51\n/ / 0 / / /\nA. A function of \ud835\udc46\nB. A function of \ud835\udc37 = ) \ud835\udc51 + \ud835\udc51 \ud835\udc43 \ud835\udc37 = \ud835\udc51 |\ud835\udc37 = \ud835\udc51\n& 0 / 0 0 / /\nC. A number\n4\n! (\ud835\udc37 = \ud835\udc51 , \ud835\udc37 = \ud835\udc51\n% % & &\nindependent\n3. Give an expression\n= ) \ud835\udc51 \ud835\udc43 \ud835\udc37 = \ud835\udc51 + \ud835\udc51 ) \ud835\udc43 \ud835\udc37 = \ud835\udc51\n0 0 0 / 0 0 events)\nfor \ud835\udc38 \ud835\udc46|\ud835\udc37 .\n& 4 4\n! !\n= \ud835\udc38 \ud835\udc37 + \ud835\udc51 = 3.5 + \ud835\udc51\n0 / / \ud835\udc38 \ud835\udc46|\ud835\udc37 = 3.5 + \ud835\udc37\n& &\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nLaw of Total\nExpectation\n15\nProperties of conditional expectation\n1. LOTUS:\n\ud835\udc38 \ud835\udc54 \ud835\udc4b |\ud835\udc4c = \ud835\udc66 = ) \ud835\udc54 \ud835\udc65 \ud835\udc5d (\ud835\udc65|\ud835\udc66)\n#|%\n!\n2. Linearity of conditional expectation:\n3 3\n\ud835\udc38 ) \ud835\udc4b | \ud835\udc4c = \ud835\udc66 = ) \ud835\udc38 \ud835\udc4b |\ud835\udc4c = \ud835\udc66\n1 1\n120 120\n3. Law of total expectation:\n\ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c what?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nProof of Law of Total Expectation \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c\n\ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc38 \ud835\udc54 \ud835\udc4c = ) \ud835\udc43 \ud835\udc4c = \ud835\udc66 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 (LOTUS, \ud835\udc54 \ud835\udc4c = \ud835\udc38 \ud835\udc4b|\ud835\udc4c )\n\"\n(def of\n= ) \ud835\udc43 \ud835\udc4c = \ud835\udc66 ) \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66\nconditional\nexpectation)\n\" !\n= ) ) \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66 = ) ) \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 (chain rule)\n\" ! \" !\n= ) ) \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 = ) \ud835\udc65 ) \ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 (switch order of\nsummations)\n! \" ! \"\n= ) \ud835\udc65\ud835\udc43 \ud835\udc4b = \ud835\udc65\n(marginalization)\n!\n= \ud835\udc38 \ud835\udc4b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nAnother way to compute \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c\n\ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ) \ud835\udc43 \ud835\udc4c = \ud835\udc66 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = \ud835\udc38 \ud835\udc4b\n\"\nIf we only have a conditional PMF of \ud835\udc4b on some discrete variable \ud835\udc4c,\nwe can compute \ud835\udc38 \ud835\udc4b as follows:\n1. Compute expectation of \ud835\udc4b given some value of \ud835\udc4c = \ud835\udc66\n2. Repeat step 1 for all values of \ud835\udc4c\n3. Compute a weighted sum (where weights are \ud835\udc43 \ud835\udc4c = \ud835\udc66 )\ndef recurse():\nif random.random() < 0.5:\nreturn 3\nUseful for analyzing recursive code.\nreturn 2 + recurse()\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 \ud835\udc43 \ud835\udc4b = 1 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 \ud835\udc43 \ud835\udc4b = 2 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 \ud835\udc43 \ud835\udc4b = 3\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 = 3\nWhen \ud835\udc4b = 1, return 3.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nIf \ud835\udc4c discrete\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 \ud835\udc43 \ud835\udc4b = 1 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 \ud835\udc43 \ud835\udc4b = 2 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 \ud835\udc43 \ud835\udc4b = 3\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 = 3\nWhat is \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 ?\nA. \ud835\udc38 5 + \ud835\udc4c\nB. \ud835\udc38 5 + \ud835\udc4c = 5 + \ud835\udc38 \ud835\udc4c\n\ud83e\udd14\nC. 5 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nIf \ud835\udc4c discrete\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 \ud835\udc43 \ud835\udc4b = 1 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 \ud835\udc43 \ud835\udc4b = 2 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 \ud835\udc43 \ud835\udc4b = 3\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 = 3 When \ud835\udc4b = 2, return 5 +\na future return value of .\nrecurse()\nWhat is \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 ?\nA. \ud835\udc38 5 + \ud835\udc4c\nB. \ud835\udc38 5 + \ud835\udc4c = 5 + \ud835\udc38 \ud835\udc4c\nC. 5 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nIf \ud835\udc4c discrete\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 \ud835\udc43 \ud835\udc4b = 1 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 \ud835\udc43 \ud835\udc4b = 2 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 \ud835\udc43 \ud835\udc4b = 3\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 = 3 \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 = 5 + \ud835\udc38 5 + \ud835\udc4c When \ud835\udc4b = 3, return\n7 + a future return value\nof recurse().\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 = \ud835\udc38 7 + \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nIf \ud835\udc4c discrete\nAnalyzing recursive code \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc38 \ud835\udc4b|\ud835\udc4c = ,\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\u2019\ndef recurse():\n# equally likely values 1,2,3\nLet \ud835\udc4c = return value of recurse().\nx = np.random.choice([1,2,3])\nif x == 1: return 3 What is \ud835\udc38 \ud835\udc4c ?\nif x == 2: return 5 + recurse()\nreturn 7 + recurse()\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 \ud835\udc43 \ud835\udc4b = 1 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 \ud835\udc43 \ud835\udc4b = 2 + \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 \ud835\udc43 \ud835\udc4b = 3\n\ud835\udc38 \ud835\udc4c|\ud835\udc4b = 1 = 3 \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 2 = 5 + \ud835\udc38 \ud835\udc4c \ud835\udc38 \ud835\udc4c|\ud835\udc4b = 3 = 7 + \ud835\udc38 \ud835\udc4c\n\ud835\udc38 \ud835\udc4c = 3 1/3 + 5 + \ud835\udc38 \ud835\udc4c 1/3 + 7 + \ud835\udc38 \ud835\udc4c 1/3\n\ud835\udc38 \ud835\udc4c = 1/3 15 + 2\ud835\udc38 \ud835\udc4c = 5 + 2/3 \ud835\udc38 \ud835\udc4c\nOn your own: What is Var \ud835\udc4c ?\n\ud835\udc38 \ud835\udc4c = 15\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nIndependent RVs, defined another way\nIf \ud835\udc4b and \ud835\udc4c are independent discrete random variables, then \u2200\ud835\udc65, \ud835\udc66:\n\ud835\udc43 \ud835\udc4b = \ud835\udc65, \ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\ud835\udc43 \ud835\udc4b = \ud835\udc65|\ud835\udc4c = \ud835\udc66 = = = \ud835\udc43 \ud835\udc4b = \ud835\udc65\n\ud835\udc43 \ud835\udc4c = \ud835\udc66 \ud835\udc43 \ud835\udc4c = \ud835\udc66\n\ud835\udc5d \ud835\udc65, \ud835\udc66 \ud835\udc5d \ud835\udc65 \ud835\udc5d \ud835\udc66\n\",$ \" $\n\ud835\udc5d \ud835\udc65|\ud835\udc66 = = = \ud835\udc5d \ud835\udc65\n\"|$ \"\n\ud835\udc5d \ud835\udc66 \ud835\udc5d \ud835\udc66\n$ $\nNote for conditional expectation, independent \ud835\udc4b and \ud835\udc4c implies\n\ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = 3 \ud835\udc65\ud835\udc5d \ud835\udc65|\ud835\udc66 = 3 \ud835\udc65\ud835\udc5d \ud835\udc65 = \ud835\udc38 \ud835\udc4b\n\"|$ \"\n! !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nindep \ud835\udc4b,\ud835\udc4c\nRandom number of random variables \ud835\udc38 \ud835\udc4b|\ud835\udc4c = \ud835\udc66 = \ud835\udc38 \ud835\udc4b\nSuppose you have a website: dorisisthebeast.com. Let:\n\u2022 \ud835\udc4b = # of people per day who visit your site. \ud835\udc4b~Poi 50\n\u2022 \ud835\udc4c = # of minutes spent per day by visitor \ud835\udc56 \ud835\udc4c~Poi 11\n1 1\n\u2022 \ud835\udc4b and all \ud835\udc4c are independent.\n1 #\nThe time spent by all visitors per day is \ud835\udc4a = ) \ud835\udc4c . What is \ud835\udc38 \ud835\udc4a ?\n1\n120\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nRandom number of random variables\nSuppose you have a website: dorisisthebeast.com. Let:\n\u2022 \ud835\udc4b = # of people per day who visit your site. \ud835\udc4b~Poi 50\n\u2022 \ud835\udc4c = # of minutes spent per day by visitor \ud835\udc56. \ud835\udc4c~Poi 11\n1 1\n\u2022 \ud835\udc4b and all \ud835\udc4c are independent.\n1 #\nThe time spent by all visitors per day is \ud835\udc4a = ) \ud835\udc4c . What is \ud835\udc38 \ud835\udc4a ?\n1\n120\n# #\n\ud835\udc38 \ud835\udc4a = \ud835\udc38 ) \ud835\udc4c = \ud835\udc38 \ud835\udc38 ) \ud835\udc4c |\ud835\udc4b Suppose \ud835\udc4b = \ud835\udc65.\n1 1\n120 120 \" \"\n\ud835\udc38 /\ud835\udc4c |\ud835\udc4b = \ud835\udc65 = /\ud835\udc38 \ud835\udc4c|\ud835\udc4b = \ud835\udc65 (linearity)\n! !\n! !#$\n!\n= \ud835\udc38 \ud835\udc4b\ud835\udc38 \ud835\udc4c\n0\n= ) \ud835\udc38 \ud835\udc4c (independence)\n1\n= \ud835\udc38 \ud835\udc4c \ud835\udc38 \ud835\udc4b (scalar \ud835\udc38 \ud835\udc4c )\n0 ! 120\n= \ud835\udc65\ud835\udc38 \ud835\udc4c\n1\n= 11 \u22c5 50 = 550\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27 <END>"}
{"prompt": "Lecture notes from CS109 _ Syllabus.txt\n\n###\n\n", "completion": "1/21/25, 1:16 PM CS109 | Syllabus\nCS109 Course Overview\nUPDATED 10 MONTHS AGO\nIf you have any questions after reading this overview, head on over to our FAQ page, post on our\ndiscussion forum, or email us at cs109@cs.stanford.edu.\nCS109: Probability for Computer Scientists starts by providing a fundamental grounding in\ncombinatorics, and then quickly moves into the basics of probability theory. We will then cover many\nessential concepts in probability theory, including common probability distributions, properties of\nprobabilities, and mathematical tools for analyzing probabilities. The last third of the class will focus\non data analysis and machine learning as direct applications of probability we've learned in the\nweeks prior. Read more here to learn what CS109 is all about. This is going to be a great quarter\nand we are looking forward to the chance to teach you!!\nTeaching Team\nLecturer: Jerry Cain\n\uf0e0jerry@cs.stanford.edu\n\uf017Office Hours: Wed, 4:30 - 7:00 pm, Huang [Week 2 onward]\nSuperstar CS109 CAs!\nI. Course Overview\nPrerequisites\nThe prerequisites for this course are CS103, CS106B, and Math 51 (or equivalent courses).\nProbability involves a fair bit of mathematics (set theory, calculus, and familiarity with linear algebra),\nand we'll be considering several applications that require you're familiar with algorithms and data\nstructures covered in CS106B. Here is a quick rundown of some of the mathematical tools from\nCS103 and Math 51 that we'll be using in this class: multivariate calculus (integration and\ndifferentiation), linear algebra (basic operations on vectors and matrices), an understanding of the\nbasics of set theory (subsets, complements, unions, intersections, cardinality, etc.), and familiarity\nwith basic proof techniques. We'll also rely on combinatorics, but we cover a fair bit of that ourselves\nhttps://web.stanford.edu/class/archive/cs/cs109/cs109.1246/handouts/syllabus.html 1/5\n1/21/25, 1:16 PM CS109 | Syllabus\nduring the first week. Past students have managed to take CS106B concurrently with CS109 and\nhave done just fine. CS103 is the pre-requisite that we rely on the least, any many take CS109 before\ntaking CS103. See our FAQ for more information.\nLearning Goals\nAfter you're done with CS109, you'll be able to:\nreason about situations using probabilities, expectation, and variance.\nfeel comfortable learning about new probability concepts beyond the scope of this class (e.g.,\nthrough one's own research, studies, or interests).\nwrite programs to simulate random experiments and to test experiment hypotheses.\nunderstand and implement simple machine learning algorithms like Naive Bayes and Logistic\nRegression.\nCourse Topics\nHere are the high-level themes of the course (in approximate order). We cover a very broad set of\ntopics so that you are equipped with the probability and statistics you will see in future CS classes.\ncounting and probability fundamentals\nsingle-dimensional random variables\nprobabilistic models\nuncertainty theory and inference\nparameter estimation\nintroductory machine learning\nII. Course Structure\nUnits\nIf you are an undergraduate, you are required to take CS109 for 5 units of credit (this is by\ndepartment and university policy, no exceptions). If you are a graduate student, you may enroll in\nCS109 for 3 or 4 units if it is necessary for you to reduce your units for administrative reasons. Taking\nthe course for reduced units does not imply any change in the course requirements.\nLectures\nWe will be holding live lectures MWF at 3:00pm, and I'll lecture for no more than 80 minutes, and\noften less. (The 4:20pm end time is a limit, but not a goal.) Come to learn the material and engage in\ninteresting problems collectively with the class. While lecture attendance isn't mandatory, it is\ncorrelated with doing well in the course and mastering the material. If you can't make lecture time,\nyou can watch the lectures on Canvas.\nSections\nActive participation plays an important role in making you a master of probability for computer\nscience. It has also been observed over many quarters that keeping up with the material highly\ncorrelates with class performance.\nEach week for 50 minutes you will meet in a small group with one of our outstanding CAs and work\nthrough problems. If you have taken any of the CS106 classes, our sections will be very similar\u2014\nexcept with more probability.\nGrading\nYour final grade is computed as follows:\nComponent Final Grade Contribution\nConcept Checks 10%\nWeekly Problem Sets (6 x 7%) 42%\nMid-Quarter Exams (2 x 11%) 22%\nFinal Exam 21 - 26%\nhttps://web.stanford.edu/class/archive/cs/cs109/cs109.1246/handouts/syllabus.html 2/5\n1/21/25, 1:16 PM CS109 | Syllabus\nComponent Final Grade Contribution\nSection Participation 0 - 5%\nConcept Checks\nCS109 moves quickly, so staying on top of the material is key to success in the class. To help you\nkeep pace, we post a \"concept check\" by 9:00pm on Monday, Wednesday, and Friday evenings.\nEach Concept check requires you answer a small number of questions exercising material introduced\nduring that day's lecture.\nRecognizing that many of you will prefer to watch or rewatch lecture videos over the course of a\nweekend, we'll allow all three of a week's concept checks to be submitted by noon the following\nTuesday. Restated, Week 1's concept checks will fall due at 12:00pm on the Tuesday of Week 2,\nWeek 2's concept checks will fall due at 12:00pm on the Tuesday of Week 3, and so forth. Of course,\nyou benefit by working through the concept checks as quickly as possible, but we also understand\nthat sometimes you just need to ignore a class for a few days and catch up later on.\nUnless you're enduring a family emergency or a severe illness, you can't submit concept checks\nafter the Tuesday deadline. In particular, we can't extend deadlines just because you're busy or you\nforgot. I want to be that cool professor that cuts you a break, but I cut breaks with problem set\ndeadlines, not concept check deadlines. The concept checks don't serve their purpose of keeping\nyou on schedule if we allow the deadlines to slip.\nProblem Sets\nDuring the course, there will be six problem sets assigned. Each student is to submit individual\nwork for the problem sets . You may discuss with other students and course staff, but you must\ncite all discussion on your individually written final write-up of the problem set. All homework\nassignments should be turned in at the beginning of class on the published due date.\nLate Policy (Problem Sets)\nWe anticipate that there may be unforeseen circumstances that make it difficult to turn in homework\nassignments on time. As opposed to the concept checks, the problem sets require a serious time\ninvestment and sometimes they just don't come together by the published deadline.\nAll students will be granted a penalty-free \"grace period\" for submission on all problem sets\n(except the final assignment). The grace period is one full class day and allows you to submit\nthe assignment after the original deadline, with no impact on the final grade. As an example, a\nproblem set due on Monday at 3:00pm may be turned in on Wednesday before 3:00pm to\nsubmit for full credit, or problem set due on Friday at 3:00pm may be turned in on the following\nMonday before 3:00pm Pacific to submit for full credit. This grace period is meant to give built-\nin flexibility for any unexpected snags\u2014however, we strongly recommend that students submit\nby the original deadline if possible, in order to avoid falling behind.\nYou are permitted to grant yourself additional penalty-free extensions\u2014beyond even the first\nself-granted extension\u2014as needed, though you need to email Jerry to let him know you need\nthe additional time. In general, you are never penalized for lateness provided you submit an\nassignment within two class periods of the original due date. We'd rather you do good work on\nthe assignment and understand the material than rush to meet some deadline and put off the\nlearning even longer than you already are.\nSections\nSection attendance and participation is required of all on-campus students. Students are allowed\none unexcused absence\u2014one for which you simply don't show up and don't tell us why\u2014in the\nquarter without penalty. Understand that absences can only be excused because of severe illness,\nCOVID isolation, family emergency, or Stanford-sponsored business or collegiate athletics travel.\nRegardless of why you miss section, you're responsible for all section handout content and\nunderstanding all problems and solutions.\nYour section grade is automatically a 100%. If you attend all sections, then you're awesome and your\nsection grade counts 5% toward your final grade. For every section you miss, your section grade\ncounts 1% less and your final exam grade counts 1% more. If you miss five or more sections, then\nyour section grade doesn't contribute to your final grade.\nhttps://web.stanford.edu/class/archive/cs/cs109/cs109.1246/handouts/syllabus.html 3/5\n1/21/25, 1:16 PM CS109 | Syllabus\nExams\nIn addition to the assignments, there will be two in-class exams during Weeks 4 and 7, and an in-\nclass final exam during our regularly scheduled final exam slot.\nWeek 4 Exam: Wednesday, April 24th, 7:00 - 9:00pm, Cemex Auditorium\nWeek 7 Exam: Wednesday, May 15th, 7:00 - 9:00pm, Cemex Auditorium\nFinal Exam: Saturday, June 8th, 8:30 - 11:30am, location TBD by Registrar\nEach of the two mid-quarter exams are traditional, pencil-on-paper exams, save for the fact that\nthey are held at night so that we can give you more time to complete them. Each of the two mid-\nquarter exams is closed-book, closed-calculator, closed-computer, although you are permitted to\nprepare and bring two pages\u2014front and back\u2014of notes with you and refer to them during the exam.\nExams cover the material you have learned in the class lectures, class handouts, concept checks,\nand assignments.\nThose holding conflicts with the evening exams for anything reasonable are permitted to take the\nexam at an earlier time the same day. And SCPD students are expected to take the exams remotely\nanytime on the Thursday or Friday, once any typos or confusing sentences clarified during the live\nexam can be incorporated into the version sent to SCPD.\nThe final exam will be a traditional in-class, pencil on paper, closed-book, closed-calculator, closed-\ncomputer exam, though you're permitted to bring four double-sided pages of notes instead of just\ntwo. The final exam is scheduled for Saturday, June 8th from 8:30 - 11:30am. For those (and only\nthose) with competing final exams because of concurrent enrollment in another MWF 3:00pm class,\nI'll allow you to take the final on Friday, June 7th from 12:15pm until 3:15pm.\nExtra Credit Contest\nCS109 has traditionally held an extra credit contest, where students apply the principles in this class\nto explore a topic of their own choice. Participation in the contest is completely optional and prizes\ninvolve extra credit to your final course grade. More details about the contest to be posted midway\nthrough the quarter.\nIII. Course Resources\nOptional Textbook\nSheldon Ross, A First Course in Probability (10th Ed.), Pearson Prentice Hall, 2018.\nThis is an optional textbook, meaning that the text is not required material, but students may find\nRoss offers a different and useful perspective on important concepts of the class. Suggested,\noptional reading assignments from the textbook (10th Ed.) are in the schedule on the course\nwebsite. The 8th, 9th, and 10th editions of the textbook are all fine for this class.\nBorrowing the textbook online: HathiTrust, a library archive of which Stanford is a member, has\ngranted the university online access to the 8th edition (2010) for the duration of the Fall quarter. The\n\"check out\" system works similarly to print reserves: A user can check out the book an hour at a time\nas long as they are actively using it. Access guidelines are on the HathiTrust How To Use It\nwebpage. Once you're logged in, the book is at this link.\nAll students should retain receipts for books and other course-related expenses, as these may be\nqualified educational expenses for tax purposes. If you are an undergraduate receiving financial aid,\nyou may be eligible for additional financial aid for required books and course materials if these\nexpenses exceed the aid amount in your award letter. For more information, review your award letter\nor visit the Student Budget website.\n\"Working\" Office Hours\nTo help make you more successful in this class, the course staff will hold \"working\" office hours. The\nidea is to encourage you to work on your problem sets at these office hours, so you can immediately\nask any questions that come up while working on them. While you are certainly not required to\nattend any of these hours, they are simply meant to encourage you to interact with the staff more\noften in order to help you better understand the material. Besides, our job is to help everyone learn\nthe material for this class, and being more accessible to you when you are actually working on your\nassignments (rather than when you just have a problem) will help the course go more smoothly.\nhttps://web.stanford.edu/class/archive/cs/cs109/cs109.1246/handouts/syllabus.html 4/5\n1/21/25, 1:16 PM CS109 | Syllabus\nAccommodations\nStudents who may need an academic accommodation based on the impact of a disability must\ninitiate the request with the Office of Accessible Education (OAE). Professional staff will evaluate the\nrequest with required documentation, recommend reasonable accommodations, and prepare an\nAccommodation Letter for faculty. For students who have disabilities that don't typically change\nappreciably over time, the letter from the OAE will be for the entire academic year; other letters will\nbe for the current quarter only. Students should contact the OAE as soon as possible since timely\nnotice (for example, at least a week before an exam) is needed to coordinate accommodations.\nStudents should also send your accommodation letter to instructors as soon as possible. If you\nrequire additional, or different, accommodations specific to the Spring 2022 learning\nenvironment, please contact your OAE adviser.\nIV. Honor Code\nEach student is expected to submit their own work on the CS109 problem sets. Students may\ndiscuss problem sets with each other as well as the course staff, and you can even confirm a final\nnumeric result so you know that you've computed the correct answer. You may not, however, present\nanother person's reasoning behind a proof or result as your own. Any discussion of problem set\nquestions with others should be noted on a student's final write-up of the problem set\nanswers. Each student must turn in their own solution. Excessive collaboration can result in honor\ncode violations. Questions regarding acceptable collaboration should be directed to the class\ninstructor prior to the collaboration.\nIt is a violation of the honor code to copy problem set from others, or to copy or derive them\nfrom solutions found online or in textbooks, previous instances of this course, interactions\nwith LLMs, or any other courses covering the same topics (e.g., Stats 116 or probability\ncourses at other schools). Copying of solutions from students who previously took this or a similar\ncourse is also a violation of the honor code. Finally, a good point to keep in mind is that you must be\nable to explain and/or re-derive anything that you submit.\nPlease read our full Honor Code Policy, which specifically prohibits you from soliciting or taking\nsolutions from other students or websites like Stack Overflow and Chegg.\nLooking Forward to a Great Quarter\nTeaching CS109 is a profound joy. Thanks for coming to learn with us. We can't wait \ud83c\udf31.\nhttps://web.stanford.edu/class/archive/cs/cs109/cs109.1246/handouts/syllabus.html 5/5 <END>"}
{"prompt": "Lecture notes from 03_probability_annotated.txt\n\n###\n\n", "completion": "03: Intro to Probability\nJerry Cain and Kanu Grover\nApril 3rd, 2024\nLecture Discussion on Ed\n1\nDefining\nProbability\n2\nKey definitions\nAn experiment in probability:\nOutcome\nExperiment\n\ud835\udc38\n\ud835\udc46\nSample Space, \ud835\udc46: The set of all possible outcomes of an experiment\nEvent, \ud835\udc38: Some subset of \ud835\udc46 (\ud835\udc38 \u2286 \ud835\udc46).\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nKey definitions\nSample Space, \ud835\udc46 Event, \ud835\udc38\n\u2022 Coin flip \u2022 Flip lands heads\n\ud835\udc46 = Heads, Tails \ud835\udc38 = Heads\n\u2022 Flipping two coins \u2022 \u2265 1 head in two coin flips\n\ud835\udc46 = (H,H), (H,T), (T,H), (T,T) \ud835\udc38 = (H,H), (H,T), (T,H)\n\u2022 Roll of 6-sided die \u2022 Roll is 3 or less:\n\ud835\udc46 = {1, 2, 3, 4, 5, 6} \ud835\udc38 = 1, 2, 3\n\u2022 # emails in a day \u2022 Low email day (\u2264 100 emails)\n\ud835\udc46 = \ud835\udc65 | \ud835\udc65 \u2208 \u2124, \ud835\udc65 \u2265 0 \ud835\udc38 = \ud835\udc65 | \ud835\udc65 \u2208 \u2124, 0 \u2264 \ud835\udc65 \u2264 100\n\u2022 TikTok hours in a day \u2022 Lost day (\u2265 5 TikTok hours):\n\ud835\udc46 = \ud835\udc65 | \ud835\udc65 \u2208 \u211d, 0 \u2264 \ud835\udc65 \u2264 24 \ud835\udc38 = \ud835\udc65 | \ud835\udc65 \u2208 \u211d, 5 \u2264 \ud835\udc65 \u2264 24\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nWhat is a probability?\nA number between 0 and 1\nto which we ascribe meaning.*\n*our belief that an event \ud835\udc38 occurs.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nWhat is a probability?\nLet \ud835\udc38 = the set of outcomes\nwhere you hit the target.\n\ud835\udc5b(\ud835\udc38)\n\ud835\udc43 \ud835\udc38 = lim\n\ud835\udc5b\n!\u2192#\n\ud835\udc5b = # of total trials\n\ud835\udc5b(\ud835\udc38) = # trials where \ud835\udc38 occurs\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nWhat is a probability?\nLet \ud835\udc38 = the set of outcomes\nwhere you hit the target.\n\ud835\udc5b(\ud835\udc38)\n\ud835\udc43 \ud835\udc38 = lim\n\ud835\udc5b\n!\u2192#\n\ud835\udc5b = # of total trials\n\ud835\udc5b(\ud835\udc38) = # trials where \ud835\udc38 occurs\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nWhat is a probability?\nLet \ud835\udc38 = the set of outcomes\nwhere you hit the target.\n\ud835\udc5b(\ud835\udc38)\n\ud835\udc43 \ud835\udc38 = lim\n\ud835\udc5b\n!\u2192#\n\ud835\udc5b = # of total trials\n\ud835\udc5b(\ud835\udc38) = # trials where \ud835\udc38 occurs\n\ud835\udc43 \ud835\udc38 \u2248 0.500\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nWhat is a probability?\nLet \ud835\udc38 = the set of outcomes\nwhere you hit the target.\n\ud835\udc5b(\ud835\udc38)\n\ud835\udc43 \ud835\udc38 = lim\n\ud835\udc5b\n!\u2192#\n\ud835\udc5b = # of total trials\n\ud835\udc5b(\ud835\udc38) = # trials where \ud835\udc38 occurs\n\ud835\udc43 \ud835\udc38 \u2248 0.667\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nWhat is a probability?\nLet \ud835\udc38 = the set of outcomes\nwhere you hit the target.\n\ud835\udc5b(\ud835\udc38)\n\ud835\udc43 \ud835\udc38 = lim\n\ud835\udc5b\n!\u2192#\n\ud835\udc5b = # of total trials\n\ud835\udc5b(\ud835\udc38) = # trials where \ud835\udc38 occurs\n\ud835\udc43 \ud835\udc38 \u2248 0.458\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nAxioms of\nProbability\n11\nQuick review of sets Review\nS \ud835\udc38 and \ud835\udc39 are events in \ud835\udc46.\nExperiment:\nDie roll\nE F\n\ud835\udc46 = 1, 2, 3, 4, 5, 6\nLet \ud835\udc38 = 1, 2 , and \ud835\udc39 = 2,3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nQuick review of sets Review\nS \ud835\udc38 and \ud835\udc39 are events in \ud835\udc46.\nExperiment:\nDie roll\nE F\n\ud835\udc46 = 1, 2, 3, 4, 5, 6\nLet \ud835\udc38 = 1, 2 , and \ud835\udc39 = 2,3\ndef Union of events, \ud835\udc38 \u222a \ud835\udc39\n\ud835\udc38 \u222a \ud835\udc39 = {1,2,3}\nThe event containing all outcomes\nin \ud835\udc38 or \ud835\udc39.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nQuick review of sets Review\nS \ud835\udc38 and \ud835\udc39 are events in \ud835\udc46.\nExperiment:\nDie roll\nE F\n\ud835\udc46 = 1, 2, 3, 4, 5, 6\nG Let \ud835\udc38 = 1, 2 , and \ud835\udc39 = 2,3\ndef Intersection of events, \ud835\udc38 \u2229 \ud835\udc39\n\ud835\udc38 \u2229 \ud835\udc39 = \ud835\udc38\ud835\udc39 = {2}\nThe event containing all outcomes\nin \ud835\udc38 and \ud835\udc39.\ndef Mutually exclusive events \ud835\udc39\nand \ud835\udc3a means that \ud835\udc39 \u2229 \ud835\udc3a = \u2205\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nQuick review of sets Review\nS \ud835\udc38 and \ud835\udc39 are events in \ud835\udc46.\nExperiment:\nDie roll\nE F\n\ud835\udc46 = 1, 2, 3, 4, 5, 6\nLet \ud835\udc38 = 1, 2 , and \ud835\udc39 = 2,3\n!\ndef Complement of event \ud835\udc38, \ud835\udc38\n!\n\ud835\udc38 = {3, 4, 5, 6}\nThe event containing all outcomes\nin that are not in \ud835\udc38.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nThree Axioms of Probability\n\"(&)\nDefinition of probability: \ud835\udc43 \ud835\udc38 = lim\n\"\u2192$ \"\nAxiom 1: 0 \u2264 \ud835\udc43 \ud835\udc38 \u2264 1\nAxiom 2: \ud835\udc43 \ud835\udc46 = 1\nAxiom 3: If \ud835\udc38 and \ud835\udc39 are mutually exclusive (\ud835\udc38 \u2229 \ud835\udc39 = \u2205),\nthen \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 = \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nAxiom 3 is the (analytically) useful axiom\nAxiom 3: If \ud835\udc38 and \ud835\udc39 are mutually exclusive\u2014that is, if\n\ud835\udc38 \u2229 \ud835\udc39 = \u2205\u2014then \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 = \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39\n$\n$\nMore generally, for any sequence of\n\ud835\udc43 O \ud835\udc38 = P \ud835\udc43 \ud835\udc38\nmutually exclusive events \ud835\udc38 , \ud835\udc38 , \u2026 : * *\n( )\n*+(\n*+(\n\ud835\udc38\n! \ud835\udc38 just like the Sum Rule of Counting, but\n\"\nfor probabilities\n\ud835\udc38\n#\n\ud835\udc46\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nEqually Likely\nOutcomes\n18\nEqually Likely Outcomes\nSome sample spaces have equally likely outcomes.\n\u2022 Flipping one coin: S = {Head, Tails}\n\u2022 Flipping two coins: S = {(H, H), (H, T), (T, H), (T, T)}\n\u2022 Roll of 6-sided die: S = {1, 2, 3, 4, 5, 6}\n1\n=\nIf we have equally likely outcomes, then P(Each outcome)\n|\ud835\udc46|\n|\ud835\udc38|\n# outcomes in E\n=\n\ud835\udc43(\ud835\udc38) = (by Axiom 3)\nTherefore\n|\ud835\udc46|\n# outcomes in S\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\n|\ud835\udc38| Equally likely\nRoll two dice\n\ud835\udc43 \ud835\udc38 =\n|\ud835\udc46| outcomes\nRoll two 6-sided fair dice. What is P(sum = 7)?\n\ud835\udc46 = { (1, 1) , (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n(2, 1) , (2, 2), (2, 3), (2, 4), (2, 5), (2, 6),\n(3, 1) , (3, 2), (3, 3), (3, 4), (3, 5), (3, 6),\n(4, 1) , (4, 2), (4, 3), (4, 4), (4, 5), (4, 6),\n(5, 1) , (5, 2), (5, 3), (5, 4), (5, 5), (5, 6),\n(6, 1) , (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)}\n\ud835\udc38 =\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\n|\ud835\udc38| Equally likely\nTarget revisited\n\ud835\udc43 \ud835\udc38 =\n|\ud835\udc46| outcomes\nLet \ud835\udc38 = the set of outcomes Screen size = 800 \u00d7800\nwhere you hit the target.\nRadius of target: 200\nThe dart is equally likely to land\nanywhere on the screen. What is \ud835\udc43 \ud835\udc38 ,\nthe probability of hitting the target?\n) )\n\ud835\udc46 = 800 \ud835\udc38 \u2248 \ud835\udf0b \u22c5 200\n)\n\ud835\udc38 \ud835\udf0b \u22c5 200\n\ud835\udc43 \ud835\udc38 = \u2248 \u2248 0.1963\n\ud835\udc46 800)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n|\ud835\udc38| Equally likely\nCats and sharks (note: stuffed animals)\n\ud835\udc43 \ud835\udc38 =\n|\ud835\udc46| outcomes\n4 cats and 3 sharks in a bag. 3 drawn.\nMake indistinct items distinct\nWhat is P(1 cat and 2 sharks drawn)? to get equally likely outcomes.\nU\nA.\nV\nQuestion: Do indistinct objects give\nW Y\nyou an equally likely sample space?\n\u22c5\nB.\nX U\nX U\n+ 2 \u22c5\n(No) C.\nV Z\nWY\nD.\nU[\nE. 0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\n|\ud835\udc38| Equally likely\nCats and sharks (ordered solution)\n\ud835\udc43 \ud835\udc38 =\n|\ud835\udc46| outcomes\n4 cats and 3 sharks in a bag. 3 drawn.\nMake indistinct items distinct\nWhat is P(1 cat and 2 sharks drawn)? to get equally likely outcomes.\nDefine\n\u2022 \ud835\udc46 = Pick 3 distinct\nitems\n\u2022 \ud835\udc38 = 1 distinct cat,\n2 distinct\nsharks\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\n|\ud835\udc38| Equally likely\nCats and sharks (unordered solution)\n\ud835\udc43 \ud835\udc38 =\n|\ud835\udc46| outcomes\n4 cats and 3 sharks in a bag. 3 drawn.\nMake indistinct items distinct\nWhat is P(1 cat and 2 sharks drawn)? to get equally likely outcomes.\nDefine\n\u2022 \ud835\udc46 = Pick 3 distinct\nitems\n\u2022 \ud835\udc38 = 1 distinct cat,\n2 distinct\nsharks\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nExercises\n25\nCS109 so far Review\nCounting tasks on ! objects\nEqually likely\nSort objects Choose \" objects Put objects in # outcomes:\n(permutations) (combinations) buckets\n|\ud835\udc38|\nDistinct\n\ud835\udc43 \ud835\udc38 =\nDistinct Some\n|\ud835\udc46|\n(distinguishable) distinct Distinct Indistinct\n1group \" groups\n#! # # #+\"\u22121 !\n#! \"$\n# !!# \"!\u22ef# #! $ # !,# \",\u22ef,# # #! \"\u22121 !\nCombinatorics Probability\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nCounting? Probability? Distinctness? Review\nWe choose 3 books from a set of\n4 distinct (distinguishable) and 2 indistinct (indistinguishable) books.\nEach set of 3 books is equally likely.\nLet event \ud835\udc38 = our choice excludes one or both indistinct books.\n1. How many distinct outcomes are in \ud835\udc38?\n2. What is \ud835\udc43 \ud835\udc38 ?\nreport\ndistinct, make indistinct\ncount\nequally likely\noutcomes keep\ndisti\nnct compute\nprobability\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nPoker Straights and Computer Chips\n1. Consider equally likely 5-card poker hands.\n\u2022 What is an example of an\n\u2022 Define \"poker straight\" as 5 consecutive equally likely outcome?\nrank cards of any suit \u2022 Should objects be\nordered or unordered?\nWhat is P(poker straight)?\n2. Computer chips: \ud835\udc5b chips are manufactured, 1 of which is defective.\n\ud835\udc58 chips are randomly selected from \ud835\udc5b for testing.\nWhat is P(defective chip is in \ud835\udc58 selected chips?)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n1. Any Poker Straight\nConsider equally likely 5-card poker hands.\n\u2022 \"straight\" is 5 consecutive rank cards of any suit\nWhat is P(Poker straight)?\nDefine\n\u2022 \ud835\udc46 (unordered)\n\u2022 \ud835\udc38 (unordered,\nconsistent with S)\nCompute \ud835\udc43 Poker straight =\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n2. Chip defect detection\n\ud835\udc5b chips are manufactured, 1 of which is defective.\n\ud835\udc58 chips are randomly selected from \ud835\udc5b for testing.\nWhat is \ud835\udc43(defective chip is in \ud835\udc58 selected chips?)\nDefine\n\u2022 \ud835\udc46 (unordered)\n\u2022 \ud835\udc38 (unordered,\nconsistent with S)\n\ud835\udc43 \ud835\udc38 =\nCompute\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\n2. Chip defect detection, solution #2\n\ud835\udc5b chips are manufactured, 1 of which is defective.\n\ud835\udc58 chips are randomly selected from \ud835\udc5b for testing.\nWhat is P(defective chip is in \ud835\udc58 selected chips?)\nRedefine experiment\n1. Choose \ud835\udc58 indistinct chips (1 way)\n2. Throw a dart and make one defective\nDefine\n\u2022 \ud835\udc46 (unordered)\n\u2022 \ud835\udc38 (unordered,\nconsistent with S)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nCorollaries of\nProbability\n32\n3 Corollaries of Axioms of Probability\n!\nCorollary 1: \ud835\udc43 \ud835\udc38 = 1 \u2212 \ud835\udc43(\ud835\udc38)\nCorollary 2: If \ud835\udc38 \u2286 \ud835\udc39, then \ud835\udc43 \ud835\udc38 \u2264 \ud835\udc43(\ud835\udc39)\nCorollary 3: \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 = \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39 \u2212 \ud835\udc43 \ud835\udc38\ud835\udc39\n(Inclusion-Exclusion Principle for Probability)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nSelecting Programmers\n\u2022 P(student programs in Python) = 0.28\n\u2022 P(student programs in C++) = 0.07\n\u2022 P(student programs in Python and C++) = 0.05.\nWhat is P(student does not program in (Python or C++))?\n1. Define events 2. Identify known 3. Solve\n& state goal probabilities\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nInclusion-Exclusion Principle (Corollary 3)\nCorollary 3: \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 = \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39 \u2212 \ud835\udc43 \ud835\udc38\ud835\udc39\n)\n) ,\n,-!\nGeneral form: \ud835\udc43 \u222a \ud835\udc38 = \u2019 \u22121 \u2019 \ud835\udc43 \u2229 \ud835\udc38\n* *\n*+! 0+! #\n,+! * .\u22ef.*\n! \"\nE \ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 \u222a \ud835\udc3a =\nr = 1: \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39 + \ud835\udc43(\ud835\udc3a)\nr = 2: \u2212 \ud835\udc43 \ud835\udc38 \u2229 \ud835\udc39 \u2212 \ud835\udc43 \ud835\udc38 \u2229 \ud835\udc3a \u2212 \ud835\udc43 \ud835\udc39 \u2229 \ud835\udc3a\nF G\nr = 3:\n+ \ud835\udc43 \ud835\udc38 \u2229 \ud835\udc39 \u2229 \ud835\udc3a\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nTakeaway: Union of events Review\nAxiom 3, Corollary 3,\nMutually exclusive events Inclusion-Exclusion Principle\nE\n\ud835\udc38\n\ud835\udc39\nF G\n\ud835\udc3a\n\ud835\udc46 \ud835\udc46\nThe challenge of probability is in defining events.\nSome event probabilities are easier to compute than others.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nSerendipity\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nSerendipity\n\u2022 The population of Stanford is \ud835\udc5b = 17,000 people.\n\u2022 You are friends with \ud835\udc5f = 100 people.\n\u2022 Walk into a room, see \ud835\udc58 = 223 random people.\n\u2022 Assume each group of \ud835\udc58 Stanford people is equally likely to be in the room.\nWhat is the probability that you see someone you know in the room?\nhttp://web.stanford.edu/class/cs109/demos/serendipity.html\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nSerendipity\n\u2022 The population of Stanford is \ud835\udc5b = 17,000 people.\n\u2022 You are friends with \ud835\udc5f = 100 people.\n\u2022 Walk into a room, see \ud835\udc58 = 223 random people.\n\u2022 Assume each group of \ud835\udc58 Stanford people is equally likely to be in the room.\nWhat is the probability that you see at least one friend in the room?\nDefine\nWhat strategy would you use?\n\u2022 \ud835\udc46 (unordered)\nA. \ud835\udc43 exactly 1 + \ud835\udc43 exactly 2\n\u2022 \ud835\udc38: \u2265 1 friend in the room\n\ud835\udc43 exactly 3 + \u22ef\nB. 1 \u2212 \ud835\udc43 see no friends\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nSerendipity\n\u2022 The population of Stanford is \ud835\udc5b = 17,000 people.\n\u2022 You are friends with \ud835\udc5f = 100 people.\n\u2022 Walk into a room, see \ud835\udc58 = 223 random people.\n\u2022 Assume each group of \ud835\udc58 Stanford people is equally likely to be in the room.\nWhat is the probability that you see at least one friend in the room?\nDefine\n\u2022 \ud835\udc46 (unordered)\n\u2022 \ud835\udc38: \u2265 1 friend in the room\nIt is often much easier to compute \ud835\udc43 \ud835\udc381 .\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nThe Birthday Paradox Problem\nWhat is the probability that in a set of n people, at least one pair of them\nshare the same birthday?\nFor you to think about (and discuss in your first section)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nCard Flipping\nIn a 52-card deck, cards are flipped one at a time.\nAfter the first ace (of any suit) appears, consider the next card.\nIs P(next card = Ace Spades) < P(next card = 2 Clubs)?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nCard Flipping\nIn a 52-card deck, cards are flipped one at a time.\nAfter the first ace (of any suit) appears, consider the next card.\nIs P(next card = Ace Spades) < P(next card = 2 Clubs)?\nSample space \ud835\udc46 = 52 in-order cards (shuffle deck)\nEvent \ud835\udc38 , next card \ud835\udc38 , next card\n,- )!\nis Ace Spades is 2 Clubs\n1. Take out Ace of Spades. 1. Take out 2 Clubs.\n2. Shuffle leftover 51 cards. 2. Shuffle leftover 51 cards.\n3. Add Ace Spades after first ace. 3. Add 2 Clubs after first ace.\n|\ud835\udc38 | = 51! \u22c5 1 |\ud835\udc38 | = 51! \u22c5 1\n,- )!\n\ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc38\n\"# $!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 <END>"}
{"prompt": "Lecture notes from 15_general_inference_annotated.txt\n\n###\n\n", "completion": "15: General Inference\nJerry Cain\nMay 3rd, 2024\nLecture Discussion on Ed\n1\nInference\n2\nInference\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nInference\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nInference\nCold\nHiccups\nFlu\nGeneral inference question:\nGiven the values of some random\nUnder-\nNausea variables, what is the conditional\ngrad\ndistribution of some other random\nvariables?\nChest\nFever\npain\nSore\nTired\nThroat\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nInference\nCold\nHiccups\nFlu\nOne inference question:\nUnder-\nNausea grad \ud835\udc43 \ud835\udc39 = 1|\ud835\udc41 = 1, \ud835\udc47 = 1\nChest \ud835\udc43 \ud835\udc39 = 1, \ud835\udc41 = 1, \ud835\udc47 = 1\nFever =\npain\n\ud835\udc43 \ud835\udc41 = 1, \ud835\udc47 = 1\nSore\nTired\nThroat\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nInference\nCold\nHiccups\nFlu\nAnother inference question:\nUnder-\nNausea grad \ud835\udc43 \ud835\udc36 = 1, \ud835\udc48 = 1|\ud835\udc46 = 0, \ud835\udc39 = 0\n! \"\n\ud835\udc43 \ud835\udc36 = 1, \ud835\udc48 = 1, \ud835\udc46 = 0, \ud835\udc39 = 0\nChest ! \"\n=\nFever\npain \ud835\udc43 \ud835\udc46 = 0, \ud835\udc39 = 0\n\"\nSore\nTired\nThroat\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nInference\nIf we know the full joint distribution,\nCold we can answer all probabilistic\ninference questions.\nHiccups\nFlu\nWhat is the size of the joint\nUnder-\n\ud835\udc41 = 9\nNausea probability table?\ngrad\nall binary RVs #$%\nA. 2 entries\n#\nB. \ud835\udc41 entries\nChest\n#\nFever C. 2 entries\npain\nD. None/other/don\u2019t know\nSore\nTired\nThroat\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nInference\nIf we know the full joint distribution,\nCold we can answer all probabilistic\ninference questions.\nHiccups\nFlu\nWhat is the size of the joint\nUnder-\n\ud835\udc41 = 9\nNausea probability table?\ngrad\nall binary RVs #$%\nA. 2 entries\n#\nB. \ud835\udc41 entries\nChest\n#\nFever C. 2 entries\npain\nD. None/other/don\u2019t know\nSore\nTired\nBrute-force computation of a full joint\nThroat\nprobability mass function is often intractable.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nN can be large\u2026\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nConditionally Independent RVs\nRecall that two events \ud835\udc34 and \ud835\udc35 are\n\ud835\udc43 \ud835\udc34\ud835\udc35|\ud835\udc38 = \ud835\udc43 \ud835\udc34|\ud835\udc38 \ud835\udc43(\ud835\udc35|\ud835\udc38)\nconditionally independent given \ud835\udc38 if:\n\ud835\udc5b discrete random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b are called conditionally\n% & \u2019\nindependent given \ud835\udc4c if:\nfor all \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 , \ud835\udc66:\n% & \u2019\n\u2019\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 , \ud835\udc4b = \ud835\udc65 , \u2026 , \ud835\udc4b = \ud835\udc65 |\ud835\udc4c = \ud835\udc66 = 6 \ud835\udc43 \ud835\udc4b = \ud835\udc65 |\ud835\udc4c = \ud835\udc66\n% % & & \u2019 \u2019 ( (\n()%\nThis implies the following (cool to remember for later):\n\u2019\nlog \ud835\udc43 \ud835\udc4b = \ud835\udc65 , \ud835\udc4b = \ud835\udc65 , \u2026 , \ud835\udc4b = \ud835\udc65 |\ud835\udc4c = \ud835\udc66 = : log \ud835\udc43 \ud835\udc4b = \ud835\udc65 |\ud835\udc4c = \ud835\udc66\n% % & & \u2019 \u2019 ( (\n()%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nBayesian\nNetworks\n12\nA simpler WebMD\nUnder-\nFlu Great! Just specify 2* = 16 joint\ngrad\nprobabilities?\n\ud835\udc43 \ud835\udc39 = \ud835\udc4e, \ud835\udc39 = \ud835\udc4f, \ud835\udc48 = \ud835\udc50, \ud835\udc47 = \ud835\udc51\n+, \"-\nFever Tired\nWhat would an infectious diseases (ID)\nexpert do?\nDescribe the joint distribution using causality!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nConstructing a Bayesian Network\nWhat would an ID expert do?\n1. Describe the joint distribution using\nUnder-\nFlu causality.\ngrad\nAssume\n2.\nconditional\nindependence.\nFever Tired\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nConstructing a Bayesian Network\nIn a Bayesian Network,\nEach random variable is\nUnder-\nFlu conditionally independent of its\ngrad\nnon-descendants, given its parents.\n\u2022 Node: random variable\n\u2022 Directed edge: conditional dependency\nFever Tired\nExamples:\n\u2022 \ud835\udc43 \ud835\udc39 = 1|\ud835\udc47 = 0,\ud835\udc39 = 1 = \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1\n!\" #$ !\" #$\n\u2022 \ud835\udc43 \ud835\udc39 = 1,\ud835\udc48 = 0 = \ud835\udc43 \ud835\udc39 = 1 \ud835\udc43 \ud835\udc48 = 0\n#$ #$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nConstructing a Bayesian Network\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$ What would an ID expert do?\n1. Describe the joint distribution using\nUnder-\nFlu causality.\ngrad\n2. Assume conditional independence.\n\u2705\n3. Provide \ud835\udc43 values|parents for each\nrandom variable\nWhat conditional probabilities\nFever Tired\nshould our expert specify?\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\n!\" #$\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nConstructing a Bayesian Network\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$ What would an ID expert do?\n1. Describe the joint distribution using\nUnder-\nFlu causality.\ngrad\n2. Assume conditional independence.\n3. Provide \ud835\udc43 values|parents for each\nrandom variable\nWhat conditional probabilities\nFever Tired\nshould our expert specify?\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0\n!\"\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 !\"\n!\" #$ \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0\n!\"\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$ \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1\n!\"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nUsing a Bayes Net\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$ What would a CS109 student do?\n1. Populate a Bayesian network by\nUnder-\nasking an infectious diseases expert\nFlu\ngrad\nor\nby using reasonable assumptions\n2. Answer inference questions\nFever Tired\nO\nu\nr\nf\nt o\no c\nd u\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1 a y s\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nInference: Math\n19\nInference via math\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n1. \ud835\udc43 \ud835\udc39 = 0, \ud835\udc48 = 1, \ud835\udc39 = 0, \ud835\udc47 = 1 ?\n+, \"-\nUnder-\nFlu\nCompute joint probabilities\ngrad\nusing chain rule.\nFever Tired\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nInference via math\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n2. \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0, \ud835\udc48 = 0, \ud835\udc47 = 1 ?\n+, \"-\nUnder-\nFlu\n1. Compute joint probabilities\ngrad\n\ud835\udc43 \ud835\udc39 = 1, \ud835\udc39 = 0, \ud835\udc48 = 0, \ud835\udc47 = 1\n*+ ,-\n\ud835\udc43 \ud835\udc39 = 0, \ud835\udc39 = 0, \ud835\udc48 = 0, \ud835\udc47 = 1\n*+ ,-\n2. Definition of conditional probability\nFever Tired \ud835\udc43 \ud835\udc39 = 1, \ud835\udc39 = 0, \ud835\udc48 = 0, \ud835\udc47 = 1\n*+ ,-\n\u2211 \ud835\udc43 \ud835\udc39 = \ud835\udc65, \ud835\udc39 = 0, \ud835\udc48 = 0, \ud835\udc47 = 1\n. *+ ,-\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8 = 0.095\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nInference via math\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n3. \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\n+,\nUnder-\nFlu\ngrad\nFever Tired\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nInference via math\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n3. \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\n+,\nUnder-\nFlu\n1. Compute joint probabilities\ngrad\n\ud835\udc43 \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc39 = 1, \ud835\udc47 = 1\n*+ ,-\n\u2026\n\ud835\udc43 \ud835\udc39 = 0, \ud835\udc48 = 1, \ud835\udc39 = 0, \ud835\udc47 = 1 ?\n*+ ,-\n2. Definition of conditional probability\n\u2211 \ud835\udc43 \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc39 = \ud835\udc66, \ud835\udc47 = 1\nFever Tired\n/ *+ ,-\n\u2211 \u2211 \ud835\udc43 \ud835\udc39 = \ud835\udc65, \ud835\udc48 = 1, \ud835\udc39 = \ud835\udc66, \ud835\udc47 = 1\n. / *+ ,-\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$ = 0.122\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nInference via math\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\nSolving inference questions\nUnder-\nFlu\nprecisely is possible, but\ngrad\nsometimes tedious.\nCan we use sampling\nto do approximate\ninference?\nFever Tired\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nRejection\nSampling\n25\nRejection sampling algorithm\n\ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\nUnder-\nFlu\ngrad\nStep 0:\nRequire a fully specified\nBayesian Network\nFever Tired\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05 #$\n!\" #$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\n[flu, und, fev, tir]\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation = \u2026\n# number of samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation = \u2026\n# number of samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\n# samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n+,\nProbability \u2248\n# samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\n[flu, und, fev, tir]\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation = \u2026\n# number of samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nRejection sampling algorithm\nN_SAMPLES = 100000\n# Method: Sample a ton\n# -------------------\n# create N_SAMPLES with likelihood proportional\n# to the joint distribution\ndef sample_a_ton():\nHow do we make a sample\nsamples = []\n\ud835\udc39 = \ud835\udc4e, \ud835\udc48 = \ud835\udc4f, \ud835\udc39 = \ud835\udc50, \ud835\udc47 = \ud835\udc51\n*+ ,-\nfor i in range(N_SAMPLES):\naccording to the\nsample = make_sample() # a particle\njoint probability?\nsamples.append(sample)\nreturn samples\nCreate a sample using the Bayesian Network!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\n# !\" #$\n# TODO: fill in \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\n# !\" #$\n# TODO: fill in \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\n# !\" #$\n# TODO: fill in \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\n# !\" #$\n# TODO: fill in \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\n#\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\nif flu == 0 and und == 0: tir = bernoulli(0.1) !\" #$\nelif flu == 0 and und == 1: tir = bernoulli(0.8) \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\nelif flu == 1 and und == 0: tir = bernoulli(0.9)\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\nelse: tir = bernoulli(1.0)\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nRejection sampling algorithm\n# Method: Make Sample \ud835\udc43 \ud835\udc39 = 1 = 0.1 \ud835\udc43 \ud835\udc48 = 1 = 0.8\n#$\n# -------------------\n# create a single sample from the joint distribution\nUnder-\n# based on the medical \"WebMD\" Bayesian Network\nFlu\ndef make_sample(): grad\n# prior on causal factors\nflu = bernoulli(0.1)\nund = bernoulli(0.8)\n# choose fever based on flu\nif flu == 1: fev = bernoulli(0.9)\nelse: fev = bernoulli(0.05)\nFever\nTired\n# choose tired based on (undergrad and flu)\n\ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 1 = 0.9\nif flu == 0 and und == 0: tir = bernoulli(0.1) !\" #$\nelif flu == 0 and und == 1: tir = bernoulli(0.8) \ud835\udc43 \ud835\udc39 = 1|\ud835\udc39 = 0 = 0.05\n!\" #$\nelif flu == 1 and und == 0: tir = bernoulli(0.9)\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 0 = 0.1\n#$\nelse: tir = bernoulli(1.0)\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 0,\ud835\udc48 = 1 = 0.8\n#$\n# a sample from the joint has an \ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 0 = 0.9\n#$\n# assignment to *all* random variables\n\ud835\udc43 \ud835\udc47 = 1|\ud835\udc39 = 1,\ud835\udc48 = 1 = 1.0\n#$\nreturn [flu, und, fev, tir]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\n[flu, und, fev, tir]\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation = \u2026\n# number of samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation = \u2026\n# number of samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\nsamples_event =\n# number of samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n*+\nreturn len(samples_event)/len(samples_observation)\nKeep only samples that are consistent\nwith the observation \ud835\udc48 = 1, \ud835\udc47 = 1 .\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\n# Method: reject_inconsistent\nsamples_event =\n# ---------------------------\nreject_inconsistent(samples_observation, event)\n# Rejects all samples that do not align with the outcome.\nreturn l#e nR(e stu ar mn ps l ea s l _i es vt e nof t )c /o ln esi ns (t se an mt ps la em sp _le os b. servation)\ndef reject_inconsistent(samples, outcome):\nconsistent_samples = []\nKeep only samples that are consistent \ud835\udc48 = 1, \ud835\udc47 = 1\nfor sample in samples:\nw i t h ithf ec ohebcske_rcvoantsioisnt e\ud835\udc47nt(=sa1m,p\ud835\udc48le=, o0ut.come):\nconsistent_samples.append(sample)\nreturn consistent_samples\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\nsamples_event =\nreject_inconsistent(samples_observation, event)\nreturn len(samples_event)/len(samples_observation)\nConditional event = samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1 .\n+,\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\nsamples_event =\nreject_inconsistent(samples_observation, event)\nreturn ledenf( sraemjepclte_si_nceovnesnitst)e/nlte(nsa(mspalmesp,l eosu_tcoobmsee)r:vation)\n.\ud835\udc39..= \ud835\udc65, \ud835\udc48 = 1, \ud835\udc39 = \ud835\udc66, \ud835\udc47 = 1 \ud835\udc39 = 1\nConditional e*v+ent = sampl,e-s with \ud835\udc39 = 1, \ud835\udc48*+ = 1, \ud835\udc47 = 1 .\n+,\nreturn consistent_samples\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nRejection sampling algorithm\nInference\nWhat is \ud835\udc43 \ud835\udc39 = 1|\ud835\udc48 = 1, \ud835\udc47 = 1 ?\nquestion: !\"\ndef rejection_sampling(event, observation):\nsamples = sample_a_ton()\nsamples_observation =\nreject_inconsistent(samples, observation)\nsamples_event =\nreject_inconsistent(samples_observation, event)\nreturn len(samples_event)/len(samples_observation)\n# samples with \ud835\udc39 = 1, \ud835\udc48 = 1, \ud835\udc47 = 1\n+,\nProbability \u2248\n# samples with \ud835\udc48 = 1, \ud835\udc47 = 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nRejection sampling\n[flu, und, fev, tir]\nIf you can sample enough from the joint distribution,\nyou can answer any probability inference question.\nWith enough samples, you can easily compute:\n\u2022 Probability estimates\n\u2022 Conditional probability estimates\n\u2022 Expectation estimates\nWhy? Because your samples represent\nthe joint distribution incredibly well!\nP(has flu | undergrad and is tired) = 0.122\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nBreaking News\n46\nBefore You Go! CS109 Challenge\nDo something cool and creative\nwith probability!\nGrand Prize:\nAll exams replaced with 100%\nAll Serious Entries:\nExtra credit (between %0.5 and\n2% added to overall average)\nOptional Proposal: Sun. 05/12, 11:59pm\nDue: Sun. 06/02, 11:59pm\nhttps://cs109.stanford.edu/handouts/challenge.html\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 47 <END>"}
{"prompt": "Lecture notes from cs109_lec23_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 23: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n3 / 3 pts\nQuestion 1\nNa\u00efve Bayes: Definitions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nNaive Bayes: Why? 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nMovie Suggestions Revisited 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Na\u00efve Bayes: Definitions\n1 Point\nWhich of the following directly follow from the Na\u00efve Bayes assumption? Select\none or more.\nP^ (X\u2223Y ) = \u220fm P^ (X \u2223Y )\nj=1 j\nY^ = argmax P^ (Y = y\u2223X)\ny\nP^ (X ,X ,X \u2223Y ) = P^ (X \u2223Y )P^ (X \u2223Y )P^ (X \u2223Y )\n1 2 3 1 2 3\nlog[P^ (X\u2223Y )] = \u2211m log[P^ (X \u2223Y )]\nj=1 j\nThe assumption that the features X are conditionally independent given Y\nQ2 Naive Bayes: Why?\n1 Point\nWhy might we use the Na\u00efve Bayes assumption?\nGreatly reduces the number of parameters of the model\nThe features X are always conditionally independent\nMany times the features are roughly conditionally independent\nMakes our model more robust and flexible\nQ3 Movie Suggestions Revisited\n1 Point\nRecall this example from today's lectre, which predicted that\nY^\n= 1 for an input\nvector of X = (1,0). Suppose instead that X = (0,1). Compute the two\nprobabilities that need to be compared, and return the absolute value of their\ndifference out to two significant digits.\n0.02 <END>"}
{"prompt": "Lecture notes from 07_section_soln.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May23,2024\nSampling and Bootstrapping, MLE, Beta\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019s\nsection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019ve\nsubmitted.\n1 Warmups\n1.1 MLE\nSuppose\ud835\udc65 1,...,\ud835\udc65 \ud835\udc5b areiid(independentandidenticallydistributed)valuessampledfromsome\ndistributionwithdensityfunction \ud835\udc53(\ud835\udc65|\ud835\udf03),where\ud835\udf03 isunknown.Recallthatthelikelihoodofthedatais\n\ud835\udc5b\n(cid:214)\n\ud835\udc3f(\ud835\udf03) = \ud835\udc53(\ud835\udc65 1,\ud835\udc65 2,...,\ud835\udc65 \ud835\udc5b|\ud835\udf03) = \ud835\udc53(\ud835\udc65 \ud835\udc56|\ud835\udf03)\n\ud835\udc56=1\nRecallwesolveanoptimizationproblemtofind \ud835\udf03\u02c6whichmaximizes \ud835\udc3f(\ud835\udf03),i.e., \ud835\udf03\u02c6 = argmax \ud835\udc3f(\ud835\udf03).\n\ud835\udf03\na. Writeanexpressionforthelog-likelihood, \ud835\udc3f\ud835\udc3f(\ud835\udf03) = log\ud835\udc3f(\ud835\udf03).\nb. Whycanweoptimize \ud835\udc3f\ud835\udc3f(\ud835\udf03) ratherthan \ud835\udc3f(\ud835\udf03)?\nc. Whymight weoptimize \ud835\udc3f\ud835\udc3f(\ud835\udf03) ratherthan \ud835\udc3f(\ud835\udf03)?\na. (cid:205) \ud835\udc56\ud835\udc5b =1log \ud835\udc53(\ud835\udc65 \ud835\udc56|\ud835\udf03)\nb. Logarithmsarestrictlyincreasingfunctions.Foranystrictlyincreasingfunction \ud835\udc53 andany\nfunction \ud835\udc54,thefollowingholds:argmax\ud835\udc54(\ud835\udc65) = argmax \ud835\udc53(\ud835\udc54(\ud835\udc65))\nc. Findingthemaxofafunctionrequiresyoutakederivatives.Theoriginalexpressionconsistsof\naproductofmanyfunctionsof \ud835\udf03.Thisleadstoadifficultderivationbecauseofthechainrule\nofcalculus.\nBytakingthelog,weconverttheproductintosums,andthederivativeofthesumofmany\nfunctionsof \ud835\udf03 ismucheasiertocompute.\nThatis, \ud835\udf15\ud835\udf15\n\ud835\udf03\n(cid:205)\n\ud835\udc56\n\ud835\udc53 \ud835\udc56(\ud835\udf03) = (cid:205)\n\ud835\udc56\n\ud835\udf15\ud835\udf15\n\ud835\udf03\n\ud835\udc53 \ud835\udc56(\ud835\udf03) whichiseasy.\nHowever, \ud835\udf15\ud835\udf15\n\ud835\udf03\n(cid:206)\n\ud835\udc56\n\ud835\udc53 \ud835\udc56(\ud835\udf03) = acomplicatedexpression\n\u20132\u2013\n1.2 Beta\na. Supposeyouhaveacoinwhereyouhavenopriorbeliefonitstrueprobabilityofheads \ud835\udc5d.How\ncanyoumodelthisbeliefasaBetadistribution?\nb. Supposeyouhaveacoinwhichyoubelieveisfair,with\u201dstrength\u201d \ud835\udefc.Thatis,pretendyou\u2019ve\nseen \ud835\udefc headsand \ud835\udefc tails.HowcanyoumodelthisbeliefasaBetadistribution?\nc. Nowsupposeyoutakethecoinfromthepreviouspartandflipit10times.Yousee8headsand\n2tails.Howcanyoumodelyourposteriorbeliefofthecoin\u2019sprobabilityofheads?\na. Beta(1,1) isauniformprior,meaningthatpriortoseeingtheexperiment,allprobabilitiesof\nheadsareequallylikely.\nb. Beta(\ud835\udefc+1,\ud835\udefc+1).Thisisourpriorbeliefaboutthedistribution.\nc. Beta(\ud835\udefc+9,\ud835\udefc+3)\n1.3 Beta Sum\nWhatisthedistributionofthesumof100iidBetas?Let \ud835\udc4b bethesum\n100\n\u2211\ufe01\n\ud835\udc4b = \ud835\udc4b \ud835\udc56 whereeach \ud835\udc4b \ud835\udc56 \u223c Beta(\ud835\udc4e = 3,\ud835\udc4f = 4)\n\ud835\udc56=1\nNotethevarianceofaBeta:\n\ud835\udc4e\ud835\udc4f\nVar(\ud835\udc4b \ud835\udc56) = where \ud835\udc4b \ud835\udc56 \u223c Beta(\ud835\udc4e,\ud835\udc4f)\n(\ud835\udc4e +\ud835\udc4f)2(\ud835\udc4e +\ud835\udc4f +1)\nBytheCentralLimitTheorem,thesumofequallyweightedIIDrandomvariableswillbeNormally\ndistributed.Wecalculatetheexpectationandvarianceof \ud835\udc4b \ud835\udc56 usingthebetaformulas:\n\ud835\udc4e\n\ud835\udc38(\ud835\udc4b \ud835\udc56) = ExpectationofaBeta\n\ud835\udc4e +\ud835\udc4f\n3\n= \u2248 0.43\n7\n\ud835\udc4e\ud835\udc4f\nVar(\ud835\udc4b \ud835\udc56) = VarianceofaBeta\n(\ud835\udc4e +\ud835\udc4f)2(\ud835\udc4e +\ud835\udc4f +1)\n3\u00b74\n=\n(3+4)2(3+4+1)\n12\n= \u2248 0.03\n49\u00b78\n\u20133\u2013\n\ud835\udc4b \u223c \ud835\udc41(\ud835\udf07 = \ud835\udc5b\u00b7 \ud835\udc38[\ud835\udc4b \ud835\udc56],\ud835\udf0e2 = \ud835\udc5b\u00b7Var(\ud835\udc4b \ud835\udc56))\n\u223c \ud835\udc41(\ud835\udf07 = 43,\ud835\udf0e2 = 3)\n2 Problems\n2.1 Variance of Hemoglobin Levels\nAmedicalresearchertreatspatientswithdangerouslylowhemoglobinlevels.Shehasformulatedtwo\nslightlydifferentdrugsandisnowtestingthemonpatients.First,sheadministereddrugAtoone\ngroupof50patientsanddrugBtoaseparategroupof50patients.Then,shemeasuredallthe\npatients\u2019hemoglobinlevelspost-treatment.Forsimplicity,assumethatallvariationinthepatient\noutcomesisduetotheirdifferentreactionstotreatment.\nTheresearchernotesthatthesamplemeanissimilarbetweenthetwogroups:bothhavemean\nhemoglobinlevelsaround10g/dL.However,drugB\u2019sgrouphasasamplevariancethatis3(g/dL)2\ngreaterthandrugA\u2019sgroup.TheresearcherthinksthatpatientsrespondtodrugsAandBdifferently.\nSpecifically,shewantstomakethescientificclaimthatdrugA\u2019spatientswillendupwitha\nsignificantlydifferentspreadofhemoglobinlevelscomparedtodrugB\u2019s.\nYouareskeptical.Itispossiblethatthetwodrugshavepracticallyidenticaleffectsandthatthe\nobserveddifferentinvariancewasaresultofchanceandasmallsamplesize,i.e.thenull\nhypothesis.Calculatetheprobabilityofthenullhypothesisusingbootstrapping.Hereisthedata.\nEachnumberisthelevelofanindependentlysampledpatient:\nHemoglobinLevelsofDrugA\u2019sGroup(\ud835\udc462 =6.0):13,12,7,16,9,11,7,10,9,8,9,7,16,7,9,8,\n13,10,11,9,13,13,10,10,9,7,7,6,7,8,12,13,9,6,9,11,10,8,12,10,9,10,8,14,13,13,10,\n11,12,9\nHemoglobinLevelsofDrugB\u2019sGroup(\ud835\udc462 =9.1):8,8,16,16,9,13,14,13,10,12,10,6,14,8,\n13,14,7,13,7,8,4,11,7,12,8,9,12,8,11,10,12,6,10,15,11,12,3,8,11,10,10,8,12,8,11,6,\n7,10,8,5\nCompletethepromptsinthisColabnotebooktoinvestigatethisquestionusingbootstrapping.\nYoucanvisitthisnotebooktoseehowwefleshedoutallofthedifferentfunctionsexpectedofyou\nforthisproblem.\n\u20134\u2013\n2.2 Parameter Estimation and Wealth Distribution\nThebroaderfieldofeconomicsalsoreliesonlikelihoodestimationandparameterestimation.One\ncontinuousprobabilitydistribution\u2014onewithalongtailas\ud835\udc65 approachesinfinity\u2014isusedtomodel\nwealthinequalityandthesocioeconomicproblemsthatstemfromit.Thisprobabilitydistributionis\ngivenas:\n\ud835\udf143\ud835\udf14\n\ud835\udc53(\ud835\udc65|\ud835\udf14) = , where\ud835\udc65 \u2265 3,\ud835\udf14 > 1\n\ud835\udc65\ud835\udf14+1\nAssumethatyou\u2019veobservedasampleofiidrandomvariables (\ud835\udc4b 1,\ud835\udc4b 2,\ud835\udc4b 3,...,\ud835\udc4b \ud835\udc5b),whereeachofthe\n\ud835\udc4b \ud835\udc56 ismodeledaccordingtotheaboveprobabilitydistributionfunction.\na. Whatisthelog-likelihoodfunction \ud835\udc3f\ud835\udc3f(\ud835\udf14) ofthesample (\ud835\udc4b 1,\ud835\udc4b 2,\ud835\udc4b 3,...,\ud835\udc4b \ud835\udc5b)?Simplifyusing\npropertiesoflogarithmswhereverpossible.\n(cid:214)\ud835\udc5b \ud835\udf143\ud835\udf14\n\ud835\udc3f(\ud835\udf14) =\n\ud835\udc65\ud835\udf14+1\n\ud835\udc56=1 \ud835\udc56\n\u2211\ufe01\ud835\udc5b \ud835\udf143\ud835\udf14\n\ud835\udc3f\ud835\udc3f(\ud835\udf14) = log\n\ud835\udc65\ud835\udf14+1\n\ud835\udc56=1 \ud835\udc56\n\ud835\udc5b \ud835\udc5b \ud835\udc5b\n\u2211\ufe01 \u2211\ufe01 \u2211\ufe01\n= log\ud835\udf14+ log3\ud835\udf14 \u2212 log\ud835\udc65\ud835\udf14+1\n\ud835\udc56\n\ud835\udc56=1 \ud835\udc56=1 \ud835\udc56=1\n\ud835\udc5b \ud835\udc5b \ud835\udc5b \ud835\udc5b\n\u2211\ufe01 \u2211\ufe01 \u2211\ufe01 \u2211\ufe01\n= log\ud835\udf14 1+\ud835\udf14 log3\u2212\ud835\udf14 log\ud835\udc65 \ud835\udc56 \u2212 log\ud835\udc65 \ud835\udc56\n\ud835\udc56=1 \ud835\udc56=1 \ud835\udc56=1 \ud835\udc56=1\n\ud835\udc5b \ud835\udc5b\n\u2211\ufe01 \u2211\ufe01\n= \ud835\udc5blog\ud835\udf14+\ud835\udc5b\ud835\udf14log3\u2212\ud835\udf14 log\ud835\udc65 \ud835\udc56 \u2212 log\ud835\udc65 \ud835\udc56\n\ud835\udc56=1 \ud835\udc56=1\nb. Setuptheequationthatwouldneedtobesolvedinordertocompute\ud835\udf14\u02c6\ud835\udc40\ud835\udc3f\ud835\udc38.Onceyouarriveat\ntheequationandhaveworkedthroughanycalculus,youcanstopandsimplypresentthe\nequationthatcanbesolvedviasimplealgebraicmanipulation.\nComputing\ud835\udf14\u02c6\ud835\udc40\ud835\udc3f\ud835\udc38 amountstofindingthevalueof\ud835\udf14 thatsolvestheequation \ud835\udeff\ud835\udc3f \ud835\udeff\ud835\udc3f \ud835\udf14(\ud835\udf14) = 0.\nFortunately,thederivativeofinterestiseasilycomputed,becauseour \ud835\udc3f\ud835\udc3f(\ud835\udf14) isasumof\n\u20135\u2013\nlogarithmsandlinearterms.\n\ud835\udc5b \ud835\udc5b\n\u2211\ufe01 \u2211\ufe01\n\ud835\udc3f\ud835\udc3f(\ud835\udf14) = \ud835\udc5blog\ud835\udf14+\ud835\udc5b\ud835\udf14log3\u2212\ud835\udf14 log\ud835\udc65 \ud835\udc56 \u2212 log\ud835\udc65 \ud835\udc56\n\ud835\udc56=1 \ud835\udc56=1\n\ud835\udc5b\n\ud835\udeff\ud835\udc3f\ud835\udc3f(\ud835\udf14) \ud835\udc5b\n\u2211\ufe01\n= +\ud835\udc5blog3\u2212 log\ud835\udc65 \ud835\udc56 = 0\n\ud835\udeff\ud835\udf14 \ud835\udf14\n\ud835\udc56=1\nYouwerewelcometostopattheaboveequation,sinceitcanbesolvedviaalgebraic\nmanipulationyouneedn\u2019tshow.Wedo,however,presentthesolutionbelowforcompleteness,\nsincethisisaarealprobabilitydistributionusedinmanyfieldsofstatisticalanalysis.\n\ud835\udc5b\n\ud835\udc5b\n\u2211\ufe01\n\ud835\udf14\u02c6\ud835\udc40\ud835\udc3f\ud835\udc38\n= \ud835\udc46 log\ud835\udc4b \u2212\ud835\udc5blog3, where \ud835\udc46 log\ud835\udc4b = log\ud835\udc65 \ud835\udc56\n\ud835\udc56=1\n\ud835\udc5b\n\ud835\udf14\u02c6\ud835\udc40\ud835\udc3f\ud835\udc38 =\n\ud835\udc46\nlog\ud835\udc4b\n\u2212\ud835\udc5blog3\n2.3 Dirk/Evan Showdown\nDirkandEvanaresettocompeteinamatchofsevengames,andtheplayerwinningthemostwillbe\nrewardedwithamedalfromtheRulerofallofBayestopia,QueenDoris.Theoutcomesofeachof\nthesevengamesareindependentofoneanother,andDirkwinseachgamewithaprobability \ud835\udc5d (so\nthatEvanwinswithprobability1\u2212 \ud835\udc5d).Unfortunately, \ud835\udc5d isunknown,soyoudecidetomodel \ud835\udc5d itself\nasaBetarandomvariablesuchthat \ud835\udc5d \u223c \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e(1,1).\nTolearnmoreabout \ud835\udc5d,youreaduponalloftheirpreviousgames,findthatthey\u2019vealreadycompeted\n12times,andlearnthatEvanhaswon7ofthose12gamesinthisorder:WLLLWWLWWLWW.\nEvenifEvan\u2019sedgeiseversoslight,heappearstobetheapriorifavorite.\na. Findtheposteriordistributionof \ud835\udc5d givenDirkandEvan\u2019spriorhistorycompetingagainstone\nanother.\nb. RecallthatthePDFofa \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e distributiononintegerparameters \ud835\udc4e and \ud835\udc4f isgivenas:\n1\n\ud835\udc53(\ud835\udc65|\ud835\udc4e,\ud835\udc4f) = \ud835\udc65\ud835\udc4e\u22121(1\u2212\ud835\udc65)\ud835\udc4f\u22121,where \ud835\udc35(\ud835\udc4e,\ud835\udc4f) isanormalizationconstant\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\nAssumingourhyperparameters \ud835\udc4e and \ud835\udc4f arepositiveintegers,explainwhytheexpectedvalue\nof\n\ud835\udc5d\ud835\udc5a(1\u2212 \ud835\udc5d)\ud835\udc5b\n\u2014thatis,\n\ud835\udc38[\ud835\udc5d\ud835\udc5a(1\u2212 \ud835\udc5d)\ud835\udc5b]\u2014isgivenby\n\u20136\u2013\n\ud835\udc35(\ud835\udc4e +\ud835\udc5a,\ud835\udc4f +\ud835\udc5b)\n\ud835\udc38[\ud835\udc5d\ud835\udc5a\n(1\u2212\n\ud835\udc5d)\ud835\udc5b\n] =\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\nYoucanassumethat \ud835\udc5a and \ud835\udc5b arenonnegativeintegersaswell.\nc. Relyingonlyontheposteriordistributionof \ud835\udc5d thatyoucomputedforpartaandtheresultfrom\npartb,computetheexpectedprobabilitythatthebest-of-sevenmatchbetweenDirkandEvan\nisn\u2019tsettledafterthefirstsixgamesandthereforerequirestheseventhbeplayed?\na. Becausetheprioris \ud835\udc5d \u223c \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e(1,1),andbecausethelikelihoodfunctionisaBinomialwith\n\ud835\udc5b = 12andunknownp,ourposteriorisalsoaBeta,butwithparametersof \ud835\udc4e = 1+5 = 6and\n\ud835\udc4f = 1+7 = 8.Morecompactly, \ud835\udc5d|data \u223c \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e(6,8).\nb. LOTUStellsusthattheexpectedvalueofanarbitraryfunction \ud835\udc53(\ud835\udc65) is:\n1 \u222b 1\n\ud835\udc38[\ud835\udc53(\ud835\udc65)] = \ud835\udc53(\ud835\udc65)\ud835\udc65\ud835\udc4e\u22121(1\u2212\ud835\udc65)\ud835\udc4f\u22121.\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\n0\n\ud835\udc53(\ud835\udc65) = \ud835\udc65\ud835\udc5a(1\u2212\ud835\udc65)\ud835\udc5b blendsbeautifullywiththePDFofourBetaposterior:\n1 \u222b 1\n\ud835\udc38[\ud835\udc53(\ud835\udc5d)] = \ud835\udc38[\ud835\udc5d\ud835\udc5a (1\u2212 \ud835\udc5d)\ud835\udc5b ] = \ud835\udc65\ud835\udc5a (1\u2212\ud835\udc65)\ud835\udc5b\ud835\udc65\ud835\udc4e\u22121(1\u2212\ud835\udc65)\ud835\udc4f\u22121\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\n0\n1 \u222b 1 \ud835\udc35(\ud835\udc4e +\ud835\udc5a,\ud835\udc4f +\ud835\udc5b)\n=\n\ud835\udc65\ud835\udc5a+\ud835\udc4e\u22121(1\u2212\ud835\udc65)\ud835\udc5b+\ud835\udc4f\u22121\n=\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f) \ud835\udc35(\ud835\udc4e,\ud835\udc4f)\n0\nc. Theprobabilitythataseventhgameisplayedis (cid:0)6(cid:1)\ud835\udc5d3(1\u2212 \ud835\udc5d)3.Sotheexpectedvalueis\n3\n(cid:0)6(cid:1)\ud835\udc5d3(1\u2212 \ud835\udc5d)3 wouldbe:\n3\n(cid:18) 6(cid:19)\ud835\udc35(9,11)\n.\n3 \ud835\udc35(6,8) <END>"}
{"prompt": "Lecture notes from cs109_lec05_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 5: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n3 / 3 pts\nQuestion 1\nIndependence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nChain Rule and Independence 2 / 2 pts\n2.1 Chain Rule: Possible Dependence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 Chain Rule: Some Independence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Independence\n1 Point\nSuppose we roll two fair N-sided dice to produce values of D and D . Define\n1 2\nthe event E to be D = 1, the event F to be that D = N, and the event G to be\n1 2\nthe sum D + D = k. Suppose we know E, F, and G are pairwise independent\n1 2\n\u2014that is, that E and F are independent, F and G are independent, and E and G\nare independent. Suppose further that E, F, and G are not three-way\nindependent. What is k?\nN\n7\nN + 1\n2N\nN2\nQ2 Chain Rule and Independence\n2 Points\nLet E, F, and G be events with nonzero probabilities.\nQ2.1 Chain Rule: Possible Dependence\n1 Point\nWhat is an equivalent expression for P(EFG)?\nP(F\u2223EG)P(G\u2223EF)P(E\u2223FG)\nP(F\u2223E)P(G\u2223E)P(E\u2223FG)\nP(F)P(G\u2223F)P(E\u2223FG)\nP(F)P(G)P(E\u2223FG)\nP(E)P(F)P(G)\nQ2.2 Chain Rule: Some Independence\n1 Point\nSuppose that F and G are independent. Using the property of independence,\nwhat is an equivalent expression for P(EFG)?\nP(F\u2223EG)P(G\u2223EF)P(E\u2223FG)\nP(F\u2223E)P(G\u2223E)P(E\u2223FG)\nP(F)P(G)P(E\u2223FG)\nP(E)P(F)P(G) <END>"}
{"prompt": "Lecture notes from 07_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May23,2024\nSampling and Bootstrapping, MLE, Beta\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019s\nsection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019ve\nsubmitted.\n1 Warmups\n1.1 MLE\nSuppose\ud835\udc65 1,...,\ud835\udc65 \ud835\udc5b areiid(independentandidenticallydistributed)valuessampledfromsome\ndistributionwithdensityfunction \ud835\udc53(\ud835\udc65|\ud835\udf03),where\ud835\udf03 isunknown.Recallthatthelikelihoodofthedatais\n\ud835\udc5b\n(cid:214)\n\ud835\udc3f(\ud835\udf03) = \ud835\udc53(\ud835\udc65 1,\ud835\udc65 2,...,\ud835\udc65 \ud835\udc5b|\ud835\udf03) = \ud835\udc53(\ud835\udc65 \ud835\udc56|\ud835\udf03)\n\ud835\udc56=1\nRecallwesolveanoptimizationproblemtofind \ud835\udf03\u02c6whichmaximizes \ud835\udc3f(\ud835\udf03),i.e., \ud835\udf03\u02c6 = argmax \ud835\udc3f(\ud835\udf03).\n\ud835\udf03\na. Writeanexpressionforthelog-likelihood, \ud835\udc3f\ud835\udc3f(\ud835\udf03) = log\ud835\udc3f(\ud835\udf03).\nb. Whycanweoptimize \ud835\udc3f\ud835\udc3f(\ud835\udf03) ratherthan \ud835\udc3f(\ud835\udf03)?\nc. Whymight weoptimize \ud835\udc3f\ud835\udc3f(\ud835\udf03) ratherthan \ud835\udc3f(\ud835\udf03)?\n1.2 Beta\na. Supposeyouhaveacoinwhereyouhavenopriorbeliefonitstrueprobabilityofheads \ud835\udc5d.How\ncanyoumodelthisbeliefasaBetadistribution?\nb. Supposeyouhaveacoinwhichyoubelieveisfair,with\u201dstrength\u201d \ud835\udefc.Thatis,pretendyou\u2019ve\nseen \ud835\udefc headsand \ud835\udefc tails.HowcanyoumodelthisbeliefasaBetadistribution?\nc. Nowsupposeyoutakethecoinfromthepreviouspartandflipit10times.Yousee8headsand\n2tails.Howcanyoumodelyourposteriorbeliefofthecoin\u2019sprobabilityofheads?\n1.3 Beta Sum\nWhatisthedistributionofthesumof100iidBetas?Let \ud835\udc4b bethesum\n100\n\u2211\ufe01\n\ud835\udc4b = \ud835\udc4b \ud835\udc56 whereeach \ud835\udc4b \ud835\udc56 \u223c Beta(\ud835\udc4e = 3,\ud835\udc4f = 4)\n\ud835\udc56=1\nNotethevarianceofaBeta:\n\ud835\udc4e\ud835\udc4f\nVar(\ud835\udc4b \ud835\udc56) = where \ud835\udc4b \ud835\udc56 \u223c Beta(\ud835\udc4e,\ud835\udc4f)\n(\ud835\udc4e +\ud835\udc4f)2(\ud835\udc4e +\ud835\udc4f +1)\n\u20132\u2013\n2 Problems\n2.1 Variance of Hemoglobin Levels\nAmedicalresearchertreatspatientswithdangerouslylowhemoglobinlevels.Shehasformulatedtwo\nslightlydifferentdrugsandisnowtestingthemonpatients.First,sheadministereddrugAtoone\ngroupof50patientsanddrugBtoaseparategroupof50patients.Then,shemeasuredallthe\npatients\u2019hemoglobinlevelspost-treatment.Forsimplicity,assumethatallvariationinthepatient\noutcomesisduetotheirdifferentreactionstotreatment.\nTheresearchernotesthatthesamplemeanissimilarbetweenthetwogroups:bothhavemean\nhemoglobinlevelsaround10g/dL.However,drugB\u2019sgrouphasasamplevariancethatis3(g/dL)2\ngreaterthandrugA\u2019sgroup.TheresearcherthinksthatpatientsrespondtodrugsAandBdifferently.\nSpecifically,shewantstomakethescientificclaimthatdrugA\u2019spatientswillendupwitha\nsignificantlydifferentspreadofhemoglobinlevelscomparedtodrugB\u2019s.\nYouareskeptical.Itispossiblethatthetwodrugshavepracticallyidenticaleffectsandthatthe\nobserveddifferentinvariancewasaresultofchanceandasmallsamplesize,i.e.thenull\nhypothesis.Calculatetheprobabilityofthenullhypothesisusingbootstrapping.Hereisthedata.\nEachnumberisthelevelofanindependentlysampledpatient:\nHemoglobinLevelsofDrugA\u2019sGroup(\ud835\udc462 =6.0):13,12,7,16,9,11,7,10,9,8,9,7,16,7,9,8,\n13,10,11,9,13,13,10,10,9,7,7,6,7,8,12,13,9,6,9,11,10,8,12,10,9,10,8,14,13,13,10,\n11,12,9\nHemoglobinLevelsofDrugB\u2019sGroup(\ud835\udc462 =9.1):8,8,16,16,9,13,14,13,10,12,10,6,14,8,\n13,14,7,13,7,8,4,11,7,12,8,9,12,8,11,10,12,6,10,15,11,12,3,8,11,10,10,8,12,8,11,6,\n7,10,8,5\nCompletethepromptsinthisColabnotebooktoinvestigatethisquestionusingbootstrapping.\n2.2 Parameter Estimation and Wealth Distribution\nThebroaderfieldofeconomicsalsoreliesonlikelihoodestimationandparameterestimation.One\ncontinuousprobabilitydistribution\u2014onewithalongtailas\ud835\udc65 approachesinfinity\u2014isusedtomodel\nwealthinequalityandthesocioeconomicproblemsthatstemfromit.Thisprobabilitydistributionis\ngivenas:\n\ud835\udf143\ud835\udf14\n\ud835\udc53(\ud835\udc65|\ud835\udf14) = , where\ud835\udc65 \u2265 3,\ud835\udf14 > 1\n\ud835\udc65\ud835\udf14+1\nAssumethatyou\u2019veobservedasampleofiidrandomvariables (\ud835\udc4b 1,\ud835\udc4b 2,\ud835\udc4b 3,...,\ud835\udc4b \ud835\udc5b),whereeachofthe\n\ud835\udc4b \ud835\udc56 ismodeledaccordingtotheaboveprobabilitydistributionfunction.\na. Whatisthelog-likelihoodfunction \ud835\udc3f\ud835\udc3f(\ud835\udf14) ofthesample (\ud835\udc4b 1,\ud835\udc4b 2,\ud835\udc4b 3,...,\ud835\udc4b \ud835\udc5b)?Simplifyusing\npropertiesoflogarithmswhereverpossible.\nb. Setuptheequationthatwouldneedtobesolvedinordertocompute\ud835\udf14\u02c6\ud835\udc40\ud835\udc3f\ud835\udc38.Onceyouarriveat\ntheequationandhaveworkedthroughanycalculus,youcanstopandsimplypresentthe\nequationthatcanbesolvedviasimplealgebraicmanipulation.\n\u20133\u2013\n2.3 Dirk/Evan Showdown\nDirkandEvanaresettocompeteinamatchofsevengames,andtheplayerwinningthemostwillbe\nrewardedwithamedalfromtheRulerofallofBayestopia,QueenDoris.Theoutcomesofeachof\nthesevengamesareindependentofoneanother,andDirkwinseachgamewithaprobability \ud835\udc5d (so\nthatEvanwinswithprobability1\u2212 \ud835\udc5d).Unfortunately, \ud835\udc5d isunknown,soyoudecidetomodel \ud835\udc5d itself\nasaBetarandomvariablesuchthat \ud835\udc5d \u223c \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e(1,1).\nTolearnmoreabout \ud835\udc5d,youreaduponalloftheirpreviousgames,findthatthey\u2019vealreadycompeted\n12times,andlearnthatEvanhaswon7ofthose12gamesinthisorder:WLLLWWLWWLWW.\nEvenifEvan\u2019sedgeiseversoslight,heappearstobetheapriorifavorite.\na. Findtheposteriordistributionof \ud835\udc5d givenDirkandEvan\u2019spriorhistorycompetingagainstone\nanother.\nb. RecallthatthePDFofa \ud835\udc35\ud835\udc52\ud835\udc61\ud835\udc4e distributiononintegerparameters \ud835\udc4e and \ud835\udc4f isgivenas:\n1\n\ud835\udc53(\ud835\udc65|\ud835\udc4e,\ud835\udc4f) = \ud835\udc65\ud835\udc4e\u22121(1\u2212\ud835\udc65)\ud835\udc4f\u22121,where \ud835\udc35(\ud835\udc4e,\ud835\udc4f) isanormalizationconstant\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\nAssumingourhyperparameters \ud835\udc4e and \ud835\udc4f arepositiveintegers,explainwhytheexpectedvalue\nof\n\ud835\udc5d\ud835\udc5a(1\u2212 \ud835\udc5d)\ud835\udc5b\n\u2014thatis,\n\ud835\udc38[\ud835\udc5d\ud835\udc5a(1\u2212 \ud835\udc5d)\ud835\udc5b]\u2014isgivenby\n\ud835\udc35(\ud835\udc4e +\ud835\udc5a,\ud835\udc4f +\ud835\udc5b)\n\ud835\udc38[\ud835\udc5d\ud835\udc5a\n(1\u2212\n\ud835\udc5d)\ud835\udc5b\n] =\n\ud835\udc35(\ud835\udc4e,\ud835\udc4f)\nYoucanassumethat \ud835\udc5a and \ud835\udc5b arenonnegativeintegersaswell.\nc. Relyingonlyontheposteriordistributionof \ud835\udc5d thatyoucomputedforpartaandtheresultfrom\npartb,computetheexpectedprobabilitythatthebest-of-sevenmatchbetweenDirkandEvan\nisn\u2019tsettledafterthefirstsixgamesandthereforerequirestheseventhbeplayed? <END>"}
{"prompt": "Lecture notes from 02_section_soln.txt\n\n###\n\n", "completion": "CS109 April18,2024\nSection 2: Conditional Probability and Bayes\nChrisPiech,MehranSahami,JerryCain,LisaYan,andnumerousCS109CA\u2019s.\nOverview of Section Materials\nThewarm-upquestionsprovidedwillhelpstudentspracticeconceptsintroducedinlectures.Thesectionprob-\nlemsaremeanttoapplytheseconceptsinmorecomplexscenariossimilartowhatyouwillseeinproblemsets\nandexams.Infact,manyofthemareoldexamquestions.\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019ssection.The\nCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\nWarm-ups\n1. Definitions:CiteBayes\u2019Theorem.Canyouexplainwhy \ud835\udc43(\ud835\udc34|\ud835\udc35) isdifferentthan \ud835\udc43(\ud835\udc35|\ud835\udc34)?\n2. TrueorFalse.NotethattruemeanstrueforALLcases.\n(a) Ingeneral, \ud835\udc43(\ud835\udc34\ud835\udc35|\ud835\udc36) = \ud835\udc43(\ud835\udc35|\ud835\udc36)\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36)\n(b) If \ud835\udc34 and \ud835\udc35 areindependent,soare \ud835\udc34 and \ud835\udc35\ud835\udc36 .\n1. Bayes\u2019Theorem: \ud835\udc43(\ud835\udc38|\ud835\udc39) = \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38) .\n\ud835\udc43(\ud835\udc39)\nAnd \ud835\udc43(\ud835\udc34|\ud835\udc35) isdifferentthan \ud835\udc43(\ud835\udc34|\ud835\udc35) becausethefirstcomputestheprobabilitythat \ud835\udc34 occurswiththeun-\nderstandthat \ud835\udc35 hasoccurred,andthesecondcomputestheprobabilitythat \ud835\udc35 occurswiththeunderstand\nthat \ud835\udc34 hasoccurred.Anexample: \ud835\udc43(\ud835\udc34|\ud835\udc35) mightbetheprobabilitythatyouhavetheflubecauseyou\u2019re\nrunningahighfever,whereas \ud835\udc43(\ud835\udc35|\ud835\udc34) wouldthenbetheprobabilityyougetahighfeverasaresultof\ncomingdownwiththeflu.Thefirstmightbeasmallprobability,becausetherecanbeallkindsofreasons\nyouhaveahighfever(bacterialinfection,overexertion,heatstroke,orasideeffectofsomemedication)\nwhereasthesecondcouldbeveryhigh(i.e.,perhapsit\u2019salmostalwaysthecasethattheflupresentsitself\nwithahighfever).\n2. (a) True\n\ud835\udc43(\ud835\udc34\ud835\udc35|\ud835\udc36) Leftside\n\ud835\udc43(\ud835\udc34\ud835\udc35\ud835\udc36)\nDef\u2019nCond\u2019nProb\n\ud835\udc43(\ud835\udc36)\n\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36)\ud835\udc43(\ud835\udc35\ud835\udc36)\nChainRule\n\ud835\udc43(\ud835\udc36)\n\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36)\ud835\udc43(\ud835\udc35|\ud835\udc36)\ud835\udc43(\ud835\udc36)\nChainRule\n\ud835\udc43(\ud835\udc36)\n\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36)\ud835\udc43(\ud835\udc35|\ud835\udc36) Cancellation\n\ud835\udc43(\ud835\udc35|\ud835\udc36)\ud835\udc43(\ud835\udc34|\ud835\udc35\ud835\udc36) \u25a0\n(b) True\nStartfromLawofTotalProbability(thisisagoodcandidateforastartingpointbecauseitrelates \ud835\udc34,\n\ud835\udc35 and \ud835\udc35\u2201 ).Wewillemploytheassumptionthat \ud835\udc34 \u22a5 \ud835\udc35 (i.e. \ud835\udc34 isindependentof \ud835\udc35)somewhere,and\nthentrytoseeifwecanarriveattheequation \ud835\udc43(\ud835\udc34\ud835\udc35\u2201) = \ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35\u2201) (thisiswhatitmeansfor \ud835\udc34 and\n\ud835\udc35\u2201\ntobeindependentmathematically).\n\ud835\udc43(\ud835\udc34) = \ud835\udc43(\ud835\udc34\ud835\udc35) + \ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) LOTP\n\ud835\udc43(\ud835\udc34) = \ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35) + \ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) \ud835\udc34 \u22a5 \ud835\udc35\n\ud835\udc43(\ud835\udc34) \u2212 \ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35) = \ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) Subtract \ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35)\n\ud835\udc43(\ud835\udc34)(1\u2212 \ud835\udc43(\ud835\udc35)) = \ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) Factor \ud835\udc43(\ud835\udc34)\n\ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35\u2201 ) = \ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) 1\u2212 \ud835\udc43(\ud835\udc35) := \ud835\udc43(\ud835\udc35\u2201 )\n\ud835\udc43(\ud835\udc34\ud835\udc35\u2201 ) = \ud835\udc43(\ud835\udc34)\ud835\udc43(\ud835\udc35\u2201 ) \u25a0\n1 Taking Expectation: Breaking Vegas\nPreamble:Whenarandomvariablefitsneatlyintoafamilywe\u2019veseenbefore(e.g.Binomial),wegetitsexpec-\ntationforfree.Whenitdoesnot,wehavetousethedefinitionofexpectation.\nProblem:Ifyoubeton\u201cRed\u201dinRoulette,thereis \ud835\udc5d = 18/38thatyouwithwin$Yanda (1\u2212\ud835\udc5d) probabilitythat\nyoulose$Y.Considerthisalgorithmforaseriesofbets:\nLetY=$1.FirstyoubetY.Ifyouwin,thenstop.Ifyoulose,thensetYtobe2Yandrepeat.\nWhatareyourexpectedwinningswhenyoustop?Itwillhelptorecallthatthesumofageometricseries \ud835\udc4e0+\ud835\udc4e1+\n\ud835\udc4e2 +\u00b7\u00b7\u00b7 = 1 if0 < \ud835\udc4e < 1.Vegasbreaksyou:Whydoesn\u2019teveryonedothis?\n1\u2212\ud835\udc4e\nLetXbethenumberofdollarsthatyourearn.\nThepossiblevaluesofxarefromtheoutcomesof:winningonyourfirstbet,winningonyoursecondbet,andso\non.\n18 2018 (cid:16)20(cid:17)218\n\ud835\udc38[\ud835\udc4b] = + (2\u22121) + (4\u22122\u22121) +...\n38 3838 38 38\n\u2211\ufe01\u221e (cid:16)20(cid:17)\ud835\udc56(cid:16)18(cid:17)(cid:16) \u2211\ufe01\ud835\udc56\u22121 (cid:17)\n\ud835\udc56 \ud835\udc57\n= 2 \u2212 2\n38 38\n\ud835\udc56=0 \ud835\udc57=0\n(cid:16)18(cid:17)\u2211\ufe01\u221e (cid:16)20(cid:17)\ud835\udc56\n=\n38 38\n\ud835\udc56=0\n(cid:16)18(cid:17) 1\n= = 1\n38 1\u2212 20\n38\nRealgameshavemaximumbetamounts.Youhavefinitemoneyandcasinoscankickyouout.But,ifyouhadno\nbettinglimitsandinfinitemoney,thengoforit!(andtellmewhichplanetyouarelivingon).\n2 Conditional Probabilities: Missing Not at Random\nPreamble:Wehavethreebigtoolsformanipulatingconditionalprobabilities:\n\u2022 Definitionofconditionalprobability: \ud835\udc43(\ud835\udc38\ud835\udc39) = \ud835\udc43(\ud835\udc38|\ud835\udc39)\ud835\udc43(\ud835\udc39)\n\u2022 LawofTotalProbability: \ud835\udc43(\ud835\udc38) = \ud835\udc43(\ud835\udc38\ud835\udc39) + \ud835\udc43(\ud835\udc38\ud835\udc39\ud835\udc36) = \ud835\udc43(\ud835\udc38|\ud835\udc39)\ud835\udc43(\ud835\udc39) + \ud835\udc43(\ud835\udc38|\ud835\udc39\ud835\udc36)\ud835\udc43(\ud835\udc39\ud835\udc36)\n\u2022 BayesRule: \ud835\udc43(\ud835\udc38|\ud835\udc39) = \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38) = \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38)\n\ud835\udc43(\ud835\udc39) \ud835\udc43(\ud835\udc39|\ud835\udc38)\ud835\udc43(\ud835\udc38)+\ud835\udc43(\ud835\udc39|\ud835\udc38\ud835\udc36)\ud835\udc43(\ud835\udc38\ud835\udc36)\nThisisagoodtimetocommitthesethreetomemoryandstartthinkingaboutwheneachofthemisuseful.\nProblem:YoucollectdataonwhetherornotpeopleintendtovoteforAyesha,acandidateinanupcomingelec-\ntion.Yousendanelectronicpollto100randomlychosenpeople.Youassumeall100responsesareindependent\nandidenticallydistributed.\nUserResponse Count\nRespondedthattheywillvoteforAyesha 40\nRespondedthattheywillnotvoteforAyesha 45\nDidnotrespond 15\nLet \ud835\udc34 betheeventthatapersonwillvoteforAyesha.Let \ud835\udc40 betheeventthatauserdidnotrespondtothepoll.\nWeareinterestedinestimating \ud835\udc43(\ud835\udc34),thoughcomputingthatestimateisdifficult,giventhat15usersdidn\u2019tactu-\nallyrespond.\na. WhatistheprobabilitythatausersaidtheywillvoteforAyeshaandthattheyrespondedtothepoll \ud835\udc43(\ud835\udc34 and \ud835\udc40\ud835\udc36)?\nb. Whichformulafromclasswouldyouusetocalculate \ud835\udc43(\ud835\udc34)?Yourformulashouldrelyonthecontextthat\nvotersforAyeshaareinoneoftwo(mutuallyexclusive)groups:thosethatmissedthepoll,andthosethat\ndidnot.\nc. Calculatethe \ud835\udc43(\ud835\udc34).Youestimatethattheprobabilitythatavoterismissing,giventhattheyweregoingto\nvoteforAyeshais \ud835\udc43(\ud835\udc40|\ud835\udc34) = 1.\n5\na. \ud835\udc43(\ud835\udc34 and \ud835\udc40\ud835\udc36) = 40 .The \ud835\udc40\ud835\udc36 partisredundant.\n100\nb. Thelawoftotalprobability.Itbreaksdown \ud835\udc43(\ud835\udc34) intotwoparts,thepartwhichintersectswith \ud835\udc40 andthe\npartthatintersectionswith\n\ud835\udc40\ud835\udc36\n.\n\ud835\udc43(\ud835\udc34) = \ud835\udc43(\ud835\udc34 and \ud835\udc40) + \ud835\udc43(\ud835\udc34 and \ud835\udc40\ud835\udc36 )\nc.\n\ud835\udc43(\ud835\udc34) = \ud835\udc43(\ud835\udc34 and \ud835\udc40\ud835\udc36 ) + \ud835\udc43(\ud835\udc34 and \ud835\udc40) Lawoftotalprobability\n40\n= + \ud835\udc43(\ud835\udc34 and \ud835\udc40) Fromparta\n100\n40\n= + \ud835\udc43(\ud835\udc40|\ud835\udc34)\ud835\udc43(\ud835\udc34) Chainrule\n100\n40\n\ud835\udc43(\ud835\udc34) \u2212 \ud835\udc43(\ud835\udc40|\ud835\udc34)\ud835\udc43(\ud835\udc34) = Therestisalgebra\n100\n40\n\ud835\udc43(\ud835\udc34) \u00b7 [1\u2212 \ud835\udc43(\ud835\udc40|\ud835\udc34)] =\n100\n4 40\n\ud835\udc43(\ud835\udc34) \u00b7 =\n5 100\n40 5\n\ud835\udc43(\ud835\udc34) = \u00b7\n100 4\n1\n\ud835\udc43(\ud835\udc34) =\n2\n3 Sending Bits to Space\nPreamble: Whensendingbinarydatatosatellites(orreallyoveranynoisychannel),thebitscanbeflippedwith\nhighprobability.In1947,RichardHammingdevelopedasystemtomorereliablysenddata.ByusingErrorCor-\nrectingHammingCodes,youcansendastreamof4bitsalongwith3redundantbits.Ifzerooroneoftheseven\nbitsarecorrupted,usingerrorcorrectingcodes,areceivercanidentifytheoriginal4bits.\nProblem: Letsconsiderthecaseofsendingasignaltoasatellitewhereeachbitisindependentlyflippedwith\nprobability \ud835\udc5d = 0.1.\na. Ifyousend4bits,whatistheprobabilitythatthecorrectmessagewasreceived(i.e.noneofthebitsare\nflipped).\nb. Ifyousend4bits,with3Hammingerrorcorrectingbits,whatistheprobabilitythataninterpretablemes-\nsage(i.e.amessagewithzerooroneerrors)wasreceived?\nc. InsteadofusingHammingcodes,youdecidetosend100copiesofeachofthefourbits.Ifforeverysingle\nbit,morethan50ofthecopiesarenotflipped,thesignalwillbecorrectable.Whatistheprobabilitythata\ncorrectablemessagewasreceived?\nHammingcodesaresuperinteresting.It\u2019sworthlookingupifyouhaven\u2019tseenthembefore!\na. LetYbethenumberof4bitscorrupted.Then \ud835\udc43(\ud835\udc4c = \ud835\udc58) isgivenas:\n(cid:18) (cid:19)\n4\n\ud835\udc43(\ud835\udc4c = 0) = (0.1)0(0.9)4 = 0.656\n0\nb. LetZbethenumberof7bitscorrupted.Acorrectablemessageisreceivedif \ud835\udc4d equals0or1:\n\ud835\udc43(correctable) = \ud835\udc43(\ud835\udc4d = 0) + \ud835\udc43(\ud835\udc4d = 1)\n(cid:18) (cid:19) (cid:18) (cid:19)\n7 7\n= (0.1)0(0.9)7 + (0.1)1(0.9)6 = 0.850\n0 1\nThatisa30%improvement!\nc. Let \ud835\udc4b \ud835\udc56 bethenumberofcopiesofbit\ud835\udc56 whicharenotcorrupted.Wecanrepresenteachasarandomvari-\nableaswedidinpartsaandb.\n4\n(cid:214)\n\ud835\udc43(correctable) = \ud835\udc43(\ud835\udc4b \ud835\udc56 > 50)\n\ud835\udc56=1\n4 100\n(cid:214) \u2211\ufe01\n= \ud835\udc43(\ud835\udc4b \ud835\udc56 = \ud835\udc57)\n\ud835\udc56=1 \ud835\udc57=51\n4 100 (cid:18) (cid:19)\n(cid:214) \u2211\ufe01 100\n=\n(0.9)\ud835\udc57 (0.1)100\u2212\ud835\udc57\n\ud835\udc57\n\ud835\udc56=1 \ud835\udc57=51\n100 (cid:18) (cid:19)\n(cid:16) \u2211\ufe01 100 (cid:17)4\n= (0.9)\ud835\udc57 (0.1)100\u2212\ud835\udc57 > 0.999\n\ud835\udc57\n\ud835\udc57=51\nButnowyouneedtosend400bits,insteadofthe7requiredbyhammingcodes:-).\nExtra:Explanationofthe\u201dHamming(7,4)\u201dtechnique\nIfwearetryingtotransmit4bits,wecansendanadditional3\u201dparity\u201dbitsthatwecanusetocorrectourorig-\ninalmessageifabitgetsflippedduetoanerrorintransmission.Considerthediagram.Thedatabitsare \ud835\udc51\n1\nthrough \ud835\udc51 .The\u201dparity\u201dbitsare \ud835\udc5d through \ud835\udc5d .Aparitybitissettowhatevervaluewouldmakeit\u2019slargecir-\n4 1 3\nclehaveanevennumberofbits.Forexample,thegreencircleconsistsof \ud835\udc5d , \ud835\udc51 , \ud835\udc51 ,and \ud835\udc51 .If \ud835\udc51 = 1, \ud835\udc51 = 1,\n1 1 2 4 1 2\nand \ud835\udc51 = 1,then \ud835\udc5d wouldbesetto1inordertoensurethereareanevennumberofbitsinthatcircle(inthis\n4 1\ncase,4bits).\nConvinceyourselfthatasingleerrorwhichappearedinanybitcouldbeidentifiedandcorrected!Forexample,\nif \ud835\udc51 isflipped,itwouldthrowofftheparityforthegreenandredcircles.Therefore,flipping \ud835\udc51 backistheonly\n2 2\nwaytocorrecttheparity.Asanotherexample,if \ud835\udc5d isflipped,thenonlythebluecirclewouldhaveaparityis-\n2\nsue,andflipping \ud835\udc5d backistheuniquesolutiontofixingtheparity.\n2 <END>"}
{"prompt": "Lecture notes from ProbabilityForComputerScientists.txt\n\n###\n\n", "completion": "This is a header\nProbability for Computer\nScientists\nCourse Reader for Stanford CS109\nCS109\nDepartment of Computer Science\nStanford University\nOct 2023\nV 0.923\nGet Started\nAcknowledgements: This book was written by Chris Piech for Stanford's CS109 course, Probability for\nComputer scientists. The course was originally designed by Mehran Sahami and followed the Sheldon\nRoss book Probability Theory from which we take inspiration. The course has since been taught by Lisa\nYan, Jerry Cain and David Varodayan and their ideas and feedback have improved this reader.\nThis course reader is open to contributions. Want to make your mark? Keen to fix a typo? Download the\ngithub project and publish a pull request. We will credit all contributors. Thank you so much to folks who\nhave contributed to editing the book: GitHub Contributors.\nRecent Updates:\n1. Set Diversity. Oct 13th 2024\n1\nIntroduction\nThis is a header\nNotation Reference\nCore Probability\nNotation Meaning\nE Capital letters can denote events\nA Sometimes they denote sets\n|E| Size of an event or set\nEC Complement of an event or set\nEF And of events (aka intersection)\nEandF And of events (aka intersection)\nE\u2229F And of events (aka intersection)\nEorF Or of events (aka union)\nE\u222aF Or of events (aka union)\ncount(E) The number of times that E occurs\nP(E) The probability of an event E\nP(E|F) The conditional probability of an event E given F\nP(E,F) The probability of event E and F\nP(E|F,G) The conditional probability of an event E given both F and G\nn! n factorial\n(n)\nBinomial coefficient\nk\n( n ) Multinomial coefficient\nr1,r2,r3\nRandom Variables\nNotation Meaning\nx Lower case letters denote regular variables\nX Capital letters are used to denote random variables\nK Capital K is reserved for constants\nE[X] Expectation of X\nVar(X) Variance of X\n1\nThis is a header\nNotation Meaning\nP(X=x) Probability mass function (PMF) of X, evaluated at x\nP(x) Probability mass function (PMF) of X, evaluated at x\nf(X=x) Probability density function (PDF) of X, evaluated at x\nf(x) Probability density function (PDF) of X, evaluated at x\nf(X=x,Y =y) Joint probability density\nf(X=x|Y =y) Conditional probability density\nF X(x) or F(x) Cumulative distribution function (CDF) of X\nIID Independent and Identically Distributed\nParametric Distributions\nNotation Meaning\nX\u223cBern(p) X is a Bernoulli random variable\nX\u223cBin(n,p) X is a Binomial random variable\nX\u223cPoi(p) X is a Poisson random variable\nX\u223cGeo(p) X is a Geometric random variable\nX\u223cNegBin(r,p) X is a Negative Binomial random variable\nX\u223cUni(a,b) X is a Uniform random variable\nX\u223cExp(\u03bb) X is a Exponential random variable\nX\u223cBeta(a,b) X is a Beta random variable\n2\nThis is a header\nCore Probability Reference\nDefinition: Empirical Definition of Probability\nThe probability of any event E can be defined as:\ncount(E)\nP(E)= lim\nn\u2192\u221e n\nWhere count(E) is the number of times that E occured in n experiments.\nDefinition: Core Identities\nFor an event E and a sample space S\n0\u2264P(E)\u22641 All probabilities are numbers between 0 and 1.\nP(S)=1 All outcomes must be from the Sample Space.\nP(E)=1\u2212P(EC) The probability of an event from its complement.\nDefinition: Probability of Equally Likely Outcomes\nIf S is a sample space with equally likely outcomes, for an event E that is a subset of the outcomes in S:\nnumberofoutcomesin E |E|\nP(E)= =\nnumberofoutcomesin S |S|\nDefinition: Conditional Probability.\nThe probability of E given that (aka conditioned on) event F already happened:\nP(EandF)\nP(E|F)=\nP(F)\nDefinition: Probability of or with Mututally Exclusive Events\nIf two events E and F are mutually exclusive then the probability of E or F occurring is:\nP(EorF)=P(E)+P(F)\nFor n events E 1,E 2,\u2026E n where each event is mutually exclusive of one another (in other words, no\noutcome is in more than one event). Then:\nn\nP(E orE or\u2026orE )=P(E )+P(E )+\u22ef+P(E )=\u2211P(E)\n1 2 n 1 2 n i\ni=1\n1\nThis is a header\nDefinition: General Probability of or (Inclusion-Exclusion)\nFor any two events E and F:\nP(EorF)=P(E)+P(F)\u2212P(EandF)\nFor three events, E, F, and G the formula is:\nP(EorForG)= P(E)+P(F)+P(G)\n\u2212P(EandF)\u2212P(EandG)\u2212P(FandG)\n+P(EandFandG)\nFor more than three events see the chapter of probability of or.\nDefinition: Probability of and for Independent Events.\nIf two events: E, F are independent then the probability of E and F occurring is:\nP(EandF)=P(E)\u22c5P(F)\nFor n events E 1,E 2,\u2026E n that are independent of one another:\nn\nP(E andE and\u2026andE )=\u220fP(E)\n1 2 n i\ni=1\nDefinition: General Probability of and (The Chain Rule)\nFor any two events E and F:\nP(EandF)=P(E|F)\u22c5P(F)\nFor n events E 1,E 2,\u2026E n:\nP(E andE and\u2026andE )=P(E )\u22c5P(E |E )\u22c5P(E |E andE )\u2026\n1 2 n 1 2 1 3 1 2\nP(E |E \u2026E )\nn 1 n\u22121\nDefinition: The Law of Total Probability\nFor any two events E and F:\nP(E)=P(EandF)+P(EandFC)\n=P(E|F)P(F)+P(E|FC)P(FC)\nFor mutually exclusive events: B 1,B 2,\u2026B n such that every outcome in the sample space falls into one\nof those events:\nn\nP(E)=\u2211P(EandB) Extensionofourobservation\ni\ni=1\nn\n=\u2211P(E|B)P(B) Usingchainruleoneachterm\ni i\ni=1\nDefinition: Bayes' Theorem\nThe most common form of Bayes' Theorem is Bayes' Theorem Classic:\nP(E|B)\u22c5P(B)\nP(B|E)=\nP(E)\nBayes' Theorem combined with the Law of Total Probability:\nP(E|B)\u22c5P(B)\nP(B|E)=\nP(E|B)\u22c5P(B)+P(E|BC)\u22c5P(BC)\n2\nThis is a header\n3\nThis is a header\nRandom Variable Reference\nDiscrete Random Variables\nBernoulli Random Variable\nNotation: X\u223cBern(p)\nDescription: A boolean variable that is 1 with probability p\nParameters: p, the probability that X=1.\nSupport: x is either 0 or 1\np if x=1\nPMF equation: P(X=x)={ 1\u2212p if x=0\nPMF (smooth): P(X=x)=px(1\u2212p)1\u2212x\nExpectation: E[X]=p\nVariance: Var(X)=p(1\u2212p)\nPMF graph:\nParameter p: 0.80\n1\nThis is a header\nBinomial Random Variable\nNotation: X\u223cBin(n,p)\nDescription: Number of \"successes\" in n identical, independent experiments each with\nprobability of success p.\nParameters: n\u2208{0,1,\u2026}, the number of experiments.\np\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{0,1,\u2026,n}\nn\nPMF equation: P(X=x)=( )px(1\u2212p)n\u2212x\nx\nExpectation: E[X]=n\u22c5p\nVariance: Var(X)=n\u22c5p\u22c5(1\u2212p)\nPMF graph:\nParameter n: 20 Parameter p: 0.60\n2\nThis is a header\nPoisson Random Variable\nNotation: X\u223cPoi(\u03bb)\nDescription: Number of events in a fixed time frame if (a) the events occur with a constant mean\nrate and (b) they occur independently of time since last event.\nParameters: \u03bb\u2208R+, the constant average rate.\nSupport: x\u2208{0,1,\u2026}\n\u03bbxe\u2212\u03bb\nPMF equation: P(X=x)=\nx!\nExpectation: E[X]=\u03bb\nVariance: Var(X)=\u03bb\nPMF graph:\nParameter \u03bb: 5\n3\nThis is a header\nGeometric Random Variable\nNotation: X\u223cGeo(p)\nDescription: Number of experiments until a success. Assumes independent experiments each\nwith probability of success p.\nParameters: p\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{1,\u2026,\u221e}\nP(X=x)=(1\u2212p)x\u22121p\nPMF equation:\nExpectation: E[X]= 1\np\nVariance: Var(X)= 1\u2212p\np2\nPMF graph:\nParameter p: 0.20\n4\nThis is a header\nNegative Binomial Random Variable\nNotation: X\u223cNegBin(r,p)\nDescription: Number of experiments until r successes. Assumes each experiment is independent\nwith probability of success p.\nParameters: r>0, the number of success we are waiting for.\np\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{r,\u2026,\u221e}\nx\u22121\nPMF equation: P(X=x)=( )pr(1\u2212p)x\u2212r\nr\u22121\nExpectation: E[X]= r\np\nVariance: Var(X)= r\u22c5(1\u2212p)\np2\nPMF graph:\nParameter r: 3 Parameter p: 0.20\n5\n\u23aa\n\u23aa\nThis is a header\nContinuous Random Variables\nUniform Random Variable\nNotation: X\u223cUni(\u03b1,\u03b2)\nDescription: A continuous random variable that takes on values, with equal likelihood, between\n\u03b1 and \u03b2\nParameters: \u03b1\u2208R, the minimum value of the variable.\n\u03b2\u2208R, \u03b2>\u03b1, the maximum value of the variable.\nSupport: x\u2208[\u03b1,\u03b2]\n1 for x\u2208[\u03b1,\u03b2]\nPDF equation: f(x)={\u03b2\u2212\u03b1\n0 else\n\u23a7x\u2212\u03b1 for x\u2208[\u03b1,\u03b2]\nCDF equation: \u03b2\u2212\u03b1\nF(x)=\u23a80 for x<\u03b1\n\u23a9\n1 for x>\u03b2\nExpectation: E[X]= 1(\u03b1+\u03b2)\n2\nVariance: Var(X)= 1 (\u03b2\u2212\u03b1)2\n12\nPDF graph:\nParameter \u03b1: 0 Parameter \u03b2: 1\n6\nThis is a header\nExponential Random Variable\nNotation: X\u223cExp(\u03bb)\nDescription: Time until next events if (a) the events occur with a constant mean rate and (b) they\noccur independently of time since last event.\nParameters: \u03bb\u2208R+, the constant average rate.\nSupport: x\u2208R+\nf(x)=\u03bbe\u2212\u03bbx\nPDF equation:\nF(x)=1\u2212e\u2212\u03bbx\nCDF equation:\nExpectation: E[X]=1/\u03bb\nVariance: Var(X)=1/\u03bb2\nPDF graph:\nParameter \u03bb: 5\n7\nThis is a header\nNormal (aka Gaussian) Random Variable\nNotation: X\u223cN(\u03bc,\u03c32)\nDescription: A common, naturally occurring distribution.\nParameters: \u03bc\u2208R, the mean.\n\u03c32\u2208R, the variance.\nSupport: x\u2208R\nPDF equation: f(x)= 1 e\u22121 2(x\u2212 \u03c3\u03bc)2\n\u03c3\u221a2\u03c0\nx\u2212\u03bc\nCDF equation: F(x)=\u03d5( ) Where \u03d5 istheCDFofthestandardnormal\n\u03c3\nExpectation: E[X]=\u03bc\nVariance: Var(X)=\u03c32\nPDF graph:\nParameter \u03bc: 5 Parameter \u03c3: 5\n8\nThis is a header\nBeta Random Variable\nNotation: X\u223cBeta(a,b)\nDescription: A belief distribution over the value of a probability p from a Binomial distribution\nafter observing a\u22121 successes and b\u22121 fails.\nParameters: a>0, the number successes + 1\nb>0, the number of fails + 1\nSupport: x\u2208[0,1]\nPDF equation: f(x)=B(a,b)\u22c5xa\u22121\u22c5(1\u2212x)b\u22121 where B(a,b)= \u0393(a)\u0393(b)\n\u0393(a,b)\nCDF equation: No closed form\nExpectation: E[X]= a\na+b\nVariance: Var(X)= ab\n(a+b)2(a+b+1)\nPDF graph:\nParameter a: 2 Parameter b: 4\n9\nThis is a header\nPython Reference\nFactorial\nCompute n! as an integer. This example computes 20!:\nimport math\nprint(math.factorial(20))\nChoose\nAs of Python 3.8, you can compute\n(n)\nfrom the math module. This example computes\n(10):\nm 5\nimport math\nprint(math.comb(10, 5))\nNatural Exponent\nCalculate ex. For example this computes e3\nimport math\nprint(math.exp(3))\nSciPy Stats Library\nSciPy is a free and open source library for scientific computing that is built on top of NumPy. You may find\nit helpful to use SciPy to check the answers you obtain in the written section of your problem sets. NumPy\nhas the capability of drawing samples from many common distributions (type `help(np.random)` in the\npython interpreter), but SciPy has the added capability of computing the probability of observing events,\nand it can perform computations directly on the probability mass/density functions.\nBinomial\nMake a Binomial Random variable X and compute its probability mass function (PMF) or cumulative\ndensity function (CDF). We love the scipy stats library because it defines all the functions you would\ncare about for a random variable, including expectation, variance, and even things we haven't talked\nabout in CS109, like entropy. This example declares X\u223cBin(n=10,p=0.2). It calculates a few\nstatistics on X. It then calculates P(X=3) and P(X\u22644). Finally it generates a few random samples\nfrom X:\nfrom scipy import stats\nX = stats.binom(10, 0.2) # Declare X to be a binomial random variable\nprint(X.pmf(3)) # P(X = 3)\nprint(X.cdf(4)) # P(X <= 4)\nprint(X.mean()) # E[X]\nprint(X.var()) # Var(X)\nprint(X.std()) # Std(X)\nprint(X.rvs()) # Get a random sample from X\nprint(X.rvs(10)) # Get 10 random samples form X\nFrom a terminal you can always use the \"help\" command to see a full list of methods defined on a\nvariable (or for a package):\n1\nThis is a header\nfrom scipy import stats\nX = stats.binom(10, 0.2) # Declare X to be a binomial random variable\nhelp(X) # List all methods defined for X\nPoisson\nMake a Poisson Random variable Y. This example declares Y \u223cPoi(\u03bb=2). It then calculates\nP(Y =3):\nfrom scipy import stats\nY = stats.poisson(2) # Declare Y to be a poisson random variable\nprint(Y.pmf(3)) # P(Y = 3)\nprint(Y.rvs()) # Get a random sample from Y\nGeometric\nMake a Geometric Random variable X, the number of trials until a success. This example declares\nX\u223cGeo(p=0.75):\nfrom scipy import stats\nX = stats.geom(0.75) # Declare X to be a geometric random variable\nprint(X.pmf(3)) # P(X = 3)\nprint(X.rvs()) # Get a random sample from Y\nNormal\nMake a Normal Random variable A. This example declares A\u223cN(\u03bc=3,\u03c32=16). It then calculates\nf Y(0) and F Y(0). Very Important!!! In class, the second parameter to a normal was the variance (\u03c32). In\nthe scipy library, the second parameter is the standard deviation (\u03c3):\nimport math\nfrom scipy import stats\nA = stats.norm(3, math.sqrt(16)) # Declare A to be a normal random variable\nprint(A.pdf(4)) # f(3), the probability density at 3\nprint(A.cdf(2)) # F(2), which is also P(Y < 2)\nprint(A.rvs()) # Get a random sample from A\nExponential\nMake an Exponential Random variable B. This example declares B\u223cExp(\u03bb=4):\nfrom scipy import stats\n# `\u03bb` is a common parameterization for the exponential,\n# but `scipy` uses `scale` which is `1/\u03bb`\nB = stats.expon(scale=1/4)\nprint(B.pdf(1)) # f(1), the probability density at 1\nprint(B.cdf(2)) # F(2) which is also P(B < 2)\nprint(B.rvs()) # Get a random sample from B\nBeta\nMake an Beta Random variable X. This example declares X\u223cBeta(\u03b1=1,\u03b2=3):\nfrom scipy import stats\nX = stats.beta(1, 3) # Declare X to be a beta random variable\nprint(X.pdf(0.5)) # f(0.5), the probability density at 1\nprint(X.cdf(0.7)) # F(0.7) which is also P(X < 0.7)\nprint(X.rvs()) # Get a random sample from X\n2\nThis is a header\n3\nPart 1: Core Probability\nThis is a header\nCounting\nAlthough you may have thought you had a pretty good grasp on the notion of counting at the age of\nthree, it turns out that you had to wait until now to learn how to really count. Aren\u2019t you glad you took\nthis class now?! But seriously, counting is like the foundation of a house (where the house is all the great\nthings we will do later in this book, such as machine learning). Houses are awesome. Foundations, on the\nother hand, are pretty much just concrete in a hole. But don\u2019t make a house without a foundation. It won\u2019t\nturn out well.\nCounting with Steps\nDefinition: Step Rule of Counting (aka Product Rule of Counting)\nIf an experiment has two parts, where the first part can result in one of m outcomes and the second part\ncan result in one of n outcomes regardless of the outcome of the first part, then the total number of\noutcomes for the experiment is m\u22c5n.\nRewritten using set notation, the Step Rule of Counting states that if an experiment with two parts has an\noutcome from set A in the first part, where |A|=m, and an outcome from set B in the second part\n(where the number of outcomes in B is the same regardless of the outcome of the first part), where\n|B|=n, then the total number of outcomes of the experiment is |A||B|=m\u22c5n.\nSimple Example: Consider a hash table with 100 buckets. Two arbitrary strings are independently hashed\nand added to the table. How many possible ways are there for the strings to be stored in the table? Each\nstring can be hashed to one of 100 buckets. Since the results of hashing the first string do not impact the\nhash of the second, there are 100 * 100 = 10,000 ways that the two strings may be stored in the hash\ntable.\nPeter Norvig, the author of the canonical textbook \"Artificial Intelligence\" made the following\ncompelling point on why computer scientists need to know how to count. To start, let's set a baseline for a\nreally big number: The number of atoms in the observable universe, often estimated to be around 10 to\nthe 80th power (1080). There certainly are a lot of atoms in the universe. As a leading expert said,\n\u201cSpace is big. Really big. You just won\u2019t believe how vastly, hugely, mind-bogglingly big it is. I mean,\nyou may think it\u2019s a long way down the road to the chemist, but that\u2019s just peanuts to space.\u201d -\nDouglas Adams\nThis number is often used to demonstrate tasks that computers will never be able to solve. Problems can\nquickly grow to an absurd size, and we can understand why using the Step Rule of Counting.\nThere is an art project to display every possible picture. Surely that would take a long time, because there\nmust be many possible pictures. But how many? We will assume the color model known as True Color,\nin which each pixel can be one of 224 \u2248 17 million distinct colors.\nHow many distinct pictures can you generate from (a) a smartphone camera shown with 12 million\npixels, (b) a grid with 300 pixels, and (c) a grid with just 12 pixels?\n1\nThis is a header\nAnswer: We can use the step rule of counting. An image can be created one pixel at a time, step by step.\nEach time we choose a pixel you can select its color out of 17 million choices. An array of n pixels\nproduces (17 million)n different pictures. (17 million)12 \u2248 1086, so the tiny 12-pixel grid produces a\nmillion times more pictures than the number of atoms in the universe! How about the 300 pixel array? It\ncan produce 102167 pictures. You may think the number of atoms in the universe is big, but that\u2019s just\npeanuts to the number of pictures in a 300-pixel array. And 12M pixels? 1086696638 pictures.\nExample: Unique states of Go\nFor example, a Go board has 19 \u00d7 19 points where a user can place a stone. Each of the points can be\nempty or occupied by black or white stone. By the Step Rule of Counting, we can compute the number of\nunique board configurations.\nIn Go there are 19x19 points. Each point can have a black stone, white stone, or no stone at all.\nHere we are going to construct the board one point at a time, step by step. Each time we add a point we\nhave a unique choice where we can decide to make the point one of three options: {Black, White, No\nStone}. Using this construction we can apply the Step Rule of Counting. If there was only one point,\nthere would be three unique board configurations. If there were four points you would have\n3\u22c53\u22c53\u22c53=81 unique combinations. In Go there are 3(19\u00d719)\u224810172 possible board positions. The way\nwe constructed our board didn't take into account which ones were illegal by the rules of Go. It turns out\nthat \"only\" about 10170 of those positions are legal. That is about the square of the number of atoms in the\nuniverse. In other words: if there was another universe of atoms for every single atom, only then would\nthere be as many atoms in the universe as there are unique configurations of a Go board.\nAs a computer scientist this sort of result can be very important. While computers are powerful, an\nalgorithm which needed to store each configuration of the board would not be a reasonable approach. No\ncomputer can store more information than atoms in the universe squared!\nThe above argument might leave you feeling like some problems are incredibly hard as a result of the\nproduct rule of counting. Let\u2019s take a moment to talk about how the product rule of counting can help!\nMost logarithmic time algorithms leverage this principle.\nImagine you are building a machine learning system that needs to learn from data and you want to\nsynthetically generate 10 million unique data points for it. How many steps would you need to encode to\nget to 10 million? Assuming that at each step you have a binary choice, the number of unique data points\nyou produce will be 2n by the Step Rule of counting. If we chose n such that log 210,000,000<n. You\nwould only need to encode n=24 binary decisions.\nExample: Rolling two dice. Two 6-sided dice, with faces numbered 1 through 6, are rolled. How many\npossible outcomes of the roll are there?\nSolution: Note that we are not concerned with the total value of the two die (\"die\" is the singular form of\n\"dice\"), but rather the set of all explicit outcomes of the rolls. Since the first die can come up with 6\npossible values and the second die similarly can have 6 possible values (regardless of what appeared on\n2\nThis is a header\nthe first die), the total number of potential outcomes is 36 (= 6 \u00d7 6). These possible outcomes are\nexplicitly listed below as a series of pairs, denoting the values rolled on the pair of dice:\n(1, 1) (1, 2) (1, 3) (1, 4) (1, 5) (1, 6)\n(2, 1) (2, 2) (2, 3) (2, 4) (2, 5) (2, 6)\n(3, 1) (3, 2) (3, 3) (3, 4) (3, 5) (3, 6)\n(4, 1) (4, 2) (4, 3) (4, 4) (4, 5) (4, 6)\n(5, 1) (5, 2) (5, 3) (5, 4) (5, 5) (5, 6)\n(6, 1) (6, 2) (6, 3) (6, 4) (6, 5) (6, 6)\nCounting with or\nIf you want to consider the total number of unique outcomes, when outcomes can come from source A or\nsource B, then the equation you use depends on whether or not there are outcomes which are both in A\nand B. If not, you can use the simpler \"Mutually Exclusive Counting\" rule. Otherwise you need to use\nthe slightly more involved Inclusion Exclusion rule.\nDefinition: Mutually Exclusive Counting\nIf the outcome of an experiment can either be drawn from set A or set B, where none of the outcomes in\nset A are the same as any of the outcomes in set B (called mutual exclusion), then there are\n|AorB|=|A|+|B| possible outcomes of the experiment.\nExample: Sum of Routes. A route finding algorithm needs to find routes from Nairobi to Dar Es Salaam.\nIt finds routes that either pass through Mt Kilimanjaro or Mombasa. There are 20 routes that pass through\nMt Kilimanjaro, 15 routes that pass through Mombasa and 0 routes which pass through both Mt\nKilimanjaro and Mombasa. How many routes are there total?\nSolution: Routes can come from either Mt Kilimanjaro or Mombasa. The two sets of routes are mutually\nexclusive as there are zero routes which are in both groups. As such the total number of routes is\naddition: 20 + 15 = 35.\nIf you can show that two groups are mutually exclusive counting becomes simple addition. Of course not\nall sets are mutually exclusive. In the example above, imagine there had been a single route which went\nthrough both Mt Kilimanjaro and Mombasa. We would have double counted that route because it would\nbe included in both the sets. If sets are not mutually exclusive, counting the or is still addition, we simply\nneed to take into account any double counting.\nDefinition: Inclusion-Exclusion Counting\nIf the outcome of an experiment can either be drawn from set A or set B, and sets A and B may\npotentially overlap (i.e., it is not the case that A and B are mutually exclusive), then the number of\noutcomes of the experiment is |AorB|=|A|+|B|\u2212|AandB|.\nNote that the Inclusion-Exclusion Principle generalizes the Sum Rule of Counting for arbitrary sets A\nand B. In the case where AandB=\u2205, the Inclusion-Exclusion Principle gives the same result as the\nSum Rule of Counting since |AandB|=0.\nExample: An 8-bit string (one byte) is sent over a network. The valid set of strings recognized by the\nreceiver must either start with \"01\" or end with \"10\". How many such strings are there?\n3\nThis is a header\nSolution: The potential bit strings that match the receiver\u2019s criteria can either be the 64 strings that start\nwith \"01\" (since that last 6 bits are left unspecified, allowing for 26=64 possibilities) or the 64 strings\nthat end with \"10\" (since the first 6 bits are unspecified). Of course, these two sets overlap, since strings\nthat start with \"01\" and end with \"10\" are in both sets. There are 24 = 16 such strings (since the middle 4\nbits can be arbitrary). Casting this description into corresponding set notation, we have: |A| = 64, |B| =\n64, and |AandB| = 16, so by the Inclusion-Exclusion Principle, there are 64 + 64 \u2212 16 = 112 strings that\nmatch the specified receiver\u2019s criteria.\nOvercounting and Correcting\nOne strategy for counting is sometimes to overcount a solution and then correct for any duplicates. This\nis especially common when it is easier to generate all outcomes under some relaxed assumptions, or\nsomeone introduces contraints. If you can argue that you have over-counted each element the same\nmultiple number of times, you can simply correct by using division. If you can count exactly how many\nelements were over-counted you can correct using subtraction.\nAs a simple example to demonstrate the point, lets revisit the problem of generating all images, but this\ntime lets just have 4 pixels (2x2) and each pixel can only be blue or white. How many unique images are\nthere? Generating any image is a four step process where you choose each pixel one at a time. Since each\npixel has two choices there are 24=16 unique images (they are not exactly Picasso \u2014 but hey, it's 4\npixels):\nNow lets say we add in a new \"constraint\" that we only want to accept pictures which have an odd\nnumber of pixels turned blue. There are two ways of getting to the answer. You could start out with the\noriginal 16 and work out that you need to subtract off 8 images that have either 0, 2 or 4 blue pixels\n(which is easier to work out after the next chapter). Or you could have counted up using Mutually\nExclusive Counting: there are 4 ways of making an image with 1 pixel and 4 ways of making an image\nwith 3. Both approaches lead to the same answer, 8.\nNext lets add a much harder constraint: mirror indistinction. If you can flip any image horizontally to\ncreate another, they are no longer considered unique. For example these two both show up in our set of 8\nodd-blue pixel images, but they are now considered to be the same (they are indistinct after a horizontal\nflip):\nHow many images have an odd number of pixels taking into account mirror indistinction? The answer is\nthat for each unique image with odd numbers of blue pixels, under this new constraint, you have counted\nit twice: itself and its horizonal flip. To convince yourself that each image has been counted exactly twice\nyou can look at all of the examples in the set of 8 images with an odd number of blue pixels. Each image\nis next to one which is indistinct after a horizontal flip. Since each image was counted exactly twice in\nthe set of 8, we can divide by two to get the updated count. If we list them out we can confirm that there\nare 8/2=4 images left after this last constraint:\n4\nThis is a header\nApplying any math (counting included) to novel contexts can be as much an art as it is a science. In the\nnext chapter we will build a useful toolset from the basic first principles of counting by steps, and\ncounting by \"or\".\n5\nThis is a header\nCombinatorics\nCounting problems can be approached from the basic building blocks described in the first section:\nCounting. However some counting problems are so ubiquitous in the world of probability that it is worth\nknowing a few higher level counting abstractions. When solving problems, if you can find the analogy\nfrom these canonical examples you can build off of the corresponding combinatorics formulas:\n1. Permutations of Distinct Objects\n2. Permutations with Indistinct Objects\n3. Combinations with Distinct Objects\n4. Bucketing with Distinct Objects\n5. Bucketing with Indistinct Objects\n6. Bucketing into Fixed Sized Containers\nWhile these are by no means the only common counting paradigms, it is a helpful set.\nPermutations of Distinct Objects\nDefinition: Permutation Rule\nA permutation is an ordered arrangement of n distinct objects. Those n objects can be permuted in\nn\u22c5(n\u20131)\u22c5(n\u20132)\u22ef2\u22c51=n! ways.\nThis changes slightly if you are permuting a subset of distinct objects, or if some of your objects are\nindistinct. We will handle those cases shortly! Note that unique is a synonym for distinct.\nExample: How many unique orderings of characters are possible for the string \"BAYES\"? Solution:\nSince the order of characters is important, we are considering all permutations of the 5 distinct characters\nB, A, Y, E, and S: 5!=120. Here is the full list:\nBAYES, BAYSE, BAEYS, BAESY, BASYE, BASEY, BYAES, BYASE, BYEAS, BYESA, BYSAE,\nBYSEA, BEAYS, BEASY, BEYAS, BEYSA, BESAY, BESYA, BSAYE, BSAEY, BSYAE, BSYEA,\nBSEAY, BSEYA, ABYES, ABYSE, ABEYS, ABESY, ABSYE, ABSEY, AYBES, AYBSE, AYEBS,\nAYESB, AYSBE, AYSEB, AEBYS, AEBSY, AEYBS, AEYSB, AESBY, AESYB, ASBYE, ASBEY,\nASYBE, ASYEB, ASEBY, ASEYB, YBAES, YBASE, YBEAS, YBESA, YBSAE, YBSEA, YABES,\nYABSE, YAEBS, YAESB, YASBE, YASEB, YEBAS, YEBSA, YEABS, YEASB, YESBA, YESAB,\nYSBAE, YSBEA, YSABE, YSAEB, YSEBA, YSEAB, EBAYS, EBASY, EBYAS, EBYSA, EBSAY,\nEBSYA, EABYS, EABSY, EAYBS, EAYSB, EASBY, EASYB, EYBAS, EYBSA, EYABS, EYASB,\nEYSBA, EYSAB, ESBAY, ESBYA, ESABY, ESAYB, ESYBA, ESYAB, SBAYE, SBAEY, SBYAE,\nSBYEA, SBEAY, SBEYA, SABYE, SABEY, SAYBE, SAYEB, SAEBY, SAEYB, SYBAE, SYBEA,\nSYABE, SYAEB, SYEBA, SYEAB, SEBAY, SEBYA, SEABY, SEAYB, SEYBA, SEYAB\nExample: a smartphone has a 4-digit passcode. Suppose there are 4 smudges over 4 digits on the screen.\nHow many distinct passcodes are possible?\nSolution: Since the order of digits in the code is important, we should use permutations. And since there\nare exactly four smudges we know that each number in the passcode is distinct. Thus, we can plug in the\npermutation formula: 4! = 24.\nPermutations of Indistinct Objects\n1\nThis is a header\nDefinition: Permutations of Indistinct Objects\nGenerally when there are n objects and:\nn 1 are the same (indistinguishable) and\nn 2 are the same and\n...\nn r are the same, then the number of distinct permutations is:\nn!\nNumberofuniqueorderings=\nn !n !\u22efn !\n1 2 r\nExample: How many distinct bit strings can be formed from three 0\u2019s and two 1\u2019s?\nSolution: 5 total digits would give 5! permutations. But that is assuming the 0\u2019s and 1\u2019s are\ndistinguishable (to make that explicit, let\u2019s give each one a subscript). Here are the 3!\u22c52!=12 different\nways that we could have arrived at the identical string \"01100\" if we thought of each 0 and 1 as unique.\n0 1 1 0 0\n1 0 1 2 3\n0 1 1 0 0\n1 0 1 3 2\n0 1 1 0 0\n2 0 1 1 3\n0 1 1 0 0\n2 0 1 3 1\n0 1 1 0 0\n3 0 1 1 2\n0 1 1 0 0\n3 0 1 2 1\n0 1 1 0 0\n1 1 0 2 3\n0 1 1 0 0\n1 1 0 3 2\n0 1 1 0 0\n2 1 0 1 3\n0 1 1 0 0\n2 1 0 3 1\n0 1 1 0 0\n3 1 0 1 2\n0 1 1 0 0\n3 1 0 2 1\nSince identical digits are indistinguishable, all the listed permutations are the same. For any given\npermutation, there are 3! ways of rearranging the 0\u2019s and 2! ways of rearranging the 1\u2019s (resulting in\nindistinguishable strings). We have over-counted. Using the formula for permutations of indistinct\nobjects, we can correct for the over-counting:\n5! 120\nTotal= = =10\n3!\u22c52! 6\u22c52\nExample: How many distinct orderings of characters are possible for the string \"MISSISSIPPI\"?\nSolution: In the case of the string \"MISSISSIPPI\", we should separate the characters into four distinct\ngroups of indistinct characters: one \"M\", four \"I\"s, four \"S\"s, and two \"P\"s. The number of distinct\norderings are:\n11!\n=34,650\n1!4!4!2!\nExample: Consider the 4-digit passcode smart-phone from before. How many distinct passcodes are\npossible if there are 3 smudges over 3 digits on the screen?\nSolution: One of 3 digits is repeated, but we don't know which one. We can solve this by making three\ncases, one for each digit that could be repeated (each with the same number of permutations). Let\nA,B,C represent the 3 digits, with C repeated twice. We can initially pretend the two C's are distinct\n2\nThis is a header\n[A,B,C 1,C 2]. Then each case will have 4! permutations: However, then we need to eliminate the\ndouble-counting of the permutations of the identical digits (one A, one B, and two C's):\n4!\n2!\u22c51!\u22c51!\nAdding up the three cases for the different repeated digits gives\n4!\n3\u22c5 =3\u22c512=36\n2!\u22c51!\u22c51!\nPart B: What if there are 2 smudges over 2 digits on the screen?\nSolution: There are two possibilities: 2 digits used twice each, or 1 digit used 3 times, and other digit\nused once.\n4! 4!\n+2\u22c5 =6+(2\u22c54)=6+8=14\n2!\u22c52! 3!\u22c51!\nYou can use the power of computers to enumerate all permutations. Here is sample python code which\nuses the built in itertools library:\n>>> import itertools\n# get all 4! = 24 permutations of 1,2,3,4 as a list:\n>>> list(itertools.permutations([1,2,3,4]))\n[(1, 2, 3, 4), (1, 2, 4, 3), (1, 3, 2, 4), (1, 3, 4, 2), (1, 4, 2, 3), (1, 4, 3, 2),\n(2, 1, 3, 4), (2, 1, 4, 3), (2, 3, 1, 4), (2, 3, 4, 1), (2, 4, 1, 3), (2, 4, 3, 1),\n(3, 1, 2, 4), (3, 1, 4, 2), (3, 2, 1, 4), (3, 2, 4, 1), (3, 4, 1, 2), (3, 4, 2, 1),\n(4, 1, 2, 3), (4, 1, 3, 2), (4, 2, 1, 3), (4, 2, 3, 1), (4, 3, 1, 2), (4, 3, 2, 1)]\n# get all 3!/2! = 3 unique permutations of 1,1,2 as a set:\n>>> set(itertools.permutations([1,1,2]))\n{(1, 2, 1), (2, 1, 1), (1, 1, 2)}\nCombinations of Distinct Objects\nDefinition: Combinations\nA combination is an unordered selection of r objects from a set of n objects. If all objects are distinct, and\nobjects are not \"replaced\" once selected, then the number of ways of making the selection is:\nn! n\nNumberofuniqueselections= =( )\nr!(n\u2212r)! r\nHere are all the\n10=(5)\nways of choosing three items from a list of 5 unique numbers:\n3\n# Get all ways of choosing three numbers from [1,2,3,4,5]\n>>> list(itertools.combinations([1,2,3,4,5], 3))\n[(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5), (2, 3, 4), (2, 3,\n5), (2, 4, 5), (3, 4, 5)]\nNotice how order doesn't matter. Since (1, 2, 3) is in the set of combinations, we don't also include (3, 2,\n1) as this is considered to be the same selection. Note that this formula does not work if some of the\nobjects are indistinct from one another.\nHow did we get the formula n! ? Consider this general way to select r unordered objects from a set\nr!(n\u2212r)!\nof n objects, e.g., \u201c7 choose 3\u201d:\n3\nThis is a header\n1. First consider permutations of all n objects. There are n! ways to do that.\n2. Then select the first r in the permutation. There is one way to do that.\n3. Note that the order of r selected objects is irrelevant. There are r! ways to permute them. The selection\nremains unchanged.\n4. Note that the order of (n\u2212r) unselected objects is irrelevant. There are (n\u2212r)! ways to permute\nthem. The selection remains unchanged.\nn! n\nTotal= =( )\nr!\u22c5(n\u2212r)! r\nExample: In the Hunger Games, how many ways are there of choosing 2 villagers from district 12,\nwhich has a population of 8,000?\nSolution: This is a straightforward combinations problem.\n(8000)=31,996,000.\n2\nPart A: How many ways are there to select 3 books from a set of 6?\nSolution: If each of the books are distinct, then this is another straightforward combination problem.\nThere are (6)= 6! =20 ways.\n3 3!3!\nPart B: How many ways are there to select 3 books if there are two books that should not both be chosen\ntogether? For example, if you are choosing 3 out of 6 probability books, don't choose both the 8th and 9th\nedition of the Ross textbook.\nSolution: This problem is easier to solve if we split it up into cases. Consider the following three\ndifferent cases:\nCase 1: Select the 8th Ed. and 2 other non-9th Ed. books: There are\n(4)\nways of doing so.\n2\nCase 2: Select the 9th Ed. and 2 other non-8th Ed. books: There are\n(4)\nways of doing so.\n2\nCase 3: Select 3 books from the 4 remaining books that are neither the 8th nor the 9th edition: There are\n(4)\nways of doing so.\n3\nUsing our old friend the Sum Rule of Counting, we can add the cases:\n4 4\nTotal=2\u22c5( )+( )=16\n2 3\nAlternatively, we could have calculated all the ways of selecting 3 books from 6, and then subtract the\n\"forbidden'' ones (i.e., the selections that break the constraint).\nForbidden Case: Select 8th edition and 9th edition and 1 other book. There are\n(4)\nways of doing so\n1\n(which equals 4). Total = All possibilities - forbidden = 20 - 4 = 16 Two different ways to get the same\nright answer!\nBucketing with Distinct Objects\nIn this section we are going to be counting the many different ways that we can think of stuffing elements\ninto containers. (It turns out that Jacob Bernoulli was into voting and ancient Rome. And in ancient Rome\nthey used urns for ballot boxes. For this reason many books introduce this through counting ways to put\nballs in urns.) This \"bucketing\" or \"group assignment\" process is a useful metaphor for many counting\nproblems.\nThe most common case that we will want to consider is when all of the items you are putting into buckets\nare distinct. In that case you can think of bucketing as a series of steps, and employ the step rule of\ncounting. The first step? You put the first distinct item into a bucket (there are number-of-buckets ways to\ndo this). Second step? You put the second distinct item into a bucket (again, there are number-of-buckets\nways to do this).\n4\nThis is a header\nBucketing Distinct Items:\nSuppose you want to place n distinguishable items into r containers. The number of ways of doing so is:\nrn\nYou have n steps (place each item) and for each item you have r choices\nProblem: Say you want to put 10 distinguishable balls into 5 urns (No! Wait! Don't say that! Not urns!).\nOkay, fine. No urns. Say we are going to put 10 different strings into 5 buckets of a hash table. How\nmany possible ways are there of doing this?\nSolution: You can think of this as 10 independent experiments each with 5 outcomes. Using our rule for\nbucketing with distinct items, this comes out to 510.\nBucketing with Indistinct Objects\nWhile the previous example allowed us to put n distinguishable objects into r distinct groups, the more\ninteresting problem is to work with n indistinguishable objects.\nDivider Method:\nSuppose you want to place n indistinguishable items into r containers. The divider method works by\nimagining that you are going to solve this problem by sorting two types of objects, your n original\nelements and (r\u22121) dividers. Thus, you are permuting n+r\u22121 objects, n of which are the same (your\nelements) and r\u22121 of which are the same (the dividers). Thus the total number of outcomes is:\n(n+r\u22121)! n+r\u22121 n+r\u22121\n=( )=( )\nn!(r\u22121)! n r\u22121\nThe divider method can be derived via the \"Stars and Bars\" method. This is a creative construction where\nwe consider permutations of indistinguishable items, represented by stars *, and dividers between our\ncontainers, represented by bars |. Any distinct permutation of these stars and bars represents a unique\nassignment of our items to containers.\nImagine we want to separate 5 indistinguishable objects into 3 containers. We can think of the problem\nas finding the number of ways to order 5 stars and 2 bars *****||. Any permutation of these symbols\nrepresents a unique assignment. Here are a few examples:\n**|*|** represents 2 items in the first bucket, 1 item in the second and 2 items in the third.\n****||* represents 4 items in the first bucket, 0 item in the second and 1 items in the third.\n||***** represents 0 items in the first bucket, 0 item in the second and 5 items in the third.\nWhy are there only 2 dividers when there are 3 buckets? This is an example of a fence-post-problem.\nWith 2 dividers you have created three containers. We already have a method for counting permutations\nwith some indistinct items. For the example above where we have seven elements in our permutation (\nn=5 stars and r\u22121=2 bars):\nn! (n+r\u22121)! 7!\nNumberofuniqueorderings= = = =21\nn !n ! n!(r\u22121)! 5!2!\n1 2\nPart A: Say you are a startup incubator and you have $10 million to invest in 4 companies (in $1 million\nincrements). How many ways can you allocate this money?\nSolution: This is just like putting 10 balls into 4 urns. Using the Divider Method we get:\n5 ( ) ( )\nThis is a header 10+4\u22121 13\nTotalways=( )=( )=286\n10 10\nThis problem is analogous to solving the integer equation x 1+x 2+x 3+x 4=10, where x i represents\nthe investment in company i such that x i\u22650 for all i=1,2,3,4.\nPart B: What if you know you want to invest at least $3 million in Company 1?\nSolution: There is one way to give $3 million to Company 1. The number of ways of investing the\nremaining money is the same as putting 7 balls into 4 urns.\n7+4\u22121 10\nTotalWays=( )=( )=120\n7 7\nThis problem is analogous to solving the integer equation x 1+x 2+x 3+x 4=10, where x 1\u22653 and\nx 2,x 3,x 4\u22650. To translate this problem into the integer solution equation that we can solve via the\ndivider method, we need to adjust the bounds on x 1 such that the problem becomes\nx 1+x 2+x 3+x 4=7, where x i is defined as in Part A.\nPart C: What if you don't have to invest all $10 M? (The economy is tight, say, and you might want to\nsave your money.)\nSolution: Imagine that you have an extra company: yourself. Now you are investing $10 million in 5\ncompanies. Thus, the answer is the same as putting 10 balls into 5 urns.\n10+5\u22121 14\nTotal=( )=( )=1001\n10 10\nThis problem is analogous to solving the integer equation x 1+x 2+x 3+x 4+x 5=10, such that\nx i\u22650 for all i=1,2,3,4,5.\nBucketing into Fixed-Sized Containers\nBucketing into Fixed-Sized Containers:\nIf n objects are distinct, then the number of ways of putting them into r groups of objects, such that\ngroup i has size n i, and \u2211r i=1n i=n, is:\nn! n\n=( )\nn !n !\u22efn ! n ,n ,\u2026,n\n1 2 r 1 2 r\nwhere ( n ) is special notation called the multinomial coefficient.\nn1,n2,\u2026,nr\nYou may have noticed that this is the exact same formula as \"Permutations With Indistinct Objects\".\nThere is a deep parallel. One way to imagine assigning objects into their groups would be to imagine the\ngroups themselves as objects. You have one object per \"slot\" in a group. So if there were two slots in\ngroup 1, three slots in group 2, and one slot in group 3 you could have six objects (1, 1, 2, 2, 2, 3). Each\nunique permutation can be used to make a unique assignment.\nProblem:\nCompany Camazon has 13 distinct new servers that they would like to assign to 3 datacenters, where\nDatacenter A, B, and C have 6, 4, and 3 empty server racks, respectively. How many different divisions\nof the servers are possible?\nSolution: This is a straightforward application of our multinomial coefficient representation. Setting\nn 1=6,n 2=4,n 3=3, ( 6,1 43 ,3)=60,060.\n6\nThis is a header\nAnother way to do this problem would be from first principles of combinations as a multipart\nexperiment. We first select the 6 servers to be assigned to Datacenter A, in (13) ways. Now out of the 7\n6\nservers remaining, we select the 4 servers to be assigned to Datacenter B, in (7) ways. Finally, we select\n4\nthe 3 servers out of the remaining 3 servers, in (3) ways. By the Product Rule of Counting, the total\n3\nnumber of ways to assign all servers would be (13)(7)(3)= 13! =60,060.\n6 4 3 6!4!3!\n7\nThis is a header\nDefinition of Probability\nWhat does it mean when someone makes a claim like \"the probability that you find a pearl in an oyster is\n1 in 5,000?\" or \"the probability that it will rain tomorrow is 52%\"?\nEvents and Experiments\nWhen we speak about probabilities, there is always an implied context, which we formally call the\n\"experiment\". For example: flipping two coins is something that probability folks would call an\nexperiment. In order to precisely speak about probability, we must first define two sets: the set of all\npossible outcomes of an experiment, and the subset that we consider to be our event (what is a set?).\nDefinition: Sample Space, S\nA Sample Space is the set of all possible outcomes of an experiment. For example:\nCoin flip: S = {Heads, Tails}\nFlipping two coins: S = {(H, H), (H, T), (T, H), (T, T)}\nRoll of 6-sided die: S = {1, 2, 3, 4, 5, 6}\nThe number of emails you receive in a day: S={x|x\u2208Z,x\u22650} (non-neg. ints)\nYouTube hours in a day: S={x|x\u2208R,0\u2264x\u226424}\nDefinition: Event, E\nAn Event is some subset of S that we ascribe meaning to. In set notation (E\u2286S).For example:\nCoin flip is heads: E = {Heads}\nAt least 1 head on 2 coin flips = {(H, H), (H, T), (T, H)}\nRoll of die is 3 or less: E = {1, 2, 3}\nYou receive less than 20 emails in a day: E={x|x\u2208Z,0\u2264x<20} (non-neg. ints)\nWasted day (\u2265 5 YouTube hours): E={x|x\u2208R,5\u2264x\u226424}\nEvents can be represented as capital letters such as E or F.\n[todo] In the world of probability, events are binary: they either happen or they don't.\nDefinition of Probability\nIt wasn't until the 20th century that humans figured out a way to precisely define what the word\nprobability means:\ncount(Event)\nP(Event)= lim\nn\u2192\u221e n\nIn English this reads: let's say you perform n trials of an \"experiment\" which could result in a particular\n\"Event\" occurring. The probability of the event occurring, P(Event), is the ratio of trials that result in\nthe event, written as count(Event), to the number of trials performed, n. In the limit, as your number of\ntrials approaches infinity, the ratio will converge to the true probability. People also apply other semantics\nto the concept of a probability. One common meaning ascribed is that P(E) is a measure of the chance of\nevent E occurring.\nExample: Probability in the limit\nHere we use the definition of probability to calculate the probability of event E, rolling a \"5\" or a \"6\" on\na fair six-sided dice. Hit the \"Run trials\" button to start running trials of the experiment \"roll dice\".\nNotice how P(E), converges to 2/6 or 0.33 repeating.\nEvent E: Rolling a 5 or 6 on a six-sided dice.\n1\nThis is a header\n\uf04b Run trials Dice outcome: \uf554 \uf70c\nn= 0 count(E)= 0 P(E)\u2248 count(E) =\nn\nMeasure of uncertainty: It is tempting to think of probability as representing some natural randomness\nin the world. That might be the case. But perhaps the world isn't random. I propose a deeper way of\nthinking about probability. There is so much that we as humans don't know, and probability is our robust\nlanguage for expressing our belief that an event will happen given our limited knowledge. This\ninterpretation acknowledges your own uncertainty of an event. Perhaps if you knew the position of every\nwater molecule, you could perfectly predict tomorrow's weather. But we don't have such knowledge and\nas such we use probability to talk about the chance of rain tomorrow given the information that we have\naccess to.\nOrigins of probabilities: The different interpretations of probability are reflected in the many origins of\nprobabilities that you will encounter in the wild (and not so wild) world. Some probabilities are\ncalculated analytically using mathematical proofs. Some probabilities are calculated from data,\nexperiments or simulations. Some probabilities are just made up to represent a belief. Most probabilities\nare generated from a combination of the above. For example, someone will make up a prior belief, that\nbelief will be mathematically updated using data and evidence. Here is an example of calculating a\nprobability from data:\nProbabilities and simulations: Another way to compute probabilities is via simulation. For some\ncomplex problems where the probabilities are too hard to compute analytically you can run simulations\nusing your computer. If your simulations generate believable trials from the sample space, then the\nprobability of an event E is approximately equal to the fraction of simulations that produced an outcome\nfrom E. Again, by the definition of probability, as your number of simulations approaches infinity, the\nestimate becomes more accurate.\nProbabilities and percentages: You might hear people refer to a probability as a percent. That the\nprobability of rain tomorrow is 32%. The proper way to state this would be to say that 0.32 is the\nprobability of rain. Percentages are simply probabilities multiplied by 100. \"Percent\" is Latin for \"out of\none hundred\".\nProblem: Use the definition of probability to approximate the answer to the question: \"What is the\nprobability a newborn elephant child is male?\" Contrary to what you might think the gender outcomes of\na newborn elephant are not equally likely between male and female. You have data from a report in\nAnimal Reproductive Science which states that 3,070 elephants were born in Myanmar of which 2,180\nwere male [1]. Humans also don't have a 50/50 sex ratio at birth [2].\n2\nThis is a header\nAnswer: The Experiment is: A single elephant birth in Myanmar.\nThe sample space is the set of possible sexes assigned at birth, {Male, Female, Intersex}.\nE is the event that a new-born elephant child is male, which in set notation is the subset {Male} of the\nsample space. The outcomes are not equally likely.\nBy the definition of probability, the ratio \u2014 of trials that result in the event, to the total number of trials\n\u2014 will tend to our desired probability:\nP(BornMale)=P(E)\ncount(E)\n= lim\nn\u2192\u221e n\n2,180\n\u2248\n3,070\n\u22480.710\nSince 3,000 is quite a bit less than infinity, this is an approximation. It turns out, however, to be a rather\ngood one. A few important notes: there is no guarantee that our estimate applies to elephants outside\nMyanmar. Later in the class we will develop language for \"how confident we can be in a number like\n0.71 after 3,000 trials?\" Using tools from later in class we can say that we have 98% confidence that the\ntrue probability is within 0.02 of 0.710.\nAxioms of Probability\nHere are some basic truths about probabilities that we accept as axioms:\nAxiom 1: 0\u2264P(E)\u22641 All probabilities are numbers between 0 and 1.\nAxiom 2: P(S)=1 All outcomes must be from the Sample Space.\nAxiom 3: If E and F are mutually exclusive, The probability of \"or\" for mutually exclusive events\nthen P(E or F)=P(E)+P(F)\nThese three axioms are formally called the Kolmogorov axioms and they are considered to be the\nfoundation of probability theory. They are also useful identities!\nYou can convince yourself of the first axiom by thinking about the math definition of probability. As you\nperform trials of an experiment it is not possible to get more events than trials (thus probabilities are less\nthan 1) and it's not possible to get less than 0 occurrences of the event (thus probabilities are greater than\n0). The second axiom makes sense too. If your event is the sample space, then each trial must produce the\nevent. This is sort of like saying; the probability of you eating cake (event) if you eat cake (sample space\nthat is the same as the event) is 1. The third axiom is more complex and in this textbook we dedicate an\nentire chapter to understanding it: Probability of or. It applies to events that have a special property called\n\"mutual exclusion\": the events do not share any outcomes.\nThese axioms have great historical significance. In the early 1900s it was not clear if probability was\nsomehow different than other fields of math -- perhaps the set of techniques and systems of proofs from\nother fields of mathematics couldn't apply. Kolmogorov's great success was to show to the world that the\ntools of mathematics did in fact apply to probability. From the foundation provided by this set of axioms\nmathematicians built the edifice of probability theory.\nProvable Identities\nWe often refer to these as corollaries that are directly provable from the three axioms given above.\nIdentity 1: P(EC)=1\u2212P(E) The probability of event E not happening\nIdentity 2: If E\u2286F, then P(E)\u2264P(F) Events which are subsets\n3\nThis is a header\nThis first identity is especially useful. For any event, you can calculate the probability of the event not\noccurring which we write in probability notation as EC, if you know the probability of it occurring -- and\nvice versa. We can also use this identity to show you what it looks like to prove a theorem in probability.\nProof: P(EC)=1\u2212P(E)\nP(S)=P(EorEC) E or EC coverseveryoutcomeinthesamplespace\nP(S)=P(E)+P(EC) Events E and EC aremututallyexclusive\n1=P(E)+P(EC) Axiom2ofprobability\nP(EC)=1\u2212P(E) Byre-arranging\n4\nThis is a header\nEqually Likely Outcomes\nSome sample spaces have equally likely outcomes. We like those sample spaces, because there is a way\nto calculate probability questions about those sample spaces simply by counting. Here are a few\nexamples where there are equally likely outcomes:\nCoin flip: S = {Head, Tails}\nFlipping two coins: S = {(H, H), (H, T), (T, H), (T, T)}\nRoll of 6-sided die: S = {1, 2, 3, 4, 5, 6}\nBecause every outcome is equally likely, and the probability of the sample space must be 1, we can prove\nthat each outcome must have probability:\n1\nP(anoutcome)=\n|S|\nWhere |S| is the size of the sample space, or, put in other words, the total number of outcomes of the\nexperiment. Of course this is only true in the special case where every outcome has the same likelihood.\nDefinition: Probability of Equally Likely Outcomes\nIf S is a sample space with equally likely outcomes, for an event E that is a subset of the outcomes in S:\nnumberofoutcomesin E |E|\nP(E)= =\nnumberofoutcomesin S |S|\nThere is some art form to setting up a problem to calculate a probability based on the equally likely\noutcome rule. (1) The first step is to explicitly define your sample space and to argue that all outcomes in\nyour sample space are equally likely. (2) Next, you need to count the number of elements in the sample\nspace and (3) finally you need to count the size of the event space. The event space must be all elements\nof the sample space that you defined in part (1). The first step leaves you with a lot of choice! For\nexample you can decide to make indistinguishable objects distinct, as long as your calculation of the size\nof the event space makes the exact same assumptions.\nExample: What is the probability that the sum of two dice is equal to 7?\nBuggy Solution: You could define your sample space to be all the possible sum values of two die (2\nthrough 12). However this sample space fails the \u201cequally likely\u201d test. You are not equally likely to\nhave a sum of 2 as you are to have a sum of 7.\nSolution: Consider the sample space from the previous chapter where we thought of the dice as distinct\nand enumerated all of the outcomes in the sample space. The first number is the roll on die 1 and the\nsecond number is the roll on die 2. Note that (1, 2) is distinct from (2, 1). Since each outcome is equally\nlikely, and the sample space has exactly 36 outcomes, the likelihood of any one outcome is 1 . Here is a\n36\nvisualization of all outcomes:\n(1,1) (1,2) (1,3) (1,4) (1,5) (1,6)\n(2,1) (2,2) (2,3) (2,4) (2,5) (2,6)\n(3,1) (3,2) (3,3) (3,4) (3,5) (3,6)\n(4,1) (4,2) (4,3) (4,4) (4,5) (4,6)\n(5,1) (5,2) (5,3) (5,4) (5,5) (5,6)\n(6,1) (6,2) (6,3) (6,4) (6,5) (6,6)\n1\nThis is a header\nThe event (sum of dice is 7) is the subset of the sample space where the sum of the two dice is 7. Each\noutcome in the event is highlighted in blue. There are 6 such outcomes: (1, 6), (2, 5), (3, 4), (4, 3), (5, 2),\n(6, 1). Notice that (1, 6) is a different outcome than (6, 1). To make the outcomes equally likely we had to\nmake the die distinct.\n|E|\nP(Sumoftwodiceis7)= Sinceoutcomesareequallylikely\n|S|\n6 1\n= = Thereare6outcomesintheevent\n36 6\nInterestingly, this idea also applies to continuous sample spaces. Consider the sample space of all the\noutcomes of the computer function \"random\" which produces a real valued number between 0 and 1,\nwhere all real-valued numbers are equally likely. Now consider the event E that the number generated is\nin the range [0.3 to 0.7]. Since the sample space is equally likely, P(E) is the ratio of the size of E to the\nsize of S. In this case P(E)= 0.4 =0.4.\n1\n2\nThis is a header\nProbability of or\nThe equation for calculating the probability of either event E or event F happening, written P(EorF) or\nequivalently as P(E\u222aF), is deeply analogous to counting the size of two sets. As in counting, the\nequation that you can use depends on whether or not the events are \"mutually exclusive\". If events are\nmutually exclusive, it is very straightforward to calculate the probability of either event happening.\nOtherwise, you need the more complex \"inclusion exclusion\" formula.\nMutually exclusive events\nTwo events: E, F are considered to be mutually exclusive (in set notation E\u2229F =\u2205) if there are no\noutcomes that are in both events (recall that an event is a set of outcomes which is a subset of the sample\nspace). In English, mutually exclusive means that two events can't both happen.\nMutual exclusion can be visualized. Consider the following visual sample space where each outcome is a\nhexagon. The set of all the fifty hexagons is the full sample space:\nExample of two events: E, F, which are mutually exclusive.\nBoth events E and F are subsets of the same sample space. Visually, we can note that the two sets do not\noverlap. They are mutually exclusive: there is no outcome that is in both sets.\nOr with Mutually Exclusive Events\nDefinition: Probability of or for mututally exclusive events\nIf two events: E, F are mutually exclusive then the probability of E or F occurring is:\nP(EorF)=P(E)+P(F)\nThis property applies regardless of how you calculate the probability of E or F. Moreover, the idea\nextends to more than two events. Lets say you have n events E 1,E 2,\u2026E n where each event is\nmutually exclusive of one another (in other words, no outcome is in more than one event). Then:\nn\nP(E orE or\u2026orE )=P(E )+P(E )+\u22ef+P(E )=\u2211P(E)\n1 2 n 1 2 n i\ni=1\nYou may have noticed that this is one of the axioms of probability. Though it might seem intuitive, it is\none of three rules that we accept without proof.\nCaution: Mutual exclusion only makes it easier to calculate the probability of EorF, not other ways\nof combining events, such as EandF.\nAt this point we know how to compute the probability of the \"or\" of events if and only if they have the\nmutual exclusion property. What if they don't?\n1\nThis is a header\nOr with Non-Mutually Exclusive Events\nUnfortunately, not all events are mutually exclusive. If you want to calculate P(EorF) where the events\nE and F are not mutually exclusive you can not simply add the probabilities. As a simple sanity check,\nconsider the event E: getting heads on a coin flip, where P(E)=0.5. Now imagine the sample space S,\ngetting either a heads or a tails on a coin flip. These events are not mutually exclusive (the outcome heads\nis in both). If you incorrectly assumed they were mutually exclusive and tried to calculate P(EorS) you\nwould get this buggy derivation:\nBuggy derivation: Incorrectly assuming mutual exclusion\nCalculate the probability of E, getting an even number on a dice role (2, 4 or 6), or F, getting three or\nless (1, 2, 3) on the same dice role.\nP(EorF)=P(E)+P(F) Incorrectlyassumesmutualexclusion\n=0.5+0.5 substitutetheprobabilitiesof E and S\n=1.0 uhoh!\nThe probability can't be one since the outcome 5 is neither three or less nor even. The problem is that\nwe double counted the probability of getting a 2, and the fix is to subtract out the probability of that\ndoubly counted case.\nWhat went wrong? If two events are not mutually exclusive, simply adding their probabilities double\ncounts the probability of any outcome which is in both events. There is a formula for calculating or of\ntwo non-mutually exclusive events: it is called the \"inclusion exclusion\" principle.\nDefinition: Inclusion Exclusion principle\nFor any two events: E, F:\nP(EorF)=P(E)+P(F)\u2212P(EandF)\nThis formula does have a version for more than two events, but it gets rather complex. See the next two\nsections for more details.\nNote that the inclusion exclusion principle also applies for mutually exclusive events. If two events are\nmutually exclusive P(EandF)=0 since its not possible for both E and F to occur. As such the\nformula P(E)+P(F)\u2212P(EandF) reduces to P(E)+P(F).\nInclusion-Exclusion with Three Events\nWhat does the inclusion exclusion property look like if we have three events, that are not mutually\nexclusive, and we want to know the probability of or, P(E 1orE 2orE 3)?\nRecall that if they are mutually exclusive, we simply add the probabilities. If they are not mutually\nexclusive, you need to use the inclusion exclusion formula for three events:\nP(E orE orE )=\n1 2 3\n+P(E )\n1\n+P(E )\n2\n+P(E )\n3\n\u2212P(E andE )\n1 2\n\u2212P(E andE )\n1 3\n\u2212P(E andE )\n2 3\n+P(E andE andE )\n1 2 3\nIn words, to get the probability of three events, you: (1) add the probability of the events on their own.\n(2) Then you need to subtract off the probability of every pair of events co-occuring. (3) Finally, you add\nin the probability of all three events co-occuring.\n2\nThis is a header n\nInclusion-Exclusion with Events\nBefore we explore the general formula, lets look at one more example. Inclusion-exclusion with four\nevents:\nP(E orE orE orE )=\n1 2 3 4\n+P(E )\n1\n+P(E )\n2\n+P(E )\n3\n+P(E )\n4\n\u2212P(E andE )\n1 2\n\u2212P(E andE )\n1 3\n\u2212P(E andE )\n1 4\n\u2212P(E andE )\n2 3\n\u2212P(E andE )\n2 4\n\u2212P(E andE )\n3 4\n+P(E andE andE )\n1 2 3\n+P(E andE andE )\n1 2 4\n+P(E andE andE )\n1 3 4\n+P(E andE andE )\n2 3 4\n\u2212P(E andE andE andE )\n1 2 3 4\nDo you see the pattern? For n events, E 1,E 2,\u2026E n: add all the probabilities of the events on their own.\nThen subtract all pairs of events. Then add all subsets of 3 events. Then subtract all subset of 4 events.\nContinue this process, up until subset of size n, adding the subsets if the size of subsets is odd, else\nsubtracting them. The alternating addition and subtraction is where the name inclusion exclusion comes\nfrom. This is a complex process and you should first check if there is an easier way to calculate your\nprobability. This can be written up mathematically \u2014 but it is a rather hard pattern to express in notation:\nn\nP(E orE or\u22eforE )=\u2211(\u22121)r+1Y\n1 2 n r\nr=1\ns.t. Y = \u2211 P(E and\u22efandE )\nr i1 ir\n1\u2264i1<\u22ef<ir\u2264n\nThe notation for Y r is especially hard to parse. Y r sums over all ways of selecting a subset of r events.\nFor each selection of r events, calculate the probability of the \"and\" of those events. (\u22121)r+1 is saying:\nalternate between addition and subtraction, starting with addition.\nIt is not especially important to follow the math notation here. The main take away is that the general\ninclusion exclusion principle gets incredibly complex with multiple events. Often, the way to make\nprogress in this situation is to find a way to solve your problem using another method.\nThe formulas for calculating the or of events that are not mutually exclusive often require calculating the\nprobability of the and of events. Learn more in the chapter Probability of and.\n3\nThis is a header\nConditional Probability\nIn English, a conditional probability states \"what is the chance of an event E happening given that I have\nalready observed some other event F\". It is a critical idea in machine learning and probability because it\nallows us to update our probabilities in the face of new evidence.\nWhen you condition on an event happening you are entering the universe where that event has taken\nplace. Formally, once you condition on F the only outcomes that are now possible are the ones which are\nconsistent with F. In other words your sample space will now be reduced to F. As an aside, in the\nuniverse where F has taken place, all rules of probability still hold!\nDefinition: Conditional Probability.\nThe probability of E given that (aka conditioned on) event F already happened:\nP(EandF)\nP(E|F)=\nP(F)\nLet's use a visualization to get an intuition for why the conditional probability formula is true. Again\nconsider events E and F which have outcomes that are subsets of a sample space with 50 equally likely\noutcomes, each one drawn as a hexagon:\nConditioning on F means that we have entered the world where F has happened (and F, which has 14\nequally likely outcomes, has become our new sample space). Given that event F has occurred, the\nconditional probability that event E occurs is the subset of the outcomes of E that are consistent with F.\nIn this case we can visually see that those are the three outcomes in EandF. Thus we have the:\nP(EandF) 3/50 3\nP(E|F)= = = \u22480.21\nP(F) 14/50 14\nEven though the visual example (with equally likely outcome spaces) is useful for gaining intuition,\nconditional probability applies regardless of whether the sample space has equally likely outcomes!\nConditional Probability Example\nLet's use a real world example to better understand conditional probability: movie recommendation.\nImagine a streaming service like Netflix wants to figure out the probability that a user will watch a movie\nE (for example, Life is Beautiful), based on knowing that they watched a different movie F (say\nAm\u00e9lie). To start lets answer the simpler question, what is the probability that a user watches the movie\nLife is Beautiful, E? We can solve this problem using the definition of probability and a dataset of movie\nwatching [1]:\ncount(E) #peoplewhowatchedmovie E\nP(E)= lim \u2248\nn\u2192\u221e n #peopleonNetflix\n1,234,231\n= \u22480.02\n50,923,123\n1\nThis is a header\nIn fact we can do this for many movies E:\nP(E)=0.02 P(E)=0.01 P(E)=0.05 P(E)=0.09 P(E)=0.03\nNow for a more interesting question. What is the probability that a user will watch the movie Life is\nBeautiful (E), given they watched Amelie (F)? We can use the definition of conditional probability.\nP(EandF)\nP(E|F)= DefofCondProb\nP(F)\n(#whowatched EandF)/(#ofpeopleonNetflix)\n\u2248 DefofProb\n(#whowatchedmovie F)/(#peopleonNetflix)\n#ofpeoplewhowatchedboth EandF\n\u2248 Simplifying\n#ofpeoplewhowatchedmovie F\nIf we let F be the event that someone watches the movie Am\u00e9lie, we can now calculate P(E|F), the\nconditional probability that someone watches movie E:\nP(E|F)=0.09 P(E|F)=0.03 P(E|F)=0.05 P(E|F)=0.02 P(E|F) = 1.00\nWhy do some probabilities go up, some probabilities go down, and some probabilities are unchanged\nafter we observe that the person has watched Amelie (F)? If you know someone watched Amelie, they\nare more likely to watch Life is Beautiful, and less likely to watch Star Wars. We have new information\non the person!\nThe Conditional Paradigm\nWhen you condition on an event you enter the universe where that event has taken place. In that new\nuniverse all the laws of probability still hold. Thus, as long as you condition consistently on the same\nevent, every one of the tools we have learned still apply. Let\u2019s look at a few of our old friends when we\ncondition consistently on an event (in this case G):\nName of Rule Original Rule Rule Conditioned on G\nAxiom of probability 1 0\u2264P(E)\u22641 0\u2264P(E|G)\u22641\nAxiom of probability 2 P(S)=1 P(S|G)=1\nAxiom of probability 3 P(EorF)=P(E)+P(F) P(EorF|G)=P(E|G)+P(F|G)\nfor mutually exclusive events for mutually exclusive events\nIdentity 1 P(EC)=1\u2212P(E) P(EC|G)=1\u2212P(E|G)\nConditioning on Multiple Events\nThe conditional paradigm also applies to the definition of conditional probability! Again if we\nconsistently condition on some event G occurring, the rule still holds:\n2\nThis is a header P(EandF|G)\nP(E|F,G)=\nP(F|G)\nThe term P(E|F,G) is new notation for conditioning on multiple events. You should read that term as\n\"The probability of E occurring, given that both F and G have occurred\". This equation states that the\ndefinition for conditional probability of E|F still applies in the universe where G has occurred. Do you\nthink that P(E|F,G) should be equal to P(E|F)? The answer is: sometimes yes and sometimes no.\n3\nThis is a header\nIndependence\nSo far we have talked about mutual exclusion as an important \"property\" that two or more events can\nhave. In this chapter we will introduce you to a second property: independence. Independence is perhaps\none of the most important properties to consider! Like for mutual exclusion, if you can establish that this\nproperty applies (either by logic, or by declaring it as an assumption) it will make analytic probability\ncalculations much easier!\nDefinition: Independence\nTwo events are said to be independent if knowing the outcome of one event does not change your belief\nabout whether or not the other event will occur. For example, you might say that two separate dice rolls\nare independent of one another: the outcome of the first dice gives you no information about the outcome\nof the second -- and vice versa.\nP(E|F)=P(E)\nAlternative Definition\nAnother definition of independence can be derived by using an equation called the chain rule, which we\nwill learn about later, in the context where two events are independent. Consider two indepedent events\nA and B:\nP(A,B)=P(A)\u22c5P(B|A) ChainRule\n=P(A)\u22c5P(B) Independence\nIndependence is Symmetric\nThis definition is symmetric. If E is independent of F, then F is independent of E. We can prove that\nP(F|E)=P(F) implies P(E|F)=P(E) starting with a law called Bayes' Theorem which we will\ncover shortly:\nP(F|E)\u22c5P(E)\nP(E|F)= BayesTheorem\nP(F)\nP(F)\u22c5P(E)\n= P(F|E)=P(F)\nP(F)\n=P(E) Cancel\nGeneralized Independence\nEvents E 1,E 2,\u2026,E n are independent if for every subset with r elements (where r\u2264n):\nr\nP(E ,E ,\u2026,E )=\u220fP(E\u2032)\n1\u2032 2\u2032 r\u2032 i\ni=1\nAs an example, consider the probability of getting 5 heads on 5 coin flips where we assume that each\ncoin flip is independent of one another.\n1\nThis is a header\nLet H i be the event that the ith coin flip is a heads:\nP(H ,H ,H ,H ,H )\n1 2 3 4 5\n=P(H )\u22c5P(H )\u22efP(H ) Independence\n1 2 5\n5\n=\u220fP(H) Productnotation\ni\ni=1\n5 1\n=\u220f\n2\ni=1\n15\n=\n2\n=0.03125\nHow to Establish Independence\nHow can you show that two or more events are independent? The default option is to show it\nmathematically. If you can show that P(E|F)=P(E) then you have proven that the two events are\nindependent. When working with probabilities that come from data, very few things will exactly match\nthe mathematical definition of independence. That can happen for two reasons: first, events that are\ncalculated from data or simulation are not perfectly precise and it can be impossible to know if a\ndiscrepancy between P(E) and P(E|F) is due to inaccuracy in estimating probabilities, or dependence\nof events. Second, in our complex world many things actually influence each other, even if just a tiny\namount. Despite that we often make the wrong, but useful, independence assumption. Since\nindependence makes it so much easier for humans and machines to calculate composite probabilities, you\nmay declare the events to be independent. It could mean your resulting calculation is slightly incorrect \u2014\nbut this \"modelling assumption\" might make it feasible to come up with a result.\nIndependence is a property which is often \"assumed\" if you think it is reasonable that one event is\nunlikely to influence your belief that the other will occur (or if the influence is negligible). Let's work\nthrough an example to better understand.\nExample: Parallel Networks\nOver networks, such as the internet, computers can send information. Often there are multiple paths\n(mediated by routers) between two computers and as long as one path is functional, information can be sent.\nConsider the following parallel network with n independent routers, each with probability p i of\nfunctioning (where 1 \u2264 i \u2264 n). Let E be the event that there is a functional path from A to B. What is P(E)?\nA simple network that connects two computers, A and B.\n2\nThis is a header\nLet F i be the event that router i fails. Note that the problem states that routers are indepenent, and as\nsuch we assume that the events F i are all independent of one another.\nP(E)=P(Atleastonerouterworks)\n=1\u2212P(Allroutersfail)\n=1\u2212P(F and F and \u2026 and F )\n1 2 n\nn\n=1\u2212\u220fP(F) Independenceof F\ni i\ni=1\nn\n=1\u2212\u220f1\u2212p\ni\ni=1\nWhere p i is the probability that router i is functional.\nIndependence and Compliments\nGiven independent events A and B, we can prove that A and BC are independent. Formally we want to\nshow that: P(ABC)=P(A)P(BC). This starts with a rule called the Law of Total Probability which we\nwill cover shortly.\nP(ABC)=P(A)\u2212P(AB) LOTP\n=P(A)\u2212P(A)P(B) Independence\n=P(A)[1\u2212P(B)] Algebra\n=P(A)P(BC) Identity1\nConditional Independence\nWe saw earlier that the laws of probability still held if you consistently conditioned on an event. As such,\nthe definition of independence also transfers to the universe of conditioned events. We use the\nterminology \"conditional independence\" to refer to events that are independent when consistently\nconditioned. For example if someone claims that events E 1,E 2,E 3 are conditionally independent given\nevent F. This implies that\nP(E ,E ,E |F)=P(E |F)\u22c5P(E |F)\u22c5P(E |F)\n1 2 3 1 2 3\nWhich can be written more succinctly in product notation\n3\nP(E ,E ,E |F)=\u220fP(E|F)\n1 2 3 i\ni=1\nWarning: While the rules of probability stay the same when conditioning on an event, the\nindependence property between events might change. Events that were dependent can become\nindependent when conditioning on an event. Events that were independent can become dependent. For\nexample, if events E 1,E 2,E 3 are conditionally independent given event F it is not necessarily true\nthat\n3\nP(E ,E ,E )=\u220fP(E)\n1 2 3 i\ni=1\nAs we are no longer conditioning on F.\n3\nThis is a header\nProbability of and\nThe probability of the and of two events, say E and F, written P(EandF), is the probability of both\nevents happening. You might see equivalent notations P(EF), P(E\u2229F) and P(E,F) to mean the\nprobability of and. How you calculate the probability of event E and event F happening depends on\nwhether or not the events are \"independent\". In the same way that mutual exclusion makes it easy to\ncalculate the probability of the or of events, independence is a property that makes it easy to calculate the\nprobability of the and of events.\nAnd with Independent Events\nIf events are independent then calculating the probability of and becomes simple multiplication:\nDefinition: Probability of and for independent events.\nIf two events: E, F are independent then the probability of E and F occurring is:\nP(EandF)=P(E)\u22c5P(F)\nThis property applies regardless of how the probabilities of E and F were calculated and whether or not\nthe events are mutually exclusive.\nThe independence principle extends to more than two events. For n events E 1,E 2,\u2026E n that are\nmutually independent of one another -- the independence equation also holds for all subsets of the\nevents.\nn\nP(E andE and\u2026andE )=\u220fP(E)\n1 2 n i\ni=1\nWe can prove this equation by combining the definition of conditional probability and the definition of\nindependence.\nProof: If E is independent of F then P(EandF)=P(E)\u22c5P(F)\nP(EandF)\nP(E|F)= Definitionof conditionalprobability\nP(F)\nP(EandF)\nP(E)= Definitionof independence\nP(F)\nP(EandF)=P(E)\u22c5P(F) Rearrangingterms\nSee the chapter on independence to learn about when you can assume that two events are independent\nAnd with Dependent Events\nEvents which are not independent are called dependent events. How can you calculate the probability of\nthe and of dependent events? If your events are mutually exclusive you might be able to use a technique\ncalled DeMorgan's law, which we cover in a later chapter. For the probability of and in dependent events\nthere is a direct formula called the chain rule which can be directly derived from the definition of\nconditional probability:\n1\nThis is a header\nDefinition: The chain rule.\nThe formula in the definition of conditional probability can be re-arranged to derive a general way of\ncalculating the probability of the and of any two events:\nP(EandF)=P(E|F)\u22c5P(F)\nOf course there is nothing special about E that says it should go first. Equivalently:\nP(EandF)=P(FandE)=P(F|E)\u22c5P(E)\nWe call this formula the \"chain rule.\" Intuitively it states that the probability of observing events E and\nF is the probability of observing F, multiplied by the probability of observing E, given that you have\nobserved F. It generalizes to more than two events:\nP(E andE and\u2026andE )=P(E )\u22c5P(E |E )\u22c5P(E |E andE )\u2026\n1 2 n 1 2 1 3 1 2\nP(E |E \u2026E )\nn 1 n\u22121\n2\nThis is a header\nLaw of Total Probability\nAn astute person once observed that when looking at a picture, like the one we saw for conditional\nprobability:\nthat event E can be thought of as having two parts, the part that is in F, (EandF), and the part that\nisn\u2019t, (EandFC). This is true because F and FC are (a) mutually exclusive sets of outcomes which (b)\ntogether cover the entire sample space. After further investigation this proved to be mathematically true,\nand there was much rejoicing:\nP(E)=P(EandF)+P(EandFC)\nThis observation proved to be particularly useful when it was combined with the chain rule and gave rise\nto a tool so useful, it was given the big name, law of total probability:\nP(E)=P(EandF)+P(EandFC)\n=P(E|F)P(F)+P(E|FC)P(FC)\nThe Law of Total Probability (LOTP)\nIf we combine our above observation with the chain rule, we get a very useful formula the Law of Total\nProbability of LOTP for short:\nP(E)=P(E|F)P(F)+P(E|FC)P(FC)\nThere is a more general version of the rule. If you can divide your sample space into any number of\nmutually exclusive events: B 1,B 2,\u2026B n such that every outcome in the sample space falls into one of\nthose events, then:\nn\nP(E)=\u2211P(EandB) Extensionofourobservation\ni\ni=1\nn\n=\u2211P(E|B)P(B) Usingchainruleoneachterm\ni i\ni=1\nGeneralization to Many Background Events\nThe events F and FC are always mutually exclusive and they always cover the entire sample space, no\nmatter what F represents! If you can find more than two background events that are also mutually\nexclusive, and their union covers the entire sample space (the universe of outcomes) then you can use the\ngeneralized version of the law of total probability.\nTo generalize the law of total probability, imagine we can divide the sample space into several mutually\nexclusive background events (B 1,B 2,\u2026,B n), where these sets cover the entire sample space. In this\ncase, any event E can be decomposed by considering the likelihood of E within each of these disjoint\nsets.\n1\nThis is a header\nIn the image above, you could compute P(E) to be equal to\nP[(EandB ) or (EandB ) or \u2026 or (EandB )]\n1 2 n\nThere are many real world cases where (a) it is much easier to think of the probability of an event E in\nthe context of a background event B i and the sample space can be discretized into several mutual\nexclusive background events B i. Lets start with an example with three events B 1,B 2,B 3. Suppose you\nare trying to determine the likelihood that a randomly selected individual will test positive for a certain\ndisease, P(E). The population can be divided into three mutually exclusive groups :\n1. B 1: Individuals who are high-risk (e.g., individuals with a known exposure to the disease),\n2. B 2: Individuals who are medium-risk (e.g., individuals with a family history of the disease but no\ndirect exposure),\n3. B 3: Individuals who are low-risk (e.g., the general population without known risk factors).\nEach of these groups has a different probability of testing positive for the disease, and the total probability\nof a random individual testing positive can be broken down as follows:\nP(E)=P(EandB )+P(EandB )+P(EandB ) LOTP\n1 2 3\n=P(E|B )P(B )+P(E|B )P(B )+P(E|B )P(B ) ChainRule\n1 1 2 2 3 3\n3\n=\u2211P(E\u2223B)P(B) SumNotation\ni i\ni=1\nWhere:\nP(E|B 1) is the probability of testing positive given someone in the high-risk group\nP(E|B 2) is the probability of testing positive given someone in the medium-risk groups,\nP(E|B 3) is the probability of testing positive given a person is in the low-risk group.\nP(B 1), P(B 2) and P(B 3) are the probabilities of a person being in the high-risk, medium-risk and\nlow-risk groups.\nThis works because everyone can belongs to one of the background events (B 1,B 2,B 3), in other words\nthe sets span the sample space. Moreovoer each person is in only one of the sets, and as such they are\nmututally exclusive. It is helpful because its easier to think of the probability of E, testing positive, in the\ncontext of the background events, where you know how at risk the patient is.\n2\nThis is a header\nBayes' Theorem\nBayes' Theorem is one of the most ubiquitous results in probability for computer scientists. In a nutshell,\nBayes' theorem provides a way to convert a conditional probability from one direction, say P(E|F), to\nthe other direction, P(F|E).\nBayes' theorem is a mathematical identity which we can derive ourselves. Start with the definition of\nconditional probability and then expand the and term using the chain rule:\nP(FandE)\nP(F|E)= Defof conditionalprobability\nP(E)\nP(E|F)\u22c5P(F)\n= Substitutethe chainrule for P(FandE)\nP(E)\nThis theorem makes no assumptions about E or F so it will apply for any two events. Bayes' theorem is\nexceptionally useful because it turns out to be the ubiquitous way to answer the question: \"how can I\nupdate a belief about something, which is not directly observable, given evidence.\" This is for good\nreason. For many \"noisy\" measurements it is straightforward to estimate the probability of the noisy\nobservation given the true state of the world. However, what you would really like to know is the\nconditional probability the other way around: what is the probability of the true state of the world given\nevidence. There are countless real world situations that fit this situation:\nExample 1: Medical tests\nWhat you want to know: Probability of a disease given a test result\nWhat is easy to know: Probability of a test result given the true state of disease\nCausality: We believe that diseases influences test results\nExample 2: Student ability\nWhat you want to know: Student knowledge of a subject given their answers\nWhat is easy to know: Likelihood of answers given a student's knowledge of a subject\nCausality: We believe that ability influences answers\nExample 3: Cell phone location\nWhat you want to know: Where is a cell phone, given noisy measure of distance to tower\nWhat is easy to know: Error in noisy measure, given the true distance to tower\nCausality: We believe that cell phone location influences distance measure\nThere is a pattern here: in each example we care about knowing some unobservable -- or hard to observe\n-- state of the world. This state of the world \"causes\" some easy-to-observe evidence. For example:\nhaving the flu (something we would like to know) causes a fever (something we can easily observe), not\nthe other way around. We often call the unobservable state the \"belief\" and the observable state the\n\"evidence\". For that reason lets rename the events! Lets call the unobservable thing we want to know B\nfor belief. Lets call the thing we have evidence of E for evidence. This makes it clear that Bayes' theorem\nallows us to calculate an updated belief given evidence: P(B|E)\n1\nThis is a header\nDefinition: Bayes' Theorem\nThe most common form of Bayes' Theorem is Bayes' Theorem Classic:\nP(E|B)\u22c5P(B)\nP(B|E)=\nP(E)\nThere are names for the different terms in the Bayes' Rule formula. The term P(B|E) is often called the\n\"posterior\": it is your updated belief of B after you take into account evidence E. The term P(B) is often\ncalled the \"prior\": it was your belief before seeing any evidence. The term P(E|B) is called the update\nand P(E) is often called the normalization constant.\nThere are several techniques for handling the case where the denominator is not known. One technique is\nto use the law of total probability to expand out the term, resulting in another formula, called Bayes'\nTheorem with Law of Total Probability:\nP(E|B)\u22c5P(B)\nP(B|E)=\nP(E|B)\u22c5P(B)+P(E|BC)\u22c5P(BC)\nRecall the law of total probability which is responsible for our new denominator:\nP(E)=P(E|B)\u22c5P(B)+P(E|BC)\u22c5P(BC)\nA common scenario for applying the Bayes' Rule formula is when you want to know the probability of\nsomething \u201cunobservable\u201d given an \u201cobserved\u201d event! For example, you want to know the probability\nthat a student understands a concept, given that you observed them solving a particular problem. It turns\nout it is much easier to first estimate the probability that a student can solve a problem given that they\nunderstand the concept and then to apply Bayes' Theorem. Intuitively, you can think about this as\nupdating a belief given evidence.\nBayes' Theorem Applied\nSometimes the (correct) results from Bayes' Theorem can be counter intuitive. Here we work through a\nclassic result: Bayes' applied to medical tests. We show a dynamic solution and present a visualization for\nunderstanding what is happening.\nExample: Probability of a disease given a noisy test\nIn this problem we are going to calculate the probability that a patient has an illness given test-result for\nthe illness. A positive test result means the test thinks the patient has the illness. You know the following\ninformation, which is typical for medical tests:\nNatural % of population with illness: 13\nProbability of a positive result given the patient has the illness 0.92\nProbability of a positive result given the patient does not have the illness 0.10\nThe numbers in this example are from the Mammogram test for breast cancer. The seriousness of cancer\nunderscores the potential for bayesian probability to be applied to important contexts. The natural\noccurrence of breast cancer is 8%. The mammogram test returns a positive result 95% of the time for\npatients who have breast cancer. The test resturns a positive result 7% of the time for people who do not\nhave breast cancer. In this demo you can enter different input numbers and it will recalculate.\nAnswer\nThe probability that the patient has the illness given a positive test result is: 0.5789\n2\nThis is a header\nTerms:\nLet I be the event that the patient has the illness\nLet E be the event that the test result is positive\nP(I|E) = probability of the illness given a positive test. This is the number we want to calculate.\nP(E|I) = probability of a positive result given illness = 0.92\nP(E|IC) = probability of a positive result given no illness = 0.10\nP(I) = natural probability of the illness = 0.13\nBayes Theorem:\nIn this problem we know P(E|I) and P(E|IC) but we want to know P(I|E). We can apply Bayes\nTheorem to turn our knowledge of one conditional into knowledge of the reverse.\nP(E|I)P(I)\nP(I|E)= Bayes'TheoremwithTotalProb.\nP(E|I)P(I)+P(E|IC)P(IC)\nNow all we need to do is plug values into this formula. The only value we don't explicitly have is P(IC).\nBut we can simply calculate it since P(IC)=1\u2212P(I). Thus:\n(0.92)(0.13)\nP(I|E)= =0.5789\n(0.92)(0.13)+(0.10)(1\u22120.13)\nNatural Frequency Intuition\nOne way to build intuition for Bayes Theorem is to think about \"natural frequences\". Let's take another\napproach to answer the probability question in the above example on belief of illness given a test. In this\ntake, we are going to imagine we have a population of 1000 people. Let's think about how many of those\nhave the illness and test positive and how many don't have the illness and test positive. This visualization\nis based off the numbers in the fields above. Feel free to change them!\nThere are many possibilities for how many people have the illness, but one very plausible number is\n1000, the number of people in our population, multiplied by the probability of the disease.\n1000\u00d7P(Illness) people have the illness\n1000\u00d7(1\u2212P(Illness)) people do not have the illness.\nWe are going to color people who have the illness in blue and those without the illness in pink (those\ncolors do not imply gender!).\nA certain number of people with the illness will test positive (which we will draw in Dark Blue) and a\ncertain number of people without the illness will test positive (which we will draw in Dark Pink):\n1000\u00d7P(Illness)\u00d7P(Positive|Illness) people have the illness and test positive\n1000\u00d7P(IllnessC)\u00d7P(Positive|IllnessC) people do not have the illness and test positive.\nHere is the whole population of 1000 people:\n3\nThis is a header\nThe number of people who test positive and have the illness is 76.\nThe number of people who test positive and don't have the illness is 65.\nThe total number of people who test positive is 141.\nOut of the subset of people who test positive, the fraction that have the illness is 76/141 = 0.5390 which\nis a close approximation of the answer. If instead of using 1000 imaginary people, we had used more, the\napproximation would have been even closer to the actual answer (which we calculated using Bayes\nTheorem).\nBayes with the General Law of Total Probability\nA classic challenge when applying Bayes' theorem is to calculate the probability of the normalization\nconstant P(E) in the denominator of Bayes' Theorem. One common strategy for calculating this\nprobability is to use the law of total probability. Our expanded version of Bayes' Theorem uses the simple\nversion of the total law of probability: P(E)=P(E|F)P(F)+P(E|Fc)P(Fc). Sometimes you will\nwant the more expanded version of the law of total probability: P(E)=\u2211 iP(E|B i)P(B i). Recall that\nthis only works if the events B i are mutually exclusive and cover the sample space.\nFor example say we are trying to track a phone which could be in any one of n discrete locations and we\nhave prior beliefs P(B 1)\u2026P(B n) as to whether the phone is in location B i. Now we gain some\nevidence (such as a particular signal strength from a particular cell tower) that we call E and we need to\nupdate all of our probabilities to be P(B i|E). We should use Bayes' Theorem!\nThe probability of the observation, assuming that the the phone is in location B i, P(E|B i), is something\nthat can be given to you by an expert. In this case the probability of getting a particular signal strength\ngiven a location B i will be determined by the distance between the cell tower and location B i .\nSince we are assuming that the phone must be in exactly one of the locations, we can find the probability\nof any of the event B i given E by first applying Bayes' Theorem and then applying the general version of\nthe law of total probability:\nP(E|B)\u22c5P(B)\nP(B|E)= i i BayesTheorem.Whattodoabout P(E)?\ni P(E)\nP(E|B)\u22c5P(B)\n= i i UseGeneralLawofTotalProbabilityfor P(E)\n\u2211n P(E|B )\u22c5P(B )\nj=1 j j\n4\nThis is a header\nUnknown Normalization Constant\nThere are times when we would like to use Bayes' Theorem to update a belief, but we don't know the\nprobability of E, P(E). All hope is not lost. This term is called the \"normalization constant\" because it is\nthe same regardless of whether or not the event B happens. The solution that we used above was the law\nof total probability: P(E)=P(E|B)P(B)+P(E|BC)P(BC). This allows us to calculate P(E).\nHere is another strategy for dealing with an unknown P(E). We can make it cancel out by calculating the\nratio of P(B|E) . This fraction tells you how many times more likely it is that B will happen given E\nP(BC|E)\nthan not B:\nP(E|B)P(B)\nP(B|E)\nP(E)\n= ApplyBayes'Theoremtobothterms\nP(BC|E) P(E|BC)P(BC)\nP(E)\nP(E|B)P(B)\n= Theterm P(E) cancels\nP(E|BC)P(BC)\n5\nThis is a header\nLog Probabilities\nA log probability logP(E) is simply the log function applied to a probability. For example if\nP(E)=0.00001 then logP(E)=log(0.00001)\u2248\u221211.51. Note that in this book, the default base is\nthe natural base e. There are many reasons why log probabilities are an essential tool for digital\nprobability: (a) computers can be rather limited when representing very small numbers and (b) logs have\nthe wonderful ability to turn multiplication into addition, and computers are much faster at addition.\nYou may have noticed that the log in the above example produced a negative number. Recall that\nlogb=c, with the implied natural base e is the same as the statement ec=b. It says that c is the\nexponent of e that produces b. If b is a number between 0 and 1, what power should you raise e to in\norder to produce b? If you raise e0 it produces 1. To produce a number less than 1, you must raise e to a\npower less than 0. That is a long way of saying: if you take the log of a probability, the result will be a\nnegative number.\n0\u2264P(E)\u22641 Axiom1ofprobability\n\u2212\u221e\u2264logP(E)\u22640 Ruleforlogprobabilities\nProducts become Addition\nThe product of probabilities P(E) and P(F) becomes addition in logarithmic space:\nlog(P(E)\u22c5P(F))=logP(E)+logP(F)\nThis is especially convenient because computers are much more efficient when adding than when\nmultiplying. It can also make derivations easier to write. This is especially true when you need to\nmultiply many probabilities together:\nlog\u220fP(E)=\u2211logP(E)\ni i\ni i\nRepresenting Very Small Probabilities\nComputers have the power to process many events and consider the probability of very unlikely\nsituations. While computers are capable of doing all the computation, the floating point representation\nmeans that computers can not represent decimals to perfect precision. In fact, python is unable to\nrepresent any probability smaller than 2.225e-308. On the other hand the log of that same number is\n-307.652 is very easy for a computer to store.\nWhy would you care? Often in the digital world, computers are asked to reason about the probability of\ndata, or a whole dataset. For example, perhaps your data is words and you want to reason about the\nprobability that a given author would write these specific words. While this probability is very small (we\nare talking about an exact document) it might be larger than the probability that a different author would\nwrite a specific document with specific words. For these sort of small probabilities, if you use computers,\nyou would need to use log probabilities.\n1\nThis is a header\nMany Coin Flips\nIn this section we are going to consider the number of heads on n coin flips. This thought experiment is\ngoing to be a basis for much probability theory! It goes far beyond coin flips.\nSay a coin comes up heads with probability p. Most coins are fair and as such come up heads with\nprobability p=0.5. There are many events for which coin flips are a great analogy that have different\nvalues of p so let's leave p as a variable. You can try simulating flipping coins here. Note that H is short\nfor Heads and T is short for Tails. We think of each coin as distinct:\nCoin Flip Simulator\nNumber of flips n: 10 Probability of heads p: 0.60 New\nsimulation\nSimulator results:\nH, T, H, H, H, T, T, H, H, H\nTotal number of heads: 7\nUsing the math in this chapter we will be able to show that the probability of getting exactly 7 heads\n(when the probability of heads on each flip is 0.6) = 0.215. Specifically in this chapter:\n1. Warmups: We calculate the probability of a few exact outcomes.\n2. Exactly k heads. We derive the general formula.\n3. More than k heads. We explore this interesting related problem.\nWarmups\nIn all of these warmups we are going to consider the probability of different outcomes when you flip a\ncoin n times and each time the probability of heads is p. In each solution we will consider the case where\nn=10 and p=0.6.\nWhat is the probability that all n flips are heads?\nThis question is asking what is the probability of getting the outcome:\nH, H, H, H, H, H, H, H, H, H\nWhere each flip lands in heads (H). Each coin flip is independent so we can use the rule for probability of\nand with independent events. As such, the probability of n heads is p multiplied by itself n times: pn.\nIf n=10 and p=0.6 then the probability of n heads = pn=0.610\u2248 0.006.\nWhat is the probability that all n flips are tails?\nLets say n=10 this question is asking what is the probability of getting:\nT, T, T, T, T, T, T, T, T, T\nEach coin flip is independent. The probability of tails on any coin flip is 1\u2212p. Again, since the coin flips\nare independent, the probability of tails n times on n flips is (1\u2212p) multiplied by itself n times:\n(1\u2212p)n. If n=10 and p=0.6 then the probability of n tails is around 0.0001.\n1\nThis is a header\nFirst k heads then n\u2212k tails\nLets say n=10 and k=4, this question is asking what is the probability of getting:\nH, H, H, H, T, T, T, T, T, T\nThe coins are still independent! The first k heads occur with probability pk the run of n\u2212k tails occurs\nwith probability (1\u2212p)n\u2212k. The probability of k heads then n\u2212k tails is the product of those two\nterms: pk\u22c5(1\u2212p)n\u2212k\nk\nExactly heads\nNext lets try to figure out the probability of exactly k heads in the n flips. Importantly we don't care\nwhere in the n flips that we get the heads, as long as there are k of them. Note that this question is\ndifferent than the question of first k heads and then n\u2212k tails which requires that the k heads come first!\nThat particular result does generate exactly k coin flips, but there are others.\nThere are many others! Lets ask the computer to list the ways we could generate exactly k=4 heads\nwithin n=10 coin flips. The output region is scrollable:\n(H, H, H, H, T, T, T, T, T, T)\n(H, H, H, T, H, T, T, T, T, T)\n(H, H, H, T, T, H, T, T, T, T)\n(H, H, H, T, T, T, H, T, T, T)\n(H, H, H, T, T, T, T, H, T, T)\n(H, H, H, T, T, T, T, T, H, T)\n(H, H, H, T, T, T, T, T, T, H)\n(H, H, T, H, H, T, T, T, T, T)\n(H, H, T, H, T, H, T, T, T, T)\n(H, H, T, H, T, T, H, T, T, T)\n(H, H, T, H, T, T, T, H, T, T)\n(H, H, T, H, T, T, T, T, H, T)\n(H, H, T, H, T, T, T, T, T, H)\n(H, H, T, T, H, H, T, T, T, T)\n(H, H, T, T, H, T, H, T, T, T)\n(H, H, T, T, H, T, T, H, T, T)\n(H, H, T, T, H, T, T, T, H, T)\n(H, H, T, T, H, T, T, T, T, H)\nLet's call each of these rows an \"ordering\" since each row is a unique way to order the 4 heads and 6\ntails. Let N be the number of unique orderings.\nExactly how many unique orderings are there with k=4 heads in n=10 flips? N =210. Why? Each\nordering listed above is a permutation of the list [H, H, H, H, T, T, T, T, T, T]. As such, the question \"how\nmany orderings are there?\" is analogous to the question, how many distinct orderings of characters are\npossible for the string \"HHHHTTTTT\"? Because H characters are indistinct from one another (and same\nfor T) we can solve this problem using Permutations of Indistinct Objects:\nn! n\nNumOrderings= =( )\nk!(n\u2212k)! k\nEach of these orderings can be thought of as one event, or outcome, of flipping 10 coins. Let's name E i\nto be the event that we get the exact outcome in the ith row. E 1 is the event that we get [H, H, H, H, T, T, T,\nT, T, T]. E 2 is the event that we get [H, H, H, T, H, T, T, T, T, T] and so on.\nThe probability of exactly k=4 heads is the probability of the or of each of these events E i. If you flip a\ncoin 10 times, it is not possible to have more than one of the E i events occur (eg both E 1 and E 2 can't be\ntrue if you flip 10 coins). In other words, each of these events E i is \"mutually exclusive\" and as such:\n2\nThis is a header P(exactly k heads)=P(E orE or\u2026orE )\n1 2 N\nN\n=\u2211P(E)\ni\ni=1\nThe next question is, what is the probability of each of these events E i?\nHere is a arbitrarily chosen ordering which satisfies the event of exactly k=4 heads in n=10 coin\nflips. It is E 128, the ordering on row 128 in the list above:\nT, H, T, T, H, T, T, H, H, T\nWhat is the probability of event E 128, the exact sequence of heads and tails in the example above? Each\ncoin flip is still independent, so we multiply p for each heads and 1\u2212p for each tails.\nP(E )=(1\u2212p)\u22c5p\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5p\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5p\u22c5p\u22c5(1\u2212p)\n128\nIf you rearrange these multiplication terms you get:\nP(E )=p\u22c5p\u22c5p\u22c5p\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5(1\u2212p)\u22c5(1\u2212p)\n128\n=p4\u22c5(1\u2212p)6\nThere is nothing too special about row 128. If you chose any row, you would get k independent heads\nand n\u2212k independent tails. For any row i, P(E i)=pk\u22c5(1\u2212p)n\u2212k.\nNow we are ready to calculate the probability of exactly k heads:\nN\nP(exactly k heads)=\u2211P(E) MutualExclusion\ni\ni=1\nN\n=\u2211pk\u22c5(1\u2212p)n\u2212k Subin P(E)\ni\ni=1\n=N\u22c5pk\u22c5(1\u2212p)n\u2212k Sum N times\nn\n=( )\u22c5pk\u22c5(1\u2212p)n\u2212k Permofindistinctobjects\nk\nLet's bring that back to the example of getting exactly k=4 heads out of n=10 where the probability\nof getting a heads on any one flip is p=0.6. The probability of exactly k heads is:\nn\nP(exactly k heads)=( )\u22c5pk\u22c5(1\u2212p)n\u2212k Justderived!\nk\n10\n=( )\u22c50.64\u22c5(1\u22120.6)10\u22124 Subin n, k, p\n4\n=210\u22c50.64\u22c50.46 Simplify\n=0.111\nWe are done! This result is truly useful. Care about the probability of number of voters who vote for a\ncandidate? Care about the number of people who get a disease? Care about the number of people who\nclick on an ad? This derivation is the basis for all of that! Later in this book we will formalize this\nincredible result into the Binomial Random Variable.\nk\nMore than heads\nThere are many cases where you care about the probability of more than k heads. We can derive a\nsolution based on the forumla for exactly k heads.\nIf you want the probability of getting more than k=4 heads out of n=10 coin flips it is the probability\nof the or of each of the events where you get exactly i heads for i=5,6,7,8,9,10. Note that all the\nevents where you get exactly i heads are mutually exclusive from the events where you get exactly j\nheads when i\u2260j. For example if you flip a coin 10 times, it is not possible to get exactly 4 heads and to\nalso get exactly 5 heads. As such the probability of or becomes addition:\n3\nThis is a header n\nP(morethan k heads)= \u2211 P(exactly i heads) MutualExclusion\ni=k+1\nn n\n= \u2211 ( )\u22c5pi\u22c5(1\u2212p)n\u2212i Substitution\ni\ni=k+1\n4\nThis is a header\nEnigma Machine\nOne of the very first computers was built to break the Nazi \u201cenigma\u201d codes in WW2. It was a hard\nproblem because the \u201cenigma\u201d machine, used to make secret codes, had so many unique configurations.\nEvery day the Nazis would choose a new configuration and if the Allies could figure out the daily\nconfiguration, they could read all enemy messages. One solution was to try all configurations until one\nproduced legible German. This begs the question: How many configurations are there?\nThe WW2 machine built to search different enigma configurations.\nThe enigma machine has three rotors. Each rotor can be set to one of 26 different positions. How many\nunique configurations are there of the three rotors?\nUsing the steps rule of counting: 26\u22c526\u22c526=263=17,576.\nWhats more! The machine has a plug board which could swap the electrical signal for letters. On the plug\nboard, wires can connect any pair of letters to produce a new configuration. A wire can\u2019t connect a letter\nto itself. Wires are indistinct. A wire from \u2018K\u2019 to \u2019L\u2019 is not considered distinct from a wire from \u2018L\u2019 to \u2019K\u2019.\nWe are going to work up to considering any number of wires.\nThe engima plugboard. For electrical reasons, each letter has two jacks and each plug has two prongs.\nSemantically this is equivalent to one plug location per letter.\nOne wire: How many ways are there to place exactly one wire that connects two letters?\nChosing 2 letters from 26 is a combination. Using the combination formula:\n(26)=325.\n2\nTwo wires: How many ways are there to place exactly two wires? Recall that wires are not considered\ndistinct. Each letter can have at most one wire connected to it, thus you couldn\u2019t have a wire connect \u2018K\u2019\nto \u2018L\u2019 and another one connect \u2018L\u2019 to \u2018X\u2019\n1\nThis is a header\nThere are\n(26)\nways to place the first wire and\n(24)\nways to place the second wire. However, since the\n2 2\nwires are indistinct, we have double counted every possibility. Because every possibility is counted twice\nwe should divide by 2:\n(26)\u22c5(24)\nTotal= 2 2 =44,850\n2\nThree wires: How many ways are there to place exactly three wires?\nThere are\n(26)\nways to place the first wire and\n(24)\nways to place the second wire. There are now\n(22)\n2 2 2\nways to place the third. However, since the wires are indistinct, and our step counting implicitly treats\nthem as distinct, we have overcounted each possibility. How many times is each pairing of three letters\novercounted? It's the number of permutations of three distinct objects: 3!\n(26)\u22c5(24)\u22c5(22)\nTotal= 2 2 2 =3,453,450\n3!\nThere is another way to arrive at the same answer. First we are going to choose the letters to be paired,\nthen we are going to pair them off. There are\n(26)\nways to select the letters that are being wired up. We\n6\nthen need to pair off those letters. One way to think about pairing the letters off is to first permute them\n(6! ways) and then pair up the first two letters, the next two, the next two, and so on. For example, if our\nletters were {A,B,C,D,E,F} and our permutation was BADCEF, then this would correspond to wiring B\nto A and D to C and E to F. We are overcounting by a lot. First, we are overcounting by a factor of 3!\nsince the ordering of the pairs doesn\u2019t matter. Second, we are overcounting by a factor of 23 since the\nordering of the letters within each pair doesn\u2019t matter.\n26 6!\nTotal=( ) =3,453,450\n6 3!\u22c523\nArbitrary wires: How many ways are there to place k wires, thus connecting 2\u22c5k letters? During WW2\nthe Germans always used a fixed number of wires. But one fear was that if they discovered the Enigma\nmachine was cracked, they could simply use an arbitrary number of wires.\nThe set of ways to use exactly i wires is mutually exclusive from the set of ways to use exactly j wires if\ni\u2260j (since no way can use both exactly i and j wires). As such Total=\u22111 k3 =0Total k Where Totalk is\nthe number of ways to use exactly k wires. Continuing our logic for ways to used exact number of wires:\n\u220fk (28\u22122i)\nTotal = i=1 2\nk k!\nBringing it all together:\n13\nTotal=\u2211Total\nk\nk=0\n13 \u220fk (28\u22122i)\n=\u2211 i=1 2\nk!\nk=0\n=532,985,208,200,576\nThe actual Enigma used in WW2 had exactly 10 wires connecting 20 letters allowing for\n150,738,274,937,250 unique configuration. The enigma machine also chose the three rotors from a set of\nfive adding another factor of\n(5)=60.\n3\nWhen you combine the number of ways of setting the rotors, with the number of ways you could set the\nplug board you get the total number of configurations of an enigma machine. Thinking of this as two\nsteps we can multiply the two numbers we earlier calculated: 17,576 \u00b7 150,738,274,937,250 \u00b7 60\n\u2248159\u22c51018 unique settings. So, Alan Turing and his team at Blechly Park went on to build a machine\nwhich could help test many configurations -- a predecessor to the first computers.\n2\nThis is a header\n3\nThis is a header\nSerendipity\nThe word serendipity comes from the Persian fairy tale of the Three Princes of Serendip\nProblem\nWhat is the probability of a seredipitous encounter with a friend? Imagine you are live in an area with a\nlarge general population (eg Stanford with 17,000 students). A small subset of the population are friends.\nWhat are the chances that you run into at least one friend if you see a handful of people from the\npopulation? Assume that seeing each person from the population is equally likely.\nTotal Population\n17000\nFriends\n150\nPeople that you see\n100\nCalculate\nAnswer\nThe probability that you see at least one friend is:\n1\nThis is a header\nRandom Shuffles\nHere is a suprising claim. If you shuffle a standard deck of cards seven times, with almost total certainty\nyou can claim that the exact ordering of cards has never been seen! Wow! Let's explore. We can ask this\nquestion formally as: What is the probability that in the n shuffles seen since the start of time, yours is\nunique?\nOrderings of 52 Cards\nOur adventure starts with a simple observation: there are very many ways to order 52 cards. But exactly\nhow many unique orderings of a standard deck are there?\nThere are 52! ways to order a standard deck of cards. Since each card is unique (each card has a unique\nsuit, value combination) then we can apply the rule for Permutations of Distinct Objects:\nNum.UniqueOrderings=52!\nThat is a humongous number. 52! equals\n80658175170943878571660636856403766975289505440883277824000000000000.\nThat is over 8\u22c51067. Recall it is estimated that there are around 1082 atoms in the observable universe\nNumber of Shuffles Ever Seen\nOf course we don't know what the value of n is \u2014 nobody has been counting how many times humans\nhave shuffled cards. We can come up with a reasonable overestimate. Assume k = 7 billion people have\nbeen shuffling cards once a second since cards were invented. Playing cards may have been invented as\nfar back as the Tang dynasty in the 9th century. To the best of my knowledge the oldest set of 52 cards is\nthe Topkap\u0131 deck of cards in Istanbul around the 15th century ad. That is about s = 16,472,828,422\nseconds ago. As such our overestimate is n=s\u22c5k\u22481020.\nNext let's calculate the probability that none of those n historical shuffles matches your particular\nordering of 52 cards. There are two valid approaches: using equally likely outcomes, and using\nindependence.\nEqually Likely Outcomes\nOne way to the probability that your ordering of 52 cards is unique in history is to use Equally Likely\nOutcomes. Consider the sample space of all the possible ordering of all the cards ever dealt. Each\noutcome in this set will have n card decks each with their own ordering. As such the size of the sample\nspace is |S|=(52!)n. Note that all outcomes in the sample space are equally likely \u2014 we can convince\nourselves of this by symmetry \u2014 no ordering is more likely than any other. Out of that sample space we\nwant to count the number of outcomes where none of the orderings matches yours. There are 52!\u22121\nways to order 52 cards that are not yours. We can construct the event space by steps: for each of the n\nshuffles in history select any one of those 52!\u22121 orderings. Thus |E|=(52!\u22121)n.\n1\nThis is a header\nLet U be the event that your particular ordering of 52 cards is unique\n|E|\nP(U)= EquallyLikelyOutcomes\n|S|\n(52!\u22121)n\n=\n(52!)n\n(52!\u22121)1020\n= n=1020\n(52!)1020\n52!\u22121 1020\n=( )\n52!\nIn theory that is the correct answer, but those numbers are so big, its not clear how to evaluate it, even\nwhen using a computer. One good idea is to first compute the log probability:\n52!\u22121 1020\nlogP(U)=log[( ) ]\n52!\n52!\u22121\n=1020\u22c5log( )\n52!\n=1020\u22c5[log(52!\u22121)\u2212log(52!)]\n=1020\u22c5(\u22121.24\u00d710\u221268)\n=\u22121.24\u00d710\u221248\nNow if we undo the log (and use the fact that e\u2212x is very close to 1\u2212x for small values of x):\nP(U)=e\u22121.24\u00d710\u221248\n\u22481\u22121.24\u00d710\u221248\nSo the probability that your particular ordering is unique is very close to 1, and the probability that\nsomeone else got the same ordering, 1\u2212P(U), is a number with 47 zeros after the decimal point. It is\nsafe to say your ordering is unique.\nIn python, you can use a special library called decimal to compute very small probabilities. Here is an\nexample of how to compute log 52!\u22121 :\n52!\nfrom decimal import *\nimport math\nn = math.pow(10, 20)\ncard_perms = math.factorial(52)\ndenominator = card_perms\nnumerator = card_perms - 1\n# decimal library because these are tiny numbers\ngetcontext().prec = 100 # increase precision\nlog_numer = Decimal(numerator).ln()\nlog_denom = Decimal(denominator).ln()\nlog_pr = log_numer - log_denom\n# approximately -1.24E-68\nprint(log_pr)\nWe can also check our result using the binomial approximation.\n2\nThis is a header\nFor small values of x, the value (1\u2212x)n is very close to 1\u2212nx, and this gives us another way to\ncompute P(U):\n(52!\u22121)n\nP(U)=\n(52!)n\n1 1020\n=(1\u2212 ) n=1020\n52!\n1020\n\u22481\u2212\n52!\n\u22481\u22121.24\u00d710\u221248\nThis agrees with the result we got using python's decimal library.\nIndependence\nAnother approach is to define events D i that the ith card shuffle is different than yours. Because we\nassume each shuffle is independent, then P(U)=\u220f iP(D i). What is the probability of (D i)? If you\nthink of the sample space of D i, it is 52! ways of ordering a deck cards. The event space is the 52! - 1\noutcomes which are not your ordering.\nn\nP(U)=\u220fP(D)\ni\ni=1\nn\nlogP(U)=\u2211logP(D)\ni\ni=1\n=n\u22c5logP(D)\ni\n52!\u22121\n=1020\u22c5log\n52!\n\u22481020\u22c5\u22121.24\u00d710\u221268\nWhich is the same answer we got with the other approach for logP(U)\nHow Random is your Shuffle?\nA final question we can look into. How do you get a truly random ordering of cards? Dave Bayer and\nPersi Diaconis in 1992 worked through this problem and published their results in the article Trailing the\nDovetail Shuffle to its Lair. They showed that if you shuffle a deck of cards seven times using a riffle\nshuffle also known as the dovetail shuffle, you are almost garunteed a random ordering of cards. The\nmethodology used paved the way for studying psuedo random numbers produced by computers.\n3\nThis is a header\nCounting Random Graphs\nIn this example we are going to explore the density of randomly generated graphs (aka networks). This\nwas a problem on the Stanford Midterm Fall 2022. As an example to get us started, here are three\ndifferent networks each with 10 nodes and 12 random edges:\nCount locations for edges: First, lets establish how many locations there are for edges in a random\nnetwork. Consider a network with 10 nodes. Count the number of possible locations for undirected edges.\nRecall that an undirected edge from node A to node B is not distinct from an edge from node B to node\nA. You can assume that an edge does not connect a node to itself.\nEach edge connects 2 nodes, and there are 10 possible options for each node, so the answer is\n10\n( )=45.\n2\nCount ways to place edges: Now lets add random edges to the network! Assume the same network (with\n10 nodes) has 12 random edges. If each pair of nodes is equally likely to have an edge, how many unique\nways could we chose the location of the 12 edges?\nLet\nk=(10)\nbe the number of possible locations for an edge, and we have 12 distinct (undirected) edges,\n2\nso there are\n(k)\nways to do place edges.\n12\nProbability of node degree: Now that we have a randomly generated graph, lets explore the degree of\nour nodes! In the same network with 10 nodes and 12 edges, select a node uniformly at random. What is\nthe probability that our node has exactly degree i? Note that 0\u2264i\u22649. Recall that there are only 9 nodes\nto connect to from our chosen node, since there are 10 nodes in the graph.\nLet E be the event that our node has exactly i connections. We will first compute the distribution of\nP(E) using |E|/|S|. The sample space is the set of ways to choose 12 edges, and the event space is the\nset of ways to do so such that we've chosen exactly i of the edges incident to our current node (which has\n9 possible edges incident to it). To construct the event space E we can consider a two step process:\n1. Select i edges from the 9 possible edge locations connected to our node.\n2. Select the location for the 12\u2212i remaining edges. The edges can go to any of the k locations for\nedges except for the 9 incident to our node.\nAs such the answer is\n|E|\nP(E)=\n|S|\n(9)(k\u22129)\n= i 12\u2212i .\n(k)\n12\n1\nThis is a header\nSet Diversity (Gini Impurity)\nIn this question we are going to asks a simple question: what is the probability that two chosen objects\nfrom a set are different. This statistic, formally called the Gini Impurity is used both in Random Forest\nalgorithms and in social science. This was a problem from the Stanford Midterm in Fall 2023.\na) Consider the following set of shapes. If you chose two shapes with replacement what is the\nprobability that the two shapes are the same? Note that it is possible to get two triangles: after you pick\nthe first triangle, you put it back into the set of shapes and it can be chosen again.\nDefine the Sample Space to be the 49 different outcomes of chosing the two shapes with replacement (7\nchoices for the first shape and 7 choices for the second shape). Notice that in our construction of the\nsample space we have chosen for the shapes to be treated as all being distinct from one another. An\noutcome in S (\u2208S) is thus an ordered tuple of distinct shapes. For example one outcome in S is (Shape4,\nShape2). |S|=7\u00d77=49. Note that all the outcomes in S are equally likely (that was the reason why\nwe treated shapes as distinct).\nLet E be the subset of S where the two shapes match. Let A be the event that you have two squares and\nlet B be the event that you have two trianges. Note that A and B are mutually exclusive. By the step rule\nof counting |A|=6\u22c56=36 since there are two steps to creating an outcome in A: chose a square then\nchose another square. Similarly |B|=1\u22c51=1.\n|E|\nP(same)=\n|S|\n|A|+|B|\n=\n|S|\n36+1\n=\n49\n37\n=\n49\nb) Consider the following set of shapes. If you chose two shapes with replacement what is the\nprobability that the two shapes are different? Notice that the previous question asked for the probability\nthat the two shapes are the same. The probability that two items are different is called the Gini Impurity\nof a set.\n1\nThis is a header\nDefine the same Sample Space to be the 49 different outcomes of chosing the two shapes with\nreplacement (7 choices for the first shape and 7 choices for the second shape). |S|=7\u00d77=49. Note\nthat all the outcomes in S are equally likely.\nLet E be the subset of S where the two shapes match.\nLet A be the event that you have two squares.\nLet B be the event that you have two trianges.\nLet C be the event that you have two stars. Note that A, B and C are mutually exclusive. By the step rule\nof counting\n|A|=4\u22c54=16\n|B|=2\u22c52=4\n|C|=1\u22c51=1\nP(different)=1\u2212P(same)\n|E|\n=1\u2212\n|S|\n|A|+|B|+|C|\n=1\u2212\n|S|\n16+4+1\n=1\u2212\n49\n21 4\n=1\u2212 =\n49 7\nGini Imputiy in Decision Trees\nNote: This next problem isn't remarkably different to the problems above. The point of this problem is to\nshow you how the concept of Gini Impurity connects to Decision Trees.\nDecision Trees (and their big brother Random Forests) are some of the most popular classification AI\nalgorithms that don't use deep nerual networks. They are built based off data, node-by-node. Once built,\nthey can be used to make classification decisions. The critical decision when making a decision tree is to\ndecide which node to add next. One way to make that decision is to chose the node which choice of new\nnode leads to the largest decrease in Gini Impurity of the shapes that end up together at the end of the\ndecision tree.\nAside: this particular node has split the shapes based off a value (which is slightly related to the shape).\nShapes with value 0 go to the left child, shapes with value 1 go to the right.\nc) Consider the node in the picture above. Let G L be the probability that two shapes, selected from the\nshapes in the left side, are different (Gini Impurity) and let G R be the probability that two shapes,\nselected from the shapes in the right side, are different (again the Gini Impurity). What is the value of\nmax(G L,G R)? We only use the shape type to calculate the Gini Impurity. The value represents the\nfeatures that were used to sort them between the left and right node and can be ignored in this question.\n2\nThis is a header\nFirst lets generalize our calculation of G for a set of shapes. Let n be the number of shapes in the set. Let\nn i be the number of shapes of type i in the set. It is going to be easier to calculate the probability that two\nshare ares are the same than the probability that two shapes are different. If we set up the sample space S\nto be the set of all ways to pick two shapes (treating each shape as distinct, and treating the selection as\nordered). The event space E is then the subset of events where the shapes are the same. Because chosing\nthe same shape of one type is mutually exclusive with chosing the same shape of another type, we can\ncalculate the probability that two shapes are the same by calculating the probability that two shapes are\nthe same for each type of shape and summing them up:\nG=1\u2212P(same)\n|E|\n=1\u2212\n|S|\n\u2211nn2\n=1\u2212 i i\n|S|\nG L=1\u2212 22 7+ 252 and G R=1\u2212 22 3+ 212 . For those curious G R is the larger of the two.\nGoing Further\nNote: in the midterm students were asked to calculate the \"Expected\" Gini Score, instead of the max.\nThat uses Expectation, a concept we will learn in the next section. We also asked for the Gini Impurity of\na Poisson random variable, a concept from Part 3.\n3\nThis is a header\nBacteria Evolution\nA wonderful property of modern life is that we have anti-biotics to kill bacterial infections. However, we\nonly have a fixed number of anti-biotic medicines, and bacteria are evolving to become resistent to our\nanti-biotics. In this example we are going to use probability to understand evolution of anti-biotic\nresistence in bacteria.\nImagine you have a population of 1 million infectious bacteria in your gut, 10% of which have a\nmutation that makes them slightly more resistant to anti-biotics. You take a course of anti-biotics. The\nprobability that bacteria with the mutation survives is 20%. The probability that bacteria without the\nmutation survives is 1%.\nWhat is the probability that a randomly chosen bacterium survives the anti-biotics?\nLet E be the event that our bacterium survives. Let M be the event that a bacteria has the mutation. By\nthe Law of Total Probability (LOTP):\nP(E)=P(EandM)+P(EandMC) LOTP\n=P(E|M)P(M)+P(E|MC)P(MC) ChainRule\n=0.20\u22c50.10+0.01\u22c50.90 Substituting\n=0.029\nWhat is the probability that a surviving bacterium has the mutation?\nUsing the same events in the last section, this question is asking for P(M|E). We aren't giving the\nconditional probability in that direction, instead we know P(E|M). Such situations call for Bayes'\nTheorem:\nP(E|M)P(M)\nP(M|E)= Bayes\nP(E)\n0.20\u22c50.10\n= Given\nP(E)\n0.20\u22c50.10\n= Calculated\n0.029\n\u22480.69\nAfter the course of anti-biotics, 69% of bacteria have the mutation, up from 10% before. If this\npopulation is allowed to reproduce you will have a much more resistent set of bacteria!\n1\nPart 2: Random Variables\nThis is a header\nRandom Variables\nA Random Variable (RV) is a variable that probabilistically takes on a value and they are one of the most\nimportant constructs in all of probability theory. You can think of an RV as being like a variable in a\nprogramming language, and in fact random variables are just as important to probability theory as\nvariables are to programming. Random Variables take on values, have types and have domains over\nwhich they are applicable.\nRandom variables work with all of the foundational theory we have built up to this point. We can define\nevents that occur if the random variable takes on values that satisfy a numerical test (eg does the variable\nequal 5, is the variable less than 8).\nLets look at a first example of a random variable. Say we flip three fair coins. We can define a random\nvariable Y to be the total number of \u201cheads\u201d on the three coins. We can ask about the probability of Y\ntaking on different values using the following notation:\nLet Y be the number of heads on three coin flips\nP(Y =0) = 1/8 (T, T, T)\nP(Y =1) = 3/8 (H, T, T), (T, H, T), (T, T, H)\nP(Y =2) = 3/8 (H, H, T), (H, T, H), (T, H, H)\nP(Y =3) = 1/8 (H, H, H)\nP(Y \u22654) = 0\nEven though we use the same notation for random variables and for events (both use capital letters) they\nare distinct concepts. An event is a scenario, a random variable is an object. The scenario where a random\nvariable takes on a particular value (or range of values) is an event. When possible, I will try and use\nletters E,F,G for events and X,Y,Z for random variables.\nUsing random variables is a convenient notation technique that assists in decomposing problems. There\nare many different types of random variables (indicator, binary, choice, Bernoulli, etc). The two main\nfamilies of random variable types are discrete and continuous. Discrete random variables can only take\non integer values. Continuous random variables can take on decimal values. We are going to develop our\nintuitions using discrete random variable and then introduce continuous.\nProperties of random variables\nThere are many properties of a random variable some of which we will dive into extensively. Here is a\nbrief summary. Each random variable has:\nNotation\nProperty Example Description\nMeaning A semantic description of the random variable\nSymbol X A letter used to denote the random variable\nSupport or Range {0,1,\u2026,3} the values the random variable can take on\nDistribution Function (PMF P(X=x) A function which maps values the RV can take on\nor PDF) to likelihood.\nExpectation E[X] A weighted average\n1\nThis is a header\nNotation\nProperty Example Description\nVariance Var(X) A measure of spread\nStandard Deviation Std(X) The square root of variance\nMode The most likely value of the random variable\nYou should set a goal of deeply understanding what each of these properties mean. There are many more\nproperties than the ones in the table above: properties like entropy, median, skew, kurtosis.\nRandom variables vs Events\nRandom variables and events are two different concepts. An event is an outcome, or a set of outcomes, to\nan experiment. A random variable is a more like an experiment -- it will take on an outcome eventually.\nProbabilities are over events, so if you want to talk about probability in the context of a random variable,\nyou must construct an event. You can make events by using any of the Relational Operators: <, \u2264, >, \u2265, =,\nor \u2260 (not equal to). This is analogous to coding where you can use relational operators to create boolean\nexpressions from numbers.\nLets continue our example of the random variable Y which represents the number of heads on three coin\nflips. Here are some events using the variable Y:\nEvent Meaning Probability Statement\nY =1 Y takes on the value 1 (there was one heads) P(Y =1)\nY <2 Y takes on 0 or 1 (note this Y can't be negative) P(Y <2)\nX>Y X takes on a value greater than the value Y takes on. P(X>Y)\nY =y Y takes on a value represented by non-random variable y P(Y =y)\nYou will see many examples like this last one, P(Y =y), in this text book as well as in scientific and\nmath research papers. It allows us to talk about the likelihood of Y taking on a value, in general. For\nexample, later in this book we will derive that for three coin flips where Y is the number of heads, the\nprobability of getting exactly y heads is:\n0.75\nP(Y =y)= If 0\u2264y\u22643\ny!(3\u2212y)!\nThis statement above is a function which takes in a parameter y as input and returns the numeric\nprobability P(Y =y) as output. This particular expression allows us to talk about the probability that the\nnumber of heads is 0, 1, 2 or 3 all in one expression. You can plug in any one of those values for y to get\nthe corresponding probability. It is customary to use lower-case symbols for non-random values. The use\nof an equals sign in the \"event\" can be confusing. For example what does this expression say\nP(Y =1)=0.375? It says that the probability that \"Y takes on the value 1\" is 0.375. For discrete\nrandom variables this function is called the \"probability mass function\" and it is the topic of our next\nchapter.\n2\nThis is a header\nProbability Mass Functions\nFor a random variable, the most important thing to know is: how likely is each outcome? For a discrete\nrandom variable, this information is called the \"probability mass function\". The probability mass\nfunction (PMF) provides the \"mass\" (i.e. amount) of \"probability\" for each possible assignment of the\nrandom variable.\nFormally, the probability mass function is a mapping between the values that the random variable could\ntake on and the probability of the random variable taking on said value. In mathematics, we call these\nassociations functions. There are many different ways of representing functions: you can write an\nequation, you can make a graph, you can even store many samples in a list. Let's start by looking at\nPMFs as graphs where the x-axis is the values that the random variable could take on and the y-axis is\nthe probability of the random variable taking on said value.\nIn the following example, on the left we show a PMF, as a graph, for the random variable: X = the value\nof a six-sided die roll. On the right we show a contrasting example of a PMF for the random variable X =\nvalue of the sum of two dice rolls:\nLeft: the PMF of a single six-sided die roll. Right: the PMF of the sum of two dice rolls.\nThe sum of two dice example in the equally likely probability section. Again, the information that is\nprovided in these graphs is the likelihood of a random variable taking on different values. In the graph on\nthe right, the value \"6\" on the x-axis is associated with the probability 5 on the y-axis. This x-axis\n36\nrefers to the event \"the sum of two dice is 6\" or Y =6. The y-axis tells us that the probability of that\nevent is 5 . In full: P(Y =6)= 5 . The value \"2\" is associated with \" 1 \" which tells us that,\n36 36 36\nP(Y =2)= 1 , the probability that two dice sum to 2 is 1 . There is no value associated with \"1\"\n36 36\nbecause the sum of two dice can not be 1. If you find this notation confusing, revisit the random variables\nsection.\nHere is the exact same information in equation form:\n1 (y\u22121) if 1\u2264y\u22647\nP(X=x)= if 1\u2264x\u22646 P(Y =y)={ 36\n6 (13\u2212y) if 8\u2264y\u226412\n36\nAs a final example, here is the PMF for Y, the sum of two dice, in Python code:\ndef pmf_sum_two_dice(y):\n# Returns the probability that the sum of two dice is y\nif y < 2 or y > 12:\nreturn 0\nif y <= 7:\nreturn (y-1) / 36\nelse:\nreturn (13-y) / 36\n1\nThis is a header\nNotation\nYou may feel that P(Y =y) is redundant notation. In probability research papers and higher-level work,\nmathematicians often use the shorthand P(y) to mean P(Y =y). This shorthand assumes that the\nlowercase value (e.g. y) has a capital letter counterpart (e.g. Y) that represents a random variable even\nthough it's not written explicitly. In this book, we will often use the full form of the event P(Y =y), but\nwe will occasionally use the shorthand P(y).\nProbabilities Must Sum to 1\nFor a variable (call it X) to be a proper random variable it must be the case that if you summed up the\nvalues of P(X=k) for all possible values k that X can take on, the result must be 1:\n\u2211P(X=k)=1\nk\nFor further understanding, let's derive why this is the case. A random variable taking on a value is an\nevent (for example X=2). Each of those events is mutually exclusive because a random variable will\ntake on exactly one value. Those mutually exclusive cases define an entire sample space. Why? Because\nX must take on some value.\nData to Histograms to Probability Mass Functions\nOne surprising way to store a likelihood function (recall that a PMF is the name of the likelihood\nfunction for discrete random variables) is simply a list of data. We simulated summing two die 10,000\ntimes to make this example dataset:\n[8, 4, 9, 7, 7, 7, 7, 5, 6, 8, 11, 5, 7, 7, 7, 6, 7, 8, 8, 9, 9, 4, 6, 7, 10,\n12, 6, 7, 8, 9, 3, 7, 4, 9, 2, 8, 5, 8, 9, 6, 8, 7, 10, 7, 6, 7, 7, 5, 4, 6, 9,\n5, 7, 4, 2, 11, 10, 11, 8, 4, 11, 9, 7, 10, 12, 4, 8, 5, 11, 5, 3, 9, 7, 5, 5,\n5, 3, 8, 6, 11, 11, 2, 7, 7, 6, 5, 4, 6, 3, 8, 5, 8, 7, 6, 9, 4, 3, 7, 6, 6, 6,\n5, 6, 10, 5, 9, 9, 8, 8, 7, 4, 8, 4, 9, 8, 5, 10, 10, 9, 7, 9, 7, 7, 10, 4, 7,\n8, 4, 7, 8, 9, 11, 7, 9, 10, 10, 2, 7, 9, 4, 8, 8, 12, 9, 5, 11, 10, 7, 6, 4, 8,\n9, 9, 6, 5, 6, 5, 6, 11, 7, 3, 10, 7, 3, 7, 7, 10, 3, 6, 8, 6, 8, 5, 10, 2, 7,\n4 8 11 9 3 4 2 8 8 6 6 12 11 10 10 10 8 4 9 4 4 6 6 7 8\nNote that this data, on its own, represents an approximation for the probability mass function. If you\nwanted to approximate P(Y =3) you could simply count the number of times that \"3\" occurs in your\ndata. This is an approximation based on the definition of probability. Here is the full histogram of the\ndata, a count of times each value occurs:\nA normalized histogram (where each value is divided by the length of your data list) is an approximation\nof the PMF. For a dataset of discrete numbers, a histogram shows the count of each value (in this case y).\nBy the definition of probability, if you divide this count by the number of experiments run, you arrive at\nan approximation of the probability of the event P(Y =y). In our example, we have 10,000 elements in\nour dataset. The count of times that 3 occurs is 552. Note that:\ncount(Y =3) 552\n= =0.0552\nn 10000\n4\nP(Y =3)= =0.0555\n36\n2\nThis is a header\nIn this case, since we ran 10,000 trials, the histogram is a very good approximation of the PMF. We use\nthe sum of dice as an example because it is easy to understand. Datasets in the real world often represent\nmore exciting events.\n3\nThis is a header\nExpectation\nA random variable is fully represented by its probability mass function (PMF), which represents each of\nthe values the random variable can take on, and the corresponding probabilities. A PMF can be a lot of\ninformation. Sometimes it is useful to summarize the random variable! The most common, and arguably\nthe most useful, summary of a random variable is its \"Expectation\".\nDefinition: Expectation\nThe expectation of a random variable X, written E[X] is the average of all the values the random\nvariable can take on, each weighted by the probability that the random variable will take on that value.\nE[X]=\u2211x\u22c5P(X=x)\nx\nExpectation goes by many other names: Mean, Weighted Average, Center of Mass, 1st Moment. All of\nwhich are calculated using the same formula.\nRecall that P(X=x), also written as P(x), is the probability mass function of the random variable X.\nHere is code that calculates the expectation of the sum of two dice, based off the probability mass\nfunction:\ndef expectation_sum_two_dice():\nexp_sum_two_dice = 0\n# sum of dice can take on the values 2 through 12\nfor x in range(2, 12 + 1):\npr_x = pmf_sum_two_dice(x) # pmf gives Pr sum is x\nexp_sum_two_dice += x * pr_x\nreturn exp_sum_two_dice\ndef pmf_sum_two_dice(x):\n# Return the probability that two dice sum to x\ncount = 0\n# Loop through all possible combinations of two dice\nfor dice1 in range(1, 6 + 1):\nfor dice2 in range(1, 6 + 1):\nif dice1 + dice2 == x:\ncount += 1\nreturn count / 36 # There are 36 possible outcomes (6x6)\nIf we worked it out manually we would get that if X is the sum of two dice, E[X]=7:\n1 2 1\nE[X]=\u2211x\u22c5P(X=x)=2\u22c5 +3\u22c5 +\u22ef+12 =7\n36 36 36\nx\n7 is the \"average\" number you expect to get if you took the sum of two dice near infinite times. In this\ncase it also happens to be the same as the mode, the most likely value of the sum of two dice, but this is\nnot always the case!\nProperties of Expectation\nProperty: Linearity of Expectation\nE[aX+b]=aE[X]+b\nWhere a and b are constants and not random variables.\n1\nThis is a header\nProperty: Expectation of the Sum of Random Variables\nE[X+Y]=E[X]+E[Y]\nThis is true regardless of the relationship between X and Y. They can be dependent, and they can have\ndifferent distributions. This also applies with more than two random variables.\nn n\nE[\u2211X]=\u2211E[X]\ni i\ni=1 i=1\nProperty: Law of The Unconcious Statistician (LOTUS)\nE[g(X)]=\u2211g(x)P(X=x)\nx\nOne can also calculate the expected value of a function g(X) of a random variable X when one knows the\nprobability distribution of X but one does not explicitly know the distribution of g(X). This theorem has\nthe humorous name of \"the Law of the Unconscious Statistician\" (LOTUS), because it is so useful that\nyou should be able to employ it unconciously.\nProperty: Expectation of a Constant\nE[a]=a\nSometimes in proofs, you will end up with the expectation of a constant (rather than a random variable).\nFor example what does the E[5] mean? Since 5 is not a random variable, it does not change, and will\nalways be 5, E[5]=5.\nExpectation of Sums Proof\nOne of the most useful properties of expectation is that the sum of expectation of random variables can\nbe calculated by summing the expectations of each random variable on its own. Later in Adding Random\nVariables we will learn that computing the full probability mass function (or probability density function)\nwhen adding random variables is quite hard, especially when the random variables are dependent.\nHowever the expectation of sums is always decomposable:\nE[X+Y]=E[X]+E[Y]\nThis very useful result is somewhat suprising. I believe that the best way to understand this result is via a\nproof. This proof, however, will use some concepts from the next section in the course reader,\nProbabilistic Models. Once you have learned how to think about random variables jointly you will be\nable to understand this proof. There is a section of the reader that goes over the proof in details and gives\nof visualization for why it is true! Proof of Expectation of Sum of Random Variables.\nExample of Law of Unconcious Statistician\nThe property of expectation:\nE[g(X)]=\u2211g(x)P(X=x)\nx\nis both useful and hard to understand just by reading the equation. It allows us to calculate the\nexpectation of a function of any function applied to a random variable! One function that will turn out to\nbe very useful when computing Variance is E[X2]. According to the Law of Unconcious Statistician:\nE[X2]=\u2211x2P(X=x)\nx\n2\nThis is a header\nIn this case g is the squaring function. To calculate E[X2] we calculate expectation in a way similar to\nE[X] with the exception that we square the value of x before multiplying by the probability mass\nfunction. Here is code that calculates E[X2] for the sum of two dice:\ndef expectation_sum_two_dice_squared():\nexp_sum_two_dice_squared = 0\n# sum of dice can take on the values 2 through 12\nfor x in range(2, 12 + 1):\npr_x = pmf_sum_two_dice(x) # pmf gives Pr(x)\nexp_sum_two_dice_squared += x**2 * pr_x\nreturn exp_sum_two_dice_squared\nExpectation with Continuous Random Variables\nLater in the course reader we will learn about continuous random variables. Expectation for those types\nof random variables is very similar. See Continuos Random Variables for details\n3\nThis is a header\nVariance\nDefinition: Variance of a Random Variable\nThe variance is a measure of the \"spread\" of a random variable around the mean. Variance for a random\nvariable, X, with expected value E[X]=\u00b5 is:\nVar(X)=E[(X\u2013\u00b5)2]\nSemantically, this is the average distance of a sample from the distribution to the mean. When computing\nthe variance often we use a different (equivalent) form of the variance equation:\nVar(X)=E[X2]\u2212E[X]2\nIn the last section we showed that Expectation was a useful summary of a random variable (it calculates\nthe \"weighted average\" of the random variable). One of the next most important properties of random\nvariables to understand is variance: the measure of spread.\nTo start, let's consider probability mass functions for three sets of graders. When each of them grades an\nassigment, meant to receive a 70/100, they each have a probability distribution of grades that they could\ngive.\nDistributions of three types of peer graders. Data is from a massive online course.\nThe distribution for graders in group C has a different expectation. The average grade that they give\nwhen grading an assignment worth 70 is a 55/100. That is clearly not great! But what is the difference\nbetween graders A and B? Both of them have the same expected value (which is equal to the correct\ngrade). The graders in group A have a higher \"spread\". When grading an assignment worth 70, they have\na reasonable chance of giving it a 100, or of giving it a 40. Graders in group B have much less spread.\nMost of the probability mass is close to 70. You want graders like those in group B: in expectation they\ngive the correct grade, and they have low spread. As an aside: scores in group B came from a\nprobabilistic algorithm over peer grades.\nTheorists wanted a number to describe spread. They invented variance to be the average of the distance\nbetween values that the random variable could take on and the mean of the random variable. There are\nmany reasonable choices for the distance function, probability theorists chose squared deviation from the\nmean:\nVar(X)=E[(X\u2013\u00b5)2]\nProof: Var(X)=E[X2]\u2212E[X]2\nIt is much easier to compute variance using E[X2]\u2212E[X]2. You certainly don't need to know why its an\nequivalent expression, but in case you were wondering, here is the proof.\n1\nThis is a header Var(X)=E[(X\u2013\u00b5)2] Note: \u03bc=E[X]\n=\u2211(x\u2212\u03bc)2P(x) DefinitionofExpectation\nx\n=\u2211(x2\u22122\u03bcx+\u03bc2)P(x) Expandingthesquare\nx\n=\u2211x2P(x)\u22122\u03bc\u2211xP(x)+\u03bc2\u2211P(x) Propagatingthesum\nx x x\n=\u2211x2P(x)\u22122\u03bcE[X]+\u03bc2\u2211P(x) Substitutedefofexpectation\nx x\n=E[X2]\u22122\u03bcE[X]+\u03bc2\u2211P(x) LOTUS g(x)=x2\nx\n=E[X2]\u22122\u03bcE[X]+\u03bc2 Since \u2211P(x)=1\nx\n=E[X2]\u22122E[X]2+E[X]2 Since \u03bc=E[X]\n=E[X2]\u2212E[X]2 Cancelation\nStandard Deviation\nVariance is especially useful for comparing the \"spread\" of two distributions and it has the useful\nproperty that it is easy to calculate. In general a larger variance means that there is more deviation around\nthe mean \u2014 more spread. However, if you look at the leading example, the units of variance are the\nsquare of points. This makes it hard to interpret the numerical value. What does it mean that the spread is\n52 points2? A more interpretable measure of spread is the square root of Variance, which we call the\nStandard Deviation Std(X)=\u221aVar(X). The standard deviation of our grader is 7.2 points. In this\nexample folks find it easier to think of spread in points rather than points2. As an aside, the standard\ndeviation is the average distance of a sample (from the distribution) to the mean, using the euclidean\ndistance function.\nVariance with Continuous Random Variables\nLater in the course reader we will learn about continuous random variables. Variance for those types of\nrandom variables is very similar. See Continuos Random Variables for details.\n2\nThis is a header\nBernoulli Distribution\nParametric Random Variables\nThere are many classic and commonly-seen random variable abstractions that show up in the world of\nprobability. At this point in the class, you will learn about several of the most significant parametric\ndiscrete distributions. When solving problems, if you can recognize that a random variable fits one of\nthese formats, then you can use its pre-derived probability mass function (PMF), expectation, variance,\nand other properties. Random variables of this sort are called parametric random variables. If you can\nargue that a random variable falls under one of the studied parametric types, you simply need to provide\nparameters. A good analogy is a class in programming. Creating a parametric random variable is very\nsimilar to calling a constructor with input parameters.\nBernoulli Random Variables\nA Bernoulli random variable (also called a boolean or indicator random variable) is the simplest kind of\nparametric random variable. It can take on two values, 1 and 0. It takes on a 1 if an experiment with\nprobability p resulted in success and a 0 otherwise. Some example uses include a coin flip, a random\nbinary digit, whether a disk drive crashed, and whether someone likes a Netflix movie. Here p is the\nparameter, but different instances of Bernoulli random variables might have different values of p.\nHere is a full description of the key properties of a Bernoulli random variable. If X is declared to be a\nBernoulli random variable with parameter p, denoted X\u223cBern(p):\nBernoulli Random Variable\nNotation: X\u223cBern(p)\nDescription: A boolean variable that is 1 with probability p\nParameters: p, the probability that X=1.\nSupport: x is either 0 or 1\np if x=1\nPMF equation: P(X=x)={ 1\u2212p if x=0\nPMF (smooth): P(X=x)=px(1\u2212p)1\u2212x\nExpectation: E[X]=p\nVariance: Var(X)=p(1\u2212p)\nPMF graph:\nParameter p: 0.80\n1\nThis is a header\nBecause Bernoulli distributed random variables are parametric, as soon as you declare a random variable\nto be of type Bernoulli you automatically can know all of these pre-derived properties! Some of these\nproperties are straightforward to prove for a Bernoulli. For example, you could have solved for\nexpectation:\nProof: Expectation of a Bernoulli. If X is a Bernoulli with parameter p, X\u223cBern(p):\nE[X]=\u2211x\u22c5P(X=x) Definitionofexpectation\nx\n=1\u22c5p+0\u22c5(1\u2212p) X cantakeonvalues0and1\n=p Removethe0term\nProof: Variance of a Bernoulli. If X is a Bernoulli with parameter p, X\u223cBern(p):\nTo compute variance, first compute E[X2]:\nE[X2]=\u2211x2\u22c5P(X=x) LOTUS\nx\n=02\u22c5(1\u2212p)+12\u22c5p\n=p\nVar(X)=E[X2]\u2212E[X]2 Defofvariance\n=p\u2212p2 Substitute E[X2]=p,E[X]=p\n=p(1\u2212p) Factorout p\nIndicator Random Variable\nDefinition: Indicator Random Variable\nAn indicator variable is a Bernoulli random variable which takes on the value 1 if an underlying event\noccurs, and 0 otherwise.\nIndicator random variables are a convenient way to convert the \"true/false\" outcome of an event into a\nnumber. That number may be easier to incoporate into an equation. See the binomial expectation\nderivation for an example.\nA random variable I is an indicator variable for an event A if I =1 when A occurs and I =0 if A does\nnot occur. Indicator random variables are Bernoulli random variables, with p=P(A). I is a common\nchoice of name for an indicator random variable.\nHere are some properties of indicator random variables: P(I =1)=P(A) and E[I]=P(A).\n2\nThis is a header\nBinomial Distribution\nIn this section, we will discuss the binomial distribution. To start, imagine the following example.\nConsider n independent trials of an experiment where each trial is a \"success\" with probability p. Let X\nbe the number of successes in n trials. This situation is truly common in the natural world, and as such,\nthere has been a lot of research into such phenomena. Random variables like X are called binomial\nrandom variables. If you can identify that a process fits this description, you can inherit many already\nproved properties such as the PMF formula, expectation, and variance!\nHere are a few examples of binomial random variables:\n# of heads in n coin flips\n# of 1\u2019s in randomly generated length n bit string\n# of disk drives crashed in 1000 computer cluster, assuming disks crash independently\nBinomial Random Variable\nNotation: X\u223cBin(n,p)\nDescription: Number of \"successes\" in n identical, independent experiments each with\nprobability of success p.\nParameters: n\u2208{0,1,\u2026}, the number of experiments.\np\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{0,1,\u2026,n}\nn\nPMF equation: P(X=x)=( )px(1\u2212p)n\u2212x\nx\nExpectation: E[X]=n\u22c5p\nVariance: Var(X)=n\u22c5p\u22c5(1\u2212p)\nPMF graph:\nParameter n: 20 Parameter p: 0.60\n1\nThis is a header\nOne way to think of the binomial is as the sum of n Bernoulli variables. Say that Y i\u223cBern(p) is an\nindicator Bernoulli random variable which is 1 if experiment i is a success. Then if X is the total number\nof successes in n experiments, X\u223cBin(n,p):\nn\nX=\u2211Y\ni\ni=1\nRecall that the outcome of Y i will be 1 or 0, so one way to think of X is as the sum of those 1s and 0s.\nBinomial PMF\nThe most important property to know about a binomial is its PMF function:\nRecall, we derived this formula in Part 1. There is a complete example on the probability of k heads in n\ncoin flips, where each flip is heads with probability 0.5: Many Coin Flips. To briefly review, if you think\nof each experiment as being distinct, then there are (n) ways of permuting k successes from n\nk\nexperiments. For any of the mutually exclusive permutations, the probability of that permutation is\npk\u22c5(1\u2212p)n\u2212k.\nThe name binomial comes from the term\n(n)\nwhich is formally called the binomial coefficient.\nk\nExpectation of Binomial\nThere is an easy way to calculate the expectation of a binomial and a hard way. The easy way is to\nleverage the fact that a binomial is the sum of Bernoulli indicator random variables. X=\u2211n i=1Y i where\nY 1 is an indicator of whether the ith experiment was a success: Y i\u223cBern(p). Since the expectation of\nthe sum of random variables is the sum of expectations, we can add the expectation, E[Y i]=p, of each\nof the Bernoulli's:\nn n\nE[X]=E[\u2211Y] Since X=\u2211Y\ni i\ni=1 i=1\nn\n=\u2211E[Y] Expectationofsum\ni\ni=1\nn\n=\u2211p ExpectationofBernoulli\ni=1\n=n\u22c5p Sum n times\nThe hard way is to use the definition of expectation:\nn\nE[X]=\u2211i\u22c5P(X=i) Defofexpectation\ni=0\nn n\n=\u2211i\u22c5( )pi(1\u2212p)n\u2212i SubinPMF\ni\ni=0\n\u22ef Manystepslater\n=n\u22c5p\nBinomial Distribution in Python\nAs you might expect, you can use binomial distributions in code. The standardized library for binomials\nis scipy.stats.binom.\n2\nThis is a header\nOne of the most helpful methods that this package provides is a way to calculate the PMF. For example,\nsay X\u223cBin(n=5,p=0.6) and you want to find P(X=2) you could use the following code:\nfrom scipy import stats\n# define variables for x, n, and p\nn = 5\np = 0.6\nx = 2\n# use scipy to compute the pmf\np_x = stats.binom.pmf(x, n, p)\n# use the probability for future work\nprint(f'P(X = {x}) = {p_x}')\nConsole:\nP(X = 2) = 0.2304\nAnother particularly helpful function is the ability to generate a random sample from a binomial. For\nexample, say X\u223cBin(n=10,p=0.3) represents the number of requests to a website. We can draw\n100 samples from this distribution using the following code:\nfrom scipy import stats\n# define variables for x, n, and p\nn = 10\np = 0.3\nx = 2\n# use scipy to compute the pmf\nsamples = stats.binom.rvs(n, p, size=100)\n# use the probability for future work\nprint(samples)\nConsole:\n[4 5 3 1 4 5 3 1 4 6 5 6 1 2 1 1 2 3 2 5 2 2 2 4 4 2 2 3 6 3 1 1 4 2 6 2 4\n2 3 3 4 2 4 2 4 5 0 1 4 3 4 3 3 1 3 1 1 2 2 2 2 3 5 3 3 3 2 1 3 2 1 2 3 3\n4 5 1 3 7 1 4 1 3 3 4 4 1 2 4 4 0 2 4 3 2 3 3 1 1 4]\nYou might be wondering what a random sample is! A random sample is a randomly chosen assignment\nfor our random variable. Above we have 100 such assignments. The probability that value x is chosen is\ngiven by the PMF: P(X=x). You will notice that even though 8 is a possible assignment to the\nbinomial above, in 100 samples we never saw the value 8. Why? Because P(X=8)\u22480.0014. You\nwould need to draw 1,000 samples before you would expect to see an 8.\nThere are also functions for getting the mean, the variance, and more. You can read the scipy.stats.binom\ndocumentation, especially the list of methods.\n3\nThis is a header\nPoisson Distribution\nA Poisson random variable gives the probability of a given number of events in a fixed interval of time\n(or space). It makes the Poisson assumption that events occur with a known constant mean rate and\nindependently of the time since the last event.\nPoisson Random Variable\nNotation: X\u223cPoi(\u03bb)\nDescription: Number of events in a fixed time frame if (a) the events occur with a constant mean\nrate and (b) they occur independently of time since last event.\nParameters: \u03bb\u2208R+, the constant average rate.\nSupport: x\u2208{0,1,\u2026}\n\u03bbxe\u2212\u03bb\nPMF equation: P(X=x)=\nx!\nExpectation: E[X]=\u03bb\nVariance: Var(X)=\u03bb\nPMF graph:\nParameter \u03bb: 5\nPoisson Intuition\nIn this section we show the intuition behind the Poisson derivation. It is both a great way to deeply\nunderstand the Poisson, as well as good practice with Binomial distributions.\nLet's work on the problem of predicting the chance of a given number of events occurring in a fixed time\ninterval \u2014 the next minute. For example, imagine you are working on a ride sharing application and you\ncare about the probability of how many requests you get from a particular area. From historical data, you\nknow that the average requests per minute is \u03bb=5. What is the probability of getting 1, 2, 3, etc requests\nin a minute?\n\uf0eb: We could approximate a solution to this problem by using a binomial distribution! Lets say we split\nour minute into 60 seconds, and make each second an indicator Bernoulli variable \u2014 you either get a\nrequest or you don't. If you get a request in a second, the indicator is 1. Otherwise it is 0. Here is a\nvisualization of our 60 binary-indicators. In this example imagine we have requests at 2.75 and 7.12\nseconds. the corresponding indicator variables are blue filled in boxes:\n1 minute\n1\nThis is a header\n\u00b7\u00b7\u00b7\nThe total number of requests received over the minute can be approximated as the sum of the sixty\nindicator variables, which conveniently matches the description of a binomial \u2014 a sum of Bernoullis.\nSpecifically define X to be the number of requests in a minute. X is a binomial with n=60 trials. What\nis the probability, p, of a success on a single trial? To make the expectation of X equal the observed\nhistorical average \u03bb=5 we should choose p so that \u03bb=E[X].\n\u03bb=E[X] Expectationmatcheshistoricalaverage\n\u03bb=n\u22c5p ExpectationofaBinomialis n\u22c5p\n\u03bb\np= Solvingfor p\nn\nIn this case since \u03bb=5 and n=60, we should choose p=5/60 and state that\nX\u223cBin(n=60,p=5/60). Now that we have a form for X we can answer probability questions about\nthe number of requests by using the Binomial PMF:\nn\nP(X=x)=( )px(1\u2212p)n\u2212x\nx\nSo for example:\n60\nP(X=1)=( )(5/60)1(55/60)60\u22121\u22480.0295\n1\n60\nP(X=2)=( )(5/60)2(55/60)60\u22122\u22480.0790\n2\n60\nP(X=3)=( )(5/60)3(55/60)60\u22123\u22480.1389\n3\nGreat! But don't forget that this was an approximation. We didn't account for the fact that there can be more\nthan one event in a single second. One way to assuage this issue is to divide our minute into more fine-\ngrained intervals (the choice to split it into 60 seconds was rather arbitrary). Instead lets divide our minute\ninto 600 deciseconds, again with requests at 2.75 and 7.12 seconds:\n1 minute\n\u00b7\u00b7\u00b7\nNow n=600, p=5/600 and X\u223cBin(n=600,p=6/600). We can repeat our example calculations\nusing this better approximation:\n600\nP(X=1)=( )(5/600)1(595/60)600\u22121\u22480.0333\n1\n600\nP(X=2)=( )(5/600)2(595/600)600\u22122\u22480.0837\n2\n600\nP(X=3)=( )(5/600)3(595/600)600\u22123\u22480.1402\n3\nChoose any value of n, the number of buckets to divide our minute into: 0\nThe larger n is, the more accurate the approximation. So what happens when n is infinity? It becomes a\nPoisson!\nPoisson, a Binomial in the limit\nOr if we really cared about making sure that we don't get two events in the same bucket, we can divide\nour minute into infinitely small buckets:\n2\nThis is a header\n1 minute\nProof: Derivation of the Poisson\nWhat does the PMF of X look like now that we have infinite divisions of our minute? We can write the\nequation and think about it as n goes to infinity. Recall that p still equals \u03bb/n:\nn\nP(X=x)= lim ( )(\u03bb/n)x(1\u2212\u03bb/n)n\u2212x\nn\u2192\u221e x\nWhile it may look intimidating, this expression simplifies nicely. This proof uses a few special limit rules\nthat we haven't introduced in this book:\nn\nP(X=x)= lim ( )(\u03bb/n)x(1\u2212\u03bb/n)n\u2212x Start:binomialinthelimit\nn\u2192\u221e x\nn \u03bbx (1\u2212\u03bb/n)n\n= lim ( )\u22c5 \u22c5 Expandingthepowerterms\nn\u2192\u221e x nx (1\u2212\u03bb/n)x\nn! \u03bbx (1\u2212\u03bb/n)n\n= lim \u22c5 \u22c5 Expandingthebinomialterm\nn\u2192\u221e (n\u2212x)!x! nx (1\u2212\u03bb/n)x\nn! \u03bbx e\u2212\u03bb\n= lim \u22c5 \u22c5 Rule lim(1\u2212\u03bb/n)n=e\u2212\u03bb\nn\u2192\u221e (n\u2212x)!x! nx (1\u2212\u03bb/n)x n\u2192\u221e\nn! \u03bbx e\u2212\u03bb\n= lim \u22c5 \u22c5 Rule lim \u03bb/n=0\nn\u2192\u221e (n\u2212x)!x! nx 1 n\u2192\u221e\nn! 1 \u03bbx e\u2212\u03bb\n= lim \u22c5 \u22c5 \u22c5 Splittingfirstterm\nn\u2192\u221e (n\u2212x)! x! nx 1\nnx 1 \u03bbx e\u2212\u03bb n!\n= lim \u22c5 \u22c5 \u22c5 lim =nx\nn\u2192\u221e 1 x! nx 1 n\u2192\u221e (n\u2212x)!\n\u03bbx e\u2212\u03bb\n= lim \u22c5 Cancel nx\nn\u2192\u221e x! 1\n\u03bbx\u22c5e\u2212\u03bb\n= Simplify\nx!\nThat is a beautiful expression! Now we can calculate the real probability of number of requests in a\nminute, if the historical average is \u03bb=5:\n51\u22c5e\u22125\nP(X=1)= =0.03369\n1!\n52\u22c5e\u22125\nP(X=2)= =0.08422\n2!\n53\u22c5e\u22125\nP(X=3)= =0.14037\n3!\nThis is both more accurate and much easier to compute!\nChanging time frames\nSay you are given a rate over one unit of time, but you want to know the rate in another unit of time. For\nexample, you may be given the rate of hits to a website per minute, but you want to know the probability\nover a 20 minute period. You would just need to multiply this rate by 20 in order to go from the \"per 1\nminute of time\" rate to obtain the \"per 20 minutes of time\" rate.\n3\nThis is a header\nMore Discrete Distributions\nStub: Chapter coming soon!\nGeometric Random Variable\nNotation: X\u223cGeo(p)\nDescription: Number of experiments until a success. Assumes independent experiments each\nwith probability of success p.\nParameters: p\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{1,\u2026,\u221e}\nP(X=x)=(1\u2212p)x\u22121p\nPMF equation:\nExpectation: E[X]= 1\np\nVariance: Var(X)= 1\u2212p\np2\nPMF graph:\nParameter p: 0.20\n1\nThis is a header\nNegative Binomial Random Variable\nNotation: X\u223cNegBin(r,p)\nDescription: Number of experiments until r successes. Assumes each experiment is independent\nwith probability of success p.\nParameters: r>0, the number of success we are waiting for.\np\u2208[0,1], the probability that a single experiment gives a \"success\".\nSupport: x\u2208{r,\u2026,\u221e}\nx\u22121\nPMF equation: P(X=x)=( )pr(1\u2212p)x\u2212r\nr\u22121\nExpectation: E[X]= r\np\nVariance: Var(X)= r\u22c5(1\u2212p)\np2\nPMF graph:\nParameter r: 3 Parameter p: 0.20\n2\nThis is a header\nCategorical Distributions\nThe Categorical Distribution is a fancy name for random variables which takes on values other than\nnumbers. As an example, imagine a random variable for the weather today. A natural representation for\nthe weather is one of a few categories: {sunny, cloudy, rainy, snowy}. Unlike in past examples, these\nvalues are not integers or real valued numbers! Are we allowed to continue? Sure! We can represent this\nrandom variable as X where X is a categorical random variable.\nThere isn't much that you need to know about Categorical distributions. They work the way you might\nexpect. To provide the Probability Mass Function (PMF) for a categorical random variable, you just need\nto provide the probability of each category. For example, if X is the weather today, then the PMF should\nassociate all the values that X could take on, with the probability that X takes on those values. Here is an\nexample PMF for the weather Categorical:\nWeather Value Probability\nSunny P(X=Sunny)=0.49\nCloudy P(X=Cloudy)=0.30\nRainy P(X=Rainy)=0.20\nRainy P(X=Snowy)=0.01\nNotice that the probabilities must sum to 1.0. This is because (in this version) the weather must be one of\nthe four categories. Since the values are not numeric, this random variable will not have an expectation\n(values are not numbers) variance nor a PMF expressed as a function, as opposed to a table.\nNote to your future self: A categorical distribution is a simplified version of a multinomial distribution\n(where the number of outcomes is 1)\n1\nThis is a header\nContinuous Distribution\nSo far, all random variables we have seen have been discrete. In all the cases we have seen in CS109 this\nmeant that our RVs could only take on integer values. Now it's time for continuous random variables\nwhich can take on values in the real number domain (R). Continuous random variables can be used to\nrepresent measurements with arbitrary precision (eg height, weight, time).\nFrom Discrete to Continuous\nTo make our transition from thinking about discrete random variables, to thinking about continuous\nrandom variables, lets start with a thought experiment: Imagine you are running to catch the bus. You\nknow that you will arrive at 2:15pm but you don't know exactly when the bus will arrive, and want to\nthink of the arrival time in minutes past 2pm as a random variable T so that you can calculate the\nprobability that you will have to wait more than five minutes P(15<T <20).\nWe immediately face a problem. For discrete distributions we would describe the probability that a\nrandom variable takes on exact values. This doesn't make sense for continuous values, like the time the\nbus arrives. As an example, what is the probability that the bus arrives at exactly 2:17pm and\n12.12333911102389234 seconds? Similarly, if I were to ask you: what is the probability of a child being\nborn with weight exactly equal to 3.523112342234 kilos, you might recognize that question as ridiculous.\nNo child will have precisely that weight. Real values can have infinite precision and as such it is a bit\nmind boggling to think about the probability that a random variable takes on a specific value.\nInstead, let's start by discretizing time, our continuous variable, by breaking it into 5 minute chunks. We\ncan now think about something like, the probability that the bus arrives between 2:00p and 2:05 as an\nevent with some probability (see figure below on the left). Five minute chunks seem a bit coarse. You\ncould imagine that instead, we could have discretized time into 2.5 minute chunks (figure in the center).\nIn this case the probability that the bus shows up between 15 mins and 20 mins after 2pm is the sum of\ntwo chunks, shown in orange. Why stop there? In the limit we could keep breaking time down into\nsmaller and smaller pieces. Eventually we will be left with a derivative of probability at each moment of\ntime, where the probability that P(15<T <20) is the integral of that derivative between 15 and 20\n(figure on the right).\nProbability Density Functions\nIn the world of discrete random variables, the most important property of a random variable was its\nprobability mass function (PMF) that would tell you the probability of the random variable taking on any\nvalue. When we move to the world of continuous random variables, we are going to need to rethink this\nbasic concept. In the continuous world, every random variable instead has a Probability Density Function\n(PDF) which defines the relative likelihood that a random variable takes on a particular value. We\ntraditionally use the symbol f for the probability density function and write it in one of two ways:\nf(X=x) or f(x)\nWhere the notation on the right hand side is shorthand and the lowercase x implies that we are talking\nabout the relative likelihood of a continuous random variable which is the upper case X. Like in the bus\nexample, the PDF is the derivative of probability at all points of the random variable. This means that the\n1\nThis is a header\nPDF has the important property that you can integrate over it to find the probability that the random\nvariable takes on values within a range (a,b).\nDefinition: Continuous Random Variable\nX is a Continuous Random Variable if there is a Probability Density Function (PDF) f(x) that takes in\nreal valued numbers x such that:\nb\nP(a\u2264X\u2264b)=\u222b f(x)dx\na\nThe following properties must also hold. These preserve the axiom that P(a\u2264X\u2264b) is a probability:\n0\u2264P(a\u2264X\u2264b)\u22641\nP(\u2212\u221e<X<\u221e)=1\nA common misconception is to think of f(x) as a probability. It is instead what we call a probability\ndensity. It represents probability/unit of X. Generally this is only meaningful when we either take an\nintegral over the PDF or we compare probability densities. As we mentioned when motivating\nprobability densities, the probability that a continuous random variable takes on a specific value (to\ninfinite precision) is 0.\na\nP(X=a)=\u222b f(x)dx=0\na\nThat is pretty different than in the discrete world where we often talked about the probability of a random\nvariable taking on a particular value.\nCumulative Distribution Function\nHaving a probability density is great, but it means we are going to have to solve an integral every single\ntime we want to calculate a probability. To avoid this unfortunate fate, we are going to use a standard\ncalled a cumulative distribution function (CDF). The CDF is a function which takes in a number and\nreturns the probability that a random variable takes on a value less than that number. It has the pleasant\nproperty that, if we have a CDF for a random variable, we don't need to integrate to answer probability\nquestions!\nFor a continuous random variable X the Cumulative Distribution Function, written F(x) is:\nx\nF(x)=P(X\u2264x)=\u222b f(x)dx\n\u2212\u221e\nWhy is the CDF the probability that a random variable takes on a value less than the input value as\nopposed to greater than? It is a matter of convention. But it is a useful convention. Most probability\nquestions can be solved simply by knowing the CDF (and taking advantage of the fact that the integral\nover the range \u2212\u221e to \u221e is 1. Here are a few examples of how you can answer probability questions by\njust using a CDF:\nProbabilityQuery Solution Explanation\nP(X<a) F(a) ThatisthedefinitionoftheCDF\nP(X\u2264a) F(a) Trickquestion. P(X=a)=0\nP(X>a) 1\u2212F(a) P(X<a)+P(X>a)=1\nP(a<X<b) F(b)\u2212F(a) F(a)+P(a<X<b)=F(b)\nThe continuous distribution also exists for discrete random variables, but there is less utility to a CDF in\nthe discrete world as none of our discrete random variables had \"closed form\" (eg without any\nsummation) functions for the CDF:\na\nF (a)=\u2211P(X=i)\nX\ni=1\n2\n\u2223\n\u2223\nThis is a header\nSolving for Constants\nLet X be a continuous random variable with PDF:\nC(4x\u22122x2) when 0<x<2\nf(x)={\n0 otherwise\nIn this function, C is a constant. What value is C? Since we know that the PDF must sum to 1:\n2\n\u222b C(4x\u22122x2)dx=1\n0\n2x3 2\nC(2x2\u2212 ) =1\n3\n0\n16\nC((8\u2212 )\u22120)=1\n3\nC=3/8\nNow that we know C, what is P(X>1)?\n\u221e\nP(X>1)=\u222b f(x)dx\n1\n2 3\n=\u222b (4x\u22122x2)dx\n8\n1\n3 2x3 2\n= (2x2\u2212 )\n8 3\n1\n3 16 2 1\n= [(8\u2212 )\u2212(2\u2212 )]=\n8 3 3 2\nExpectation and Variance of Continuous Variables\nFor continuous RV X:\n\u221e\nE[X]=\u222b xf(x)dx\n\u2212\u221e\n\u221e\nE[g(X)]=\u222b g(x)f(x)dx\n\u2212\u221e\n\u221e\nE[Xn]=\u222b xnf(x)dx\n\u2212\u221e\nFor both continuous and discrete RVs:\nE[aX+b]=aE[X]+b\nVar(X)=E[(X\u2212\u03bc)2]=E[X2]\u2212(E[X])2\nVar(aX+b)=a2Var(X)\n3\n\u23aa\n\u23aa\nThis is a header\nUniform Distribution\nThe most basic of all the continuous random variables is the uniform random variable, which is equally\nlikely to take on any value in its range (\u03b1,\u03b2). X is a uniform random variable (X\u223cUni(\u03b1,\u03b2)) if it has\nPDF:\n1 when \u03b1\u2264x\u2264\u03b2\nf(x)={\u03b2\u2212\u03b1\n0 otherwise\nNotice how the density 1/(\u03b2\u2212\u03b1) is exactly the same regardless of the value for x. That makes the\ndensity uniform. So why is the PDF 1/(\u03b2\u2212\u03b1) and not 1? That is the constant that makes it such that the\nintegral over all possible inputs evaluates to 1.\nUniform Random Variable\nNotation: X\u223cUni(\u03b1,\u03b2)\nDescription: A continuous random variable that takes on values, with equal likelihood, between\n\u03b1 and \u03b2\nParameters: \u03b1\u2208R, the minimum value of the variable.\n\u03b2\u2208R, \u03b2>\u03b1, the maximum value of the variable.\nSupport: x\u2208[\u03b1,\u03b2]\n1 for x\u2208[\u03b1,\u03b2]\nPDF equation: f(x)={\u03b2\u2212\u03b1\n0 else\n\u23a7x\u2212\u03b1 for x\u2208[\u03b1,\u03b2]\nCDF equation: \u03b2\u2212\u03b1\nF(x)=\u23a80 for x<\u03b1\n\u23a9\n1 for x>\u03b2\nExpectation: E[X]= 1(\u03b1+\u03b2)\n2\nVariance: Var(X)= 1 (\u03b2\u2212\u03b1)2\n12\nPDF graph:\nParameter \u03b1: 0 Parameter \u03b2: 1\nExample: You are running to the bus stop. You don\u2019t know exactly when the bus arrives. You believe all\ntimes between 2 and 2:30 are equally likely. You show up at 2:15pm. What is P(wait < 5 minutes)?\nLet T be the time, in minutes after 2pm that the bus arrives. Because we think that all times are equally\nlikely in this range, T \u223cUni(\u03b1=0,\u03b2=30). The probability that you wait 5 minutes is equal to the\nprobability that the bus shows up between 2:15 and 2:20. In other words P(15<T <20):\n1\n\u2223\nThis is a header P(Waitunder5mins)=P(15<T <20)\n20\n=\u222b f (x)\u2202x\nT\n15\n20 1\n=\u222b \u2202x\n\u03b2\u2212\u03b1\n15\n1\n= \u2202x\n30\nx 20\n=\n30\n15\n20 15 5\n= \u2212 =\n30 30 30\nWe can come up with a closed form for the probability that a uniform random variable X is in the range a\nto b, assuming that \u03b1\u2264a\u2264b\u2264\u03b2:\nb\nP(a\u2264X\u2264b)=\u222b f(x)dx\na\nb 1\n=\u222b dx\n\u03b2\u2212\u03b1\na\nb\u2212a\n=\n\u03b2\u2212\u03b1\n2\nThis is a header\nExponential Distribution\nAn exponential distribution measures the amount of time until a next event occurs. It assumes that the\nevents occur via a poisson process. Note that this is different from the Poisson Random Variable which\nmeasures number of events in a fixed amount of time.\nExponential Random Variable\nNotation: X\u223cExp(\u03bb)\nDescription: Time until next events if (a) the events occur with a constant mean rate and (b) they\noccur independently of time since last event.\nParameters: \u03bb\u2208R+, the constant average rate.\nSupport: x\u2208R+\nPDF equation:\nf(x)=\u03bbe\u2212\u03bbx\nCDF equation:\nF(x)=1\u2212e\u2212\u03bbx\nExpectation: E[X]=1/\u03bb\nVariance: Var(X)=1/\u03bb2\nPDF graph:\nParameter \u03bb: 5\nAn exponential distribution is a great example of a continuous distribution where the cumulative\ndistribution function (CDF) is much easier to work with as it allows you to answer probability questions\nwithout using integrals.\nExample: Based on historical data from the USGS, earthquakes of magnitude 8.0+ happen in a certain\nlocation at a rate of 0.002 per year. Earthquakes are known to occur via a poisson process. What is the\nprobability of a major earthquake in the next 4 years?\nLet Y be the years until the next major earthquake. Because Y measures time until the next event it fits\nthe description of an exponential random variable: Y \u223cExp(\u03bb=0.002). The question is asking, what is\nP(Y <4)?\nP(Y <4)=F (4) TheCDFmeasures P(Y <y)\nY\n=1\u2212e\u2212\u03bb\u22c5y TheCDFofanExp\n=1\u2212e\u22120.002\u22c54 TheCDFofanExp\n\u22480.008\nNote that it is possible to answer this question using the PDF, but it will require solving an integral.\n1\nThis is a header\nExponential is Memoryless\nOne way to gain intuition for what is meant by the \"poisson process\" is through the proof that the\nexponential distribution is \"memoryless\". That means that the occurrence (or lack of occurrence) of\nevents in the past does not change our belief as to how long until the next occurrence. This can be stated\nformally. If X\u223cExp(\u03bb) then for an interval of time until the start s, and a proceeding, query, interval of\ntime t:\nP(X>s+t|X>s)=P(X>t)\nWhich is something we can prove:\nP(X>s+tandX>s)\nP(X>s+t|X>s)= Defofconditionalprob.\nP(X>s)\nP(X>s+t)\n= Because X>s+t implies X>s\nP(X>s)\n1\u2212F (s+t)\n= X DefofCDF\n1\u2212F (s)\nX\ne\u2212\u03bb(s+t)\n= ByCDFofExp\ne\u2212\u03bbs\n=e\u2212\u03bbt Simplify\n=1\u2212F (t) ByCDFofExp\nX\n=P(X>t) DefofCDF\n2\nThis is a header\nNormal Distribution\nThe single most important random variable type is the Normal (aka Gaussian) random variable,\nparametrized by a mean (\u03bc) and variance (\u03c32), or sometimes equivalently written as mean and variance (\n\u03c32). If X is a normal variable we write X\u223cN(\u03bc,\u03c32). The normal is important for many reasons: it is\ngenerated from the summation of independent random variables and as a result it occurs often in nature.\nMany things in the world are not distributed normally but data scientists and computer scientists model\nthem as Normal distributions anyways. Why? Because it is the most entropic (conservative) modelling\ndecision that we can make for a random variable while still matching a particular expectation (average\nvalue) and variance (spread).\nThe Probability Density Function (PDF) for a Normal X\u223cN(\u03bc,\u03c32) is:\nf X(x)= 1 e\u2212(x 2\u03c3\u2212 2\u03bc)2\n\u03c3\u221a2\u03c0\nNotice the x in the exponent of the PDF function. When x is equal to the mean (\u03bc) then e is raised to the\npower of 0 and the PDF is maximized.\nBy definition a Normal has E[X]=\u03bc and Var(X)=\u03c32.\nThere is no closed form for the integral of the Normal PDF, and as such there is no closed form CDF.\nHowever we can use a transformation of any normal to a normal with a precomputed CDF. The result of\nthis mathematical gymnastics is that the CDF for a Normal X\u223cN(\u03bc,\u03c32) is:\nx\u2212\u03bc\nF (x)=\u03a6( )\nX \u03c3\nWhere \u03a6 is a precomputed function that represents that CDF of the Standard Normal.\n1\nThis is a header\nNormal (aka Gaussian) Random Variable\nNotation: X\u223cN(\u03bc,\u03c32)\nDescription: A common, naturally occurring distribution.\nParameters: \u03bc\u2208R, the mean.\n\u03c32\u2208R, the variance.\nSupport: x\u2208R\nPDF equation: f(x)= 1 e\u22121 2(x\u2212 \u03c3\u03bc)2\n\u03c3\u221a2\u03c0\nx\u2212\u03bc\nCDF equation: F(x)=\u03d5( ) Where \u03d5 istheCDFofthestandardnormal\n\u03c3\nExpectation: E[X]=\u03bc\nVariance: Var(X)=\u03c32\nPDF graph:\nParameter \u03bc: 5 Parameter \u03c3: 5\nLinear Transform\nIf X is a Normal such that X\u223cN(\u03bc,\u03c32) and Y is a linear transform of X such that Y =aX+b then Y\nis also a Normal where:\nY \u223cN(a\u03bc+b,a2\u03c32)\nProjection to Standard Normal\nFor any Normal X we can find a linear transform from X to the standard normal Z\u223cN(0,1). Note that\nZ is the typical notation choice for the standard normal. For any normal, if you subtract the mean (\u03bc) of\nthe normal and divide by the standard deviation (\u03c3) the result is always the standard normal. We can\nprove this mathematically. Let W = X\u2212\u03bc :\n\u03c3\nX\u2212\u03bc\nW = TransformX:Subtractby \u03bc anddivingby \u03c3\n\u03c3\n1 \u03bc\n= X\u2212 Usealgebratorewritetheequation\n\u03c3 \u03c3\n1 \u03bc\n=aX+b Lineartransformwhere a= , b=\u2212\n\u03c3 \u03c3\n\u223cN(a\u03bc+b,a2\u03c32) ThelineartransformofaNormalisanotherNormal\n\u03bc \u03bc \u03c32\n\u223cN( \u2212 , ) Substitutingvaluesinfor a and b\n\u03c3 \u03c3 \u03c32\n\u223cN(0,1) Thestandardnormal\nUsing this transform we can express F X(x), the CDF of X, in terms of the known CDF of Z, F Z(x).\nSince the CDF of Z is so common it gets its own Greek symbol: \u03a6(x)\n2\nThis is a header F (x)=P(X\u2264x)\nX\nX\u2212\u03bc x\u2212\u03bc\n=P( \u2264 )\n\u03c3 \u03c3\nx\u2212\u03bc\n=P(Z\u2264 )\n\u03c3\nx\u2212\u03bc\n=\u03a6( )\n\u03c3\nThe values of \u03a6(x) can be looked up in a table. Every modern programming language also has the ability\nto calculate the CDF of a normal random variable!\nExample: Let X\u223cN(3,16), what is P(X>0)?\nX\u22123 0\u22123 3 3\nP(X>0)=P( > )=P(Z>\u2212 )=1\u2212P(Z\u2264\u2212 )\n4 4 4 4\n3 3 3\n=1\u2212\u03a6(\u2212 )=1\u2212(1\u2212\u03a6( ))=\u03a6( )=0.7734\n4 4 4\nWhat is P(2<X<5)?\n2\u22123 X\u22123 5\u22123 1 2\nP(2<X<5)=P( < < )=P(\u2212 <Z< )\n4 4 4 4 4\n2 1 1 1\n=\u03a6( )\u2212\u03a6(\u2212 )=\u03a6( )\u2212(1\u2212\u03a6( ))=0.2902\n4 4 2 4\nExample: You send voltage of 2 or -2 on a wire to denote 1 or 0. Let X = voltage sent and let R = voltage\nreceived. R=X+Y, where Y \u223cN(0,1) is noise. When decoding, if R\u22650.5 we interpret the voltage\nas 1, else 0. What is P(errorafterdecoding|originalbit=1)?\nP(X+Y <0.5)=P(2+Y <0.5)\n=P(Y <\u22121.5)\n=\u03a6(\u22121.5)\n\u22480.0668\nExample: The 67% rule of a normal within one standard deviation. What is the probability that a normal\nvariable X\u223cN(\u03bc,\u03c3) has a value within one standard deviation of its mean?\nP(Withinone \u03c3 of \u03bc)=P(\u03bc\u2212\u03c3<X<\u03bc+\u03c3)\n=P(X<\u03bc+\u03c3)\u2212P(X<\u03bc\u2212\u03c3) Probofarange\n(\u03bc+\u03c3)\u2212\u03bc (\u03bc\u2212\u03c3)\u2212\u03bc\n=\u03a6( )\u2212\u03a6( ) CDFofNormal\n\u03c3 \u03c3\n\u03c3 \u2212\u03c3\n=\u03a6( )\u2212\u03a6( ) Cancel \u03bcs\n\u03c3 \u03c3\n=\u03a6(1)\u2212\u03a6(\u22121) Cancel \u03c3s\n\u22480.8413\u22120.1587\u22480.683 Pluginto \u03a6\nWe made no assumption about the value of \u03bc or the value of \u03c3 so this will apply to every single normal\nrandom variable. Since it uses the Normal CDF this doesn't apply to other types of random variables.\nCDF Calculator\nTo calculate the Cumulative Density Function (CDF) for a normal (aka Gaussian) random variable at a\nvalue x, also writen as F(x), you can transform your distribution to the \"standard normal\" and look up\nthe corresponding value in the standard normal CDF. However, most programming libraries will provide\na normal cdf funciton:\n3\nThis is a header\nNorm CDF Calculator\nx 0.0\nmu 0\nstd 1\nnorm.cdf(x, mu, std)\nIn python you can calculate these values using the scipy library\nfrom scipy import stats\n# get the input values\nmean = 1.0\nstd_dev = 0.5\nquery = 0.1 # aka x\n# calc the CDF in two lines\nX = stats.norm(mean, std_dev)\np = X.cdf(query)\n# calc the CDF in one line\np = stats.norm.cdf(query, mean, std_dev)\nIt is important to note that in the python library, the second parameter for the Normal distribution is standard\ndeviation not variance, as it is typically defined in math notation. Recall that standard deviation is the\nsquare root of variance.\n4\nThis is a header\nBinomial Approximation\nThere are times when it is exceptionally hard to numerically calculate probabilities for a binomial\ndistribution, especially when n is large. For example, say X\u223cBin(n=10000,p=0.5) and you want\nto calculate P(X>5500). The correct formula is:\n10000\nP(X>55)= \u2211 P(X=x)\ni=5500\n10000 10000\n= \u2211 ( )pi(1\u2212p)10000\u2212i\ni\ni=5500\nThat is a difficult value to calculate. Luckily there is an easier way. For deep reasons which we will cover\nin our section on \"uncertainty theory\" it turns out that a binomial distribution can be very well\napproximated by both Normal distributions and Poisson distributions if n is large enough.\nUse the Poisson approximation when n is large (>20) and p is small (<0.05). A slight dependence\nbetween results of each experiment is ok\nUse the Normal approximation when n is large (>20), and p is mid-ranged. Specifically it's considered an\naccurate approximation when the variance is greater then 10, in other words: np(1\u2212p)>10. There are\nsituations where either a Poisson or a Normal can be used to approximate a Binomial. In that situation go\nwith the Normal!\nPoisson Approximation\nWhen defining the Poisson we proved that a Binomial in the limit as n\u2192\u221e and p=\u03bb/n is a Poisson.\nThat same logic can be used to show that a Poisson is a great approximation for a Binomial when the\nBinomial has extreme values of n and p. A Poisson random variable approximates Binomial where n is\nlarge, p is small, and \u03bb=np is \u201cmoderate\u201d. Interestingly, to calculate the things we care about (PMF,\nexpectation, variance) we no longer need to know n and p. We only need to provide \u03bb which we call the\nrate. When approximating a Poisson with a Binomial, always choose \u03bb=n\u22c5p.\nThere are different interpretations of \"moderate\". The accepted ranges are n>20 and p<0.05 or\nn>100 and p<0.1.\nLet's say you want to send a bit string of length n=104 where each bit is independently corrupted with\np=10\u22126. What is the probability that the message will arrive uncorrupted? You can solve this using a\nPoisson with \u03bb=np=10410\u22126=0.01. Semantically, \u03bb=0.01 means that we expect 0.01 corrupt bits\nper string, assuming bits are continuous. Let X\u223cPoi(0.01) be the number of corrupted bits. Using the\nPMF for Poisson:\n\u03bbi\nP(X=0)= e\u2212\u03bb\ni!\n0.010\n= e\u22120.01\n0!\n\u223c0.9900498\nWe could have also modelled X as a binomial such that X\u223cBin(104,10\u22126). That would have been\nimpossible to calculate on a computer but would have resulted in the same number (up to the millionth\ndecimal).\nNormal Approximation\nFor a Binomial where n is large and p is mid-ranged, a Normal can be used to approximate the Binomial.\nLet's take a side by side view of a normal and a binomial:\n1\nThis is a header\nLets say our binomial is a random variable X\u223cBin(100,0.5) and we want to calculate P(X\u226555). We\ncould cheat by using the closest fit normal (in this case Y \u223cN(50,25)). How did we choose that\nparticular Normal? Simply select one with a mean and variance that matches the Binomial expectation\nand variance. The binomial expectation is np=100\u22c50.5=50. The Binomial variance is\nnp(1\u2212p)=100\u22c50.5\u22c50.5=25.\nYou can use a Normal distribution to approximate a Binomial X\u223cBin(n,p). To do so define a normal\nY \u223c(E[X],Var(X)). Using the Binomial formulas for expectation and variance, Y \u223c(np,np(1\u2212p)).\nThis approximation holds for large n and moderate p. That gets you very close. However since a Normal\nis continuous and Binomial is discrete we have to use a continuity correction to discretize the Normal.\n1 1 k\u2212np+0.5 k\u2212np\u22120.5\nP(X=k)\u223cP(k\u2212 <Y <k+ )=\u03a6( )\u2212\u03a6( )\n2 2 \u221anp(1\u2212p) \u221anp(1\u2212p)\nYou should get comfortable deciding what continuity correction to use. Here are a few examples of discrete\nprobability questions and the continuity correction:\nDiscrete(Binomial)probabilityquestion Equivalentcontinuousprobabilityquestion\nP(X=6) P(5.5<X<6.5)\nP(X\u22656) P(X>5.5)\nP(X>6) P(X>6.5)\nP(X<6) P(X<5.5)\nP(X\u22646) P(X<6.5)\n2\nThis is a header\nExample: 100 visitors to your website are given a new design. Let X = # of people who were given the\nnew design and spend more time on your website. Your CEO will endorse the new design if X\u226565.\nWhat is P(CEOendorseschange|ithasnoeffect)?\nE[X]=np=50. Var(X)=np(1\u2212p)=25. \u03c3=\u221aVar(X)=5. We can thus use a Normal\napproximation: Y \u223cN(\u03bc=50,\u03c32=25).\nY \u221250 64.5\u221250\nP(X\u226565)\u2248P(Y >64.5)=P( > )=1\u2212\u03a6(2.9)=0.0019\n5 5\nExample: Stanford accepts 2480 students and each student has a 68% chance of attending. Let X = #\nstudents who will attend. X\u223cBin(2480,0.68). What is P(X>1745)?\nE[X]=np=1686.4. Var(X)=np(1\u2212p)=539.7. \u03c3=\u221aVar(X)=23.23. We can thus use a\nNormal approximation: Y \u223cN(\u03bc=1686.4,\u03c32=539.7).\nP(X>1745)\u2248P(Y >1745.5)\nY \u22121686.4 1745.5\u22121686.4\n\u2248P( > )\n23.23 23.23\n\u22481\u2212\u03a6(2.54)=0.0055\n3\nThis is a header\n100 Binomial Problems\nJust for fun (and to give you a lot of practice) I wrote a generative probabilistic program which could\nsample binomial distribution problems. Here are 100 binomial questions:\nQuestions\nQuestion 1: Laura is running a server cluster with 50 computers. The probability of a crash on a given\nserver is 0.5. What is the standard deviation of crashes?\nAnswer 1:\nLet X be the number of crashes. X\u223cBin(n=50,p=0.5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a50\u22c50.5\u22c5(1\u22120.5)\n=3.54\nQuestion 2: You are showing an online-ad to 30 people. The probability of an ad ignore on each ad\nshown is 2/3. What is the expected number of ad clicks?\nAnswer 2:\nLet X be the number of ad clicks. X\u223cBin(n=30,p=1/3)\nE[X]=np\n=30\u22c51/3\n=10\nQuestion 3: A machine learning algorithm makes binary predictions. The machine learning algorithm\nmakes 50 guesses where the probability of a incorrect prediction on a given guess is 19/25. What is the\nprobability that the number of correct predictions is greater than 0?\nAnswer 3:\nLet X be the number of correct predictions. X\u223cBin(n=50,p=6/25)\nP(X>0)=1\u2212P(0<=X<=0)\nn\n=1\u2212( )p0(1\u2212p)n\u22120\n0\nQuestion 4: Wind blows independently across 50 locations. The probability of no wind at a given\nlocation is 0.5. What is the expected number of locations that have wind?\nAnswer 4:\nLet X be the number of locations that have wind. X\u223cBin(n=50,p=0.5)\nE[X]=np\n=50\u22c50.5\n=25.0\nQuestion 5: Wind blows independently across 30 locations. What is the standard deviation of locations\nthat have wind? the probability of wind at each location is 0.6.\n1\nThis is a header\nAnswer 5:\nLet X be the number of locations that have wind. X\u223cBin(n=30,p=0.6)\nStd(X)=\u221anp(1\u2212p)\n=\u221a30\u22c50.6\u22c5(1\u22120.6)\n=2.68\nQuestion 6: You are trying to mine bitcoins. There are 50 independent attempts where the probability of a\nmining a bitcoin on a given attempt is 0.6. What is the expectation of bitcoins mined?\nAnswer 6:\nLet X be the number of bitcoins mined. X\u223cBin(n=50,p=0.6)\nE[X]=np\n=50\u22c50.6\n=30.0\nQuestion 7: You are testing a new medicine on 40 patients. What is P(X is exactly 38)? The number of\ncured patients can be represented by a random variable X. X ~ Bin(40, 3/10).\nAnswer 7:\nLet X be the number of cured patients. X\u223cBin(n=40,p=3/10)\nn\nP(X=38)=( )p38(1\u2212p)n\u221238\n38\n40\n=( )3/1038(1\u22123/10)40\u221238\n38\n<0.00001\nQuestion 8: You are manufacturing chips and are testing for defects. There are 50 independent tests and\n0.5 is the probability of a defect on each test. What is the standard deviation of defects?\nAnswer 8:\nLet X be the number of defects. X\u223cBin(n=50,p=0.5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a50\u22c50.5\u22c5(1\u22120.5)\n=3.54\nQuestion 9: Laura is flipping a coin 12 times. The probability of a tail on a given coin-flip is 5/12. What\nis the probability that the number of tails is greater than or equal to 2?\nAnswer 9:\nLet X be the number of tails. X\u223cBin(n=12,p=5/12)\nP(X>=2)=1\u2212P(0<=X<=1)\n1 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=0\nQuestion 10: You are asking a survey question where responses are \"like\" or \"dislike\". There are 30\nresponses. You can assume each response is independent where the probability of a dislike on a given\nresponse is 1/6. What is the probability that the number of likes is greater than 28?\n2\nThis is a header\nAnswer 10:\nLet X be the number of likes. X\u223cBin(n=30,p=5/6)\nP(X>28)=P(29<=X<=30)\n30 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=29\nQuestion 11: A ball hits a series of 50 pins where it can bounce either right or left. The probability of a\nleft on a given pin hit is 0.4. What is the standard deviation of rights?\nAnswer 11:\nLet X be the number of rights. X\u223cBin(n=50,p=3/5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a50\u22c53/5\u22c5(1\u22123/5)\n=3.46\nQuestion 12: You are sending a stream of 30 bits to space. The probability of a no corruption on a given\nbit is 1/3. What is the probability that the number of corruptions is 10?\nAnswer 12:\nLet X be the number of corruptions. X\u223cBin(n=30,p=2/3)\nn\nP(X=10)=( )p10(1\u2212p)n\u221210\n10\n30\n=( )2/310(1\u22122/3)30\u221210\n10\n=0.00015\nQuestion 13: Wind blows independently across locations. The probability of wind at a given location is\n0.9. The number of independent locations is 20. What is the probability that the number of locations that\nhave wind is not less than 19?\nAnswer 13:\nLet X be the number of locations that have wind. X\u223cBin(n=20,p=0.9)\nP(X>=19)=P(19<=X<=20)\n20 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=19\nQuestion 14: You are sending a stream of bits to space. There are 30 independent bits where 5/6 is the\nprobability of a no corruption on each bit. What is the probability that the number of corruptions is 21?\nAnswer 14:\nLet X be the number of corruptions. X\u223cBin(n=30,p=1/6)\nn\nP(X=21)=( )p21(1\u2212p)n\u221221\n21\n30\n=( )1/621(1\u22121/6)30\u221221\n21\n<0.00001\nQuestion 15: Cody generates random bit strings. There are 20 independent bits. Each bit has a 1/4\nprobability of resulting in a 1. What is the probability that the number of 1s is 11?\n3\nThis is a header\nAnswer 15:\nLet X be the number of 1s. X\u223cBin(n=20,p=1/4)\nn\nP(X=11)=( )p11(1\u2212p)n\u221211\n11\n20\n=( )1/411(1\u22121/4)20\u221211\n11\n=0.00301\nQuestion 16: In a restaurant some customers ask for a water with their meal. A random sample of 40\ncustomers is selected where the probability of a water requested by a given customer is 9/20. What is the\nprobability that the number of waters requested is 16?\nAnswer 16:\nLet X be the number of waters requested. X\u223cBin(n=40,p=9/20)\nn\nP(X=16)=( )p16(1\u2212p)n\u221216\n16\n40\n=( )9/2016(1\u22129/20)40\u221216\n16\n=0.10433\nQuestion 17: A student is guessing randomly on an exam with 12 questions. What is the expected\nnumber of correct answers? the probability of a correct answer on a given question is 5/12.\nAnswer 17:\nLet X be the number of correct answers. X\u223cBin(n=12,p=5/12)\nE[X]=np\n=12\u22c55/12\n=5\nQuestion 18: Laura is trying to mine bitcoins. The number of bitcoins mined can be represented by a\nrandom variable X. X ~ Bin(n = 100, p = 1/2). What is P(X is equal to 53)?\nAnswer 18:\nLet X be the number of bitcoins mined. X\u223cBin(n=100,p=1/2)\nn\nP(X=53)=( )p53(1\u2212p)n\u221253\n53\n100\n=( )1/253(1\u22121/2)100\u221253\n53\n=0.06659\nQuestion 19: You are showing an online-ad to customers. The add is shown to 100 people. The\nprobability of an ad ignore on a given ad shown is 1/2. What is the standard deviation of ad clicks?\nAnswer 19:\nLet X be the number of ad clicks. X\u223cBin(n=100,p=0.5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c50.5\u22c5(1\u22120.5)\n=5.00\n4\nThis is a header\nQuestion 20: You are running a server cluster with 40 computers. 5/8 is the probability of a computer\ncontinuing to work on each server. What is the expected number of crashes?\nAnswer 20:\nLet X be the number of crashes. X\u223cBin(n=40,p=3/8)\nE[X]=np\n=40\u22c53/8\n=15\nQuestion 21: You are hashing 100 strings into a hashtable. The probability of a hash to the first bucket on\na given string hash is 3/20. What is the probability that the number of hashes to the first bucket is greater\nthan or equal to 97?\nAnswer 21:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=100,p=3/20)\nP(X>=97)=P(97<=X<=100)\n100 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=97\nQuestion 22: You are running in an election with 50 voters. 6/25 is the probability of a vote for you on\neach vote. What is the probability that the number of votes for you is less than 2?\nAnswer 22:\nLet X be the number of votes for you. X\u223cBin(n=50,p=6/25)\nP(X<2)=P(0<=X<=1)\n1 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=0\nQuestion 23: Irina is sending a stream of 40 bits to space. The probability of a corruption on each bit is\n3/4. What is the probability that the number of corruptions is 22?\nAnswer 23:\nLet X be the number of corruptions. X\u223cBin(n=40,p=3/4)\nn\nP(X=22)=( )p22(1\u2212p)n\u221222\n22\n40\n=( )3/422(1\u22123/4)40\u221222\n22\n=0.00294\nQuestion 24: You are hashing 100 strings into a hashtable. The probability of a hash to the first bucket on\na given string hash is 9/50. What is the probability that the number of hashes to the first bucket is greater\nthan 97?\nAnswer 24:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=100,p=9/50)\nP(X>97)=P(98<=X<=100)\n100 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=98\nQuestion 25: You generate random bit strings. There are 100 independent bits. The probability of a 1 at a\ngiven bit is 3/25. What is the probability that the number of 1s is less than 97?\n5\nThis is a header\nAnswer 25:\nLet X be the number of 1s. X\u223cBin(n=100,p=3/25)\nP(X<97)=1\u2212P(97<=X<=100)\n100 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=97\nQuestion 26: You are manufacturing toys and are testing for defects. What is the probability that the\nnumber of defects is greater than 1? the probability of a non-defect on a given test is 16/25 and you test\n50 objects.\nAnswer 26:\nLet X be the number of defects. X\u223cBin(n=50,p=9/25)\nP(X>1)=1\u2212P(0<=X<=1)\n1 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=0\nQuestion 27: Laura is sending a stream of 40 bits to space. The number of corruptions can be represented\nby a random variable X. X is a Binomial with n = 40 and p = 3/4. What is P(X = 25)?\nAnswer 27:\nLet X be the number of corruptions. X\u223cBin(n=40,p=3/4)\nn\nP(X=25)=( )p25(1\u2212p)n\u221225\n25\n40\n=( )3/425(1\u22123/4)40\u221225\n25\n=0.02819\nQuestion 28: 100 trials are run. What is the probability that the number of successes is 78? 1/2 is the\nprobability of a success on each trial.\nAnswer 28:\nLet X be the number of successes. X\u223cBin(n=100,p=1/2)\nn\nP(X=78)=( )p78(1\u2212p)n\u221278\n78\n100\n=( )1/278(1\u22121/2)100\u221278\n78\n<0.00001\nQuestion 29: You are flipping a coin. You flip the coin 20 times. The probability of a tail on a given coin-\nflip is 1/10. What is the standard deviation of heads?\nAnswer 29:\nLet X be the number of heads. X\u223cBin(n=20,p=0.9)\nStd(X)=\u221anp(1\u2212p)\n=\u221a20\u22c50.9\u22c5(1\u22120.9)\n=1.34\nQuestion 30: Irina is showing an online-ad to 12 people. 5/12 is the probability of an ad click on each ad\nshown. What is the probability that the number of ad clicks is less than or equal to 11?\n6\nThis is a header\nAnswer 30:\nLet X be the number of ad clicks. X\u223cBin(n=12,p=5/12)\nP(X<=11)=1\u2212P(12<=X<=12)\nn\n=1\u2212( )p12(1\u2212p)n\u221212\n12\nQuestion 31: You are flipping a coin 50 times. 19/25 is the probability of a head on each coin-flip. What\nis the standard deviation of tails?\nAnswer 31:\nLet X be the number of tails. X\u223cBin(n=50,p=6/25)\nStd(X)=\u221anp(1\u2212p)\n=\u221a50\u22c56/25\u22c5(1\u22126/25)\n=3.02\nQuestion 32: You are running in an election with 100 voters. The probability of a vote for you on each\nvote is 1/4. What is the probability that the number of votes for you is less than or equal to 97?\nAnswer 32:\nLet X be the number of votes for you. X\u223cBin(n=100,p=1/4)\nP(X<=97)=1\u2212P(98<=X<=100)\n100 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=98\nQuestion 33: You are running a server cluster with 40 computers. What is the probability that the number\nof crashes is less than or equal to 39? 3/4 is the probability of a computer continuing to work on each\nserver.\nAnswer 33:\nLet X be the number of crashes. X\u223cBin(n=40,p=1/4)\nP(X<=39)=1\u2212P(40<=X<=40)\nn\n=1\u2212( )p40(1\u2212p)n\u221240\n40\nQuestion 34: Waddie is sending a stream of bits to space. Waddie sends 100 bits. The probability of a\ncorruption on each bit is 1/2. What is the standard deviation of corruptions?\nAnswer 34:\nLet X be the number of corruptions. X\u223cBin(n=100,p=1/2)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c51/2\u22c5(1\u22121/2)\n=5.00\nQuestion 35: A student is guessing randomly on an exam with 100 questions. Each question has a 0.5\nprobability of resulting in a incorrect answer. What is the probability that the number of correct answers\nis greater than 97?\n7\nThis is a header\nAnswer 35:\nLet X be the number of correct answers. X\u223cBin(n=100,p=1/2)\nP(X>97)=P(98<=X<=100)\n100 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=98\nQuestion 36: You are testing a new medicine on patients. 0.5 is the probability of a cured patient on each\ntrial. There are 10 independent trials. What is the expected number of cured patients?\nAnswer 36:\nLet X be the number of cured patients. X\u223cBin(n=10,p=0.5)\nE[X]=np\n=10\u22c50.5\n=5.0\nQuestion 37: A ball hits a series of pins where it can either go right or left. The number of independent\npin hits is 100. The probability of a right on each pin hit is 0.5. What is the standard deviation of rights?\nAnswer 37:\nLet X be the number of rights. X\u223cBin(n=100,p=0.5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c50.5\u22c5(1\u22120.5)\n=5.00\nQuestion 38: You are flipping a coin 40 times. The probability of a head on a given coin-flip is 1/2. What\nis the probability that the number of heads is 38?\nAnswer 38:\nLet X be the number of heads. X\u223cBin(n=40,p=1/2)\nn\nP(X=38)=( )p38(1\u2212p)n\u221238\n38\n40\n=( )1/238(1\u22121/2)40\u221238\n38\n<0.00001\nQuestion 39: 100 trials are run and the probability of a success on a given trial is 1/2. What is the\nstandard deviation of successes?\nAnswer 39:\nLet X be the number of successes. X\u223cBin(n=100,p=1/2)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c51/2\u22c5(1\u22121/2)\n=5.00\nQuestion 40: You are trying to mine bitcoins. There are 40 independent attempts. The probability of a\nmining a bitcoin on each attempt is 3/10. What is the probability that the number of bitcoins mined is 19?\n8\nThis is a header\nAnswer 40:\nLet X be the number of bitcoins mined. X\u223cBin(n=40,p=3/10)\nn\nP(X=19)=( )p19(1\u2212p)n\u221219\n19\n40\n=( )3/1019(1\u22123/10)40\u221219\n19\n=0.00852\nQuestion 41: 20 trials are run. 0.5 is the probability of a failure on each trial. What is the probability that\nthe number of successes is 6?\nAnswer 41:\nLet X be the number of successes. X\u223cBin(n=20,p=0.5)\nn\nP(X=6)=( )p6(1\u2212p)n\u22126\n6\n20\n=( )0.56(1\u22120.5)20\u22126\n6\n=0.03696\nQuestion 42: You are flipping a coin. What is the probability that the number of tails is 0? there are 30\nindependent coin-flips where the probability of a head on a given coin-flip is 5/6.\nAnswer 42:\nLet X be the number of tails. X\u223cBin(n=30,p=1/6)\nn\nP(X=0)=( )p0(1\u2212p)n\u22120\n0\n30\n=( )1/60(1\u22121/6)30\u22120\n0\n=0.00421\nQuestion 43: In a restaurant some customers ask for a water with their meal. A random sample of 20\ncustomers is selected and each customer has a 1/4 probability of resulting in a water not requested. What\nis the probability that the number of waters requested is 14?\nAnswer 43:\nLet X be the number of waters requested. X\u223cBin(n=20,p=3/4)\nn\nP(X=14)=( )p14(1\u2212p)n\u221214\n14\n20\n=( )3/414(1\u22123/4)20\u221214\n14\n=0.16861\nQuestion 44: A student is guessing randomly on an exam. 3/8 is the probability of a incorrect answer on\neach question. The number of independent questions is 40. What is the probability that the number of\ncorrect answers is less than or equal to 37?\nAnswer 44:\nLet X be the number of correct answers. X\u223cBin(n=40,p=5/8)\nP(X<=37)=1\u2212P(38<=X<=40)\n40 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=38\n9\nThis is a header\nQuestion 45: You are running in an election with 30 voters. 3/5 is the probability of a vote for you on\neach vote. What is the standard deviation of votes for you?\nAnswer 45:\nLet X be the number of votes for you. X\u223cBin(n=30,p=3/5)\nStd(X)=\u221anp(1\u2212p)\n=\u221a30\u22c53/5\u22c5(1\u22123/5)\n=2.68\nQuestion 46: Charlotte is flipping a coin 100 times. The probability of a tail on each coin-flip is 0.5.\nWhat is the probability that the number of tails is greater than 2?\nAnswer 46:\nLet X be the number of tails. X\u223cBin(n=100,p=0.5)\nP(X>2)=1\u2212P(0<=X<=2)\n2 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=0\nQuestion 47: You are trying to mine bitcoins. You try 50 times. 3/5 is the probability of a not mining a\nbitcoin on each attempt. What is the probability that the number of bitcoins mined is 14?\nAnswer 47:\nLet X be the number of bitcoins mined. X\u223cBin(n=50,p=2/5)\nn\nP(X=14)=( )p14(1\u2212p)n\u221214\n14\n50\n=( )2/514(1\u22122/5)50\u221214\n14\n=0.02597\nQuestion 48: You are testing a new medicine on 100 patients. The probability of a cured patient on a\ngiven trial is 3/25. What is the probability that the number of cured patients is not less than 97?\nAnswer 48:\nLet X be the number of cured patients. X\u223cBin(n=100,p=3/25)\nP(X>=97)=P(97<=X<=100)\n100 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=97\nQuestion 49: Wind blows independently across 40 locations. What is the probability that the number of\nlocations that have wind is 40? 11/20 is the probability of no wind at each location.\nAnswer 49:\nLet X be the number of locations that have wind. X\u223cBin(n=40,p=9/20)\nn\nP(X=40)=( )p40(1\u2212p)n\u221240\n40\n40\n=( )9/2040(1\u22129/20)40\u221240\n40\n<0.00001\n10\nThis is a header\nQuestion 50: You are showing an online-ad to 30 people. 1/6 is the probability of an ad click on each ad\nshown. What is the probability that the number of ad clicks is less than or equal to 28?\nAnswer 50:\nLet X be the number of ad clicks. X\u223cBin(n=30,p=1/6)\nP(X<=28)=1\u2212P(29<=X<=30)\n30 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=29\nQuestion 51: You are flipping a coin. You flip the coin 40 times and 7/8 is the probability of a head on\neach coin-flip. What is the standard deviation of tails?\nAnswer 51:\nLet X be the number of tails. X\u223cBin(n=40,p=1/8)\nStd(X)=\u221anp(1\u2212p)\n=\u221a40\u22c51/8\u22c5(1\u22121/8)\n=2.09\nQuestion 52: Cody is sending a stream of bits to space. 2/5 is the probability of a no corruption on each\nbit and there are 20 independent bits. What is the expectation of corruptions?\nAnswer 52:\nLet X be the number of corruptions. X\u223cBin(n=20,p=3/5)\nE[X]=np\n=20\u22c53/5\n=12\nQuestion 53: You are running in an election. There are 12 independent votes and 5/6 is the probability of\na vote for you on each vote. What is the probability that the number of votes for you is greater than or\nequal to 9?\nAnswer 53:\nLet X be the number of votes for you. X\u223cBin(n=12,p=5/6)\nP(X>=9)=P(9<=X<=12)\n12 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=9\nQuestion 54: You are flipping a coin. The number of tails can be represented by a random variable X. X\nis a Bin(n = 30, p = 5/6). What is the probability that X = 1?\nAnswer 54:\nLet X be the number of tails. X\u223cBin(n=30,p=5/6)\nn\nP(X=1)=( )p1(1\u2212p)n\u22121\n1\n30\n=( )5/61(1\u22125/6)30\u22121\n1\n<0.00001\n11\nThis is a header\nQuestion 55: In a restaurant some customers ask for a water with their meal. A random sample of 100\ncustomers is selected where 0.3 is the probability of a water requested by each customer. What is the\nexpected number of waters requested?\nAnswer 55:\nLet X be the number of waters requested. X\u223cBin(n=100,p=0.3)\nE[X]=np\n=100\u22c50.3\n=30.0\nQuestion 56: You are hashing strings into a hashtable. 30 strings are hashed. The probability of a hash to\nthe first bucket on each string hash is 1/6. What is the expected number of hashes to the first bucket?\nAnswer 56:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=30,p=1/6)\nE[X]=np\n=30\u22c51/6\n=5\nQuestion 57: You are flipping a coin 100 times. What is the probability that the number of tails is greater\nthan or equal to 98? 19/20 is the probability of a head on each coin-flip.\nAnswer 57:\nLet X be the number of tails. X\u223cBin(n=100,p=1/20)\nP(X>=98)=P(98<=X<=100)\n100 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=98\nQuestion 58: Irina is running a server cluster. What is the probability that the number of crashes is less\nthan 99? the server has 100 computers which crash independently and the probability of a computer\ncontinuing to work on a given server is 22/25.\nAnswer 58:\nLet X be the number of crashes. X\u223cBin(n=100,p=3/25)\nP(X<99)=1\u2212P(99<=X<=100)\n100 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=99\nQuestion 59: You are manufacturing chairs and are testing for defects. You test 100 objects. 1/2 is the\nprobability of a non-defect on each test. What is the probability that the number of defects is not greater\nthan 97?\nAnswer 59:\nLet X be the number of defects. X\u223cBin(n=100,p=1/2)\nP(X<=97)=1\u2212P(98<=X<=100)\n100 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=98\nQuestion 60: In a restaurant some customers ask for a water with their meal. There are 50 customers. You\ncan assume each customer is independent. 0.2 is the probability of a water requested by each customer.\nWhat is the expected number of waters requested?\n12\nThis is a header\nAnswer 60:\nLet X be the number of waters requested. X\u223cBin(n=50,p=0.2)\nE[X]=np\n=50\u22c50.2\n=10.0\nQuestion 61: You are showing an online-ad to 40 people. 1/4 is the probability of an ad ignore on each ad\nshown. What is the probability that the number of ad clicks is 9?\nAnswer 61:\nLet X be the number of ad clicks. X\u223cBin(n=40,p=3/4)\nn\nP(X=9)=( )p9(1\u2212p)n\u22129\n9\n40\n=( )3/49(1\u22123/4)40\u22129\n9\n<0.00001\nQuestion 62: 100 trials are run. Each trial has a 22/25 probability of resulting in a failure. What is the\nstandard deviation of successes?\nAnswer 62:\nLet X be the number of successes. X\u223cBin(n=100,p=3/25)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c53/25\u22c5(1\u22123/25)\n=3.25\nQuestion 63: A machine learning algorithm makes binary predictions. There are 12 independent guesses\nwhere the probability of a incorrect prediction on a given guess is 1/6. What is the expected number of\ncorrect predictions?\nAnswer 63:\nLet X be the number of correct predictions. X\u223cBin(n=12,p=5/6)\nE[X]=np\n=12\u22c55/6\n=10\nQuestion 64: Waddie is showing an online-ad to customers. 1/2 is the probability of an ad click on each\nad shown. The add is shown to 100 people. What is the average number of ad clicks?\nAnswer 64:\nLet X be the number of ad clicks. X\u223cBin(n=100,p=1/2)\nE[X]=np\n=100\u22c51/2\n=50\nQuestion 65: Charlotte is testing a new medicine on 50 patients. The probability of a cured patient on a\ngiven trial is 1/5. What is the probability that the number of cured patients is 12?\n13\nThis is a header\nAnswer 65:\nLet X be the number of cured patients. X\u223cBin(n=50,p=1/5)\nn\nP(X=12)=( )p12(1\u2212p)n\u221212\n12\n50\n=( )1/512(1\u22121/5)50\u221212\n12\n=0.10328\nQuestion 66: You are running in an election. The number of votes for you can be represented by a\nrandom variable X. X is a Bin(n = 50, p = 0.4). What is P(X is exactly 8)?\nAnswer 66:\nLet X be the number of votes for you. X\u223cBin(n=50,p=0.4)\nn\nP(X=8)=( )p8(1\u2212p)n\u22128\n8\n50\n=( )0.48(1\u22120.4)50\u22128\n8\n=0.00017\nQuestion 67: Irina is flipping a coin 100 times. The probability of a head on a given coin-flip is 1/2.\nWhat is the probability that the number of tails is less than or equal to 99?\nAnswer 67:\nLet X be the number of tails. X\u223cBin(n=100,p=0.5)\nP(X<=99)=1\u2212P(100<=X<=100)\nn\n=1\u2212( )p100(1\u2212p)n\u2212100\n100\nQuestion 68: You are manufacturing airplanes and are testing for defects. You test 30 objects and the\nprobability of a defect on a given test is 5/6. What is the probability that the number of defects is 14?\nAnswer 68:\nLet X be the number of defects. X\u223cBin(n=30,p=5/6)\nn\nP(X=14)=( )p14(1\u2212p)n\u221214\n14\n30\n=( )5/614(1\u22125/6)30\u221214\n14\n<0.00001\nQuestion 69: You are flipping a coin 20 times. The number of heads can be represented by a random\nvariable X. X is a Binomial with 20 trials. Each trial is a success, independently, with probability 1/4.\nWhat is the standard deviation of X?\nAnswer 69:\nLet X be the number of heads. X\u223cBin(n=20,p=1/4)\nStd(X)=\u221anp(1\u2212p)\n=\u221a20\u22c51/4\u22c5(1\u22121/4)\n=1.94\n14\nThis is a header\nQuestion 70: You are giving a survey question where responses are \"like\" or \"dislike\" to 100 people.\nWhat is the probability that X is equal to 4? The number of likes can be represented by a random variable\nX. X is a Bin(100, 0.5).\nAnswer 70:\nLet X be the number of likes. X\u223cBin(n=100,p=0.5)\nn\nP(X=4)=( )p4(1\u2212p)n\u22124\n4\n100\n=( )0.54(1\u22120.5)100\u22124\n4\n<0.00001\nQuestion 71: You are flipping a coin. There are 20 independent coin-flips where the probability of a tail\non a given coin-flip is 0.9. What is the standard deviation of tails?\nAnswer 71:\nLet X be the number of tails. X\u223cBin(n=20,p=0.9)\nStd(X)=\u221anp(1\u2212p)\n=\u221a20\u22c50.9\u22c5(1\u22120.9)\n=1.34\nQuestion 72: You are flipping a coin. There are 50 independent coin-flips. The probability of a tail on a\ngiven coin-flip is 4/5. What is the expectation of heads?\nAnswer 72:\nLet X be the number of heads. X\u223cBin(n=50,p=1/5)\nE[X]=np\n=50\u22c51/5\n=10\nQuestion 73: You are giving a survey question where responses are \"like\" or \"dislike\" to 100 people.\nWhat is the standard deviation of likes? the probability of a dislike on each response is 41/50.\nAnswer 73:\nLet X be the number of likes. X\u223cBin(n=100,p=9/50)\nStd(X)=\u221anp(1\u2212p)\n=\u221a100\u22c59/50\u22c5(1\u22129/50)\n=3.84\nQuestion 74: In a restaurant some customers ask for a water with their meal. 0.6 is the probability of a\nwater requested by each customer and there are 30 independent customers. What is the expected number\nof waters requested?\nAnswer 74:\nLet X be the number of waters requested. X\u223cBin(n=30,p=0.6)\nE[X]=np\n=30\u22c50.6\n=18.0\n15\nThis is a header\nQuestion 75: There are 40 independent trials and 0.5 is the probability of a failure on each trial. What is\nthe expectation of successes?\nAnswer 75:\nLet X be the number of successes. X\u223cBin(n=40,p=1/2)\nE[X]=np\n=40\u22c51/2\n=20\nQuestion 76: Imran is showing an online-ad to 30 people. 5/6 is the probability of an ad click on each ad\nshown. What is the standard deviation of ad clicks?\nAnswer 76:\nLet X be the number of ad clicks. X\u223cBin(n=30,p=5/6)\nStd(X)=\u221anp(1\u2212p)\n=\u221a30\u22c55/6\u22c5(1\u22125/6)\n=2.04\nQuestion 77: You are running a server cluster. What is the probability that the number of crashes is 1? the\nserver has 30 computers which crash independently and each server has a 1/3 probability of resulting in a\ncrash.\nAnswer 77:\nLet X be the number of crashes. X\u223cBin(n=30,p=1/3)\nn\nP(X=1)=( )p1(1\u2212p)n\u22121\n1\n30\n=( )1/31(1\u22121/3)30\u22121\n1\n=0.00008\nQuestion 78: Cody is running a server cluster with 40 computers. What is P(X <= 39)? The number of\ncrashes can be represented by a random variable X. X is a Bin(n = 40, p = 3/4).\nAnswer 78:\nLet X be the number of crashes. X\u223cBin(n=40,p=3/4)\nP(X<=39)=1\u2212P(40<=X<=40)\nn\n=1\u2212( )p40(1\u2212p)n\u221240\n40\nQuestion 79: You are hashing strings into a hashtable. 5/6 is the probability of a hash to the first bucket\non each string hash. There are 30 independent string hashes. What is the probability that the number of\nhashes to the first bucket is greater than or equal to 29?\nAnswer 79:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=30,p=5/6)\nP(X>=29)=P(29<=X<=30)\n30 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=29\n16\nThis is a header\nQuestion 80: Irina is flipping a coin. Irina flips the coin 30 times and the probability of a head on each\ncoin-flip is 0.4. What is the probability that the number of tails is 19?\nAnswer 80:\nLet X be the number of tails. X\u223cBin(n=30,p=0.6)\nn\nP(X=19)=( )p19(1\u2212p)n\u221219\n19\n30\n=( )0.619(1\u22120.6)30\u221219\n19\n=0.13962\nQuestion 81: You are asking a survey question where responses are \"like\" or \"dislike\". The probability of\na like on a given response is 1/2. You give the survey to 100 people. What is the probability that the\nnumber of likes is not less than 2?\nAnswer 81:\nLet X be the number of likes. X\u223cBin(n=100,p=1/2)\nP(X>=2)=1\u2212P(0<=X<=1)\n1 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=0\nQuestion 82: Wind blows independently across locations. The number of independent locations is 100.\nThe probability of wind at a given location is 3/20. What is the probability that the number of locations\nthat have wind is 93?\nAnswer 82:\nLet X be the number of locations that have wind. X\u223cBin(n=100,p=3/20)\nn\nP(X=93)=( )p93(1\u2212p)n\u221293\n93\n100\n=( )3/2093(1\u22123/20)100\u221293\n93\n<0.00001\nQuestion 83: You are flipping a coin. 0.9 is the probability of a tail on each coin-flip. You flip the coin 50\ntimes. What is the expected number of heads?\nAnswer 83:\nLet X be the number of heads. X\u223cBin(n=50,p=0.1)\nE[X]=np\n=50\u22c50.1\n=5.0\nQuestion 84: A machine learning algorithm makes binary predictions. What is the probability that the\nnumber of correct predictions is less than or equal to 0? the probability of a incorrect prediction on a\ngiven guess is 1/4. The number of independent guesses is 40.\nAnswer 84:\nLet X be the number of correct predictions. X\u223cBin(n=40,p=3/4)\nP(X<=0)=P(0<=X<=0)\nn\n=( )p0(1\u2212p)n\u22120\n0\n17\nThis is a header\nQuestion 85: Wind blows independently across 20 locations. 1/2 is the probability of wind at each\nlocation. What is the standard deviation of locations that have wind?\nAnswer 85:\nLet X be the number of locations that have wind. X\u223cBin(n=20,p=1/2)\nStd(X)=\u221anp(1\u2212p)\n=\u221a20\u22c51/2\u22c5(1\u22121/2)\n=2.24\nQuestion 86: 7/10 is the probability of a failure on each trial and the number of independent trials is 100.\nWhat is the probability that the number of successes is 7?\nAnswer 86:\nLet X be the number of successes. X\u223cBin(n=100,p=0.3)\nn\nP(X=7)=( )p7(1\u2212p)n\u22127\n7\n100\n=( )0.37(1\u22120.3)100\u22127\n7\n<0.00001\nQuestion 87: You generate random bit strings. What is the expectation of 1s? there are 100 independent\nbits and 0.1 is the probability of a 1 at each bit.\nAnswer 87:\nLet X be the number of 1s. X\u223cBin(n=100,p=0.1)\nE[X]=np\n=100\u22c50.1\n=10.0\nQuestion 88: You are testing a new medicine on patients. 3/5 is the probability of a cured patient on each\ntrial. There are 30 independent trials. What is the probability that the number of cured patients is greater\nthan or equal to 1?\nAnswer 88:\nLet X be the number of cured patients. X\u223cBin(n=30,p=3/5)\nP(X>=1)=1\u2212P(0<=X<=0)\nn\n=1\u2212( )p0(1\u2212p)n\u22120\n0\nQuestion 89: A student is guessing randomly on an exam. 0.9 is the probability of a correct answer on\neach question and the test has 20 questions. What is the standard deviation of correct answers?\nAnswer 89:\nLet X be the number of correct answers. X\u223cBin(n=20,p=0.9)\nStd(X)=\u221anp(1\u2212p)\n=\u221a20\u22c50.9\u22c5(1\u22120.9)\n=1.34\n18\nThis is a header\nQuestion 90: A student is guessing randomly on an exam with 40 questions. What is the probability that\nthe number of correct answers is 32? 0.5 is the probability of a correct answer on each question.\nAnswer 90:\nLet X be the number of correct answers. X\u223cBin(n=40,p=0.5)\nn\nP(X=32)=( )p32(1\u2212p)n\u221232\n32\n40\n=( )0.532(1\u22120.5)40\u221232\n32\n=0.00007\nQuestion 91: In a restaurant some customers ask for a water with their meal. A random sample of 40\ncustomers is selected where the probability of a water not requested by a given customer is 1/4. What is\nthe standard deviation of waters requested?\nAnswer 91:\nLet X be the number of waters requested. X\u223cBin(n=40,p=3/4)\nStd(X)=\u221anp(1\u2212p)\n=\u221a40\u22c53/4\u22c5(1\u22123/4)\n=2.74\nQuestion 92: A machine learning algorithm makes binary predictions. The number of correct predictions\ncan be represented by a random variable X. X is a Bin(n = 30, p = 2/5). What is P(X < 27)?\nAnswer 92:\nLet X be the number of correct predictions. X\u223cBin(n=30,p=2/5)\nP(X<27)=1\u2212P(27<=X<=30)\n30 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=27\nQuestion 93: Irina is flipping a coin. The probability of a tail on each coin-flip is 3/4. The number of\nindependent coin-flips is 40. What is the probability that the number of tails is greater than 0?\nAnswer 93:\nLet X be the number of tails. X\u223cBin(n=40,p=3/4)\nP(X>0)=1\u2212P(0<=X<=0)\nn\n=1\u2212( )p0(1\u2212p)n\u22120\n0\nQuestion 94: Waddie is sending a stream of 50 bits to space. The probability of a no corruption on a\ngiven bit is 1/2. What is the expectation of corruptions?\nAnswer 94:\nLet X be the number of corruptions. X\u223cBin(n=50,p=0.5)\nE[X]=np\n=50\u22c50.5\n=25.0\n19\nThis is a header\nQuestion 95: You are hashing strings into a hashtable. There are 30 independent string hashes where the\nprobability of a hash to the first bucket on each string hash is 5/6. What is the probability that the number\nof hashes to the first bucket is 24?\nAnswer 95:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=30,p=5/6)\nn\nP(X=24)=( )p24(1\u2212p)n\u221224\n24\n30\n=( )5/624(1\u22125/6)30\u221224\n24\n=0.16009\nQuestion 96: Charlotte is hashing strings into a hashtable. 100 strings are hashed and the probability of a\nhash to the first bucket on a given string hash is 1/5. What is the probability that the number of hashes to\nthe first bucket is greater than or equal to 1?\nAnswer 96:\nLet X be the number of hashes to the first bucket. X\u223cBin(n=100,p=1/5)\nP(X>=1)=1\u2212P(0<=X<=0)\nn\n=1\u2212( )p0(1\u2212p)n\u22120\n0\nQuestion 97: You are flipping a coin. Each coin-flip has a 3/10 probability of resulting in a head and\nthere are 100 coin-flips. You can assume each coin-flip is independent. What is the probability that the\nnumber of heads is 0?\nAnswer 97:\nLet X be the number of heads. X\u223cBin(n=100,p=3/10)\nn\nP(X=0)=( )p0(1\u2212p)n\u22120\n0\n100\n=( )3/100(1\u22123/10)100\u22120\n0\n<0.00001\nQuestion 98: Chris is sending a stream of 50 bits to space. 16/25 is the probability of a no corruption on\neach bit. What is the probability that the number of corruptions is greater than or equal to 47?\nAnswer 98:\nLet X be the number of corruptions. X\u223cBin(n=50,p=9/25)\nP(X>=47)=P(47<=X<=50)\n50 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=47\nQuestion 99: You are flipping a coin 30 times. What is the probability that the number of tails is less than\n29? the probability of a tail on a given coin-flip is 2/3.\nAnswer 99:\nLet X be the number of tails. X\u223cBin(n=30,p=2/3)\nP(X<29)=1\u2212P(29<=X<=30)\n30 n\n=1\u2212\u2211( )pi(1\u2212p)n\u2212i\ni\ni=29\n20\nThis is a header\nQuestion 100: You are manufacturing chips and are testing for defects. There are 40 independent tests.\nThe probability of a non-defect on a given test is 5/8. What is the probability that the number of defects is\n10?\nAnswer 100:\nLet X be the number of defects. X\u223cBin(n=40,p=3/8)\nn\nP(X=10)=( )p10(1\u2212p)n\u221210\n10\n40\n=( )3/810(1\u22123/8)40\u221210\n10\n=0.03507\n21\nThis is a header\nWinning the Series\nThe Golden State Warriors are the basketball team for the Bay Area. The Warriors are going to play the\nBucks (another professional basketball team) in a best of 7 series during the next NBA finals. They will\nwin the series if you win at least 4 games. What is the probability that the warriors win the series? Each\ngame is independent. Each game, the warriors have a 0.55 probability of winning.\nThis problem is equivalent to: Flip a biased coin 7 times (with a p=0.55 probability of getting a heads).\nWhat is the probability of at least 4 heads?\nNote: without loss of generality you could imagine that the two teams always play all 7 games, regardless\nof the outcome. Technically they stop playing after one team has achieved 4 wins, because the outcomes\nof the games no longer impact who wins. However, you could imagine that they continue.\nWhat is the probability that the warriors win the series? Leave your answer to 3 decimal places\nA critical step is to define a random variable and to recognize it is a Binomial. Let X be the number of\ngames won. Since each game is independent, X\u223cBin(n=7,p=0.55). The question is asking:\nP(X\u22654)?\nTo answer this question, first recognize that:\nP(X\u22654)=P(X=4)+P(X=5)\n+P(X=6)+P(X=7)\nThis is because the question is asking the probability of the \"or\" of each of the events on the right hand\nside of the equals sign. Since each of these events; X=4, X=5, etc are mutually exclusive, the\nprobability of the \"or\" is simply the sum of the probabilities.\nP(X\u22654)=P(X=4)+P(X=5)\n+P(X=6)+P(X=7)\n7\n=\u2211P(X=i)\ni=4\nEach of these probabilities are PMF questions:\n7\nP(X\u22654)=\u2211P(X=i)\ni=4\n7 n\n=\u2211( )pi(1\u2212p)n\u2212i\ni\ni=4\n7 7\n=\u2211( )0.55i\u22c50.457\u2212i\ni\ni=4\nHere is that equation graphically. It represents the sum of these columns in the PMF:\n1\nThis is a header\nAt this point we have an equation that we can compute in order to find the answer. But how should we\ncompute it? We could do it by hand! Or using a calculator. Or, we can use python, and specifically the\nscipy package:\nfrom scipy import stats\npr = 0\n# calculate the sum\nfor i in range(4, 8):\n# this for loop gives i in [4,5,6,7]\npr_i = stats.binom.pmf(i, n = 7, p = 0.55)\npr += pr_i\nprint(f'P(X >= 4) = {pr}')\nWhich produces the correct answer:\nP(X >= 4) = 0.6082877968750001\nBuggy Solution\nA good reason to study this problem is because of this common misconception for how to compute\nP(X\u22654). It is worth understanding why it is wrong.\nIncorrectly trying to recreate the binomial\nSimilar to how we defined a binomial distribution PMF equation (see: Many Coin Flips) we can\nconstruct outcomes of the seven game series where the warriors win.\nWe are going to choose 4 slots where the Warriors win, and we don't care about the rest. They could\neither be wins or losses. Out of 7 games, select 4 where the Warriors win. There are\n(7)\nways to do so.\n4\nThe probability of each particular selection of four games to win is p4 because we need them to win those\nfour games, and we don't care about the rest. As such the probability is:\n7\nP(X\u22654)=( )p4\n4\nThis idea seems good, but it doesn't work. First of all, we can recognize that there is a problem by\nconsidering the outcome if we set p=1.0. In this case P(X\u22654)=(7)p4=(7)14=35. Clearly 35 is\n4 4\nan invalid probability (which is much greater than 1). As such this can't be the right answer.\nBut what is wrong with this approach? Lets enumerate the 35 different outcomes that they are\nconsidering. Let B = we don't know who wins. Let W = the warriors win. Here each outcome is the\nassignment to each of the 7 games in the series:\n2\nThis is a header\n(B, B, B, W, W, W, W)\n(B, B, W, B, W, W, W)\n(B, B, W, W, B, W, W)\n(B, B, W, W, W, B, W)\n(B, B, W, W, W, W, B)\n(B, W, B, B, W, W, W)\n(B, W, B, W, B, W, W)\n(B, W, B, W, W, B, W)\n(B, W, B, W, W, W, B)\n(B, W, W, B, B, W, W)\n(B, W, W, B, W, B, W)\n(B, W, W, B, W, W, B)\n(B, W, W, W, B, B, W)\n(B, W, W, W, B, W, B)\n(B, W, W, W, W, B, B)\n(W, B, B, B, W, W, W)\n(W, B, B, W, B, W, W)\n(W, B, B, W, W, B, W)\n(W, B, B, W, W, W, B)\n(W, B, W, B, B, W, W)\n(W, B, W, B, W, B, W)\n(W, B, W, B, W, W, B)\n(W, B, W, W, B, B, W)\n(W, B, W, W, B, W, B)\n(W, B, W, W, W, B, B)\n(W, W, B, B, B, W, W)\n(W, W, B, B, W, B, W)\n(W, W, B, B, W, W, B)\n(W, W, B, W, B, B, W)\n(W, W, B, W, B, W, B)\n(W, W, B, W, W, B, B)\n(W, W, W, B, B, B, W)\n(W, W, W, B, B, W, B)\n(W, W, W, B, W, B, B)\n(W, W, W, W, B, B, B)\nIt is in fact the case that the probability of any of these 35 outcomes is p4. For example: (W, W, W, W, B,\nB, B). The warriors need to win the first 4 independent games: p4. Then there are three events where\neither team could win. The probability of \"B\", that either team could win, is 1. That makes sense. Either\nthe warriors win or the other team wins. As such our probability of any given outcome, aka row in the set\nof outcomes above, is: p4\u22c513=p4\nThe bug here is that these outcomes are not mutually exclusive, yet the answer treats them as such. In the\nmany coin flips example, we constructed outcomes in the format (T, T, T, H, H, T, H). These outcomes\nare in fact mutually exclusive. Its not possible for two distinct lists of outcomes to simultaneously exist.\nOn the other hand in the version where \"B\" stands for either team could win, the outcomes do have\noverlap. For example consider the two rows from the examples above:\n(B, W, W, W, B, B, W)\n(B, W, W, W, B, W, B)\nThese could both occur (and hence are not mutually exclusive). For example if the warriors win all 7\ngames! Or the warriors win all games except for games 1 and 5. Both events are satisfied. Because the\nevents are not mutually exclusive, if we want the probability of the \"or\" of each of these events we can\nnot just sum the probabilities of each of the events (and that is exactly what\nP(X\u22654)=(7)p4\nimplies.\n4\nInstead you would need to use inclusion exclusion for the or of 35 events (yikes!). Alternatively see the\nanswer we propose above.\n3\nThis is a header\nApproximate Counting\nWhat if you wanted a counter that could count up to the number of atoms in the universe, but you wanted to\nstore the counter in 8 bits? You could use the amazing probabilistic algorithm described below! In this\nexample we are going to show that the expected return value of stochastic_counter(4), where count is\ncalled four times, is in fact equal to four.\ndef stochastic_counter(true_count):\nn = -1\nfor i in range(true_count):\nn += count(n)\nreturn 2 ** n # 2^n, aka 2 to the power of n\ndef count(n):\n# To return 1 you need n heads. Always returns 1 if n is <= 0\nfor i in range(n):\nif not coin_flip():\nreturn 0\nreturn 1\ndef coin_flip():\n# returns true 50% of the time\nreturn random.random() < 0.5\nLet X be a random variable for the value of n at the end of \\texttt{stochastic\\_counter(4)}. Note that X is\nnot a binomial because the probabilities of each outcome change.\nLet R be the return value of the function. R=2X which is a function of X. Use the law of unconscious\nstatistician\nE[R]=\u22112x\u22c5P(X=x)\nx\nWe can compute each of the probabilities P(X=x) separately. Note that the first two calls to count will\nalways return 1. Let H i be the event that the ith call returns 1. Let T i be the event that the ith call returns\n0. X can't be less than 1 because the first two calls to count always return 1. P(X=1)=P(T 3,T 4) \\\nP(X=2)=P(H 3,T 4)+P(T 3,H 4) \\ P(X=3)=P(H 3,H 4)\nAt the point of the third call to count, n=1. If H 3 then n=2 for the fourth call and the loop runs twice.\nP(H ,T )=P(H )\u22c5P(T |H )\n3 4 3 4 3\n1 1 1\n= \u22c5( + )\n2 2 4\nP(H ,H )=P(H )\u22c5P(H |H )\n3 4 3 4 3\n1 1\n= \u22c5\n2 2\nIf T 3 then n=1 for the fourth call.\nP(T ,H )=P(T )\u22c5P(H |T )\n3 4 3 4 3\n1 1\n= \u22c5\n2 2\nP(T ,T )=P(T )\u22c5P(T |T )\n3 4 3 4 3\n1 1\n= \u22c5\n2 2\nPlug everything in:\n1\nThis is a header 3\nE[R]=\u22112x\u22c5P(X=x)\nx=1\n1 5 1\n=2\u22c5 +4\u22c5 +8\u22c5\n4 8 8\n=4\n2\nThis is a header\nJury Selection\nIn the Supreme Court case: Berghuis v. Smith, the Supreme Court (of the US) discussed the question: \"If\na group is underrepresented in a jury pool, how do you tell?\"\nJustice Breyer [Stanford Alum] opened the questioning by invoking the binomial theorem. He\nhypothesized a scenario involving \u201can urn with a thousand balls, and sixty are red, and nine hundred\nforty are green, and then you select them at random\u2026 twelve at a time.\u201d According to Justice Breyer and\nthe binomial theorem, if the red balls were black jurors then \u201cyou would expect\u2026 something like a third\nto a half of juries would have at least one black person\u201d on them.\nNote: What is missing in this conversation is the power of diverse backgrounds when making difficult\ndecisions.\nSimulate\nSimulation:\nExplanation:\nTechnically, since jurors are selected without replacement, you should represent the number of under-\nrepresentative jurors as being a Hyper Geometric Random Variable (a random variable we don't look at\nexplicitely in CS109) st\nX\u223cHypGeo(n=12,N =1000,m=60)\nP(X\u22651)=1\u2212P(X=0)\n(60)(940)\n=1\u2212 0 12\n(1000)\n12\n\u22480.5261\nHowever Justic Breyer made his case by citing a Binomial distribution. This isn't a perfect use of\nbinomial, because the binomial assumes that each experiment has equal likelihood (p) of success.\nBecause the jurors are selected without replacement, the probability of getting a minority juror changes\nslightly after each selection (and depending on what the selection was). However, as we will see, because\nthe probabilities don't change too much the binomial distribution is not too far off.\nX\u223cBinomial(n=12,p=60/1000)\nP(X\u22651)=1\u2212P(X=0)\n60\n=1\u2212( )(1\u22120.06)12\n0\n\u22480.5241\nAcknowledgements: Problem posed and solved by Mehran Sahami\n1\nThis is a header\nGrading Eye Inflammation\nWhen a patient has eye inflammation, eye doctors \"grade\" the inflammation. When \"grading\"\ninflammation they randomly look at a single 1 millimeter by 1 millimeter square in the patient's eye and\ncount how many \"cells\" they see.\nThere is uncertainty in these counts. If the true average number of cells for a given patient's eye is 6, the\ndoctor could get a different count (say 4, or 5, or 7) just by chance. As of 2021, modern eye medicine\ndoes not have a sense of uncertainty for their inflammation grades! In this problem we are going to\nchange that. At the same time we are going to learn about Poisson distributions over space.\nWhy is the number of cells observed in a 1x1 square governed by a Poisson process?\nWe can approximate a distribution for the count by discretizing the square into a fixed number of equal\nsized buckets. Each bucket either has a cell or not. Therefore, the count of cells in the 1x1 square is a sum\nof Bernoulli random variables with equal p, and as such can be modeled as a binomial random variable.\nThis is an approximation because it doesn't allow for two cells in one bucket. Just like with time, if we\nmake the size of each bucket infinitely small, this limitation goes away and we converge on the true\ndistribution of counts. The binomial in the limit, i.e. a binomial as n\u2192\u221e, is truly represented by a\nPoisson random variable. In this context, \u03bb represents the average number of cells per 1\u00d71 sample. See\nFigure 2.\nFor a given patient the true average rate of cells is 5 cells per 1x1 sample. What is the probability that in a\nsingle 1x1 sample the doctor counts 4 cells?\nLet X denote the number of cells in the 1x1 sample. We note that X\u223cPoi(5). We want to find\nP(X=4).\n54e\u22125\nP(X=4)= \u22480.175\n4!\nMultiple Observations\nHeads up! This section uses concepts from Part 3. Specifically Independence in Variables\n1\nThis is a header\nFor a given patient the true average rate of cells is 5 cells per 1mm by 1mm sample. In an attempt to be\nmore precise, the doctor counts cells in two different, larger 2mm by 2mm samples. Assume that the\noccurrences of cells in one 2mm by 2mm samples are independent of the occurrences in any other 2mm\nby 2mm samples. What is the probability that she counts 20 cells in the first samples and 20 cells in the\nsecond?\nLet Y 1 and Y 2 denote the number of cells in each of the 2x2 samples. Since there are 5 cells in a 1x1\nsample, there are 20 samples in a 2x2 sample since the area quadrupled, so we have that Y 1\u223cPoi(20)\nand Y 2\u223cPoi(20). We want to find P(Y 1=20\u2227Y 2=20). Since the number of cells in the two\nsamples are independent, this is equivalent to finding P(Y 1=20)P(Y 2=20).\nEstimating Lambda\nHeads up! This section uses concepts from Part 5. Specifically Maximum A Posteriori\nInflammation prior: Based on millions of historical patients, doctors have learned that the prior\nprobability density function of true rate of cells is:\nf(\u03bb)=K\u22c5\u03bb\u22c5e\u2212\u03bb\n2\nWhere K is a normalization constant and \u03bb must be greater than 0.\nA doctor takes a single sample and counts 4 cells. Give an equation for the updated probability density of\n\u03bb. Use the \"Inflammation prior\" as the prior probability density over values of \u03bb. Your probability density\nmay have a constant term.\nLet \u03b8 be the random variable for true rate. Let X be the random variable for the count\nP(X=4|\u03b8=\u03bb)f(\u03b8=\u03bb)\nf(\u03b8=\u03bb|X=4)=\nP(X=4)\n\u03bb4e\u2212\u03bb \u22c5K\u22c5\u03bb\u22c5e\u03bb/2\n= 4!\nP(X=4)\nK\u22c5\u03bb5e\u22123\u03bb\n= 2\n4!P(X=4)\nA doctor takes a single sample and counts 4 cells. What is the Maximum A Posteriori estimate of \u03bb?\n2\nThis is a header\nMaximize the \"posterior\" of the parameter calculated in the previous section:\nK\u22c5\u03bb5e\u22123\u03bb\narg max 2 =arg max\u03bb5e\u22123 2\u03bb\n4!P(X=4)\n\u03bb \u03bb\nTake logarithm (preserves argmax, and easier derivative):\n=arg maxlog(\u03bb5e\u22123 2\u03bb)\n\u03bb\n3\n=arg max(5log\u03bb\u2212 \u03bb)\n2\n\u03bb\nCalculate the derivative with respect to the parameter, and set equal to 0\n\u2202 3\n0= (5log\u03bb\u2212 \u03bb)\n\u2202\u03bb 2\n5 3\n0= \u2212\n\u03bb 2\n10\n\u03bb=\n3\nExplain, in words, the difference between the two estimates of lambda in the two previous parts.\nThe estimate in the first part is a ``distribution\" (also called a soft estimate) whereas the estimate in the\nsecond part is a single value (also called a point estimate). The former contains information about\nconfidence.\nWhat is the MLE estimate of \u03bb?\nThe MLE estimate doesn't use the prior belief. The MLE estimate for a poisson is simply the average of\nthe observations. In this case the average of our single observation is 4. MLE is not a great tool for\nestimating our parameter from just one datapoint.\nA patient comes on two separate days. The first day the doctor counts 5 cells, the second day the doctor\ncounts 4 cells. Based only on this observation, and treating the true rates on the two days as independent,\nwhat is the probability that the patient's inflammation has gotten better (in other words, that their \u03bb has\ndecreased)?\nLet \u03b8 1 be the random variable for lambda on the first day and \u03b8 2 be the random variable for lambda on\nthe second day.\nf(\u03b8 =\u03bb|X=5)=K \u22c5\u03bb6e\u22123\u03bb\n1 1 2\nf(\u03b8 =\u03bb|X=4)=K \u22c5\u03bb5e\u22123\u03bb\n2 2 2\nThe question is asking what is P(\u03b8 1>\u03b8 2)? There are a few ways to calculate this exactly:\n\u221e \u03bb1\n\u222b \u222b f(\u03b8 =\u03bb ,\u03b8 =\u03bb )\n1 1 2 2\n\u03bb1=0 \u03bb2=0\n\u221e \u03bb1\n=\u222b \u222b f(\u03b8 =\u03bb )\u22c5f(\u03b8 =\u03bb )\n1 1 2 2\n\u03bb1=0 \u03bb2=0\n\u221e \u03bb1\n=\u222b f(\u03b8 =\u03bb )\u222b f(\u03b8 =\u03bb )\n1 1 2 2\n\u03bb1=0 \u03bb2=0\n=\u222b\n\u221e\nK \u22c5\u03bb6e\u22123\u03bb\u222b\n\u03bb1\nK \u22c5\u03bb5e\u22123\u03bb\n1 2 2 2\n\u03bb1=0 \u03bb2=0\n3\nThis is a header\nGrades are Not Normal\nSometimes you just feel like squashing normals:\nLogit Normal\nThe logit normal is the continuous distribution that results from applying a special \"squashing\" function\nto a Normally distributed random variable. The squashing function maps all values the normal could take\non onto the range 0 to 1. If X\u223cLogitNormal(\u03bc,\u03c32) it has:\nPDF: f\nX(x)={\u03c3(\u221a2\u03c0)1 x(1\u2212x)e\u2212(logit 2( \u03c3x 2)\u2212\u03bc)2 if 0<x<1\n0 otherwise\nlogit(x)\u2212\u03bc\nCDF: F (x)=\u03a6( )\nX \u03c3\nx\nWhere: logit(x)=log( )\n1\u2212x\nA new theory shows that the Logit Normal better fits exam score distributions than the traditionally used\nNormal. Let's test it out! We have some set of exam scores for a test with min possible score 0 and max\npossible score 1, and we are trying to decide between two hypotheses:\nH 1: our grade scores are distributed according to X\u223cNormal(\u03bc=0.7,\u03c32=0.22).\nH 2: our grade scores are distributed according to X\u223cLogitNormal(\u03bc=1.0,\u03c32=0.92).\nUnder the normal assumption, H 1, what is P(0.9<X<1.0)? Provide a numerical answer to two\ndecimal places.\n1.0\u22120.7 0.9\u22120.7\nP(0.9<X<1.0)=\u03a6( )\u2212\u03a6( )=\u03a6(1.5)\u2212\u03a6(1.0)=0.9332\u22120.8413=0.09\n0.2 0.2\nUnder the logit-normal assumption, H 2, what is P(0.9<X<1.0)?\nlogit(1.0)\u22121.0 logit(0.9)\u22121.0\nF (1.0)\u2212F (0.9)=\u03a6( )\u2212\u03a6( )\nX X 0.9 0.9\nWhich we can solve for numerically:\nlogit(1.0)\u22121.0 logit(0.9)\u22121.0\n\u03a6( )\u2212\u03a6( )=1\u2212\u03a6(1.33)\u22480.91\n0.9 0.9\nUnder the normal assumption, H 1, what is the maximum value that X can take on?\n1\nThis is a header\n\u221e\nBefore observing any test scores, you assume that (a) one of your two hypotheses is correct and (b) that\ninitially, each hypothesis is equally likely to be correct, P(H 1)=P(H 2)= 1 2. You then observe a single\ntest score, X=0.9. What is your updated probability that the Logit-Normal hypothesis is correct?\nf(X=0.9|H )P(H )\nP(H |X=0.9)= 2 2\n2 f(X=0.9|H )P(H )+f(X=0.9|H )P(H )\n2 2 1 1\nf(X=0.9|H )\n= 2\nf(X=0.9|H )+f(X=0.9|H )\n2 1\n1 e\u2212(logit 2(0 \u2217. 09 .) 9\u2212 21.0)2\n\u03c3(\u221a2\u03c0)0.9\u2217(1\u22120.9)\n=\n1 e\u2212(logit 2(0 \u2217. 09 .) 9\u2212 21.0)2 + 1 e\u2212(0. 29 \u2217\u2212 0.0 2. 27)2\n\u03c3(\u221a2\u03c0)0.9\u2217(1\u22120.9) 0.2\u221a2\u03c0\n2\nThis is a header\nCurse of Dimensionality\nIn machine learning, like many fields of computer science, often involves high dimensional points, and\nhigh dimension spaces have some surprising probabilistic properties.\nA random value X i is a Uni(0, 1).\nA random point of dimension d is a list of d random values: [X 1\u2026X d].\nA random value X i is close to an edge if X i is less than 0.01 or X i is greater than 0.99. What is the\nprobability that a random value is close to an edge?\nLet E be the event that a random value is close to an edge.\nP(E)=P(X <0.01)+P(X >0.99)=0.02\ni i\nA random point [X 1,X 2,X 3] of dimension 3 is close to an edge if any of its values are close to an edge.\nWhat is the probability that a 3 dimensional point is close to an edge?\nThe event is equivalent to the complement of none of the dimensions of the point is close to an edge,\nwhich is: 1\u2212(1\u2212P(E))3=1\u22120.983\u22480.058\nA random point [X 1,\u2026X 100] of dimension 100 is close to an edge if any of its values are close to an\nedge. What is the probability that a 100 dimensional point is close to an edge?\nSimilarly, it is: 1\u2212(1\u2212P(E))100=1\u22120.98100\u22480.867\nThere are many other phenomena of high dimensional points: such as, the euclidean distance between points\nstarts to converge.\n1\nThis is a header\nAlgorithmic Art\nWe want to generate probabilistic artwork, efficiently. We are going to use random variables to make a\npicture filled with non-overlapping circles:\nRegenerate\nIn our art, the circles are different sizes. Specifically, each circle's radius is drawn from a Pareto\ndistribution (which is described below). The placement algorithm is greedy: we sample 1000 circle sizes.\nSort them by size, largest to smallest. Loop over the circle sizes and place circles one by one.\nTo place a circle on the canvas, we sample the location of the center of the circle. Both the x and y\ncoordinates are uniformly distributed over the dimensions of the canvas. Once we have selected a\nprospective location we then check if there would be a collision with a circle that has already been\nplaced. If there is a collision we keep trying new locations until you find one that has no collisions.\n1\nThis is a header\nThe Pareto Distribution\nPareto Random Variable\nNotation: X\u223cPareto(a)\nDescription: A long tail distribution. Large values are rare and small values are common.\nParameters: a\u22651, the shape parameter\nNote there are other optional params. See wikipedia\nSupport: x\u2208[0,1]\n1\nPDF equation: f(x)=\nxa+1\n1\nCDF equation: F(x)=1\u2212\nxa\nSampling from a Pareto Distribution\nHow can we draw samples from a pareto? In python its simple: stats.pareto.rvs(a) however in\nJavaScript, or other languages, it might not be made transparent. We can use \"inverse transform\nsampling\". The simple idea is to choose a uniform random variable in the range (0, 1) and then select the\nvalue x assignment such that F(x) equals the randomly chosen value.\n1\ny=1\u2212( )\u03b1\nx\n1\n( )\u03b1=1\u2212y\nx\n1\n=(1\u2212y)\u03b11\nx\n1\nx=\n(1\u2212y)1\n\u03b1\n2\nPart 3: Probabilistic Models\nThis is a header\nJoint Probability\nMany interesting problems involve not one random variable, but rather several interacting with one\nanother. In order to create interesting probabilistic models and to reason in real world situations, we are\ngoing to need to learn how to consider several random variables jointly.\nIn this section we are going to use disease prediction as a working example to introduce you to the\nconcepts involved in probabilistic models. The general question is: a person has a set of observed\nsymptoms. Given the symptoms what is the probability over each possible disease?\nWe have already considered events that co-occur and covered concepts such as independence and\nconditional probability. What is new about this section is (1) we are going to cover how to handle random\nvariables which co-occur and (2) we are going to talk about how computers can reason under large\nprobabilistic models.\nJoint Probability Functions\nFor single random variables, the most important information was the PMF or, if the variable was\ncontinuous, the PDF. When dealing with two or more variables, the equivalent function is called the Joint\nfunction. For discrete random variables, it is a function which takes in a value for each variable and\nreturns the probability (or probability density for continuous variables) that each variable takes on its\nvalue. For example if you had two discrete variables the Joint function is:\nP(X=x,Y =y) Jointfunctionfor X and Y\nYou should read the comma as an \"and\" and as such this is saying the probability that X=x and Y =y.\nAgain like for single variables, as shorthand, we often write just the values and it implies that we are\ntalking about the probability of the random variables taking on those values. This notation is convenient\nbecause it is shorter, and it makes it explicit that the function is operating over two parameters. It requires\nto recall that the event is a random variable taking on the given value.\nP(x,y) Shorthandfor P(X=x,Y =y)\nIf any of the variables are continuous we use different notation to make it clear that we need a probability\ndensity function, something we can integrate over to get a probability. We will cover this in detail:\nf(X=x,Y =y) Jointdensityfunctionif X or Y arecontinuous\nThe same idea extends to as many variables as you have in your model. For example if you had three\ndiscrete random variables X, Y, and Z, the joint probability function would state the likelihood of an\nassignment to all three: P(X=x,Y =y,Z=z).\nJoint Probability Tables\nDefinition: Joint Probability Table\nA joint probability table is a way of specifying the \"joint\" distribution between multiple random\nvariables. It does so by keeping a multi-dimensional lookup table (one dimension per variable) so that\nthe probability mass of any assignment, eg P(X=x,Y =y,\u2026), can be directly looked up.\nLet us start with an example. In 2020 the Covid-19 pandemic disrupted lives around the world. Many\npeople were unable to get tested and had to determine whether or not they were sick based on home\ndiagnosis. Let's build a very simple probabilistic model to enable us to make a tool which can predict the\nprobability of having the illness given observed symptoms. To make it clear that this is a pedagogical\nexample, let's consider a made up illness called Determinitis. The two main symptoms are fever and loss\nof smell.\n1\nThis is a header\nVariable Symbol Type\nHas Determinitis D Bernoulli (1 indicates has Determinitis)\nFever F Categorical (none, low, high)\nCan Smell S Bernoulli (1 indicates can smell)\nA joint probability table is a brute force way to store the probability mass of a particular assignment of\nvalues to our variables. Here is a probabilistic model for our three random variables (aside: the values in\nthis joint are realistic and based on reasearch, but are primarily for teaching. Consult a doctor before\nmaking medical decisions).\nD=0\nS=0 S=1\nF =none 0.024 0.783\nF =low 0.003 0.092\nF =high 0.001 0.046\nD=1\nS=0 S=1\nF =none 0.006 0.014\nF =low 0.005 0.011\nF =high 0.004 0.011\nA few key observations:\nEach cell in this table represents the probability of one assignment of variables. For example the\nprobability that someone can't smell, S=0, has a low fever, F =low, and has the illness, D=1, can\nbe directly read off the table: P(D=1,S=0,F =low)=0.005.\nThese are joint probabilities not conditional probabilities. The value 0.005 is the value of illness, no\nsmell and low fever. It is not the probability of no smell and low fever given illness. A table which\nstored conditional probabilities would be called a conditional probability table, this is a joint\nprobability table.\nIf you sum over all cells, the total will be 1. Each cell is a mutually exclusive combination of events\nand the cells are meant to span the entire space of possible outcomes.\nThis table is large! We can count the number of cells using the step rule of counting. If n i is the\nnumber of different values that random variable i can take on, the number of cells in the joint table is\n\u220f in i.\nProperties of Joint Distributions\nThere are many properties of a random variable of any joint distribution some of which we will dive into\nextensively. Here is a brief summary. Each random variable has:\n2\nThis is a header\nProperty Notation Example Description\nDistribution Function P(X=x,Y =y,\u2026) or A function which maps values the RV\n(PMF or PDF) f(X=x,Y =y,\u2026) can take on to likelihood.\nCumulative Distribution F(X<x,Y <y,\u2026) Probability that each variable is less\nFunction (CDF) than its corresponding parameter\nCovariance \u03c3 X,Y A measure of how much two random\nvariables vary together.\nCorrelation \u03c1 X,Y Normalized co-variance\n3\nThis is a header\nMarginalization\nAn important insight regarding probabilistic models with many random variables is that \"the joint\ndistribution is complete information.\" From the joint distribution you can compute all probability\nquestions involving those random variables in the model. This chapter is an example of that insight.\nThe central question of this chapter is: Given a joint distribution, how can you compute the probability of\nrandom variables on their own?\nMarginalization From Two Random Variables\nTo start, consider two random variables X and Y. If you are given the joint how can you compute\nP(X=x)? Recall that if you have the joint you have a way to know the probability P(X=x,Y =y)\nfor any value x and y . We already have a technique for computing P(X=x) from the joint. We can use\nthe Law of Total Probability (LOTP)! In this case the events Y =y make up the \"background events\":\nP(X=x)=\u2211P(X=x,Y =y)\ny\nNote that to apply the LOTP it must be the case that the different events Y =i must be mutually\nexclusvie and it must be the case that \u2211 P(Y =y)=1. Both are true.\ny\nIf we wanted P(Y =y) we could again use the Law of Total Probability, this time with X taking on each\nof its possible values as the background events:\nP(Y =y)=\u2211P(X=x,Y =y)\nx\nExample: Favorite Number\nConsider the following joint distribution for X and Y where X is a person's favorite binary digit and Y is\ntheir year at Stanford. Here is a real joint distribution form a past class:\nVariable Symbol Type\nFavorite Digit X Discrete number {0, 1}\nYear in School Y Categorical {Frosh, Soph, Junior, Senior, 5+}\nX=0 X=1\nY =Frosh 0.01 0.13\nY =Soph 0.05 0.33\nY =Junior 0.04 0.21\nY =Senior 0.03 0.12\nY =5+ 0.02 0.06\nWhat is the probability that a student's favorite digit is 0, P(X=0)? We can use the LOTP to compute\nthis probability:\n1\nThis is a header P(X=0)=\u2211P(X=0,Y =y)\ny\n=+P(X=0,Y =Frosh)\n+P(X=0,Y =Soph)\n+P(X=0,Y =Junior)\n+P(X=0,Y =Senior)\n+P(X=0,Y =5+)\n=0.01+0.05+0.04+0.03+0.02\n=0.15\nMarginalization with More Variables\nThe idea of marginalization can be extended to joint distributions with more than two random variables.\nConsider having three random variables X, Y, and Z, we could marginalize out any of the variables:\nP(X=x)=\u2211P(X=x,Y =y,Z=z)\ny,z\nP(Y =y)=\u2211P(X=x,Y =y,Z=z)\nx,z\nP(Z=z)=\u2211P(X=x,Y =y,Z=z)\nx,y\nNotation: Double Sum\nIn this case the double sum notation:\n\u2211\ny,z\nAlso written equivalently as:\n\u2211\u2211\ny z\nmeans that we are summing over all possible values of y and z. For example, if Y is a random variable\nwith 3 possible values and Z is a random variable with 4 possible values, then \u2211 means that we are\ny,z\nsumming over all 12 possible combinations of y and z.\nHere is an example in code. Assume we have a function joint(x, y, z) and that all X, Y and Z can\ntake on values in the set {0,1,2,3,4}\n2\nThis is a header\nMultinomial\nThe multinomial is an example of a parametric distribution for multiple random variables. The\nmultinomial is a gentle introduction to joint distributions. It is a extension of the binomial. In both cases,\nyou have n independent experiments. In a binomial each outcome is a \"success\" or \"not success\". In a\nmultinomial there can be more than two outcomes (multi). A great analogy for the multinomial is: we are\ngoing to roll an m sided dice n times. We care about reporting the number of outcomes of each side of\nyour dice.\nHere is the formal definition of the multinomial. Say you perform n independent trials of an experiment\nwhere each trial results in one of m outcomes, with respective probabilities: p 1,p 2,\u2026,p m (constrained\nso that \u2211 ip i=1). Define X i to be the number of trials with outcome i. A multinomial distribution is a\nclosed form function that answers the question: What is the probability that there are c i trials with\noutcome i. Mathematically:\nn\nP(X 1=c 1,X 2=c 2,\u2026,X m=c m)=(\nc ,c ,\u2026,c\n)\u22c5pc 11\u22c5pc 22\u2026pc mm\n1 2 m\nn\n=( )\u22c5\u220fpci\nc ,c ,\u2026,c i\n1 2 m i\nThis is our first joint random variable model! We can express it in a card, much like we would for\nrandom variables:\nMultinomial Joint Distribution\nDescription: Number of outcomes of each possible outcome type in n identical, independent\nexperiments. Each experiment can result in one of m different outcomes.\nParameters: p 1,\u2026,p m where each p i\u2208[0,1] is the probability of outcome type i in one experiment.\nn\u2208{0,1,\u2026}, the number of experiments\nSupport: c i\u2208{0,1,\u2026,n}, for each outcome i. It must be the case that \u2211 ic i=n\nn\nPMF P(X 1=c 1,X 2=c 2,\u2026,X m=c m)=(\nc ,c ,\u2026,c\n)\u220fpc ii\nequation: 1 2 m i\nExamples\nStandard Dice Example:\nA 6-sided die is rolled 7 times. What is the probability that you roll: 1 one, 1 two, 0 threes, 2 fours, 0\nfives, 3 sixes (disregarding order).\nP(X =1,X =1,X =0,X =2,X =0,X =3)\n1 2 3 4 5 6\n7! 1 1 1 1 1 0 1 2 1 0 1 3\n= ( ) ( ) ( ) ( ) ( ) ( )\n2!3! 6 6 6 6 6 6\n1 7\n=420( )\n6\nWeather Example:\nEach day the weather in Bayeslandia can be {Sunny, Cloudy, Rainy} where p sunny=0.7, p cloudy=0.2\nand p rainy=0.1. Assume each day is independent of one another. What is the probability that over the\nnext 7 days we have 5 sunny days, 1 cloudy day and 1 rainy days?\n1\nThis is a header P(X =6,X =1,X =0)\nsunny rainy cloudy\n7!\n= (0.7)5\u22c5(0.2)1\u22c5(0.1)1\n5!1!1!\n\u22480.14\nHow does that compare to the probability that every day is sunny?\nP(X =7,X =0,X =0)\nsunny rainy cloudy\n7!\n= (0.7)7\u22c5(0.2)0\u22c5(0.1)0\n7!1!\n\u22480.08\nThe multinomial is especially popular because of its use as a model of language. For a full example see\nthe Federalist Paper Authorship example.\nDeriving Joint Probability\nA way to deeper understand the multinomial is to derive the joint probability function for a particular\nmultinomial. Consider the multinomial from the previous example. In that multinomial with n=7\noutcomes where each outcome can be one of three values {S,C,R} where S stands for Sunny, C stands\nfor Cloudy and R stands for Rainy, and days are independent. p s=0.7, p c=0.2, p r=0.1. We are going\nto derive the probability that out of the n=7 days, 5 are sunny, 1 is cloudy and 1 is rainy.\nLike our derivation for the binomial, we are going to consider all of the possible weeks with 5 sunny\ndays, 1 rainy day and 1 cloudy day.\n('S', 'S', 'S', 'S', 'S', 'C', 'R')\n('S', 'S', 'S', 'S', 'S', 'R', 'C')\n('S', 'S', 'S', 'S', 'C', 'S', 'R')\n('S', 'S', 'S', 'S', 'C', 'R', 'S')\n('S', 'S', 'S', 'S', 'R', 'S', 'C')\n('S', 'S', 'S', 'S', 'R', 'C', 'S')\n('S', 'S', 'S', 'C', 'S', 'S', 'R')\n('S', 'S', 'S', 'C', 'S', 'R', 'S')\n('S', 'S', 'S', 'C', 'R', 'S', 'S')\n('S', 'S', 'S', 'R', 'S', 'S', 'C')\n('S', 'S', 'S', 'R', 'S', 'C', 'S')\n('S', 'S', 'S', 'R', 'C', 'S', 'S')\n('S', 'S', 'C', 'S', 'S', 'S', 'R')\n('S', 'S', 'C', 'S', 'S', 'R', 'S')\n('S', 'S', 'C', 'S', 'R', 'S', 'S')\n('S', 'S', 'C', 'R', 'S', 'S', 'S')\n('S', 'S', 'R', 'S', 'S', 'S', 'C')\n('S', 'S', 'R', 'S', 'S', 'C', 'S')\nFirst, note that each outcome for assignments to the weeks are mutually exclusive. Then note that the\nprobability of any one outcome will be (p S)5\u22c5p C\u22c5p R. The number of unique weeks with the chosen\ncount of outcomes can be derived using the rule for Permutations with Indistinct Objects. There are 7\nobjects, 5 are indistinct from one another. The number of distinct outcomes is:\n7 7!\n( )= =7\u22c56=42\n5,1,1 5!1!1!\nSince the outcomes are mutually exclusive, we are going to be adding the probability of each case to\nitself 7! times. Putting this all together we get the multinomial joint function for this particular case:\n5!1!1!\nP(X =5,X =1,X =1)\nsunny rainy cloudy\n7!\n= (0.7)5\u22c5(0.2)1\u22c5(0.1)1\n5!1!1!\n\u22480.14\n2\nThis is a header\nContinuous Joint\nRandom variables X and Y are Jointly Continuous if there exists a joint Probability Density Function\n(PDF) f such that:\na2 b2\nP(a <X\u2264a ,b <Y \u2264b )=\u222b \u222b f(X=x,Y =y)dy dx\n1 2 1 2\na1 b1\nUsing the PDF we can compute marginal probability densities:\n\u221e\nf(X=a)=\u222b f(X=a,Y =y)dy\n\u2212\u221e\n\u221e\nf(Y =b)=\u222b f(X=x,Y =b)dx\n\u2212\u221e\nLet F(x,y) be the Cumulative Density Function (CDF):\nP(a <X\u2264a ,b <Y \u2264b )=F(a ,b )\u2212F(a ,b )+F(a ,b )\u2212F(a ,b )\n1 2 1 2 2 2 1 2 1 1 2 1\nFrom Discrete Joint to Continuous Joint\nThinking about multiple continuous random variables jointly can be unintuitive at first blush. But we can\nturn to our helpful trick that we can use to understand continuous random variables: start with a discrete\napproximation. Consider the example of creating the CS109 seal. It was generated by throwing half a\nmillion darts at an image of the stanford logo (keeping all the pixels that get hit by at least one dart). The\ndarts could hit any continuous location on the logo, and, the locations are not equally likely. Instead, the\nlocation a dart hits is goverened by a joint continuous distribution. In this case there are only two\nsimultaneous random variables, the x location of the dart and the y location of the dart. Each random\nvariable is continuous (it takes on real numbers). Thinking about the joint probability density function is\neasier by first considering a discretization. I am going to break the dart landing area into 25 discrete\nbuckets:\n1\nThis is a header\nOn the left is a visualization of the probability mass of this joint distribution, and on the right is a\nvisualization of how we could answer the question: what is the probability that a dart hits within a certain\ndistance of the center. For each bucket there is a single number, the probability that a dart will fall into\nthat particular bucket (these probabilities are mutually exclusive and sum to 1).\nOf course this discretization only approximates the joint probability distribution. In order to get a better\napproximation we could create more fine-grained discretizations. In the limit we can make our buckets\ninfinitely small, and the value associated with each bucket becomes a second derivative of probability.\n2\nThis is a header\nTo represent the 2D probability density in a graph, we use the darkness of a value to represent the density\n(darker means more density). Another way to visualize this distribution is from an angle. This makes it\neasier to realize that this is a function with two inputs and one output. Below is an different visualization\nof the exact same density function:\nJust like in the single random variable case, we are now representing our belief in the continuous random\nvariables as densities rather than probabilities. Recall that a density represents a relative belief. If the\ndensity of f(X=1.1,Y =0.9) is twice as high as the density that f(X=1.1,Y =1.1) the function is\nexpressing that it is twice as likely to find the particular combination of X=1.1 and Y =0.9.\nMultivariate Gaussian\nThe density that is depicted in this example happens to be a particular of joint continuous distribution\ncalled Multivariate Gaussian. In fact it is a special case where all of the constituent variables are\nindependent.\n3\nThis is a header\nDef: Independent Multivariate Gaussian . An Independent Multivariate Gaussian can model a\ncollection of continuous joint random variables X\u2192 =(X 1\u2026X n) as being a composition of independent\nnormals with means \u03bc\u2192=(\u03bc 1\u2026\u03bc n) and standard deviations \u03c3\u2192=(\u03c3 1\u2026\u03c3 n). Notice how we now have\nvariables in vectors (similar to a list in python). The notation for the multivariate uses vector notation:\nX\u2192 \u223cN\u2192(\u03bc\u2192,\u03c3\u2192)\nThe joint PDF is:\nn\nf(x\u2192)=\u220ff(x)\ni\ni=1\nn 1 \u2212(x\u2212\u03bci)2\n=\u220f e 2\u03c32\ni\n\u03c3\u221a2\u03c0\ni=1 i\nAnd the joint CDF is\nn\nF(x\u2192)=\u220fF(x)\ni\ni=1\nn x \u2212\u03bc\n=\u220f\u03a6( i i)\n\u03c3\ni=1 i\nExample: Gaussian Blur\nIn the same way that many single random variables are assumed to be gaussian, many joint random\nvariables may be assumed to be Multivariate Gaussian. Consider this example of Gaussian Blur:\nIn image processing, a Gaussian blur is the result of blurring an image by a Gaussian function. It is a\nwidely used effect in graphics software, typically to reduce image noise. A Gaussian blur works by\nconvolving an image with a 2D independent multivariate gaussian (with means of 0 and equal valued\nstandard deviations).\n4\nThis is a header\nIn order to use a Gaussian blur, you need to be able to compute the probability mass of that 2D gaussian\nin the space of pixels. Each pixel is given a weight equal to the probability that X and Y are both within\nthe pixel bounds. The center pixel covers the area where \u22120.5\u2264x\u22640.5 and \u22120.5\u2264y\u22640.5. Let's do\none step in computing the Gaussian function discretized over image space. What is the weight of the\ncenter pixel for gaussian blur with a multivariate gaussian which has means of 0 and standard deviation\nof 3?\nLet\nB\u2192\nbe the multivariate gaussian,\nB\u2192\u223cN(\u03bc\u2192=[0,0],\u03c3\u2192=[3,3]).\nLet's compute the CDF of this\nmultivariate gaussian F(x 1,x 2):\nn x \u2212\u03bc\nF(x ,x )=\u220f\u03a6( i i)\n1 2 \u03c3\ni=1 i\nx \u2212\u03bc x \u2212\u03bc\n=\u03a6( 1 1)\u22c5\u03a6( 2 2)\n\u03c3 \u03c3\n1 2\nx x\n=\u03a6( 1)\u22c5\u03a6( 2)\n3 3\nNow we are ready to calculate the weight of the center pixel:\n5\nThis is a header P(\u22120.5<X \u22640.5,\u22120.5<X \u22640.5)\n1 2\n=F(0.5,0.5)\u2212F(\u22120.5,0.5)+F(\u22120.5,\u22120.5)\u2212F(0.5,\u22120.5)\n0.5 0.5 \u22120.5 0.5 \u22120.5 \u22120.5 0.5 \u22120.5\n=\u03a6( )\u22c5\u03a6( )\u2212\u03a6( )\u22c5\u03a6( )+\u03a6( )\u22c5\u03a6( )\u2212\u03a6( )\u22c5\u03a6( )\n3 3 3 3 3 3 3 3\n\u22480.026\nHow can this 2D gaussian blur the image? Wikipedia explains: \"Since the Fourier transform of a\nGaussian is another Gaussian, applying a Gaussian blur has the effect of reducing the image's high-\nfrequency components; a Gaussian blur is a low pass filter\" [2].\n6\nThis is a header\nInference\nSo far we have set the foundation for how we can represent probabilistic models with multiple random\nvariables. These models are especially useful because they let us perform a task called \"inference\" where\nwe update our belief about one random variable in the model, conditioned on new information about\nanother. Inference in general is hard! In fact, it has been proven that in the worst case, the inference task,\ncan be NP-Hard where n is the number of random variables [1].\nFirst we are going to practice it with two random variables (in this section). Then, later in this unit we are\ngoing to talk about inference in the general case, with many random variables.\nEarlier we looked at conditional probabilities for events. The first task in inference is to understand how\nto combine conditional probabilities and random variables. The equations for both the discrete and\ncontinuous case are intuitive extensions of our understanding of conditional probability:\nThe Discrete Conditional\nThe discrete case, where every random variable in your model is discrete, is a straightforward\ncombination of what you know about conditional probability (which you learned in the context of\nevents). Recall that every relational operator applied to a random variable defines an event. As such the\nrules for conditional probability directly apply: The conditional probability mass function (PMF) for the\ndiscrete case:\nLet X and Y be discrete random variables.\nDef: Conditional definition with discrete random variables.\nP(X=x,Y =y)\nP(X=x|Y =y)=\nP(Y =y)\nDef: Bayes' Theorem with discrete random variables.\nP(Y =y|X=x)P(X=x)\nP(X=x|Y =y)=\nP(Y =y)\nIn the presence of multiple random variables, it becomes increasingly useful to use shorthand! The above\ndefinition is identical to this notation where a lowercase symbol such as x is short hand for the event\nX=x:\nP(x,y)\nP(x|y)=\nP(y)\nThe conditional definition works for any event and as such we can also write conditionals using\ncumulative density functions (CDFs) for the discrete case:\nP(X\u2264a,Y =y)\nP(X\u2264a|Y =y)=\nP(Y =y)\n\u2211 P(X=x,Y =y)\n= x\u2264a\nP(Y =y)\nHere is a neat result: this last term can be rewritten, by a clever manipulation. We can make the sum\nextend over the whole fraction:\n\u2211 P(X=x,Y =y)\nP(X\u2264a|Y =y)= x\u2264a\nP(Y =y)\nP(X=x,Y =y)\n=\u2211\nP(Y =y)\nx\u2264a\n=\u2211P(X=x|Y =y)\nx\u2264a\n1\nThis is a header\nIn fact it becomes straight forward to translate the rules of probability (such as Bayes' Theorem, law of\ntotal probability, etc) to the language of discrete random variables: we simply need to recall that every\nrelational operator applied to a random variable defines an event.\nMixing Discrete and Continuous\nWhat happens when we want to reason about continuous random variables using our rules of probability\n(such as Bayes' Theorem, law of total probability, chain rule, etc)? There is a simple practical answer: the\nrules still apply, but we have to replace probability terminology with probability density functions. As a\nconcrete example let's look at Bayes' Theorem with one continuous random variable.\nDef: Bayes' Theorem with mixed discrete and continuous.\nLet X be a continuous random variable and let N be a discrete random variable. The conditional\nprobabilities of X given N and N given X respectively are:\nP(N =n|X=x)f(X=x)\nf(X=x|N =n)=\nP(N =n)\nf(X=x|N =n)P(N =n)\nP(N =n|X=x)=\nf(X=x)\nThese equations might seem complicated since they mix probability densities and probabilities. Why\nshould we believe that they are correct? First, observe that anytime the random variable on the left hand\nside of the conditional is continuous, we use a density, whenever it is discrete, we use a probability. This\nresult can be derived by making the observation:\nP(X=x)=f(X=x)\u22c5\u03f5\nx\nIn the limit as \u03f5 x\u21920. In order to obtain a probability from a density function is to integrate under the\nfunction. If you wanted to approximate the probability that X=x you could consider the area created by\na rectangle which has height f(X=x) and some very small width. As that width gets smaller, your\nanswer becomes more accurate:\nA value of \u03f5 x is problematic if it is left in a formula. However, if we can get them to cancel, we can arrive\nat a working equation. This is the key insight used to derive the rules of probability in the context of one\nor more continuous random variables. Again, let X be continuous random variable and let N be a\ndiscrete random variable:\nP(X=x|N =n)P(N =n)\nP(N =n|X=x)= Bayes'Theorem\nP(X=x)\nf(X=x|N =n)\u22c5\u03f5 \u22c5P(N =n)\n= x P(X=x)=f(X=x)\u22c5\u03f5\nf(X=x)\u22c5\u03f5 x\nx\nf(X=x|N =n)\u22c5P(N =n)\n= Cancel \u03f5\nf(X=x) x\n2\nThis is a header\nThis strategy applies beyond Bayes' Theorem. For example here is a version of the Law of Total\nProbability when X is continuous and N is discrete:\nf(X=x)=\u2211f(X=x|N =n)P(N =n)\nn\u2208N\nProbability Rules with Continuous Random Variables\nThe strategy used in the above section can be used to derive the rules of probability in the presence of\ncontinuous random variables. The strategy also works when there are multiple continuous random\nvariables. For example here is Bayes' Theorem with two continuous random variables.\nDef: Bayes' Theorem with continuous random variables.\nLet X and Y be continuous random variables.\nf(X=x,Y =y)\nf(X=x|Y =y)=\nf(Y =y)\nExample: Inference with a Continuous Variable\nConsider the following question:\nQuestion: At birth, girl elephant weights are distributed as a Gaussian with mean 160kg, and standard\ndeviation 7kg. At birth, boy elephant weights are distributed as a Gaussian with mean 165kg, and\nstandard deviation of 3kg. All you know about a newborn elephant is that it is 163kg. What is the\nprobability that it is a girl?\nAnswer: Let G be an indicator that the elephant is a girl. G is Bern(p = 0.5) Let X be the distribution of\nweight of the elephant.\nX|G=1 is N(\u03bc=160,\u03c32=72)\nX|G=0 is N(\u03bc=165,\u03c32=32)\nf(X=163|G=1)P(G=1)\nP(G=1|X=163)= Bayes\nf(X=163)\nIf we can solve this equation we will have our answer. What is f(X=163|G=1)? It is the probability\ndensity function of a gaussian X which has \u03bc=160,\u03c32=72 at the point x is 163:\n3\nThis is a header\nf(X=163|G=1)=\n1 e\u22121 2(x\u2212 \u03c3\u03bc)2\nPDFGauss\n\u03c3\u221a2\u03c0\n=\n1 e\u22121 2(163\u2212 7160)2\nPDF X at 163\n7\u221a2\u03c0\nNext we note that P(G=0)=P(G=1)= 1 . Putting this all together, and using the law of total\n2\nprobability to compute the denominator we get:\nP(G=1|X=163)\nf(X=163|G=1)P(G=1)\n=\nf(X=163)\nf(X=163|G=1)P(G=1)\n=\nf(X=163|G=1)P(G=1)+f(X=163|G=0)P(G=0)\n1 e\u22121 2(163\u2212 7160)2 \u22c5 1\n= 7\u221a2\u03c0 2\n1 e\u22121 2(163\u2212 7160)2 \u22c5 1 + 1 e\u22121 2(163\u2212 3165)2 \u22c5 1\n7\u221a2\u03c0 2 3\u221a2\u03c0 2\n1e\u22121 2( 49 9)\n= 7\n1e\u22121 2( 49 9)+ 1e\u22121 2(4 9)2\n7 3\n\u22480.328\n4\nThis is a header\nBayesian Networks\nAt this point in the reader we have developed tools for analytically solving for probabilities. We can\ncalculate the likelihood of random variables taking on values, even if they are interacting with other\nrandom variables (which we have called multi-variate models, or we say the random variables are jointly\ndistributed). We have also started to study samples and sampling.\nConsider the WebMD Symptom Checker. WebMD has built a probabilistic model with random variables\nwhich roughly fall under three categories: symptoms, risk factors and diseases. For any combination of\nobserved symptoms and risk factors, they can calculate the probability of any disease. For example, they\ncan calculate the probability that I have influenza given that I am a 21-year-old female who has a fever\nand who is tired: P(I =1|A=21,G=1,T =1,F =1). Or they could calculate the probability that I\nhave a cold given that I am a 30-year-old with a runny nose: P(C=1|A=30,R=1). At first blush\nthis might not seem difficult. But as we dig deeper we will realize just how hard it is. There are two\nchallenges: (1) Modelling: sufficiently specifying the probabilistic model and (2) Inference: calculating\nany desired probability.\nBayesian Networks\nBefore we jump into how to solve probability (aka inference) questions, let's take a moment to go over\nhow an expert doctor could specify the relationship between so many random variables. Ideally we could\nhave our expert sit down and specify the entire \"joint distribution\" (see the first lecture on multi-variable\nmodels). She could do so either by writing a single equation that relates all the variables (which is as\nimpossible as it sounds), or she could come up with a joint distribution table where she specifies the\nprobability of any possible combination of assignments to variables. It turns out that is not feasible either.\nWhy? Imagine there are N =100 binary random variables in our WebMD model. Our expert doctor\nwould have to specify a probability for each of the 2N >1030 combinations of assignments to those\nvariables, which is approaching the number of atoms in the universe. Thankfully, there is a better way.\nWe can simplify our task if we know the \"generative\" process that creates a joint assignment. Based on\nthe generative process we can make a data structure known as a Bayesian Network. Here are two\nnetworks of random variables for diseases:\nFor diseases the flow of influence is directed. The states of \"demographic\" random variables influence\nwhether someone has particular \"conditions\", which influence whether someone shows particular\n\"symptoms\". On the right is a simple model with only four random variables. Though this is a less\ninteresting model it is easier to understand when first learning Bayesian Networks. Being in university\n(binary) influences whether or not someone has influenza (binary). Having influenza influences whether\nor not someone has a fever (binary) and the state of university and influenza influences whether or not\nsomeone feels tired (also binary).\n1\nThis is a header\nIn a Bayesian Network an arrow from random variable X to random variable Y articulates our\nassumption that X directly influences the likelihood of Y. We say that X is a parent of Y. To fully define\nthe Bayesian network we must provide a way to compute the probability of each random variable (X i)\nconditioned on knowing the value of all their parents:\nP(X i=k|Parentsof X i takeonspecifiedvalues). Here is a concrete example of what needs to be\ndefined for the simple disease model. Recall that each of the random variables is binary:\nP(Uni=1)=0.8\nP(Influenza=1|Uni=1)=0.2 P(Fever=1|Influenza=1)=0.9\nP(Influenza=1|Uni=0)=0.1 P(Fever=1|Influenza=0)=0.05\nP(Tired=1|Uni=0,Influenza=0)=0.1 P(Tired=1|Uni=0,Influenza=1)=0.9\nP(Tired=1|Uni=1,Influenza=0)=0.8 P(Tired=1|Uni=1,Influenza=1)=1.0\nLet's put this in programming terms. All that we need to do in order to code up a Bayesian network is to\ndefine a function: getProbXi(i, k, parents) which returns the probability that X i (the random var\nwith index i) takes on the value k given a value for each of the parents of X i encoded by the list\nparents: P(X i=x i|Valuesofparentsof X i)\nDeeper understanding: The reason that a Bayes Net is so useful is that the \"joint\" probability can be\nexpressed in exponentially less space as the product of the probabilities of each random variable\nconditioned on its parents! Without loss of generality, let X i refer to the ith random variable (such that if\nX i is a parent of X j then i<j):\nP(Joint)=P(X =x ,\u2026,X =x )=\u220fP(X =x|Valuesofparentsof X)\n1 1 n n i i i\ni\nWhat assumptions are implicit in a Bayes Net? Using the chain rule we can decompose the exact joint\nprobability for n random variables. To make the following math easier to digest I am going to use x i as\nshorthand for the event that X i=x i:\nP(x ,\u2026,x )=\u220fP(x|x ,\u2026,x )\n1 n i i\u22121 1\ni\nBy looking at the difference in the two equations, we can see that a Bayes Net is assuming that\nP(x|x ,\u2026,x )=P(x|Valuesofparentsof X)\ni i\u22121 1 i i\nThis is a conditional independence statement. It is saying that once you know the value of the parents of\na variable in your network, X i, any further information about non-descendents will not change your\nbelief in X i. Formally we say that X i is conditionally independent of its non-descendents, given its\nparents. What is a non-descendent again? In a graph, a descendent of X i is anything which is in the\nsubtree that starts at X i. Everything else is a non-descendent. Non-descendents include the \"ancestor\"\nnodes of X i as well as nodes which are totally unconnected to X i. When designing Bayes Nets you don't\nhave to think about this assumption directly. It turns out to be a naturally good assumption if the arrows\nbetween your nodes follow a causal path.\nDesigning a Bayes Net\nThere are several steps to designing a Bayes Net.\n1. Choose your random variables, and make them nodes.\n2. Add edges, often based off your assumptions about which nodes directly cause which others.\n3. Define P(X i=x i|Valuesofparentsof X i) for all nodes.\nAs you might have guessed, we can do step (2) and (3) by hand, or, we can have computers try and\nperform those tasks based on data. The first task is called \"structure learning\" and the second is an\ninstance of \"machine learning.\" There are fully autonomous solutions to structure learning\u2014but they\nonly work well if you have a massive amount of data. Alternatively people will often compute a statistic\ncalled correlation between all pairs of random variables to help in the art form of designing a Bayes Net.\n2\nThis is a header\nIn the next part of the reader we are going to talk about how we could learn\nP(X i=x i|Valuesofparentsof X i) from data. For now let's start with the (reasonable) assumption that\nan expert can write down these functions in equations or as python: getProbXi.\nNext Steps\nGreat! We have a feasible way to define a large network of random variables. First challenge complete.\nWe haven't talked about continuous or multinomial random variables in Bayes Nets. None of the theory\nchanges: the expert will just have to define getProbXi to handle more values of k than 0 or 1.\nA Bayesian network is not very interesting to us unless we can use it to solve different conditional\nprobability questions. How can we perform \"inference\" on a network as complex as a Bayesian network?\n3\nThis is a header\nIndependence in Variables\nDiscrete\nTwo discrete random variables X and Y are called independent if:\nP(X=x,Y =y)=P(X=x)P(Y =y) forall x,y\nIntuitively: knowing the value of X tells us nothing about the distribution of Y. If two variables are not\nindependent, they are called dependent. This is a similar conceptually to independent events, but we are\ndealing with multiple variables. Make sure to keep your events and variables distinct.\nContinuous\nTwo continuous random variables X and Y are called independent if:\nP(X\u2264a,Y \u2264b)=P(X\u2264a)P(Y \u2264b) forall a,b\nThis can be stated equivalently using either the CDF or the PDF:\nF (a,b)=F (a)F (b) forall a,b\nX,Y X Y\nf(X=x,Y =y)=f(X=x)f(Y =y) forall x,y\nMore generally, if you can factor the joint density function then your random variable are independent (or\nthe joint probability function for discrete random variables):\nf(X=x,Y =y)=h(x)g(y)\nP(X=x,Y =y)=h(x)g(y)\nExample: Showing Independence\nLet N be the # of requests to a web server/day and that N \u223cPoi(\u03bb). Each request comes from a human\nwith probability = p or from a \"bot\" with probability = (1\u2013p). Define X to be the # of requests from\nhumans/day and Y to be the # of requests from bots/day. Show that the number of requests from humans,\nX, is independent of the number of requests from bots, Y.\nSince requests come in independently, the probability of X conditioned on knowing the number of\nrequests is a Binomial. Specifically:\n(X|N)\u223cBin(N,p)\n(Y|N)\u223cBin(N,1\u2212p)\nTo get started we need to first write an expression for the joint probability of X and Y. To do so, we use\nthe chain rule:\nP(X=x,Y =y)=P(X=x,Y =y|N =x+y)P(N =x+y)\nWe can calculate each term in this expression. The first term is the PMF of the binomial X|N having x\n\"successes\". The second term is the probability that the Poisson N takes on the value x+y :\nx+y\nP(X=x,Y =y|N =x+y)=( )px(1\u2212p)y\nx\n\u03bbx+y\nP(N =x+y)=e\u2212\u03bb\n(x+y)!\nNow we can put those together we have an expression for the joint:\nx+y \u03bbx+y\nP(X=x,Y =y)=( )px(1\u2212p)ye\u2212\u03bb\nx (x+y)!\n1\nThis is a header\nAt this point we have derived the joint distribution over X and Y. In order to show that these two are\nindependent, we need to be able to factor the joint:\nP(X=x,Y =y)\nx+y \u03bbx+y\n=( )px(1\u2212p)ye\u2212\u03bb\nx (x+y)!\n(x+y)! \u03bbx+y\n= px(1\u2212p)ye\u2212\u03bb\nx!\u22c5y! (x+y)!\n1\n= px(1\u2212p)ye\u2212\u03bb\u03bbx+y Cancel(x+y)!\nx!\u22c5y!\npx\u22c5\u03bbx (1\u2212p)y\u22c5\u03bby\n= \u22c5 \u22c5e\u2212\u03bb Rearrange\nx! y!\nBecause the joint can be factored into a term that only has x and a term that only has y, the random\nvariables are independent.\nSymmetry of Independence\nIndependence is symmetric. That means that if random variables X and Y are independent, X is\nindependent of Y and Y is independent of X. This claim may seem meaningless but it can be very useful.\nImagine a sequence of events X 1,X 2,\u2026. Let A i be the event that X i is a \"record value\" (eg it is larger than\nall previous values). Is A n+1 independent of A n? It is easier to answer that A n is independent of A n+1. By\nsymmetry of independence both claims must be true.\nExpectation of Products\nLemma: Product of Expectation for Independent Random Variables:\nIf two random variables X and Y are independent, the expectation of their product is the product of the\nindividual expectations.\nE[X\u22c5Y]=E[X]\u22c5E[Y] if X and Y areindependent\nE[g(X)h(Y)]=E[g(X)]E[h(Y)] where g and h arefunctions\nNote that this assumes that X and Y are independent. Contrast this to the sum version of this rule\n(expectation of sum of random variables, is the sum of individual expectations) which does not require\nthe random variables to be independent.\n2\nThis is a header\nCorrelation\nCovariance\nCovariance is a quantitative measure of the extent to which the deviation of one variable from its mean\nmatches the deviation of the other from its mean. It is a mathematical relationship that is defined as:\nCov(X,Y)=E[(X\u2212E[X])(Y \u2212E[Y])]\nThat is a little hard to wrap your mind around (but worth pushing on a bit). The outer expectation will be\na weighted sum of the inner function evaluated at a particular (x,y) weighted by the probability of (x,y).\nIf x and y are both above their respective means, or if x and y are both below their respective means, that\nterm will be positive. If one is above its mean and the other is below, the term is negative. If the weighted\nsum of terms is positive, the two random variables will have a positive correlation. We can rewrite the\nabove equation to get an equivalent equation:\nCov(X,Y)=E[XY]\u2212E[Y]E[X]\nLemma: Correlation of Independent Random Variables:\nIf two random variables X and Y are independent, than their covariance must be 0.\nCov(X,Y)=E[XY]\u2212E[Y]E[X] DefofCov\n=E[X]E[Y]\u2212E[Y]E[X] LemmaProductofExpectation\n=0\nNote that the reverse claim is not true. Covariance of 0 does not prove independence.\nUsing this equation (and the product lemma) it is easy to see that if two random variables are independent\ntheir covariance is 0. The reverse is not true in general.\nProperties of Covariance\nSay that X and Y are arbitrary random variables:\nCov(X,Y)=Cov(Y,X)\nCov(X,X)=E[X2]\u2212E[X]E[X]=Var(X)\nCov(aX+b,Y)=aCov(X,Y)\nLet X=X 1+X 2+\u22ef+X n and let Y =Y 1+Y 2+\u22ef+Y m. The covariance of X and Y is:\nn m\nCov(X,Y)=\u2211\u2211Cov(X,Y )\ni j\ni=1 j=1\nn n\nCov(X,X)=Var(X)=\u2211\u2211Cov(X,X )\ni j\ni=1 j=1\nThat last property gives us a third way to calculate variance. We can use it to, again, show how to get the\nvariance of a Binomial.\nCorrelation\nWe left off last class talking about covariance. Covariance was interesting because it was a quantitative\nmeasurement of the relationship between two variables. Today we are going to extend that concept to\ncorrelation. Correlation between two random variables, \u03c1(X,Y) is the covariance of the two variables\nnormalized by the variance of each variable. This normalization cancels the units out:\nCov(X,Y)\n\u03c1(X,Y)=\n\u221aVar(X)Var(Y)\nCorrelation measures linearity between X and Y.\n1\nThis is a header \u03c1(X,Y)=1 Y =aX+b where a=\u03c3 /\u03c3\ny x\n\u03c1(X,Y)=\u22121 Y =aX+b where a=\u2212\u03c3 /\u03c3\ny x\n\u03c1(X,Y)=0 absenceoflinearrelationship\nIf \u03c1(X,Y)=0 we say that X and Y are \"uncorrelated.\"\nWhen people use the term correlation, they are actually referring to a specific type of correlation called\n\"Pearson\" correlation. It measures the degree to which there is a linear relationship between the two\nvariables. An alternative measure is \"Spearman\" correlation which has a formula almost identical to your\nregular correlation score, with the exception that the underlying random variables are first transformed\ninto their rank. \"Spearman\" correlation is outside the scope of CS109.\n2\nThis is a header\nGeneral Inference\nA Bayesian Network gives us a reasonable way to specify the joint probability of a network of many\nrandom variables. Before we celebrate, realize that we still don't know how to use such a network to\nanswer probability questions. There are many techniques for doing so. I am going to introduce you to one\nof the great ideas in probability for computer science: we can use sampling to solve inference questions\non Bayesian networks. Sampling is frequently used in practice because it is relatively easy to understand\nand easy to implement.\nRejection Sampling\nAs a warmup consider what it would take to sample an assignment to each of the random variables in our\nBayes net. Such a sample is often called a \"joint sample\" or a \"particle\" (as in a particle of sand). To\nsample a particle, simply sample a value for each random variable one at a time based on the value of the\nrandom variable's parents. This means that if X i is a parent of X j, you will have to sample a value for X i\nbefore you sample a value for X j.\nLet's work through an example of sampling a \"particle\" for the Simple Disease Model in the Bayes Net\nsection:\n1. Sample from P(Uni=1): Bern(0.8). Sampled value for Uni is 1.\n2. Sample from P(Influenza=1|Uni=1): Bern(0.2). Sampled value for Influenza is 0.\n3. Sample from P(Fever=1|Influenza=0): Bern(0.05). Sampled value for Fever is 0.\n4. Sample from P(Tired=1|Uni=1,Influenza=0): Bern(0.8). Sampled value for Tired is 0.\nThus the sampled particle is: [Uni = 1, Influenza = 0, Fever = 0, Tired = 0]. If we were to run the process\nagain we would get a new particle (with likelihood determined by the joint probability).\nNow our strategy is simple: we are going to generate N samples where N is in the hundreds of thousands\n(if not millions). Then we can compute probability queries by counting. Let N(X=k) be notation for\nthe number of particles where random variables X take on values k. Recall that the bold notation X\nmeans that X is a vector with one or more elements. By the \"frequentist\" definition of probability:\nN(X=k)\nP(X=k)=\nN\nCounting for the win! But what about conditional probabilities? Well using the definition of conditional\nprobabilities, we can see it's still some pretty straightforward counting:\nP(X=a,Y=b) N(X=a,Y=b) N(X=a,Y=b)\nP(X=a|Y=b)= = N =\nP(Y=b) N(Y=b) N(Y=b)\nN\nLet's take a moment to recognize that this is straight-up fantastic. General inference based on analytic\nprobability (math without samples) is hard even given a Bayesian network (if you don't believe me, try to\ncalculate the probability of flu conditioning on one demographic and one symptom in the Full Disease\nModel). However if we generate enough samples we can calculate any conditional probability question\nby reducing our samples to the ones that are consistent with the condition\n(Y\u2192 =\u2192b)\nand then counting how\nmany of those are also consistent with the query (X\u2192 =a\u2192). Here is the algorithm in pseudocode:\nN = 10000\n# \"query\" is the assignment to variables we want probabilities for\n# condition\" is the assignments to variables we will condition on\ndef get_any_probability(query, condition):\nparticles = generate_many_joint_samples(N)\ncond_particles = reject_non_consistent_samples(particles, condition)\nK = count_consistent_samples(cond_particles, query)\nreturn K / len(cond_particles)\n1\nThis is a header\nThis algorithm is sometimes called \"Rejection Sampling\" because it works by generating many particles\nfrom the joint distribution and rejecting the ones that are not consistent with the set of assignments we are\nconditioning on. Of course this algorithm is an approximation, though with enough samples it often\nworks out to be a very good approximation. However, in cases where the event we're conditioning on is\nrare enough that it doesn't occur after millions of samples are generated, our algorithm will not work. The\nlast line of our code will result in a divide by 0 error. See the next section for solutions!\nGeneral Inference when Conditioning on Rare Events\nJoint Sampling is a powerful technique that takes advantage of computational power. But it doesn't\nalways work. In fact it doesn't work any time that the probability of the event we are conditioning is rare\nenough that we are unlikely to ever produce samples that exactly match the event. The simplest example\nis with continuous random variables. Consider the Simple Disease Model. Let's change Fever from being\na binary variable to being a continuous variable. To do so the only thing we need to do is re-specify the\nlikelihood of fever given assignments to its parents (influenza). Let's say that the likelihoods come from\nthe normal PDF:\nifInfluenza=0,thenFever\u223cN(\u03bc=98.3,\u03c3=0.7)\n\u2234f(Fever=x)=\n1 e\u2212(x\u221298.3)2\n2\u22c50.7\n\u221a2\u03c0\u22c50.7\nifInfluenza=1,thenFever\u223cN(\u03bc=100.0,\u03c3=1.8)\n\u2234f(Fever=x)=\n1 e\u2212(x\u2212100.0)2\n2\u22c51.8\n\u221a2\u03c0\u22c51.8\nDrawing samples (aka particles) is still straightforward. We apply the same process until we get to the\nstep where we sample a value for the Fever random variable (in the example from the previous section\nthat was step 3). If we had sampled a 0 for influenza we draw a value for fever from the normal for\nhealthy adults (which has \u03bc=98.3). If we had sampled a 1 for influenza we draw a value for fever from\nthe normal for adults with the flu (which has \u03bc=100.0). The problem comes in the \"rejection\" stage of\njoint sampling.\nWhen we sample values for fever we get numbers with infinite precision (eg 100.819238 etc). If we\ncondition on someone having a fever equal to 101 we would reject every single particle. Why? No\nparticle will have exactly a fever of 101.\nThere are several ways to deal with this problem. One especially easy solution is to be less strict when\nrejecting particles. We could round all fevers to whole numbers.\nThere is an algorithm called \"Likelihood Weighting\" which sometimes helps, but which we don't cover in\nCS109. Instead, in class we talked about a new algorithm called Markov Chain Monte Carlo (MCMC)\nthat allowed us to sample from the \"posterior\" probability: the distribution of random variables after\n(post) us fixing variables in the conditioned event. The version of MCMC we talked about is called Gibbs\nSampling. While I don't require that students in CS109 know how to implement Gibbs Sampling, I\nwanted everyone to know that it exists and that it isn't beyond your capabilities. If you need to use it, you\ncan learn it given the knowledge you have now.\nMCMC does require more math than Joint Sampling. For every random variable you will need to specify\nhow to calculate the likelihood of assignments given the variable's: parents, children and parents of its\nchildren (a set of variables cozily called a \"blanket\"). Want to learn more? Take CS221 or CS228!\nThoughts\nWhile there are slightly-more-powerful \"general inference algorithms\" that you will get to learn in the\nfuture, it is worth recognizing that at this point we have reached an important milestone in CS109. You\ncan take very complicated probability models (encoded as Bayesian networks) and can answer general\ninference queries on them. To get there we worked through the concrete example of predicting disease.\nWhile the WebMD website is great for home users, similar probability models are being used in\nthousands of hospitals around the world. As you are reading this general inference is being used to\n2\nThis is a header\nimprove health care (and sometimes even save lives) for real human beings. That's some probability for\ncomputer scientists that is worth learning. What if we don't have an expert? Could we learn those\nprobabilities from data? Jump to part 5 to answer that question.\n3\nThis is a header\nFairness in Artificial Intelligence\nArtificial Intelligence often gives the impression that it is objective and \"fair\". However, algorithms are\nmade by humans and trained by data which may be biased. There are several examples of deployed AI\nalgorithms that have been shown to make decisions that were biased based on gender, race or other\nprotected demographics \u2014 even when there was no intention for it.\nThese examples have also led to a necessary research into a growing field of algorithmic fairness. How\ncan we demonstrate, or prove, that an algorithm is behaving in a way that we think is appropriate? What\nis fair? Clearly these are complex questions and are deserving of a complete conversation. This example\nis simple for the purpose of giving an introduction to the topic.\nML stands for Machine Learning. Solon Barocas and Moritz Hardt, \"Fairness in Machine Learning\",\nNeurIPS 2017\nWhat is Fairness?\nAn artificial intelligence algorithm is going to be used to make a binary prediction (G for guess) for\nwhether a person will repay a loan. The question has come up: is the algorithm \"fair\" with respect to a\nbinary protected demographic (D for demographic)? To answer this question we are going to analyze\npredictions the algorithm made on historical data. We are then going to compare the predictions to the\ntrue outcome (T for truth). Consider the following joint probability table from the history of the\nalgorithm\u2019s predictions:\nD=0 D=1\nG=0 G=1 G=0 G=1\nT =0 0.21 0.32 T =0 0.01 0.01\nT =1 0.07 0.28 T =1 0.02 0.08\nRecall that cell D=i,G=j,T =k contains the probability P(D=i,G=j,T =k). A joint\nprobability table gives the probability of all combination of events. Recall that since each cell is mutually\nexclusive, the \u2211 \u2211 \u2211 P(D=i,G=j,T =k)=1. Note that this assumption of mutual exclusion\ni j k\ncould be problematic for demographic variables (some people are mixed ethnicity, etc) which gives you a\nhint that we are just scratching the surface in our conversation about fairness. Let's use this joint\nprobability to learn about some of the common definitions of fairness.\nPractice with joint marginalization\nWhat is P(D=0)? What is P(D=1)?\nProbabilities with assignments to a subset of the random variables in the joint distribution can be\ncalculated by a process called marginalization: sum the probability from all cells where that assignment\nis true.\n1\nThis is a header P(D=1)= \u2211 \u2211 P(D=1,G=j,T =k)\nj\u2208{0,1}k\u2208{0,1}\n=0.01+0.01+0.02+0.08=0.12\nP(D=0)= \u2211 \u2211 P(D=0,G=j,T =k)\nj\u2208{0,1}k\u2208{0,1}\n=0.21+0.32+0.07+0.28=0.88\nNote that P(D=0)+P(D=1)=1. That implies that the demographics are mututally exclusive.\nFairness definition #1: Parity\nAn algorithm satisfies \u201cparity\u201d if the probability that the algorithm makes a positive prediction (G = 1) is\nthe same regardless of being conditioned on demographic variable.\nDoes this algorithm satisfy parity?\nP(G=1,D=1)\nP(G=1|D=1)= Cond.Prob.\nP(D=1)\nP(G=1,D=1,T =0)+P(G=1,D=1,T =1)\n= Probor\nP(D=1)\n0.01+0.08\n= =0.75 Fromjoint\n0.12\nP(G=1,D=0)\nP(G=1|D=0)= Cond.Prob.\nP(D=0)\nP(G=1,D=0,T =0)+P(G=1,D=0,T =1)\n= Probor\nP(D=0)\n0.32+0.28\n= \u22480.68 Fromjoint\n0.88\nNo. Since P(G=1|D=1)\u2260P(G=1|D=0) this algorithm does not satisfy parity. It is more likely\nto guess 1 when the demographic indicator is 1.\nFairness definition #2: Calibration\nAn algorithm satisfies \u201ccalibration\u201d if the probability that the algorithm is correct (G=T) is the same\nregardless of demographics.\nDoes this algorithm satisfy calibration?\nThe algorithm satisfies calibration if P(G=T|D=0)=P(G=T|D=1)\nP(G=T|D=0)=P(G=1,T =1|D=0)+P(G=0,T =0|D=0)\n0.28+0.21\n= \u22480.56\n0.88\nP(G=T|D=1)=P(G=1,T =1|D=1)+P(G=0,T =0|D=1)\n0.08+0.01\n= =0.75\n0.12\nNo: P(G=T|D=0)\u2260P(G=T|D=1)\nFairness definition #3: Equality of Odds\nAn algorithm satisfies \"equality of odds\" if the probability that the algorithm predicts a positive outcome\n(G=1) is the same regardless of demographics given that the outcome will occur (T =1).\nDoes this algorithm satisfy equality of odds?\nThe algorithm satisfies equality of odds if P(G=1|D=0,T =1)=P(G=1|D=1,T =1)\n2\nThis is a header P(G=1,D=1,T =1)\nP(G=1|D=1,T =1)=\nP(D=1,T =1)\n0.08\n= =0.8\n0.08+0.02\nP(G=1,D=0,T =1)\nP(G=1|D=0,T =1)=\nP(D=0,T =1)\n0.28\n= =0.8\n0.28+0.07\nYes: P(G=1|D=0,T =1)=P(G=1|D=1,T =1)\nWhich of these definitions seems right to you? It turns out, it can actually be proven that these three\ncannot be jointly optimized, and this is called the Impossibility Theorem of Machine Fairness. In other\nwords, any AI system we build will necessarily violate some notion of fairness. For a deeper treatment of\nthe subject, here is a useful summary of the latest research Pessach et al. Algorithmic Fairness.\nGender Shades\nIn 2018, Joy Buolamwini and Timnit Gebru had a breakthrough result called \"gender shades\" published\nin the first conference on Fairness, Accountability and Transparency in ML [1]. They showed that facial\nrecognition algorithms, which had been deployed to be used by Facebook, IBM and Microsoft, were\nsubstantially better at making predicitons (in this case classifying gender) when looking at lighter skinned\nmen than darker skinned women. Their work exposed several shortcomings in production AI: biased\ndatasets, optimizing for average accuracy (which means that the majority demographic gets most weight)\nlack of awareness of intersectionality, and more. Let's take a look at some of their results.\nFigure by Joy Buolamwini and Timnit Gebru. Facial recognition algorithms perform very differently\ndepending on who they are looking at. [1]\nTimnit and Joy looked at three classifiers trained to predict gender, and computed several statistics. Let's\ntake a look at one statistic, accuracy, for one of the facial recognition classifiers, IBMs:\nWomen Men Darker Lighter\nAccuracy 79.7 94.4 77.6 96.8\nUsing the language of fairness, accuracy measures P(G=T). The cell in the table above under\n\"Women\" says the accuracy when looking at photos of women P(G=T|D=Women). It is easy to\nshow that these production level systems are terribly \"uncalibrated\":\nP(G=T|D=Woman)\u2260P(G=T|D=Man)\nP(G=T|D=Lighter)\u2260P(G=T|D=Darker)\n3\nThis is a header\nWhy should we care about calibration and not the other definitions of fairness? In this case the classifier\nwas making a prediction of gender where a positive prediction (say predicting women) doesn't have a\ndirectly associated reward as in our above example, where we were predicting if someone should receive\na loan. As such the most salient idea is: is the algorithm just as accurate for different genders\n(calibration)?\nThe lack of calibration between men/women and lighter/darker skinned photos is an issue. What Joy and\nTimnit showed next was that the problem becomes even worse when you look at intersectional\ndemographics.\nDarker Men Darker Women Lighter Men Lighter Women\nAccuracy 88.0 65.3 99.7 92.9\nIf the algorithms were \"fair\" according to the calibration you would expect the accuracy to be the same\nregardless of demographics. Instead there is almost a 34.2 percentage point difference!\nP(G=T|D=DarkerWoman) = 65.3 compared to P(G=T|D=LigherMan)=99.7\n[1] Buolamwini, Gebru. Gender Shades. 2018\nWays Forward?\nWadsworth et al. Achieving Fairness through Adversarial Learning\n4\nThis is a header\nFederalist Paper Authorship\nLet's write a program to decide whether or not James Madison or Alexander Hamilton wrote Federalist\nPaper 49. Both men have claimed to have written it, and hence the authorship is in dispute. First we used\nhistorical essays to estimate p i, the probability that Hamilton generates the word i (independent of all\nprevious and future choices of words). Similarly we estimated q i, the probability that Madison generates\nthe word i. For each word i we observe the number of times that word occurs in Federalist Paper 49 (we\ncall that count c i). We assume that, given no evidence, the paper is equally likely to be written by\nMadison or Hamilton.\nDefine three events: H is the event that Hamilton wrote the paper, M is the event that Madison wrote the\npaper, and D is the event that a paper has the collection of words observed in Federalist Paper 49. We\nwould like to know whether P(H|D) is larger than P(M|D). This is equivalent to trying to decide if\nP(H|D)/P(M|D) is larger than 1.\nThe event D|H is a multinomial parameterized by the values p. The event D|M is also a multinomial,\nthis time parameterized by the values q.\nUsing Bayes Rule we can simplify the desired probability.\nP(D|H)P(H)\nP(H|D) P(D|H)P(H) P(D|H)\nP(D)\n= = =\nP(M|D) P(D|M)P(M) P(D|M)P(M) P(D|M)\nP(D)\n=\n( c1,c2,n \u2026,cm)\u220f ipc ii\n=\n\u220f ipc ii\n( n )\u220f qci \u220f qci\nc1,c2,\u2026,cm i i i i\nThis seems great! We have our desired probability statement expressed in terms of a product of values we\nhave already estimated. However, when we plug this into a computer, both the numerator and\ndenominator come out to be zero. The product of many numbers close to zero is too hard for a computer\nto represent. To fix this problem, we use a standard trick in computational probability: we apply a log to\nboth sides and apply some basic rules of logs.\nP(H|D) \u220f pci\nlog( )=log( i i )\nP(M|D) \u220f qci\ni i\n=log(\u220fpci)\u2212log(\u220fqci)\ni i\ni i\n=\u2211log(pci)\u2212\u2211log(qci)\ni i\ni i\n=\u2211clog(p)\u2212\u2211clog(q)\ni i i i\ni i\nThis expression is \"numerically stable\" and my computer returned that the answer was a negative\nnumber. We can use exponentiation to solve for P(H|D)/P(M|D). Since the exponent of a negative\nnumber is a number smaller than 1, this implies that P(H|D)/P(M|D) is smaller than 1. As a result, we\nconclude that Madison was more likely to have written Federalist Paper 49. That is the standing\nassumption currently made by historians!\n1\nThis is a header\nName to Age\nBecause of shifting patterns in name popularity, a person's name is a hint as to their age. The United\nStates publishes a data which contains counts of how many US residents were born with a given name in\na given year, based off Social Security applications. We can use inference to compute the reverse\nprobability distribution: an updated belief in a person's age, given their name. As a reminder, if I know\nthe year someone was born, I can calculate their age within one year.\nQuery Name: Katherine\nRecords with name: 589753\nThis demo is based on real data from US Social Security applications between 1914 and 2014. Thank you\nto https://www.kaggle.com/kaggle/us-baby-names for compiling the data. Download Data .\nComputation\nThe US Social Security applications data provides you with a function: count(year, name) which\nreturns the number of US citizens, born in a given year with a given name. You also have access to a list\nnames which has each name ever given in the US and years which has all the years. This function is\nimplicitly giving us the joint probability over names and birth year. The probability of a joint assignment\nto name and birth year can be estimated as the count of people with that name, born on that year, over the\ntotal number of people in the dataset. Let B be the year someone is born, and let N be their name. We\nwill use k to denote the number of entries in the dataset:\ncount(b,n)\nP(B=b,N =n)\u2248\nk\nThe question we would really like to answer is: what is your belief that a resident was born in 1950,\ngiven that their name is Gary?\nWe can get started by applying the definition of conditional probability for random variables:\nP(N =Gary,B=1950)\nP(B=1950|N =Gary)=\nP(N =Gary)\nNote: Bayes' Theorem is a more typical choice for inference tasks like this one. However, in this case its\nwas necessary because it is easier to compute P(B=b,N =n) than P(N =n|B=b). That is why we\nused the definition of conditional probability instead. The conditional probability approach this leaves one\nterm to compute: P(N =Gary) which we can compute using marginalization:\n1\nThis is a header P(N =Gary)= \u2211 P(B=y,N =Gary)\ny\u2208years\ncount(y,Gary)\n\u2248 \u2211\nk\ny\u2208years\nPutting this all together we have:\nP(N =Gary,B=1950)\nP(B=1950|N =Gary)=\nP(N =Gary)\n(count(1950,Gary))\nk\n\u2248\n\u2211 count(y,Gary)\n(y\u2208years )\nk\ncount(1950,Gary)\n\u2248\n\u2211 count(y,Gary)\ny\u2208years\nMore generally, for any name, we can compute the conditional probability mass function over birth year\nB:\ncount(b,n)\nP(B=b|N =n)\u2248\n\u2211 count(y,n)\ny\u2208years\nFrom Birth Year to Age\nOf course, if B is the birth year of a person, their age, A is approximately the current year minus B. This\ncould be off by one if someone has a birth day later in the year, but we will ignore this small deviation for\nnow. So for example, if we think that a person was born in 1988, since the current year is 2024 then their\nage is 2024 - 1988 = 36\nAssumptions\nThis problem makes many assumptions which are worth highlighting. In fact, any time we make\ngeneralizations (especially about demographics) based on sparse information we should tread lightly.\nHere are the assumptions that I can think of:\n1. This data only is accurate for names of people in the US. The probability of age given names could be\nvery different in other countries.\n2. The US census is not perfect. It does not capture all people who are resident in the US, and there are\ndemographics which are underrepresented. This will also skew our results.\nNames that Give Away Your Age\nSome names have certain years where they were exceptionally popular. These names provide quite a lot\nof information about birth year. Let's look at some of the names with the highest max probability.\nMedium Popularity (>10,000 people with the name)\nName Age with max prob Prob of most likely age\nKatina 49 0.245\nMarquita 38 0.233\nAshanti 19 0.250\nMiley 13 0.250\nAria 7 0.247\nHigh Popularity (>100,000 people with the name)\nName Age with max prob Prob of most likely age\nDebbie 62 0.104\n2\nThis is a header\nName Age with max prob Prob of most likely age\nWhitney 35 0.098\nChelsea 29 0.103\nAidan 18 0.098\nAddison 14 0.112\nA search for \"Katina 1972\" brought up this interesting article about a baby named Katina in a 1972 CBS\nSoap Opera. Marquita's popularity was likely from a 1983 toothpase add. Ashanti Douglas and Miley\nCirus were popular singers in 2002 and 2008 respectively.\nFuther Reading\nSome names don't seem to have enough data to make good probability estimates. Can we quantify our\nuncertainty in such probability estimates? For example, if a name has only 10,000 entries in the database,\nof which only 100 were born in the year 1950, how confident are we that the true probability for 1950 is\n100 =0.01? One way to express our uncertainty would be through a Beta Distribution. In this scenario\n10000\nwe could represent our belief in the probability for 1950 as X\u223cBeta(a=101,b=9901) reflecting\nthat we have seen 100 people born in 1950 and 9900 people who were not. We can plot that belief,\nzoomed into the range [0, 0.03]:\nWe can now ask questions such as, what is the probability that X is within 0.002 of 0.01?\nP(0.008<X<0.012)\n=P(X<0.012)\u2212P(X<0.008)\n=F (0.012)\u2212F (0.008)\nX X\n=0.966\u22120.013\n=0.953\nSemantically this leads to the claim that, after observing 100 births with a name in 1950, out of 10,000\nbirths with that name over the whole dataset, there is a 95% chance that the probability of someone being\nborn in 1950 is 0.010 \u00b1 0.002.\n3\nThis is a header\nProbability and Babies\nThis demo used to be live. We now know that the delivery happened on Jan 23rd. Lets go back in time\nto Jan 1st and see what the probability looked like at that point.\nWhat is the probability that Laura gives birth today (given that she hasn't given birth up until today)?\nToday's Date 1/Jan/2021\nDue Date 18/Jan/2021\nProbability of delivery today: 0.014\nProbability of delivery in next 7 days: 0.144\nCurrent days past due date: -17 days\nUnconditioned probability mass before today: 0.128\nHow likely is delivery, in humans, relative to the due date? There have been millions of births which\ngives us a relatively good picture [1]. The length of human pregnancy varies by quite a lot! Have you\nheard that it is 9 months? That is a rough, point estimate. The mean duration of pregnancy is 278.6 days,\nand pregnancy length has a standard deviation (SD) of 12.5 days. This distribution is not normal, but\nroughly matches a \"skewed normal\". This is a general probability mass function for the first pregnancy\ncollected from hundreds of thousands of women (this PMF is very similar across demographics, but\nchanges based on whether the woman has given birth before):\nOf course, we have more information. Specifically, we know that Laura hasn't given birth up until today\n(we will update this example when that changes). We also know that babies which are over 14 days late\nare \"induced\" on day 14. How likely is delivery given that we haven't delivered up until today? Note that\nthe y-axis is scalled differently:\n1\nThis is a header\nLet's approach this problem formally using inference. First we introduce a random variable D to\nrepresent the days after delivery that the baby is born. Note that D can be negative if the baby is due\nbefore the due date. We can use Inference to update our belief in D given our observation that we have\nnot delivered yet:\nP(NoBabyYet|D=i)P(D=i)\nP(D=i|NoBabyYet)=\nP(NoBabyYet)\nP(NoBabyYet|D=i) is always either 1 or 0. Note that conditioning on D=i means we are being\ntold the actual date of delivery. If the delivery hasn't happened yet (eg today is before i) then the\nprobability of No Baby Yet is 1. If the delivery has already happened (eg today is after i) then the\nprobability of No Baby Yet is 0.\nP(D=i) is our prior belief (the probability of delivery dates based off historical data).\nP(NoBabyYet) is the normalization constant. Instead of calculating it explicity, we can compute the\nnumerators for each value of i. We can then normalize the distribution (compute the sum of the\nnumerators, and divide every probability by this sum) in order to implicitly compute it. An equivalent\n(but more compute heavy) solution would be to expand P(NoBabyYet) using the law of total\nprobability:\nP(NoBabyYet)=\u2211P(NoBabyYet|D=i)P(D=i)\ni\nHow do we deal with the fact that babies are induced after D=14? Well we can adjust our prior so that\nall of the probability for days 14 and on is shifted to day 14. This is equivalent to the following\ncalculation:\nP(D=14)=\u2211P(D=i)\ni\u226514\n2\nThis is a header\ndef update_belief_baby(prior, today = -19):\n# pr_D[i] is P(D = i| No Baby Yet).\npr_D = {}\nmin_i = -50\nmax_i = 14\nfor i in range(min_i, max_i + 1):\n# P(NoBaby | D = i)\nlikelihood = 0 if i < today else 1\npr_D[i] = likelihood * prior[i]\n# implicitly computes the LOTP\nnormalize(pr_D)\nreturn pr_D\ndef normalize(unormalized_pmf):\ntotal_sum = sum(unormalized_pmf.values())\nnormalized = {}\nfor key, value in unormalized_pmf.items():\nnormalized[key] = value / total_sum\nreturn normalized\nExtension Problem\nChris had two other good friends who had babies with the exact same due date (Really! This actually\nhappened). What is the probability that all three babies are delivered on the exact same day?\nProbability of three couples on the same day: 0.002\nHow did we get that number? Let p i be the probability that one baby is delivered on day i -- this number\ncan be read off the probability mass function. Let D i be the event that all three babies are delivered on\nday i. Note that the event D i is mutually exclusive with the event that all three babies are born on\nanother day (So for example, D 1 is mutually exclusive with D 2, D 3 etc). Let N =3 be the event that all\nbabies are born on the same day:\nP(N =3)=\u2211P(D) Sincedaysaremutuallyexclusive\ni\ni\n=\u2211p3 Sincethethreecouplesareindependent\ni\ni\n[1] Predicting delivery date by ultrasound and last menstrual period in early gestation\nAcknowledgements: This problem was first posed to me by Chris Gregg.\n3\nThis is a header\nBayesian Carbon Dating\nWe are able to know the age of ancient artefacts using a process called carbon dating. This process\ninvolves a lot of uncertainty! You observe a measurement of 90% of natural C14 molecules in a sample.\nWhat is your belief distribution over the age of the sample? This task requires probabilistic models\nbecause we have to think about two random variables together: the age A of the sample, and M the\nremaining C14 molecules.\nCarbon Dating Demo\nImagine you have just taken a sample from your artifact. For the sample size you took, a living organism\nwould have had 1000 molecules of C14. Use this demo to explore the relationship between how much\nC14 is left and your belief ditribution for how old your artifact is.\nRemaining C14: 900\nNote: this demo was created in 2023 and the age reported is relative to that year! This chapter only has\nhistorical C14 rates from 10,000 years ago and as such is not able to estimate age when there are fewer\nthan 350 molecules of C14 in the sample.\n1\nThis is a header\nCarbon dating allows us to know the age of things that used to be alive, like dinosaur bones.\nUnderstanding Decay of C14 molecule\nAll living things have a constant proportion of a radioactive molecule called C14 in them. When living\nthings die those molecules start to decay radioactively. Specifically, the time to decay in years, T, of a\nsingle C14 molecule is distributed as an exponential, T \u223cExp(\u03bb=1/8267) where 8267 is the mean life\nof C14.\nConsider a single C14 molecule. What is the probability that it decays within 750 years?\nP(T \u2264750)=1\u2212e\u2212\u03bb\u22c5750 Exp.CDF\n=1\u2212e\u2212 1 \u22c5750\n8267\n=0.0867\nThat is only for a single molecule. Since C14 molecules decay independently, it is not much harder to\nthink of how many are left out of a larger initial count of C14. A particular sample started with 1000\nmolecules. What is the probability that exactly 900 are left after 750 years? This is equivalently to the\nevent that 100 molecules have decayed.\nX\u223cBin(n=1000,p=0.0867)\n1000\nP(X=100)=( )0.0867100(1\u22120.0867)900\n100\n\u22480.0144\nLet's generalize. Define M to be a random variable for the number of molecules left, and A to be the age\nof the sample. The probability P(M =m|A=i) of having m remaining C14 molecules given that the\nartifact is i years old will be equal to P(X=n\u2212m) where n is the starting number of C14 molecules,\np=1\u2212e\u2212i/8267 and X\u223cBin(n,p) is the count of decayed C14 molecules.\n2\nThis is a header\nInferring Age From C14\nYou observe a measurement of 900 C14 molecules in a sample. You assume that the sample originally\nhad 1000 C14 molecules when it died. Infer P(A=i|M =900) where A=i is the event that the\nsample organism died i years ago. Note that age is a discrete random variable which takes on whole\nnumbers of years. You will need use P(M =m|A=i) from the previous part.\nFor your prior belief you know that the sample must be between A=100 and A=10000 inclusive and\nyou assume that every year in that range is equally likely.\nThis is a perfect case for Bayes theorem. However instead of updating our belief in an event, like we did\nin Part 1, we are updating the belief over all the values that a random variable can take on, a process\ncalled inference. Here is the generalized version of Bayes' theorem for infering age, A:\nP(M =900|A=i)P(A=i)\nP(A=i|M =900)=\nP(M =900)\nP(A=i)\n=P(M =900|A=i)\u22c5\nP(M =900)\n=P(M =900|A=i)\u22c5K\nThe critical part of the last line was to recognize that P(A=i) is a constant with respect to i. The term\nP(M=900)\nP(A=i) is constant as our prior over A was uniform. We could compute the value of P(M =900)\nexplicitely using the law of total probability. In code this is most easily implemented by computing all\nvalues of P(M =900|A=i) and normalizing as K will be the value that makes all of the values\nP(A=i|M =900) sum to 1.\nFluctuating History\nThe amount of C14 in the atmosphere fluctuates over time; it is not a constant baseline! Here is the delta\nC14 (per 1000 molecules) that you would have found if the object died different number of years ago. To\nincorporate this information we simply start our binomial with 1000 molecules plus the delta for the year,\ndownloaded from a public dataset [1]:\nThis offset is archeology theory not probability theory. We include it in this chapter because otherwise\nour code will give an incorrect preiction. Also, it gives the posterior a really interesting shape (see the\ndemo).\nPython Code\nThe math, derived above, leads to the following python code for a function inference(m) which returns\nthe probability mass function for age A, given an observation of m C14 molecules in a sample that\nshould have 1000 molecules, were it alive today. Notice the use of normalization to avoid explicitely\ncomputing the prior or P(M =m) from Bayes Theorem.\n3\nThis is a header\nfrom scipy import stats\nimport math\nC14_MEAN_LIFE = 8267\ndef inference(m = 900):\n\"\"\"\nReturns a dictionary A, where A[i] contains the\ncorresponding probability, P(A = i| M = m).\nm is the number of C14 molecules remaining and i\nis age in years. i is in the range 100 to 10000\n\"\"\"\nA = {}\nfor i in range(100,10000+1):\nA[i] = calc_likelihood(m, i) # P(M = m | A = i)\n# implicitly computes the normalization constant\nnormalize(A)\nreturn A\ndef calc_likelihood(m, age):\n\"\"\"\nComputes P(M = m | A = age), the probability of\nhaving m molecules left given the sample is age\nyears old. Uses the exponential decay of C14\n\"\"\"\nn_original = 1000 + delta_start(age)\nn_decayed = n_original - m\np_single = 1 - math.exp(-age/C14_MEAN_LIFE)\nreturn stats.binom.pmf(n_decayed, n_original, p_single)\ndef normalize(prob_dict):\n# first compute the sum of the probability\nsum = 0\nfor key, pr in prob_dict.items():\nsum += pr\n# then divide each probability by that sum\nfor key, pr in prob_dict.items():\nprob_dict[key] = pr / sum\n# now the probabilities sum to 1 (aka are normalized)\ndef delta_start(age):\n\"\"\"\nThe amount of atmospheric C14 is not the same every\nyear. If the sample died \"age\" years ago, then it would\nhave started with slightly more, or slightly less than\n1000 C14 molecules. We can look this value up from the\nIntCal database. See the next section!\n\"\"\"\nreturn historical_c14_delta[age]\nIndustry Strength Bayesian Carbon Dating\nThere are other sources of uncertainty in Carbon Dating which we have not considered. For example a\ncommon source of uncertainty is laboraty error: if the same sample were sent to a lab several times,\ndifferent results would come back.\nPerhaps the most fascinating extension is modelling \"stratigraphic\" relationships. Often in archeological\nsites, you can know relative age of artifacts based on their position in sediment. This requires a joint\nmodel of the age of each artifact with the constraint that you *know* some are older than others.\nInference can then be performed using a General Inference technique (often MCMC) and will be much\nmore accurate.\n4\nThis is a header\nBinomial Approximations?\nCould we have used an approximation for the binomial PMF calculation? In Bayesian Carbon dating\nboth a normal and a poisson approximation are appropriate. The decay binomial X\u223cBin(n,p) is well\napproximated by either a Poisson with \u03bb=n\u22c5p or a Gaussian with \u03bc=n\u22c5p and \u03c32=n\u22c5p\u22c5(1\u2212p).\nThis could be used to speed up calculations. Let's rework the example where we had\nX\u223cBin(n=1000,p=0.0867). We computed that P(X=100)=0.0144\nPoisson Approximation:\nY \u223cPoi(\u03bb=86.7)\nP(X=100)\u2248P(Y =100)\n=scipy.stats.poi.pmf(100,86.7)\n\u22480.0151\nNormal Approximation:\nY \u223cN(\u03bc=86.7,\u03c32=79.2)\nP(X=100)\u2248P(Y >100.5)\u2212P(Y >99.5)\n\u22480.0146\n[1] IntCal Historical Atmospheric C14\n5\nThis is a header\nDigital Vision Test\nThe Story: This problem was initially posed as a CS109 Final exam problem in Spring 2017. This\ngrew into a collaboration with a former student, Ali Malik, as well as a Stanford Ophthalmology\ndoctor Charles Lin. We realized that it was actually a much more accurate way of measuring visual\nacuity. The algorithm, which is called the Stanford Acuity Test, or StAT, has since been published as\nan article for AAAI and covered by Science Magazine and The Lancet. To the best of our knowledge,\nthe algorithm is still the most acurate way to infer ability to see from an optotype based test.\nYou can find a demo of the Stanford Acuity Test here: https://myeyes.ai/. Look out for the bar icon \uf012 to\nsee the belief distribution change as the test progresses.\nDigital Vision Tests\nThe goal of a digital vision test is to estimate how well a patient can see. You can give the patient a series\nof vision tests, observe their responses and then based on those responses eventually make your\ndiagnosis. In this chapter we consider the Tumbling E tasks. The patient is presented an E at a chosen\nfont size. The E will be randomly written up, down, left or right and the patient must say which direction\nit is facing. Their guess will either be correct, or incorrect. The patient will have a series of 20 of these\ntasks. Vision tests as useful for people who need glasses, but can be critical for folks with eye disease\nwho need to closely monitor for subtle decreases in vision.\nThere are two primary tasks in a digital vision test: (1) based on the patient responses, infer their ability\nto see and (2) select the next font size to show to the patient.\nHow to Represent Ability to See?\nAbility is a random variable! We define A to represent the ability of someone to see. A takes on values\nbetween 0.0 (representing legal blindness) and 1.0 (representing standard vision). While ability to see is\nin theory a continuous random variable, we are going to represent ability to see as discretized into one\nhundreths. As such A\u2208{0.00,0.01,\u2026,0.99}. As a small aside, visual acuity can be represented in\nmany different units (such as a log based unit called LogMAR). We chose this 0 to 1 scale as it makes the\nmath easier to explain.\nThe prior probability mass function for A, written as P(A=a), represents our belief that A takes on the\nvalue of a, before we have seen any observations about the patient. This prior belief comes from the\nnatural distribution of how well people can see. To make our algorithm most accurate, the prior should\nbest reflect our patient population. Since our eye test is built for doctors in an eye hospital, we used\nhistorical data from eye hospital visits to build our prior. Here is P(A=a) as a graph:\nThe prior belief on ability to see\n1\nThis is a header\nHere is that exact same probability mass function written as a table. A table representation is possible\nbecause of our choice to discretize A. In code we can access P(A=a) as a dictionary lookup,\nbelief[a] where belief stores the whole probability mass function:\na P(A=a) a P(A=a) a P(A=a)\n0.00 0.0020 0.20 0.0037 \u22ef\n0.01 0.0021 0.21 0.0038 0.81 0.0171\n0.02 0.0021 0.22 0.0040 0.82 0.0173\n0.03 0.0022 0.23 0.0041 0.83 0.0175\n0.04 0.0023 0.24 0.0042 0.84 0.0177\n0.05 0.0023 0.25 0.0043 0.85 0.0180\n0.06 0.0024 0.26 0.0045 0.86 0.0181\n0.07 0.0025 0.27 0.0046 0.87 0.0183\n0.08 0.0026 0.28 0.0048 0.88 0.0185\n0.09 0.0026 0.29 0.0049 0.89 0.0186\n0.10 0.0027 0.30 0.0050 0.90 0.0188\n0.11 0.0028 0.31 0.0052 0.91 0.0189\n0.12 0.0029 0.32 0.0054 0.92 0.0190\n0.13 0.0030 0.33 0.0055 0.93 0.0191\n0.14 0.0031 0.34 0.0057 0.94 0.0192\n0.15 0.0032 0.35 0.0058 0.95 0.0192\n0.16 0.0033 0.36 0.0060 0.96 0.0192\n0.17 0.0034 0.37 0.0062 0.97 0.0193\n0.18 0.0035 0.38 0.0064 0.98 0.0192\n0.19 0.0036 0.39 0.0066 0.99 0.0192\nObservations\nOnce the patient starts the test, you will begin collecting observations. Consider this first observation,\nobs 1 where the patient was shown a letter with font size 0.7 and answered the question incorrectly:\nWe can represent this observation as a tuple with font size and correctness. Mathematically this could be\nwritten as obs 1=[0.7,False]. In code this observation could be stored as a dictionary\n2\nThis is a header\nobs_1 = {\n\"font_size\":0.7,\n\"is_correct\":False\n}\nEventually we will have 20 of these observations: [obs 1,obs 2,\u2026,obs 20].\nInfering Ability\nOur first major task is to write code which can update our probability mass function for A based on\nobservations. First let us consider how to update our belief in ability to see from a single observation, obs\n(aside: formally this the event that random variable Obs takes on the value obs). We can use Bayes'\nTheory for random variables:\nP(obs|A=a)P(A=a)\nP(A=a|obs)=\nP(obs)\nThis will be computed inside a for loop for each assignment a to ability to see. How can we compute\neach term in the Bayes' Theorem expression? We already have values for the prior P(A=a) and we can\ncompute the denominator P(obs) using the Law of Total Probability:\nP(obs)=\u2211P(obs,A=x) LOTP\nx\n=\u2211P(obs|A=x)P(A=x) ChainRule\nx\nNotice how the terms in this new expression for P(obs) already show up in the numerator of our Bayes'\nTheorem equation. As such, in code we are going to (1) compute the numerator for every value of a,\nstore it as the value of belief, (2) compute the sum of all of those terms and (3) devide each value of\nbelief by the sum. The process of doing steps 2 and 3 is also known as normalization:\ndef update_belief(belief, obs):\n\"\"\"\nTake in a prior belief (stored as a dictionary) for a random\nvariable representing how well someone can see based on a single\nobservation (obs). Update the belief based using Bayes' Theorem\n\"\"\"\n# loop over every value in the support of the belief RV\nfor a in belief:\n# the prior belief P(A = a)\nprior_a = belief[a]\n# the obs probability P(obs | A = a)\nlikelihood = calc_likelihood(a, obs)\n# numerator of Bayes' Theorem\nbelief[a] = prior_a * likelihood\n# calculate the denominator of Bayes' Theorem\nnormalize(belief)\ndef normalize(belief):\n# in place normalization of a belief dictionary\ntotal = belief_sum(belief)\nfor key in belief:\nbelief[key] /= total\ndef belief_sum(belief):\n# get the sum of probability mass for a discrete belief\ntotal = 0\nfor key in belief:\ntotal += belief[key]\nreturn total\nAt this point we have an expression, and corresponding code, to update our belief in ability to see given\nan observation. However we are missing a way to compute P(obs|A=a). In our code this expression is\nthe currently undefined calc_likelihood(a, obs) function. In the next section we will go over how\n3\nThis is a header\nto compute this \"likelihood\" function. Before we do so, let's take a look at the result of applying\nupdate_belief for a patient with the single observation obs_1 defined above.\nobs_1 says that this patient got a rather large letter (font-size of 0.7) incorrect. As such in our posterior\nwe think they can't see very well, though we have a lot of uncertainty as it has only been one observation.\nThis belief is expressed in our updated probability mass function for A, P(A=a|obs 1), called the\nposterior. Here is what the posterior looks like for obs_1. Note that the posterior P(A=a|obs 1) is still\nrepresented in code as a dictionary, as in the prior, P(A=a):\nThe posterior belief on ability to see given a patient incorrectly identified a letter with font size 0.7. It shows\na belief that the patient can't see very well.\nLikelihood Function\nWe are not done yet! We have not yet said how we will compute P(obs|A=a). In Bayes' Theorem this\nterm is called the \"likelihood.\" The likelhood for our eye exam will be function that returns back\nprobabilities for inputs of a and obs. In python this will be a function calc_likelihood(a, obs). In\nthis function obs is a single observation such as obs_1 described above. Imagine a concrete call to the\nlikelihood function bellow. This call will return back the probability a person who has true ability to see\nof 0.5 would get a letter of font-size 0.7 incorrect.\n# get an observation\nobs = {\n\"font_size\":0.7,\n\"is_correct\":False\n}\n# calculate likelihood for obs given a, P(obs | A = a)\ncalc_likelihood(a = 0.5, obs)\nBefore going any further, let's make two critical notes about the likelihood function:\nNote 1: When computing the likelihood term, P(obs|A=a), we do not have to estimate A as it shows\nup on the right hand size of the conditional. In the likelihood term we are told exactly how well the\nperson can see. Their vision is truly a. Do not be fooled by the fact that a is a (non-random) variable.\nWhen computing the likelihood function this varaible will have a numeric value.\nNote 2: The variable obs represents a single patient interaction. It has two parts: a font-size and a\nboolean for whether the patient got the letter correct. However, we don't think of font-size as being a\nrandom variable. Instead we think of it as a contant which has been fixed by the computer. As such\nP(obs|A=a) can be simplified to P(correct|A=a). \"correct\" is short hand for the event that a random\nvariable Correct takes on the True or False value correct:\nP(obs|A=a)\n=P(correct,f|A=a) obsisatuple\n=P(correct|A=a) f isaconstant\n4\nThis is a header\nDefining the likelihood function P(correct|A=a) involves more medical and education theory than\nprobability theory. You don't need to know either for this course! But it is still neat to learn and without\nthe likelihood function we won't have complete code. So, let's dive in.\nA very practical starting point for the likelihood function for a vision test comes from a classic education\nmodel called \"Item Response Theory\", also known as IRT. IRT assumes the probability that a student\nwith ability a gets a question with difficulty d correct is governed by the easy to compute function:\nP(Correct=True|a)\n=sigmoid(a\u2212d) d isdifficulty\n1\n=\n1+e\u2212(a\u2212d)\nwhere e is the natural base constant and sigmoid(x)= 1 . The sigmoid function is a handy function\n1+e\u2212x\nwhich takes in any real valued input and returns a corresponding value in the range [0,1].\nThis IRT model introduces a new constant: difficulty of a letter d. How difficult is it to correctly respond\nto a letter with a given font size? The simplest way to model difficulty, while accounting for the fact that\nlarge font sizes are easier than small ones, is to define the difficulty of a letter with font size f to be\nd=1\u2212f. Plugging this in:\nP(Correct=True|a)\n=sigmoid(a\u2212[1\u2212f])\n=sigmoid(a\u22121+f)\n1\n=\n1+e\u2212(a\u22121+f)\nWe now have a complete, if simplistic, liklihood function! In code it would look like this:\ndef calc_likelihood(a, obs):\n# returns P(obs | A = a) using Item Response Theory\nf = obs[\"font_size\"]\np_correct_true = sigmoid(a + f - 1)\nif obs[\"is_correct\"]:\nreturn p_correct_true\nelse:\nreturn 1 - p_correct_true\ndef sigmoid(x):\n# the classic squashing function. All outputs are [0,1]\nreturn 1 / (1 + math.exp(-x))\nNote that Item Response Theory returns the probability that a a patient answers a letter correctly. In the\ncode above, notice what we do if the patient instead guesses the letter incorrectly:\nP(Correct=False|a,f)=1\u2212P(Correct=True|a,f)\nIn the published version of the Stanford Acuity Test we extend Item Response Theory in several ways.\nWe have a term for the probability that a patient gets the answer correct by random guessing as well as a\nterm that they make a mistake, aka \"slip\", even though they know the correct answer. We also observed\nthat a Floored Exponential seems to be a more accurate function than the sigmoid. These extensions are\nbeyond the scope of this chapter as they are not central to the probability insight. For more details see the\noriginal paper [1].\nMultiple Observations\nWhat if you have multiple observations? For multiple observations the only term that will change will be\nthe likelihood term P(Observations|A=a). We assume that each observation is independent,\nconditioned on ability to see. Formally\nP(obs ,\u2026,obs |A=a)=\u220fP(obs|A=a)\n1 20 i\ni\n5\nThis is a header\nAs such the likelihood of all observations will be the product of the likelihood of each observation on its\nown. This is equivalent mathematically to calculating the posterior for one observation and calling the\nposterior your new prior.\nThe Full Code\nHere is the full code for inference of ability to see given observations, minus the user interface functions\nand the file reading for the prior belief:\ndef main():\n\"\"\"\nCompute your belief in how well someone can see based\noff an eye exam with 20 questions at different fonts\n\"\"\"\nbelief_a = load_prior_from_file()\nobservations = get_observations()\nfor obs in observations:\nupdate_belief(belief_a,obs)\nplot(belief_a)\ndef update_belief(belief, obs):\n\"\"\"\nTake in a prior belief (stored as a dictionary) for a random\nvariable representing how well someone can see based on a single\nobservation (obs). Update the belief based using Bayes' Theorem\n\"\"\"\n# loop over every value in the support of the belief RV\nfor a in belief:\n# the prior belief P(A = a)\nprior_a = belief[a]\n# the obs probability P( obs | A = a)\nlikelihood = calc_likelihood(a, obs)\n# numerator of Bayes' Theorem\nbelief[a] = prior_a * likelihood\n# calculate the denominator of Bayes' Theorem\nnormalize(belief)\ndef calc_likelihood(a, obs):\n# returns P(obs | A = a) using Item Response Theory\nf = obs[\"font_size\"]\np_correct = sigmoid(a + f - 1)\nif obs[\"is_correct\"]:\nreturn p_correct\nelse:\nreturn 1 - p_correct\n# ----------- Helper Functions -----------\ndef sigmoid(x):\n# the classic squashing function. All outputs are [0,1]\nreturn 1 / (1 + math.exp(-x))\ndef normalize(belief):\n# in place normalization of a belief dictionary\ntotal = belief_sum(belief)\nfor key in belief:\nbelief[key] /= total\ndef belief_sum(belief):\n# get the sum of probability mass for a discrete belief\ntotal = 0\nfor key in belief:\ntotal += belief[key]\nreturn total\n6\nThis is a header\nChosing the Next Font Size\nAt this point, we have a way to calculate a probability mass function of our belief in how well the patient\ncan see, at any point in our test. This leaves one more task for us to perform: In a digital eye test, we\nselect the next font size to show to the patient. Instead of showing a predetermined set, we should make a\nchoice which is informed by our current belief in how well the patient can see. We were inspired by\nThompson Sampling, an algorithm which is able to balance exploring uncertainty and narrowing in on\nyour most confident belief. When chosing a font size we simply take a sample from our current belief A\nand then chose the font size that we think a person with ability with that sampled value could see with\n80% accuracy. We chose the 80% constant so that the eye test would not be too painful.\nOne of the neat take aways from this application is that there are many problems where you could take\nthe knowledge learned from this course and improve on the current state of the art! Often the most\ncreative task is to recognize where computer based probability could be usefully applied. Even for eye\ntests this is not the end of the story. The Stanford Eye Test, which started in CS109, is just a step on the\njourney to a more accurate digital eye test. There is ./always a better way. Have an idea?\nPublications and press coverage:\n[1] The Stanford Acuity Test: A Precise Vision Test Using Bayesian Techniques and a Discovery in\nHuman Visual Response. Association for the Advancement of Artificial Intelligence\n[2] Digitising the vision test. The Lancet Journal.\n[3] Eye, robot: Artificial intelligence dramatically improves accuracy of classic eye exam. Science\nMagazine.\nSpecial thanks to Ali Malik who co-invented the Stanford Acuity Test.\n7\nThis is a header\nBridge Card Game\nBridge is one of the most popular collaborative card games. It is played with four players in two teams. A\nfew interesting probability problems come up in this game. You do not need to know the rules of bridge to\nfollow this example. I focus on a set of probability problems which are most important for game strategy.\nDistribution of Hand Strength\nThe way folks play bridge is that they make a calculation about their \"hand strength\" and then make\ndecisions based off that number. The strength of your hand is a number which is equal to 4 times the number\nof \"aces\", 3 times the number of \"kings\", 2 times the number of \"queens\" and 1 times the number of \"jacks\"\nin your hand. No other cards contribute to your hand strength. Lets consider your hand strength to be a\nrandom variable and compute its distribution. It seems complex to compute by hand -- but perhaps we could\nrun a simulation? Here we simulate a million deals of bridge hands and calculate the hand strengths. Let X\nbe the strength of a hand. From the Definition of Probability:\ncount(x)\nP(X=x)\u2248\n100000\nWait! Is that a Poisson?\nIf you pay very close attention might notice that this PMF looks a lot like a poisson PMF with rate\n\u03bb=10. There is a nice explanation for why the rate might be 10. Let H be the value of your hand. Let\nX i be the points of the ith card in your hand, which has 13 cards. H =\u22111 i=3 1X i.\nFirst we compute E[X i], the expectation of points for the ith card in your hand \u2014 without considering\nthe other cards . A card can take on four non zero values X i\u2208{1,2,3,4}. For each value there are four\ncards out of 52 with that value, eg P(X i=1)= 54 2. Thus\nE[X]=\u2211x\u22c5P(X =x)\ni i\nx\n1\n=(1+2+3+4)\n13\n10\n=\n13\nWe can then calculate E[H] by using the fact that the expectation of the sum of random variables is the\nsum of expectations, regardless of independence:\n1\nSaying that is approximately is an interesting claim. It suggests that points in a hand\ncome at a constant rate, and that the next point in your hand is independent of when you got your last\npoint. Of course this second part of the assumption is mildly violated. There are a fixed set of cards so\ngetting one card changes the probabilities of others. For this reason the poisson is a close, but not perfect\napproximation.\nJoint Distribution of Hand Strength Among Two Hands\nIt doesn't just matter how strong your hand is, but the relative strength of your hand and your partners hand\n(recall that in Bridge you play with a partner). We know that the two hands are not independent of each\nother. If I tell you that your partner has a strong hand, that means there are fewer \"high value\" cards that can\nbe in your hand, and as such my belief in your strength has changed. If you think about each player's hand\nstrength as a random variable, we care about the joint distribution of hand strength. In the joint distribution\nbellow the x-axis is your partner's hand strength and on the y-axis is your hand strength. The value is\n. This joint distribution was calculated by simulating a million randomly\ndealt hands:\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n0 1 2 3 4 5 6 7 8 9\n01 11 21 31 41 51 61 71 81 91 02 12 22 32 42 52 62 72 82 92 03\nThis is a header 13\nE[H]=\u2211E[X]\ni\ni=1\n=13\u22c5E[X]\ni\n10\n=13\u22c5\n13\n=10\nH \u223cPoi(\u03bb=10)\nP(Partner=x,YourPoints=y)\nFrom this joint distribution we can compute conditional probabilities. For example we can compute the\nconditional distribution of your partner's points given your points using lookups from the joint:\n2\nThis is a header P(Partner=x|YourPoints=y)\nP(Partner=x,YourPoints=y)\n= Cond.Prob.\nP(YourPoints=y)\nP(Partner=x,YourPoints=y)\n= LOTP\n\u2211 P(Partner=z,YourPoints=y)\nz\nHere is a working demo of the result\nYour points: 13\nDistribution of Suit Splits\nWhen playing the game there are many times when one player will know exactly how many cards there are\nof a certain suit between their two opponents hands (call the opponents A and B). However, the player won't\nknow the \"split\": how many of that particular suit are in opponent A's hand and how many cards of that suit\nare in opponent B's hand.\nBoth opponents have equal sized hands with k cards left. Across the two hands there are a known number of\ncards of a particular suit (eg spades) n, and you want to know how many are in one hand and how many are\nin the other. A split is represented as a tuple. For example (0,5) would mean 0 cards of the suit in opponent\nA's hands and 5 in opponent B's. Feel free to chose specific values for k and n:\nk, the number of cards in each player's hand: 13\nn, the number of cards of particular suit among the two hands: 5\nA few notes: If there are k cards in each of the 2 hands there are 2k cards total bewteen the two players. At\nthe start of a game of bridge k=13. It must be the case that n\u22642k because you can't have more cards of\nthe suit left than number of cards! If there are n of a suit, then there are 2k\u2212n of other suits. This problem\nassumes that the cards are properly shuffled.\nProbability of different splits of the suit:\nLet Y be a random variable representing the number of the suit in opponent A's hand. We can calculate the\nprobability that Y equals different values i by counting equally likely outcomes.\n(n)\u22c5(2\u22c5k\u2212n)\nP(Y =i)= i k\u2212i\n(2\u22c5k)\nk\nEach outcome in the sample set is a chosen set of k distinct cards to be dealt to one player (out of the 2k\ncards). To create an outcome in the event space we first chose the i cards from the n cards of the given suit.\nWe then chose k\u2212i from the cards of other suits. For k=13 and n=5 here is the PMF over splits:\n3\nThis is a header\nIf we want to think about the probability of a given split, it is sufficient to chose one hand (call it \"hand\none\"). If I tell you how many of a suit are in one hand, you can automatically figure out how many of the\nsuit are in the other hand: recall that the number of the suit sums to n.\nProbability that either hand has at least j cards of suit\nLet X be a random variable representing the highest number of cards of the suit in either hand. We can\ncalculate the probability by using probability of or.\nj\u22121\nP(X\u2265j)=1\u2212 \u2211 P(Y =i)\ni=n\u2212j+1\n4\nThis is a header\nExpectation of Sum Proof\nNow that we have learned about joint probabilities, we have all the tools we need to prove one of the\nmost useful properties of Expectation: the fact that the expectation of a sum of random variables is equal\nto the sum of expectation (even if the variables are not independent). In other words:\nFor any two random variables X and Y,\nE[X+Y]=E[X]+E[Y]\nThe proof is going to use the Law of Unconcious statistician (LOTUS) where the function is addition!\nProof: Expectation of Sum\nLet X and Y be any two random variables:\nE[X+Y]\n=\u2211\u2211(x+y)\u22c5P(X=x,Y =y) LOTUS\nx y\n=\u2211\u2211x\u22c5P(X=x,Y =y)+y\u22c5P(X=x,Y =y) Distribute\nx y\n=\u2211\u2211x\u22c5P(X=x,Y =y)+\u2211\u2211y\u22c5P(X=x,Y =y) RearrangeSums\nx y y x\n=\u2211x\u2211P(X=x,Y =y)+\u2211y\u2211P(X=x,Y =y) FactorOut\nx y y x\n=\u2211x\u22c5P(X=x)+\u2211y\u22c5P(Y =y) DefofMarginal\nx y\n=E[X]+E[Y] DefofExpectation\nAt no point in the proof do we need to assume that X and Y are independent. In the second step the joint\nprobability ends up in each sum, and in both cases, one of the sums ends up marginalizing over the joint\nprobability!\nDemonstration of the Proof\nHere is an example to show the idea behind the proof. This table shows the joint probabilities\nP(X=x,Y =y) for two random variables X and Y that are not independent. You will see how\ncomputing E[X+Y] is the sum of terms that are used in E[X] and E[Y].\nY =4 Y =5\nX=1 0.1 0.3\nX=2 0.2 0.4\nAside: These two random variables can each only take on two values. Having only four values in the\njoint table will make it easier to gain intuition.\nComputing E[X] using joint probabilities:\nA key insight from the proof is that we can compute E[X] using values from the joint. To do this we are\ngoing to use marginalization:\nP(X=x)=\u2211P(X=x,Y =y)\ny\nWe can expand E[X] so that it is calculated only using values from the joint probability table:\n1\nThis is a header E[X]=\u2211x\u22c5P(X=x)\nx\n=\u2211x\u22c5\u2211P(X=x,Y =y) Marginalizationof X\nx y\n=\u2211\u2211x\u22c5P(X=x,Y =y) Distribute y\nx y\nx y P(X=x,Y =y) x\u22c5P(X=x,Y =y)\n1 4 0.1 1 \u00d7 0.1 = 0.1\n1 5 0.3 1 \u00d7 0.3 = 0.3\n2 4 0.2 2 \u00d7 0.2 = 0.4\n2 5 0.4 2 \u00d7 0.4 = 0.8\nE[X] = 0.1 + 0.3 + 0.4 + 0.8 = 1.6\nComputing E[Y] using joint probabilities:\nSimilarly, we can compute E[Y] using only values from the joint:\nE[Y]=\u2211y\u22c5P(Y =y)\ny\n=\u2211y\u22c5\u2211P(X=x,Y =y) Marginalizationof Y\nx x\n=\u2211\u2211y\u22c5P(X=x,Y =y) Distribute x\nx y\nx y P(X=x,Y =y) y\u22c5P(X=x,Y =y)\n1 4 0.1 4 \u00d7 0.1 = 0.4\n1 5 0.3 5 \u00d7 0.3 = 1.5\n2 4 0.2 4 \u00d7 0.2 = 0.8\n2 5 0.4 5 \u00d7 0.4 = 2.0\nE[Y] = 0.4 + 1.5 + 0.8 + 2.0 = 4.7\nComputing E[X+Y] using joint probabilities:\nWe can rewrite E[X+Y] to be the sum of terms used in the calculations of E[X] and E[Y] above:\nE[X+Y]=\u2211(x+y)\u22c5P(X=x,Y =y)\nx,y\n=\u2211x\u22c5P(X=x,Y =y)+y\u22c5P(X=x,Y =y)\nx,y\nx y P(x,y) x\u22c5P(x,y) y\u22c5P(x,y) (x+y)\u22c5P(x,y)\n1 4 0.1 0.1 0.4 0.1 + 0.4 = 0.5\n1 5 0.3 0.3 1.5 0.3 + 1.5 = 1.8\n2 4 0.2 0.4 0.8 0.4 + 0.8 = 1.2\n2 5 0.4 0.8 2.0 0.8 + 2.0 = 2.8\n2\nThis is a header\nRecall that P(x,y) is shorthand for P(X=x,Y =y).\nUsing the above derivation of the formula for E[X+Y] in terms of values from the joint probability\ntable:\nE[X+Y]=\u2211x\u22c5P(X=x,Y =y)+y\u22c5P(X=x,Y =y)\nx,y\nPlugging in values:\nE[X+Y] = 0.1 + 0.4 + 0.3 + 1.5 + 0.4 + 0.8 + 0.8 + 2.0 = 6.3\nWe can observe that each of these values showed up exactly once when calculating E[X] and E[Y]. This\nis why the proof works for any two random variables, even if they are not independent.\nE[X] = 0.1 + 0.3 + 0.4 + 0.8 = 1.6\nE[Y] = 0.4 + 1.5 + 0.8 + 2.0 = 4.7\nBecause they are summing the same values, it is no surprise that the sum of the expectations is equal to\nthe expectation of the sum: E[X+Y]=E[X]+E[Y]=1.6+4.7=6.3\n3\nThis is a header\nBayesian Viral Load Test\nQuestion from Fall 2022 Stanford Midterm\nWe are going to build a Bayesian Viral Load Test which updates a belief distribution regarding a patient's\nviral load. Though viral load is continuous, in our test we represent it by discretizing the quantity into\nwhole numbers between 0 and 99, inclusive. The units of viral load are the number of viral instances per\nmillion samples.\nIf a person has a viral load of 9 (in other words, 9 viruses out of every 1 million samples) what is the\nprobability that a random sample from the person is a virus?\n9\n1,000,000\nWe test 100,000 samples from one person for the virus. If the person's true viral load is 9, what is the\nprobability that exactly 1 of our 100,000 samples is a virus? Use a computationally efficient\napproximation to compute your answer. Your approximation should respect that there is 0 probability of\ngetting negative virus samples.\nLet's define a random variable X, the number of samples that are viral given the true viral load is 9. The\nquestion is asking for P(X=1). We can think about this as a binomial process, where the number of\ntrials n is the number of samples and the probability p is the probability that a sample is viral.\n9\nn=100,000,p=\n1,000,000\nNotice that n is very small and p is very large, so we can use the Poisson approximation to approximate\nour answer. We find \u03bb=np=100,000\u22c59/1,000,000=0.9, so X\u223c\\Poi(\u03bb=0.9). The last step is to\nuse the PMF of the Poisson distribution.\n(0.9)1e\u22120.9\nP(X=1)=\n1!\nBased on what we know about a patient (their symptoms and personal history) we have encoded a prior\nbelief in a list prior where prior[i] is the probability that the viral load equals i. prior is of length\n100 and has keys 0 through 99.\nWrite an equation for the updated probability that the true viral load is i given that we observe a count of\n1 virus sample out of 100,000 tested. Recall that 0\u2264i\u226499. You may use approximations.\n1\nThis is a header\nWe want to find\n1\nP(viralload=i|observedcountof )\n100000\nWe can apply Bayes Rule to get\nP(observedcountof 1 |viralload=i)P(viralload=i)\n= 100000\nP(observedcountof 1 )\n100000\nWe know that we can define a random variable X\u223cobservedcountoutof100,000|viralload=i,\nand we can model X as a Poisson approximation to a binomial with n=100000 and p= i , with\n1000000\ni i\n\u03bb=np=100000\u22c5 =\n1000000 10\nSo X can be written as\ni\nX\u223cPoi(\u03bb= )\n10\nNow we can rewrite our Bayes Rule equation as\nP(X=1)P(viralload=i)\n=\nP(observedcountof 1 )\n100000\nWe can now use the Poisson PMF and our given \\texttt{prior} to get:\n1i 0e\u2212 10i\n\u22c5prior[i]\n= 1!\nP(observedcountof 1 )\n100000\nWe now need to expand our denominator. We can use the General Law of Total Probability to expand\n1 99 1\nP(observedcountof )=\u2211P(observedcountof |viralload=i)P(viralload=i)\n100000 100000\nj=0\nWe can rewrite this as\n99 j e\u2212j\n=\u2211 10 10 \u22c5prior[j]\n1!\nj=0\n99 j\n=\u2211 e\u2212j \u22c5prior[j]\n10 10\nj=0\nAnd finally, we can plug this in to get\ni e\u2212i \u22c5prior[i]\n10 10 .\n\u221199 j e\u2212j \u22c5prior[j]\nj=0 10 10\n2\nCS109 Logo\nTo generate the CS109 logo, we are going to throw half a million darts at a picture of the Stanford seal.\nWe only keep the pixels that are hit by at least one dart. Each dart has it's x-pixel and y-pixel chosen at\nrandom from gaussian distributions. Let X be a random variable which represent the x-pixel, Y be a\nrandom variable which represents the y-pixel and S be a constant that equals the size of the logo (its\nwidth is equal to its height). X\u223cN(S, S) and Y \u223cN(S, S)\n2 2 3 5\nDarts thrown: 9500\nDart Results Dart Probability Density\nX Distribution\n0.0009\n0.0008\n0.0007\n0.0006\n0.0005\n0.0004\n0.0003\n0.0002\n0.0001\n0.0000\n0 100200300400500600700800900\npixel x\nytisneD\nytilibaborP\nY Distribution\n0.0022\n0.0020\n0.0017\n0.0015\n0.0012\n0.0010\n0.0007\n0.0005\n0.0002\n0.0000\n0 100200300400500600700800900\npixel y\nytisneD\nytilibaborP\nThis is a header\n1\nThis is a header\nTracking in 2D\nWarning: After learning about joint distributions, and about inference, you have all the technical\nabilities necessary to follow this example. However this is very very difficult. Primarily because you\nneed to understand three complex things at the same time: (1) how to represent a continuous joint\ndistribution, (2) inference in probabilistic models and (3) a rather complex probability of observation\ncalculation.\nIn this example we are going to explore the problem of tracking an object in 2D space. The object exists\nat some (x,y) location, however we are not sure exactly where! Thus we are going to use random\nvariables X and Y to represent location.\nf(X=x,Y =y)=f(X=x)\u22c5f(Y =y) InthepriorXandYareindependen\n=\n1 \u22c5e\u2212(x\u22123)2\n\u22c5\n1 \u22c5e\u2212(y\u22123)2\nUsingthePDFequationfornormals\n2\u22c54 2\u22c54\n\u221a2\u22c54\u22c5\u03c0 \u221a2\u22c54\u22c5\u03c0\n=K\n\u22c5e\u2212(x\u22123)2+(y\u22123)2\nAllconstantsareputinto K\n1 8 1\nThis combinations of normals is called a bivariate distribution. Here is a visualization of the PDF of our\nprior.\nThe interesting part about tracking an object is the process of updating your belief about it's location\nbased on an observation. Let's say that we get an instrument reading from a sonar that is sitting on the\norigin. The instrument reports that the object is 4 units away. Our instrument is not perfect: if the true\ndistance was t units away, than the instrument will give a reading which is normally distributed with\nmean t and variance 1. Let's visualize the observation:\nBased on this information about the noisiness of our prior, we can compute the conditional probability of\n1\nThis is a header\nseeing a particular distance reading D, given the true location of the object X, Y. If we knew the object\nwas at location (x,y), we could calculate the true distance to the origin \u221ax2+y2 which would give us\nthe mean for the instrument Gaussian:\nf(D=d|X=x,Y =y)= 1 \u22c5e\u2212(d\u2212\u221a 2x \u22c52 1+y2)2 NormalPDFwhere \u03bc=\u221ax2+y2\n\u221a2\u22c51\u22c5\u03c0\n=K\n\u22c5e\u2212(d\u2212\u221ax2+y2)2\nAllconstantsareputinto K\n2 2\u22c51 2\nHow about we try this out on actual numbers. How much more likely is an instrument reading of 1\ncompared to 2, given that the location of the object is at (1, 1)?\nf(D=1|X=1,Y =1) K\n\u22c5e\u2212(1\u2212\u221a12+12)2\n= 2 2\u22c51 SubstitutingintotheconditionalPDFofD\nf(D=2|X=1,Y =1)\nK\n\u22c5e\u2212(2\u2212\u221a12+12)2\n2 2\u22c51\ne0\n= \u22481.65 Noticehowthe K cancelout\ne\u22121/2 2\nAt this point we have a prior belief and we have an observation. We would like to compute an updated\nbelief, given that observation. This is a classic Bayes' formula scenario. We are using joint continuous\nvariables, but that doesn't change the math much, it just means we will be dealing with densities instead\nof probabilities:\nf(X=x,Y =y|D=4)\nf(D=4|X=x,Y =y)\u22c5f(X=x,Y =y)\n= Bayesusingdensities\nf(D=4)\nK\n\u22c5e\u2212[4\u2212\u221ax2+y2)2]\n\u22c5K\n\u22c5e\u2212[(x\u22123)2+(y\u22123)2]\n= 1 2 2 8 Substitute\nf(D=4)\n= K 1\u22c5K 2 \u22c5e\u2212[[4\u2212\u221ax2+y2)2]+[(x\u22123)2+(y\u22123)2]] f(D=4) isaconstantw.r.t. (x,y)\n2 8\nf(D=4)\n=K\n\u22c5e\u2212[(4\u2212\u221ax2+y2)2 +[(x\u22123)2+(y\u22123)2]]\nK isanewconstant\n3 2 8 3\nWow! That looks like a pretty interesting function! You have successfully computed the updated belief.\nLet's see what it looks like. Here is a figure with our prior on the left and the posterior on the right:\nHow beautiful is that! Its like a 2D normal distribution merged with a circle. But wait, what about that\nconstant! We do not know the value of K 3 and that is not a problem for two reasons: the first reason is\nthat if we ever want to calculate a relative probability of two locations, K 3 will cancel out. The second\nreason is that if we really wanted to know what K 3 was, we could solve for it. This math is used every\nday in millions of applications. If there are multiple observations the equations can get truly complex\n(even worse than this one). To represent these complex functions often use an algorithm called particle\nfiltering.\n2\nPart 4: Uncertainty Theory\nThis is a header\nBeta Distribution\nThe Beta distribution is the distribution most often used as the distribution of probabilities. In this section\nwe are going to have a very meta discussion about how we represent probabilities. Until now\nprobabilities have just been numbers in the range 0 to 1. However, if we have uncertainty about our\nprobability, it would make sense to represent our probabilities as random variables (and thus articulate\nthe relative likelihood of our belief).\nBeta Random Variable\nNotation: X\u223cBeta(a,b)\nDescription: A belief distribution over the value of a probability p from a Binomial distribution\nafter observing a\u22121 successes and b\u22121 fails.\nParameters: a>0, the number successes + 1\nb>0, the number of fails + 1\nSupport: x\u2208[0,1]\nPDF equation: f(x)=B(a,b)\u22c5xa\u22121\u22c5(1\u2212x)b\u22121 where B(a,b)= \u0393(a)\u0393(b)\n\u0393(a,b)\nCDF equation: No closed form\nExpectation: E[X]= a\na+b\nVariance: Var(X)= ab\n(a+b)2(a+b+1)\nPDF graph:\nParameter a: 2 Parameter b: 4\np\nWhat is your Belief in After 9 Heads in 10 Flips?\nImagine we have a coin and we would like to know its true probability of coming up heads, p. We flip the\ncoin 10 times and observe 9 heads and 1 tail. What is your belief in p based off this evidence? Using the\ndefinition of probability we could guess that p\u2248 9 . That number is a very rough estimate, especially\n10\n9\nsince it is only based off 10 coin flips. Moreover the \"point-value\" does not have the ability to\n10\narticulate how uncertain it is.\nCould we instead have a random variable for the true probability? Formally, let X represent the true\nprobability of the coin coming up heads. We don't use the symbol P for random variables, so X will have\nto do. If X=0.7 then the probability of heads is 0.7. X must be a continuous random variable with\nsupport [0,1] since probabilities are continuous values which must be between 0 and 1.\n1\nThis is a header\nBefore flipping the coin, we could say that our belief about the coin's heads probability is uniform:\nX\u223cUni(0,1). Let H be a random variable for the number of heads and let T be a random variable for\nthe number of tails observed. What is P(X=x|H =9,T =1)?\nThat probability is hard to think about! However it is much easier to reason about the probability with the\ncondition reveresed: P(H =9,T =1|X=x). This term asks the question: what is the probability of\nseeing 9 heads and 1 tail in 10 coin flips, given that the true probability of a heads is x. Convince\nyourself that this probability is just a binomial probability mass function with n=10 experiements, and\np=x evaluated at k=9 heads:\n10\nP(H =9,T =1|X=x)=( )x9(1\u2212x)1\n9\nWe are presented with a perfect context for Bayes' theorem with random variables. We know a\nconditional probability in one direction and we would like to know it in the other:\nf(X=x|H =9,T =1)\nP(H =9,T =1|X=x)\u22c5f(X=x)\n= BayesTheorem\nP(H =9,T =1)\n(10)x9(1\u2212x)1\u22c5f(X=x)\n= 9 BinomialPMF\nP(H =9,T =1)\n(10)x9(1\u2212x)1\u22c51\n= 9 UniformPDF\nP(H =9,T =1)\n(10)\n= 9 x9(1\u2212x)1 Constantstofront\nP(H =9,T =1)\n=K\u22c5x9(1\u2212x)1 Renameconstant\nLets take a look at that function. For now we can let K=110. Regardless of K we will get the same\nshape, just scaled:\nWhat a beautiful image. It tells us relatively likelihood over the probability that is governing our\ncoinflips. Here are a few observations from this chart:\n1. Even after only 10 coin flips we are very confident that the true probability is > 0.5\n2. It is almost 10 times more likely that X=0.9 as it is that X=0.6.\n3. f(X=1)=0, which makes sense. How could we have flipped that one tail if the probability of heads\nwas 1?\nWait but why?\nIn the derivation above for f(X=x|H =9,T =1) we made the claim that P(H =9,T =1) is a\nconstant. A lot of folks find that hard to believe. Why is that the case?\n2\nThis is a header\nIt may be helpful to juxtapose P(H =9,T =1) with P(H =9,T =1|X=x). The later says \"what is\nthe probability of 9 heads, given the true probability is x\". The former says \"what is the probability of 9\nheads, under all possible assignments of x\". If you wanted to calculate P(H =9,T =1) you could use\nthe law of total probability:\nP(H =9,T =1)\n1\n=\u222b P(H =9,T =1|X=y)f(X=y)\ny=0\nThat is a hard number to calculate, but it is in fact a constant with respect to x.\nBeta Derivation\nLet's generalize the derivation from the previous section, using h for the number of observed heads and t\nthe number of observed tails.\nIf we let H =h be the event that we saw h heads, and let T =t be the event that we saw t tails in h+t\ncoinflips. We want to calculate the probability density function f(X=x|H =h,T =t). We can use the\nexact same series of steps, starting with Bayes Theorem:\nf(X=x|H =h,T =t)\nP(H =h,T =t|X=x)f(X=x)\n= BayesTheorem\nP(H =h,T =t)\n(h+t)xh(1\u2212x)t\n= h BinomialPMF,UniformPDF\nP(H =h,T =t)\n(h+t)\n= h xh(1\u2212x)t Movingtermsaround\nP(H =h,T =t)\n1 1\n= \u22c5xh(1\u2212x)t where c=\u222b xh(1\u2212x)tdx\nc\n0\nThe equation that we arrived at when using a Bayesian approach to estimating our probability defines a\nprobability density function and thus a random variable. The random variable is called a Beta\ndistribution, and it is defined as follows:\nThe Probability Density Function (PDF) for X\u223cBeta(a,b) is:\n1 xa\u22121(1\u2212x)b\u22121 if 0<x<1 1\nf(X=x)={B(a,b) where B(a,b)=\u222b xa\u22121(1\u2212x)b\u22121dx\n0 otherwise\n0\nA Beta distribution has E[X]= a and Var(X)= ab . All modern programming languages\na+b (a+b)2(a+b+1)\nhave a package for calculating Beta CDFs. You will not be expected to compute the CDF by hand in\nCS109.\nTo model our estimate of the probability of a coin coming up heads: set a=h+1 and b=t+1. Beta is\nused as a random variable to represent a belief distribution of probabilities in contexts beyond estimating\ncoin flips. For example perhaps a drug has been given to 6 patients, 4 of whom have been cured. We\ncould express our belief in the probability that the drug can cure patients as X\u223cBeta(a=5,b=3):\n3\nThis is a header\nNotice how the most likely belief for the probability of curing a patient, is 4/6, the fraction of patients\ncured. This distribution shows that we hold a non-zero belief that the probability could be something\nother than 4/6. It is unlikely that the probability is 0.01 or 0.09, but reasonably likely that it could be 0.5.\nBeta as a Prior\nYou can set X\u223cBeta(a,b) as a prior to reflect how biased you think the coin is apriori to flipping it.\nThis is a subjective judgment that represent a+b\u22122 \"imaginary\" trials with a\u22121 heads and b\u22121 tails.\nIf you then observe h+t real trials with h heads you can update your belief. Your new belief would be,\nX\u223cBeta(a+h,b+t). Using the prior Beta(1,1)=Uni(0,1) is the same as saying we haven't seen\nany \"imaginary\" trials, so apriori we know nothing about the coin. Here is the proof for the distribution of\nX when the prior was a Beta too:\nIf our prior belief is X\u223cBeta(a,b), then our posterior is Beta(a+h,b+t):\nf(X=x|H =h,T =t)\nP(H =h,T =t|X=x)f(X=x)\n= BayesTheorem\nP(H =h,T =t)\n(h+t)xh(1\u2212x)t\u22c5 1 \u22c5xa\u22121(1\u2212x)b\u22121\n= h c BetaPMF,UniformPDF\nP(H =h,T =t)\n=K\u22c5xh(1\u2212x)t\u22c5xa\u22121(1\u2212x)b\u22121 CombineConstants\n=K\u22c5xa+h\u22121(1\u2212x)b+t\u22121 CombineLikeBases\nWhich is the PDF of Beta(a+h,b+t)\nIt is pretty convenient that if we have a Beta prior belief, then our posterior belief is also Beta. This\nmakes Betas especially convenient to work with, in code and in proof, if there are many updates that you\nwill make to your belief over time. This property where the type of distribution is the same before and\nafter an observation is called a conjugate prior.\nQuick question: Are you allowed to just make up priors and imaginary trials? Some folks think that is\nfine (they are called Bayesians) and some folks think that you shouldn't make up prior beliefs (they are\ncalled frequentists). In general, for small data it can make you much better at making predictions if you\nare able to come up with a good prior belief.\nObservation: There is a deep connection between the beta-prior and the uniform-prior (which we used\ninitially). It turns out that Beta(1,1)=Uni(0,1). Recall that Beta(1,1) means 0 imaginary heads and 0\nimaginary tails.\n4\nThis is a header\nAdding Random Variables\nIn this section on uncertainty theory we are going to explore some of the great results in probability\ntheory. As a gentle introduction we are going to start with convolution. Convolution is a very fancy way\nof saying \"adding\" two different random variables together. The name comes from the fact that adding\ntwo random varaibles requires you to \"convolve\" their distribution functions. It is interesting to study in\ndetail because (1) many natural processes can be modelled as the sum of random variables, and (2)\nbecause mathemeticians have made great progress on proving convolution theorems. For some particular\nrandom variables computing convolution has closed form equations. Importantly convolution is the sum\nof the random variables themselves, not the addition of the probability density functions (PDF)s that\ncorrespond to the random variables.\n1. Adding Two Random Variables\n2. Sum of Independent Poissons\n3. Sum of Independent Binomials\n4. Sum of Independent Normals\n5. Sum of Independent Uniforms\nAdding Two Random Variables\nDeriving an expression for the likelihood for the sum of two random variables requires an interesting\ninsight. If your random variables are discrete then the probability that X+Y =n is the sum of mutually\nexclusive cases where X takes on a values in the range [0,n] and Y takes on a value that allows the two\nto sum to n. Here are a few examples X=0andY =n, X=1andY =n\u22121 etc. In fact all of the\nmutually exclusive cases can be enumerated in a sum:\nDef: General Rule for the Convolution of Discrete Variables\n\u221e\nP(X+Y =n)= \u2211 P(X=i,Y =n\u2212i)\ni=\u2212\u221e\nIf the random variables are independent you can futher decompose the term P(X=i,Y =n\u2212i). Let's\nexpand on some of the mutually exclusive cases where X+Y =n:\ni X Y\n0 0 n P(X=0,Y =n)\n1 1 n\u22121 P(X=1,Y =n\u22121)\n2 2 n\u22122 P(X=2,Y =n\u22122)\n...\nn n 0 P(X=n,Y =0)\nConsider the sum of two independent dice. Let X and Y be the outcome of each dice. Here is the\nprobability mass function for the sum X+Y:\n1\nThis is a header\nLet's use this context to practice deriving the sum of two variables, in this case P(X+Y =n), starting\nwith the General Rule for the Convolution of Discrete Random Variables. We start by considering values of\nn between 2 and 7. In this range P(X=i,Y =n\u2212i)= 1 for all values of i between 1 and n\u22121. There\n36\nis exactly one outcome of the two die where X=i and Y =n\u2212i. For values of i outside this range n\u2212i\nis not a valid dice outcome and P(X=i,Y =n\u2212i)=0:\nP(X+Y =n)\n\u221e\n= \u2211 P(X=i,Y =n\u2212i)\ni=\u2212\u221e\nn\u22121\n=\u2211P(X=i,Y =n\u2212i)\ni=1\nn\u22121 1\n=\u2211\n36\ni=1\nn\u22121\n=\n36\nFor values of n greater than 7 we could use the same approach, though different values of i would make\nP(X=i,Y =n\u2212i) non-zero.\nThis derivation for a general rule has a continuous equivalent:\n\u221e\nf(X+Y =n)=\u222b f(X=n\u2212i,Y =i)di\ni=\u2212\u221e\nSum of Independent Poissons\nFor any two Poisson random variables: X \u223cPoi(\u03bb 1) and Y \u223cPoi(\u03bb 2) the sum of those two random\nvariables is another Poisson: X+Y \u223cPoi(\u03bb 1+\u03bb 2). This holds even when \u03bb 1 is not the same as \u03bb 2.\nHow could we prove a the above claim?\nExample derivation:\nLet's go about proving that the sum of two independent Poisson random variables is also Poisson. Let\nX\u223cPoi(\u03bb 1) and Y \u223cPoi(\u03bb 2) be two independent random variables, and Z=X+Y. What is\nP(Z=n)?\n2\nThis is a header P(Z=n)=P(X+Y =n)\n\u221e\n= \u2211 P(X=k,Y =n\u2212k) (Convolution)\nk=\u2212\u221e\n\u221e\n= \u2211 P(X=k)P(Y =n\u2212k) (Independence)\nk=\u2212\u221e\nn\n=\u2211P(X=k)P(Y =n\u2212k) (Rangeof X and Y)\nk=0\nn \u03bbk \u03bbn\u2212k\n=\u2211e\u2212\u03bb1 1e\u2212\u03bb2 2 (PoissonPMF)\nk! (n\u2212k)!\nk=0\nn \u03bbk\u03bbn\u2212k\n=e\u2212(\u03bb1+\u03bb2)\u2211 1 2\nk!(n\u2212k)!\nk=0\n=\ne\u2212(\u03bb1+\u03bb2) \u2211n n!\n\u03bbk\u03bbn\u2212k\nn! k!(n\u2212k)! 1 2\nk=0\ne\u2212(\u03bb1+\u03bb2)\n= (\u03bb +\u03bb )n (Binomialtheorem)\nn! 1 2\nNote that the Binomial Theorem (which we did not cover in this class, but is often used in contexts like\nexpanding polynomials) says that for two numbers a and b and positive integer n,\n(a+b)n=\u2211n (n)akbn\u2212k.\nk=0 k\np\nSum of Independent Binomials with equal\nFor any two independent Binomial random variables with the same \"success\" probability p:\nX \u223cBin(n 1,p) and Y \u223cBin(n 2,p) the sum of those two random variables is another binomial:\nX+Y \u223cBin(n 1+n 2,p).\nThis result hopefully makes sense. The convolution is the number of sucesses across X and Y. Since\neach trial has the same probability of success, and there are now n 1+n 2 trials, which are all\nindependent, the convolution is simply a new Binomial. This rule does not hold when the two Binomial\nrandom variables have different parameters p.\nSum of Independent Normals\nFor any two independent normal random variables X \u223cN(\u03bc 1,\u03c32 1) and Y \u223cN(\u03bc 2,\u03c32 2) the sum of\nthose two random variables is another normal: X+Y \u223cN(\u03bc 1+\u03bc 2,\u03c32 1+\u03c32 2).\nAgain this only holds when the two normals are independent.\nSum of Independent Uniforms\nIf X and Y are independent uniform random variables where X\u223cUni(0,1) and Y \u223cUni(0,1):\n\u23a7n if 0<n\u22641\nf(X+Y =n)=\u23a82\u2212n if 1<n\u22642\n\u23a9\n0 else\nExample derivation:\nCalculate the PDF of X+Y for independent uniform random variables X\u223cUni(0,1) and\nY \u223cUni(0,1)? First plug in the equation for general convolution of independent random variables:\n3\nThis is a header 1\nf(X+Y =n)=\u222b f(X=n\u2212i,Y =i)di\ni=0\n1\n=\u222b f(X=n\u2212i)f(Y =i)di Independence\ni=0\n1\n=\u222b f(X=n\u2212i)di Because f(Y =y)=1\ni=0\nIt turns out that is not the easiest thing to integrate. By trying a few different values of n in the range\n[0,2] we can observe that the PDF we are trying to calculate is discontinuous at the point n=1 and thus\nwill be easier to think about as two cases: n<1 and n>1. If we calculate f(X+Y =n) for both cases\nand correctly constrain the bounds of the integral we get simple closed forms for each case:\n\u23a7n if 0<n\u22641\nf(X+Y =n)=\u23a82\u2212n if 1<n\u22642\n\u23a9\n0 else\n4\nThis is a header\nCentral Limit Theorem\nThere are two ways that you could state the central limit theorem. Either that the sum of IID random\nvariables is normally distributed, or that the average of IID random variables is normally distributed.\nThe Central Limit Thorem (Sum Version)\nLet X 1,X 2\u2026X n be independent and identically distributed random variables. The sum of these\nrandom variables approaches a normal as n\u2192\u221e:\nn\n\u2211X \u223cN(n\u22c5\u03bc,n\u22c5\u03c32)\ni\ni=1\nWhere \u03bc=E[X i] and \u03c32=Var(X i). Note that since each X i is identically distributed they share the\nsame expectation and variance.\nAt this point you probably think that the central limit theorem is awesome. But it gets even better. With\nsome algebraic manipulation we can show that if the sample mean of IID random variables is normal, it\nfollows that the sum of equally weighted IID random variables must also be normal:\nThe Central Limit Thorem (Average Version)\nLet X 1,X 2\u2026X n be independent and identically distributed random variables. The average of these\nrandom variables approaches a normal as n\u2192\u221e:\n1 n \u03c32\n\u2211X \u223cN(\u03bc, )\nn i n\ni=1\nWhere \u03bc=E[X i] and \u03c32=Var(X i).\nCentral Limit Theorem Intuition\nIn the previous section we explored what happens when you add two random variables. What happens\nwhen you add more than two random variables? For example, what if I wanted to add up 100 different\nuniform random variables:\nfrom random import random\ndef add_100_uniforms():\ntotal = 0\nfor i in range(100):\n# returns a sample from uniform(0, 1)\nx_i = random()\ntotal += x_i\nreturn total\nThe value, total returned by this function will be a random variable. Hit the button below to run the\nfunction and observe the resulting value of total:\nadd_100_uniforms() total: 47.00654\nWhat does total look like as a distribution? Let's calculate total many times and visualize the histogram\nof values it produces.\n1\nThis is a header\n10,000 more runs\nThat is interesting! total which is the sum of 100 independent uniforms looks normal. Is that a special\nproperty of uniforms? No! It turns out to work for almost any type of distribution (as long as the thing\nyou are adding has finite mean and finite variance, everything we have covered in this reader).\nSum of 40 X i where X i\u223cBeta(a=5,b=4)? Normal.\nSum of 90 X i where X i\u223cPoi(\u03bb=4)? Normal.\nSum of 50 dice-rolls? Normal.\nAverage of 10000 X i where X i\u223cExp(\u03bb=8)? Normal.\nFor any distribution the sum, or average, of n independent equally-weighted samples from that\ndistribution, will be normal.\nContinuity Correction\nNow we can see that the Binomial Approximation using a Normal actually derives from the central limit\ntheorem. Recall that, when computing probabilities for a normal approximation, we had to to use a\ncontinuity correction. This was because we were approximating a discrete random variable (a binomial)\nwith a continuous one (a normal). You should use a continuity correction any time your normal is\napproximating a discrete random variable. The rules for a general continuity correction are the same as\nthe rules for the binomial-approximation continuity correction.\nIn the motivating example above, where we added 100 uniforms, a continuity correction isn't needed\nbecause the sum of uniforms is continuous. In the dice sum example below, a continuity correction is\nneeded because die outcomes are discrete.\nExamples\nExample:\nYou will roll a 6 sided dice 10 times. Let X be the total value of all 10 dice = X 1+X 2+\u22ef+X 10. You\nwin the game if X\u226425 or X\u226545. Use the central limit theorem to calculate the probability that you\nwin. Recall that E[X i]=3.5 and Var(X i)= 3 15 2.\nLet Y be the approximating normal. By the Central Limit Theorem Y \u223cN(10\u22c5E[X i],10\u22c5Var(X i)).\nSubstituting in the known values for expectation and variance: Y \u223cN(35,29.2)\n2\nThis is a header P(X\u226425 or X\u226545)\n=P(X\u226425)+P(X\u226545)\n\u2248P(Y <25.5)+P(Y >44.5) ContinuityCorrection\n\u2248P(Y <25.5)+[1\u2212P(Y <44.5)]\n25.5\u221235 44.5\u221235\n\u2248\u03a6( )+[1\u2212\u03a6( )] NormalCDF\n\u221a29.2 \u221a29.2\n\u2248\u03a6(\u22121.76)+[1\u2212\u03a6(1.76)]\n\u22480.039+(1\u22120.961)\u22480.078\nExample:\nSay you have a new algorithm and you want to test its running time. You have an idea of the variance of\nthe algorithm's run time: \u03c32=4sec2 but you want to estimate the mean: \u03bc=tsec. You can run the\nalgorithm repeatedly (IID trials). How many trials do you have to run so that your estimated runtime =\nt\u00b10.5 with 95\\% certainty? LetX i be the run time of the i-th run (for 1\u2264i\u2264n).\n\u2211n X\n0.95=P(\u22120.5\u2264 i=1 i \u2212t\u22640.5)\nn\nBy the central limit theorem, the standard normal Z must be equal to:\n(\u2211n X)\u2212n\u03bc\nZ= i=1 i\n\u03c3\u221an\n(\u2211n X)\u2212nt\n= i=1 i\n2\u221an\nNow we rewrite our probability inequality so that the central term is Z:\n0.95=P(\u22120.5\u2264\n\u2211n i=1X i \u2212t\u22640.5)=P(\u22120.5\u221an\n\u2264\n\u2211n i=1X i\n\u2212t\u2264\n0.5\u221an\n)\nn 2 n 2\n=P(\u22120.5\u221an\n\u2264\n\u221an \u2211n i=1X i\n\u2212\n\u221an\nt\u2264\n0.5\u221an )=P(\u22120.5\u221an\n\u2264\n\u2211n i=1X i\n\u2212\n\u221an \u221ant\n\u2264\n2 2 n 2 2 2 2\u221an \u221an 2\n=P(\u22120.5\u221an\n\u2264\n\u2211n i=1X i\u2212nt\n\u2264\n0.5\u221an\n)\n2 2\u221an 2\n\u22120.5\u221an 0.5\u221an\n=P( \u2264Z\u2264 )\n2 2\nAnd now we can find the value of n that makes this equation hold.\n\u221an \u221an \u221an \u221an\n0.95=\u03d5( )\u2212\u03d5(\u2212 )=\u03d5( )\u2212(1\u2212\u03d5( ))\n4 4 4 4\n\u221an\n=2\u03d5( )\u22121\n4\n\u221an\n0.975=\u03d5( )\n4\n\u221an\n\u03d5\u22121(0.975)=\n4\n\u221an\n1.96=\n4\nn=61.4\nThus it takes 62 runs. If you are interested in how this extends to cases where the variance is unknown,\nlook into variations of the students' t-test.\n3\nThis is a header\nSampling\nIn this section we are going to talk about statistics calculated on samples from a population. We are then\ngoing to talk about probability claims that we can make with respect to the original population -- a central\nrequirement for most scientific disciplines.\nLet's say you are the king of Bhutan and you want to know the average happiness of the people in your\ncountry. You can't ask every single person, but you could ask a random subsample. In this next section we\nwill consider principled claims that you can make based on a subsample. Assume we randomly sample\n200 Bhutanese and ask them about their happiness. Our data looks like this: 72,85,\u2026,71. You can also\nthink of it as a collection of n = 200 I.I.D. (independent, identically distributed) random variables\nX 1,X 2,\u2026,X n.\nUnderstanding Samples\nThe idea behind sampling is simple, but the details and the mathematical notation can be complicated.\nHere is a picture to show you all of the ideas involved:\nThe theory is that there is some large population (for example the 774,000 people who live in Bhutan).\nWe collect a sample of n people at random, where each person in the population is equally likely to be in\nour sample. From each person we record one number (for example their reported happiness). We are\ngoing to call the number from the ith person we sampled X i. One way to visualize your samples\nX 1,X 2,\u2026,X n is to make a histogram of their values.\nWe make the assumption that all of our X is are identically distributed. That means that we are assuming\nthere is a single underlying distribution F that we drew our samples from. Recall that a distribution for\ndiscrete random variables should define a probability mass function.\nEstimating Mean and Variance from Samples\nWe assume that the data we look at are IID from the same underlying distribution (F) with a true mean (\n\u03bc) and a true variance (\u03c32). Since we can't talk to everyone in Bhutan we have to rely on our sample to\nestimate the mean and variance. From our sample we can calculate a sample mean\n(X\u00af\n) and a sample\nvariance (S2). These are the best guesses that we can make about the true mean and true variance.\nn X\nX\u00af =\u2211 i\nn\ni=1\n1 n\nS2= \u2211(X \u2212X\u00af)2\nn\u22121 i\ni=1\nThe first question to ask is, are those unbiased estimates? Yes. Unbiased, means that if we were to repeat\nthis sampling process many times, the expected value of our estimates should be equal to the true values\nwe are trying to estimate. We will prove that that is the case for X\u00af . The proof for S2 is in lecture slides.\n1\nThis is a header n X 1 n\nE[X\u00af]=E[\u2211 i]= E[\u2211X]\nn n i\ni=1 i=1\n1 n 1 n 1\n= \u2211E[X]= \u2211\u03bc= n\u03bc=\u03bc\nn i n n\ni=1 i=1\nThe equation for sample mean seems related to our understanding of expectation. The same could be said\nabout sample variance except for the surprising (n\u22121) in the denominator of the equation. Why (n\u22121)\n? That denominator is necessary to make sure that the E[S2]=\u03c32.\nThe intuition behind the proof is that sample variance calculates the distance of each sample to the\nsample mean, not the true mean. The sample mean itself varies, and we can show that its variance is also\nrelated to the true variance.\nStandard Error\nOk, you convinced me that our estimates for mean and variance are not biased. But now I want to know\nhow much my sample mean might vary relative to the true mean.\nn X 1 2 n\nVar(X\u00af)=Var(\u2211 i)=( ) Var(\u2211X)\nn n i\ni=1 i=1\n1 2 n 1 2 n 1 2 \u03c32\n=( ) \u2211Var(X)=( ) \u2211\u03c32=( ) n\u03c32=\nn i n n n\ni=1 i=1\nS2\n\u2248\nn\nS2\nStd(X\u00af)\u2248\u221a\nn\nThat term,\nStd(X\u00af\n), has a special name. It is called the standard error and its how you report uncertainty of\nestimates of means in scientific papers (and how you get error bars). Great! Now we can compute all\nthese wonderful statistics for the Bhutanese people. But wait! You never told me how to calculate the\nStd(S2). That is hard because the central limit theorem doesn't apply to the computation of S2. Instead\nwe will need a more general technique. See the next chapter: Bootstrapping\nLet's say we calculate the our sample of happiness has n = 200 people. The sample mean is X\u00af =83\n(what is the unit here? happiness score?) and the sample variance is S2=450. We can now calculate the\nstandard error of our estimate of the mean to be 1.5. When we report our results we will say that our\nestimate of the average happiness score in Bhutan is 83 \u00b1 1.5. Our estimate of the variance of happiness\nis 450 \u00b1 ?.\n2\nThis is a header\nBootstrapping\nThe bootstrap is a newly invented statistical technique for both understanding distributions of statistics\nand for calculating p-values (a p-value is a the probability that a scientific claim is incorrect). It was\ninvented here at Stanford in 1979 when mathematicians were just starting to understand how computers,\nand computer simulations, could be used to better understand probabilities.\nThe first key insight is that: if we had access to the underlying distribution (F) then answering almost\nany question we might have as to how accurate our statistics are becomes straightforward. For example,\nin the previous section we gave a formula for how you could calculate the sample variance from a sample\nof size n. We know that in expectation our sample variance is equal to the true variance. But what if we\nwant to know the probability that the true variance is within a certain range of the number we calculated?\nThat question might sound dry, but it is critical to evaluating scientific claims! If you knew the\nunderlying distribution, F, you could simply repeat the experiment of drawing a sample of size n from F\n, calculate the sample variance from our new sample and test what portion fell within a certain range.\nThe next insight behind bootstrapping is that the best estimate that we can get for F is from our sample\nitself! The simplest way to estimate F (and the one we will use in this class) is to assume that the\nP(X=k) is simply the fraction of times that k showed up in the sample. Note that this defines the\nprobability mass function of our estimate F^ of F.\ndef bootstrap(sample):\nN = number of elements in sample\npmf = estimate the underlying pmf from the sample\nstats = []\nrepeat 10,000 times:\nresample = draw N new samples from the pmf\nstat = calculate your stat on the resample\nstats.append(stat)\nstats can now be used to estimate the distribution of the stat\nBootstrapping is a reasonable thing to do because the sample you have is the best and only information\nyou have about what the underlying population distribution actually looks like. Moreover most samples\nwill, if they're randomly chosen, look quite like the population they came from.\nTo calculate Var(S2) we could calculate S2 for each resample i and after 10,000 iterations, we could\ni\ncalculate the sample variance of all the S2s. You might be wondering why the resample is the same size\ni\nas the original sample (n). The answer is that the variation of the variation of stat that you are calculating\ncould depend on the size of the sample (or the resample). To accurately estimate the distribution of the\nstat we must use resamples of the same size.\nThe bootstrap has strong theoretic grantees, and is accepted by the scientific community. It breaks down\nwhen the underlying distribution has a ``long tail\" or if the samples are not I.I.D.\nExample of p-value calculation\nWe are trying to figure out if people are happier in Bhutan or in Nepal. We sample n 1=200 individuals\nin Bhutan and n 2=300 individuals in Nepal and ask them to rate their happiness on a scale from 1 to\n10. We measure the sample means for the two samples and observe that people in Nepal are slightly\nhappier--the difference between the Nepal sample mean and the Bhutan sample mean is 0.5 points on the\nhappiness scale.\nIf you want to make this claim scientific you should calculate a p-value. A p-value is the probability that,\nwhen the null hypothesis is true, the statistic measured would be equal to, or more extreme than, than the\nvalue you are reporting. The null hypothesis is the hypothesis that there is no relationship between two\nmeasured phenomena or no difference between two groups.\n1\nThis is a header\nIn the case of comparing Nepal to Bhutan, the null hypothesis is that there is no difference between the\ndistribution of happiness in Bhutan and Nepal. The null hypothesis argument is: there is no difference in\nthe distribution of happiness between Nepal and Bhutan. When you drew samples, Nepal had a mean that\n0.5 points larger than Bhutan by chance.\nWe can use bootstrapping to calculate the p-value. First, we estimate the underlying distribution of the\nnull hypothesis underlying distribution, by making a probability mass function from all of our samples\nfrom Nepal and all of our samples from Bhutan.\ndef pvalue_bootstrap(bhutan_sample, nepal_sample):\nN = size of the bhutan_sample\nM = size of the nepal_sample\nuniversal_sample = combine bhutan_samples and nepal_samples\nuniversal_pmf = estimate the underlying pmf of the universalSample\ncount = 0\nobserved_difference = mean(nepal_sample) - mean(bhutan_sample)\nrepeat 10,000 times:\nbhutan_resample = draw N new samples from the universalPmf\nnepal_resample = draw M new samples from the universalPmf\nmu_bhutan = sample mean of the bhutanResample\nmu_nepal = sample mean of the nepalResample\nmean_difference = |muNepal - muBhutan|\nif mean_difference > observed_difference:\ncount += 1\npvalue = count / 10,000\nThis is particularly nice because nowhere did we have to make an assumption about a parametric\ndistribution that our samples came from (ie we never had to claim that happiness is gaussian). You might\nhave heard of a t-test. That is another way of calculating p-values, but it makes the assumption that both\nsamples are gaussian and that they both have the same variance. In the modern context where we have\nreasonable computer power, bootstrapping is a more correct and versatile tool.\n2\nThis is a header\nAlgorithmic Analysis\nIn this section we are going to use probability to analyze code. Specifically we are going to be calculating\nexpectations on code: expected run time, expected resulting values etc. The reason that we are going to\nfocus on expectation is that it has several nice properties. One of the most useful properties that we have\nseen so far is that the expectation of a sum, is the sum of expectations, regardless of whether the random\nvariables are independent of one another. In this section we will see a few more helpful properties,\nincluding the Law of Total Expectation, which is also helpful in analyzing code:\nLaw of Total Expectation\nThe law of total expectation gives you a way to calculate E[X] in the scenareo where it is easier to\ncompute E[X|Y =y] where Y is some other random variable:\nE[X]=\u2211E[X|Y =y]P(Y =y)\ny\nDistributed File System\nImagine the task of loading a large file from your computer at Stanford, over the interet. Your file is\nstored in a distributed file system. In a distributed file system, the closest instance of your file might be\non one of several computers at different locations in the world. Imagine you know the probability that the\nfile is in one of a few locations l: P(L=l), and for each location the expected time, T, to get the file,\nE[T|L=l], given it is in that location:\nLocation P(L=l) E[T|L=l]\nSoCal 0.5 0.3 seconds\nNew York 0.2 20.7 seconds\nJapan 0.3 96.3 seconds\nThe Law of Total Expectation gives a straightforward way to compute E[T]:\nE[T]=\u2211E[T|L=l]P(L=l)\nl\n=0.5\u22c50.3+0.2\u22c520.7+0.3\u22c596.7\n=33.3 seconds\nToy Example of Recursive Code\nIn theoretical computer science, there are many times where you want to analyze the expected runtime of an\nalgorithm. To practice this technique let's try to solve a simple recursive function. Let Y be the value\nreturned by recurse(). What is E[Y]?\ndef recurse():\nx = random.choice([1, 2, 3]) # Equally likely values\nif x == 1:\nreturn 3;\nelse if (x == 2):\nreturn 5 + recurse()\nelse:\nreturn 7 + recurse()\n1\nThis is a header\nIn order to solve this problem we are going to need to use the law of total expectation considering X as\nyour background variable.\nE[Y]= \u2211 E[Y|X=i]P(X=i)\ni\u2208{1,2,3}\n=E[Y|X=1]P(X=1)\n+E[Y|X=2]P(X=2)\n+E[Y|X=3]P(X=3)\nWe know the probability P(X=x)= 1 for x\u2208{1,2,3}. How can we compute a value such as\n3\nE[Y|X=2]? Well that is the expectation of your return, in the world where X=2. In that case you will\nreturn 5 + recurse(). The expectation of that is 5+E[Y]. Plugging a similar result for each case we can\ncontinue our solution:\nE[Y|X=1]=3\nE[Y|X=2]=5+E[Y]\nE[Y|X=3]=7+E[Y]\nNow we can just plug values into the law of total expectation:\nE[Y]= \u2211 E[Y|X=i]P(X=i)\ni\u2208{1,2,3}\n=E[Y|X=1]P(X=1)\n+E[Y|X=2]P(X=2)\n+E[Y|X=3]P(X=3)\n=3\u22c51/3\n+(5+E[Y])\u22c51/3\n+(7+E[Y])\u22c51/3\n=(15+2E[Y])\u22c51/3\n1/3\u22c5E[Y]=5\nE[Y]=15\nProof of Law of Total Expectation\nLet's prove the law of total expectation. In this proof we are going to go backwards! We are going to start\nwith \u2211 E[X|Y =y]P(Y =y) and show this equals E[X]. Our first step will be to expand E[X|Y =y]\ny\n. The rest of the proof will just be algebra:\n\u2211E[X|Y =y]P(Y =y)\ny\n=\u2211\u2211xP(X=x|Y =y)P(Y =y)\ny x\n=\u2211\u2211xP(X=x,Y =y)\ny x\n=\u2211\u2211xP(X=x,Y =y)\nx y\n=\u2211x\u2211P(X=x,Y =y)\nx y\n=\u2211xP(X=x)\nx\n=E[X]\n2\nThis is a header\nInformation Theory\nInformation theory is an incredibly powerful perspective which plays a central role in a ton of algorithms,\nincluding Decision Trees, the WordleBot, Adaptive Tests, Optimal Poker Play and even ompression of\ndata (like Huffman Encoding or even Jpeg files)! The goal of this chapter is to balance showing off the\nawesome power of Information Theory while also keeping things as straight forward as possible. To that\nend, a great place to start is thinking about how you could write a bot that can play the question\nanswering game of, \"Think of an Animal\".\nThink of an Animal!\nThe game of \"Think of an Animal\" goes like this: The human is going to be thinking of an animal. We\nassume that the distribution of how often they chose an animal is known (based off how popular the\nanimal is to four year olds):\nThe task of your algorithm is to select which question to ask next. Assume you are given a bank of yes or\nno questions which include classics like:\nIs it a pet?\nDoes it live in the water?\nAre you thinking of a dog?\nChosing a Best Question\nHow can we chose the best question to ask? Consider a simplified game with five animals (Dog, Cat,\nElephant, Bear and Monkey) and only two questions to chose from \"Is it a pet?\" and \"Is it a Dog?\" For each\nquestion we can use the Law of Total Probability to think through the probability the response will be \"yes\"\nor \"no\". Even better! For each possible answer to each possible question, we can think through the resulting\nprobability mass function over animals if we were to see that answer to that question:\n1\nThis is a header\nWe are so close! If we could only quantify how much uncertainty the four resulting probability mass\nfunctions have, we could simply chose the question that minimizes our expected uncertainty as to what\nanimal the person is thinking of. This quantification of uncertainty is formally called \"Entropy\" and it is\nthe key concept in Information Theory.\nMeasure of Uncertainty from a High Level\nLet X be any random variable. A very elegant way to quantify how much uncertainty the Probability\nMass Function of X represents is to think through all the values that X could take on and for each value\ncalculate how surprised you would be if it turned out that X in fact took on that value. If you calculate a\nweighted sum over these surprise values, you would get the expected Surprise of the random variable\nUncertainty(X)\n=E[Surprise(X)]\n=\u2211Surprise(x)\u22c5P(X=x)\nx\nThat is the big idea! The main remaining todo is to define what we mean by \"Surprise\" of an event.\nMeasure of Surprise of an Event\nHow should we quantify the degree to which we would be surprised if we were told that X took on the\nvalue x? There are many ways one could quantify Surprise, all of which are based on the probability of\nthe event P(X=x). Here are three reasonble Surprise functions:\nAll of these functions hit the following desiderata:\nLow probability events are surprising\nHigh probability events are not surprising\nSurprise is a monotonically decreasing function of probability\nFor many reasons, Information Theory defines Surprise using a variation of the middle equation\n2\nThis is a header 1\nSurprise(E)=log\n2 P(E)\nLooking at the relationship between P(E) and the value of Surprise(E) we can observe some of those\nintuitive relationships:\nProbability of Event Surprise of Event\nP(E) Surprise(E)=log 1\n2 P(E)\n1/2 1\n1/4 2\n1/8 3\n1/16 4\n1/32 5\n1/64 6\n1/128 7\nIf an event with probability P(E)=1/16 were to occur we would be four times as \"Surprised\" as if an\nevent with P(E)=1/2 were to occur. That feels nice!\nDefinition: Surprise of an Event (Information Content)\nThe information content, also called the surprisal or self-information, of an event E is a function which\nincreases as the probability of an event decreases. When the probability is close to 1, the surprisal of the\nevent is low, but if the probability is close to 0, the surprisal of the event occuring is high. This\nrelationship is described by the function:\n1\nSurprise(E)=log ( )\n2 P(E)\nThis can be written (in a more confusing way) as:\n1\nSurprise(E)=log ( )\n2 P(E)\n=log P(E)\u22121\n2\n=\u2212log P(E)\n2\nIn the initial definition of Surprise of an Event, the function name I was used as shorthand for Surprise. I\nstands for \"Information Content\" or \"Self Information\", two other names for Surprise of an event.\nThere are many other stories that we could tell for why log 2 P(1 E) is a great choice for our measure of\nSurprise. Claude Shannon, the father of information theory, chose the base 2 logarithm because it would\nallow you to express your amount of surprise in bits (as in 0, 1 values used in a computer). Information\ntheory has many applications, but it was first invented when he was trying to come up with a way to\noptimally compress text based data!\nUncertainty of a Random Variable (Entropy)\nNow that we have a formal definition of Surprise we can revisit the computation of Uncertainty of a\nrandom variable.\n3\nThis is a header\nDefinition: Uncertainty of an Random Variable (Entropy)\nLet H be our measure of how much uncertainty we have about a random variable X. Define H to be the\nexpected surprise of observing the assignment to X. H(X)=E[Surprise(X)]. Using the Law of\nUnconcious Statistician, and the definition of Surprise of an event, we can expand out the formula for H\nas:\n1\nH(X)=\u2211log ( )\u22c5P(X=x)\n2 P(X=x)\nx\u2208X\nUncertainty (H) can also be rewritten (in a more confusing way) as:\nH(X)=\u2211Surprise(X=x)\u22c5P(X=x)\nx\u2208X\n1\n=\u2211log \u22c5P(X=x)\n2 P(X=x)\nx\u2208X\n=\u2211log P(X=x)\u22121\u22c5P(X=x)\n2\nx\u2208X\n=\u2211\u2212log P(X=x)\u22c5P(X=x)\n2\nx\u2208X\n=\u2212\u2211log P(X=x)\u22c5P(X=x)\n2\nx\u2208X\n=\u2212\u2211log P(X=x)\u22c5P(X=x)\n2\nx\u2208X\nHere is code that calculates the Uncertainty (H) of a random variable, based on its probability mass\nfunction:\nimport numpy as np\ndef calc_uncertainty(pmf):\n\"\"\"\nCalculate how much uncertainty is represented by this\nprobability mass function. Also known as the Entropy of a\nrandom variable, H(X).\n\"\"\"\nuncertainty = 0\nfor x in pmf:\np_x = pmf[x]\n# skip zero probabilities\nif p_x == 0: continue\nsuprise_x = np.log2(1/p_x)\nuncertainty += suprise_x * p_x\nreturn uncertainty\nWe now have all the theoretical tools we need to select our best question in the game of \"Think of an\nAnimal\". For each possible resulting Probability Mass Function, we can calculate the Uncertainty (H) of\nthat PMF:\n4\nThis is a header\nThe question \"Is it a pet?\" has an expected uncertainty of 1.3. The question \"Is it a Dog?\" has an expected\nuncertainty of 1.7. As such we would be less uncertain about what animal our friend is thinking about, in\nexpectation, if we were to ask the question \"Is it a pet?\"\nThis is one of many applications of Information Theory!\n5\nThis is a header\nDistance Between Distributions\nHere is an important question! How can you quantify how different two distributions are? In other words,\nif I have two Probability Mass Functions, can I calculate a number that says how much they diverge from\none another? Here are three reasonable ways to quantify distance between distributions:\nTotal Variational Distance\nLoop over all possible values and calculate the absolute difference in probability.\nDefinition: Total Variation Distance\nLet X and Y be discrete random variables\n1\nTV(X,Y)= \u2211|P(X=i)\u2212P(Y =i)|\n2\ni\nEarth Mover's Distance\nImagine one distribution is a lump of dirt. How much work would it take to make it look just like the\nother? Also called the Wasserstein metric.\nThis value is very meaningful, but it doesn't have a closed form equation. Instead it is computed by\nsolving a linear program. If the range of values that the random variables can take on is of size n, the\nlinear program has a run time of O(n3\u22c5logn) which is very slow.\nKullback Leiber Divergence\nLet X and Y be discrete random variables. Calculate the expected \"excess surprise\" from using Y as your\nProbability Mass Function instead of X when the actual Probability Mass Function is X.\nDefinition: Kullback Leiber Divergence\nLet X and Y be discrete random variables\nKL(X,Y)=\u2211ExcessSurprise(x)\u22c5P(X=x)\nx\u2208X\n=\u2211[Surprise (x)\u2212Surprise (x)]\u22c5P(X=x)\nX Y\nx\u2208X\n1 1\n=\u2211[log \u2212log ]\u22c5P(X=x)\n2 P(Y =x) 2 P(X=x)\nx\u2208X\n=\u2211\u2212log P(Y =x)+log P(X=x)\u22c5P(X=x)\n2 2\nx\u2208X\nP(X=x)\n=\u2211log \u22c5P(X=x)\n2 P(Y =x)\nx\u2208X\nHere is example code for calculating how different an observed pmf of hurricanes per year is from a\npredicted poisson distribution\n1\nThis is a header\nfrom scipy import stats\nimport math\ndef kl_divergence(predicted_lambda, observed_pmf):\n\"\"\"\nWe predicted that the number of hurricanes would be\nX ~ Poisson(predicted_lambda) and observed a real world\nnumber of hurricanes Y ~ observed_pmf\n\"\"\"\nX = stats.poisson(predicted_lambda)\ndivergence = 0\n# loop over all the values of hurricanes\nfor i in range(0, 40):\npr_X_i = X.pmf(i)\npr_Y_i = observed_pmf[i]\nexcess_surprise_i = math.log(pr_X_i / pr_Y_i)\ndivergence += excess_surprise_i * pr_X_i\nreturn divergence\n2\nThis is a header\nThompson Sampling\nImagine having to make the following series of decisions. You have two drugs you can administer, drug\n1, or drug 2. Initially you have no idea which drug is better. You want to know which drug is the most\neffective, but at the same time, there are costs to exploration \u2014 the stakes are high.\nHere is an example:\nWelcome to the drug simulator.\nThere are two drugs: 1 and 2.\nNext patient. Which drug? (1 or 2): 1\nFailure. Yikes!\nNext patient. Which drug? (1 or 2): 2\nSuccess. Patient lives!\nNext patient. Which drug? (1 or 2): 2\nFailure. Yikes!\nNext patient. Which drug? (1 or 2): 1\nFailure. Yikes!\nNext patient. Which drug? (1 or 2): 1\nSuccess. Patient lives!\nNext patient. Which drug? (1 or 2): 1\nFailure. Yikes!\nNext patient. Which drug? (1 or 2): 2\nSuccess. Patient lives!\nNext patient. Which drug? (1 or 2): 2\nFailure. Yikes!\nNext patient. Which drug? (1 or 2):\nThis problem is suprisingly complex. It sometimes goes by the name \"the multi-armed bandit problem!\"\nIn fact, the perfect answer to this question can be exponentially hard to calculate. There are many\napproximate solutions and it is an active area of research.\nOne solution has risen to be a rather popular option: Thompson Sampling. It is easy to implement,\nelegant to understand, has provable garuntees [1], and in practice does very well [2].\nWhat You Know About The Choices\nThe first step in Thompson sampling is to express what you know (and what you do not know) about\nyour choices. Let us revisit the example of the two drugs in the previous section. By the end we had\ntested drug 1 four times (with 1 success) and we had tested drug 2 four times (with 2 successes). A\n1\nThis is a header\nsophisticated way to represent our belief in the two hidden probabilites behind drug 1 and drug 2 is to use\nthe Beta distribution. Let X 1 be the belief in the probability for drug 1 and let X 2 be the belief in the\nprobability for drug 2.\nX \u223cBeta(a=2,b=4)\n1\nX \u223cBeta(a=3,b=3)\n2\nRecall that in the Beta distribution with a uniform prior the first parameter, a, is number of observed\nsuccesses + 1. The second parameter, b, is the number of observed fails + 1. It is helpful to look at these\ntwo distributions graphically:\nIf we had to guess, drug 2 is looking better, but there is still a lot of uncertainty, represented by the high\nvariance in these beliefs. That is a helpful representation. But how can we use this information to make a\ngood decision of the next drug.\nMaking a Choice\nIt is hard to know what is the right choice! If you only had one more patient, then it is clear what you\nshould do. You should calculate the probability that X 2>X 1 and if that probability is over 0.5 then you\nshould chose a. However, if you need to continually administer the pills then it is less clear what is the\nright choice. If you chose 1, you miss out on the chance to learn more about 2. What should we do? We\nneed to balance this need for \"exploring\" and the need to take advantage of what we already know.\nThe simple idea behind Thompson Sampling is to randomly make your choice according to its\nprobability of being optimal. In this case we should chose drug 1 with the probability that 1 is > 2. How\ndo people do this in practice? They have a very simple formula. Take a random sample from each Beta\ndistribution. Chose the option which has a larger value for its sample.\nsample_a = sample_beta(2, 4)\nsample_b = sample_beta(3, 3)\nif sample_a > sample_b:\nchoose choice a\nelse:\nchoose choice b\nWhat does it mean to take a sample? It means to chose a value according to the probability density (or\nprobability mass) function. So in our example above, we might sample 0.4 for drug 1, and sample 0.35\nfor drug 2. In which case we would go with drug 1.\nAt the start Thompson Sampling \"explores\" quite a lot of time. As it gets more confident that one drug is\nbetter than another, it will start to chose that drug most of the time. Eventually it will converge to\nknowing which drug is best, and it will always chose that drug.\n2\nThis is a header\nNight Sight\nIn this problem we explore how to use probability theory to take photos in the dark. Digital cameras have\na sensor that capture photons over the duration of a photo shot to produce pictures. However, these\nsensors are subject to \u201cshot noise\u201d which are random fluctuations in the amount of photons that hit the\nlens. In the scope of this problem, we only consider a single pixel. The arrival of shot noise photons on a\nsurface is independent with constant rate.\nLeft: photo captured using a standard photo. Right: the same photo using a shot burst [1].\nFor shot noise, standard deviation is what matters! Why? Because if the camera can compute the\nexpected amount of noise, it can simply subtract it out. But the fluctuations around the mean (measured\nas standard deviation) lead to changes in measurement that the camera can't simply subtract out.\nPart 1: A Standard Photo\nFirst lets calculate the amount of noise if we take a photo the standard way. If the time duration of a\nphoto shot is 1000 \ud835\udf07s, what is the standard deviation of the amount of photons captured by the pixel\nduring a single photo? Note that shot noise photons land on a particular pixel at a rate of 10 photons per\nmicrosecond (\ud835\udf07s).\nNoise in a standard photo: As you may have guessed, because photos hit the camera at a constant rate,\nand independent of one another, the number of shot noise photos hitting any pixel is modelled as a\nPoisson! For the given rate of noise, let X be the amount of shot noise photos that hit the pixel:\nX\u223cPoi(\u03bb=10,000).\nNote that 10,000 is the average number of photons that hit in 1000\ud835\udf07s (duration in microseconds\nmultiplied by photons per microsecond). The standard of a Poisson is simply equal to the square root of\nits parameter,\n\u221a\u03bb.\nThus the standard deviation of the shot noise photons captured is 100 (quite high).\nPart 2: A Shutter Shot\nTo mitigate shot noise, Stanford graduates realized that you can take a shutter shot (many camera shots in\nquick succession) and sum the number of photons captured. Because of limitations in cell phone cameras,\nthe largest number of photos a camera can take in 1000\u03bcs is 15 photos, each with a duration of 66\u03bcs.\nWhat is the standard deviation of shot noise if we average the photons across a shutter shot of 15 photos?\n1\nThis is a header\nNoise with a shutter shot:\nLet Y be the average quantity of shot noise photons across the 15 photos, captured by the single pixel.\nWe want to calculate the Var(Y). Specifically, Y = 11 5 \u22111 i=5 1X i where X i is the amount of shot noise\nphotons in the ith photo. Similar to the previous part:\nX \u223cPoi(\u03bb=66\u22c510)\ni\nand since X i is a Poisson, E[X i]=660 and Var(X i)=660.\nSince Y is the average of IID random variables, the Central Limit Theorem will kick in. Moreover, by\nthe CLT rule Y will have variance equal to 1/n\u22c5Var(X i).\nVar(Y)=1/n\u22c5Var(X)\ni\n=1/15\u22c5660=44\nThe standard deviation will then be the square root of this variance\nStd(Y)=\u221a44\nwhich is\napproximately 6.6. That is a huge reduction in shot noise!\nProblem by Will Song and Chris Piech. Night Sight by Google.\n2\nThis is a header\nP-Hacking\nIt turns out that science has a bug! If you test many hypotheses but only report the one with the lowest p-\nvalue you are more likely to get a spurious result (one resulting from chance, not a real pattern).\nRecall p-values: A p-value was meant to represent the probability of a spurious result. It is the chance of\nseeing a difference in means (or in whichever statistic you are measuring) at least as large as the one\nobserved in the dataset if the two populations were actually identical. A p-value < 0.05 is considered\n\"statistically significant\". In class we compared sample means of two populations and calculated p-\nvalues. What if we had 5 populations and searched for pairs with a significant p-value? This is called p-\nhacking!\nTo explore this idea, we are going to look for patterns in a dataset which is totally random \u2013 every value\nis Uniform(0,1) and independent of every other value. There is clearly no significance in any difference\nin means in this toy dataset. However, we might find a result which looks statistically significant just by\nchance. Here is an example of a simulated dataset with 5 random populations, each of which has 20\nsamples:\nThe numbers in the table above are just for demonstration purposes. You should not base your answer off\nof them. We call each population a random population to emphasize that there is no pattern.\nThere are Many comparisons\nHow many ways can you choose a pair of two populations from a set of five to compare? The values of\nelements within the population do not matter nor does the order of the pair.\n5\n( )\n2\nUnderstanding the mean of IID Uniforms\nWhat is the variance of a Uniform(0, 1)?\n1\nThis is a header\nLet Z\u223cUni(0,1)\n1\nVar(Z)= (\u03b2\u2212\u03b1)\n12\n1\n= (1\u22120)\n12\n1\n=\n12\nWhat is an approximation for the distribution of the mean of 20 samples from Uniform(0,1)?\nLet Z 1...Z n be i.i.d. Uni(0,1). Let X\u00af = n1 \u2211n i=1Z i.\n1 n 1 n n\nE[X]= \u2211E[Z]= \u22110.5= 0.5=0.5\nn i n n\ni=1 i=1\n1 n\nVar(X)=Var( \u2211Z)\nn i\ni=1\n1 n\n= Var(\u2211Z)\nn2 i\ni=1\n1 n\n= \u2211Var(Z)\nn2 i\ni=1\n1 n\n= \u2211v\nn2\ni=1\nn v v 1\n= v= = =\nn2 n 20 240\nUsing CLT, X\u00af \u223cN(\u03bc=0.5,\u03c32= 1 )\n240\nWhat is an approximation for the distribution of the mean from one population minus the mean from\nanother population? Note: this value may be negative if the first population has a smaller mean than the\nsecond.\nLet X 1 and X 2 be the means of the populations.\nX \u223cN(\u03bc=0.5,\u03c32= 1 )\n1 240\nX 2\u223cN(\u03bc=0.5,\u03c32= 21 40) The expectation is simple to calculate because\nE[X \u2212X ]=E[X ]\u2212E[X ]=0\n1 2 1 2\nVar(X \u2212X )=Var(X )+Var(X )\n1 2 1 2\n1\n=\n120\nThe sum (or difference) of independent normals is still normal: \\fbox{Y \u223cN(\u03bc=0,\u03c32= v )}\n10\n(8 points) What is the smallest difference in means, k, that would look statistically significant if there were\nonly two populations? In other words, the probability of seeing a difference in means of k or greater is <\n0.05.\nOne tricky part of this problem is to recognize the double sidedness to distance. We would consider it a\nsignificant distance if P(Y <\u2212k) or P(Y >k).\nP(Y <\u2212k)+P(Y >k)=0.05\nF (\u2212k)+(1\u2212F (k))=0.05\nY Y\n(1\u2212F (k))+(1\u2212F (k))=0.05\nY Y\n2\u22122F (k)=0.05\nY\nF (k)=0.975\nY\nNow we need the inverse \u03a6 to get the value of k out.\n2\n\u239c \u239f\nThis is a header k\u22120\n0.975=\u03a6( )\n\u221av/10\nk\n\u03a6\u22121(0.975)=\n\u221av/10\nk=\u03a6\u22121(0.975)\u221av/10\n(5 points) Give an expression for the probability that the smallest sample mean among 5 random\npopulations is less than 0.2.\nLet X i be the sample mean of population i.\n5\nP(min{X ...X }<0.2)=P(\u22c3X <0.2)\n1 n i\ni=1\n\u239b 5 \u2201\u239e\n=1\u2212P (\u22c3X <0.2)\ni\n\u239d \u23a0\ni=1\n5\n=1\u2212P(\u22c2X \u22650.2)\ni\ni=1\n5\n=1\u2212\u220fP(X \u22650.2)\ni\ni=1\n5 0.2\u22120.5\n=1\u2212\u220f1\u2212\u03a6( )\n\u221av/20\ni=1\n(7 points) Use the following functions to write code that estimates the probability that among 5 populations\nyou find a difference of means which would be considered significant (using the bootstrapping method\ndesigned to compare 2 populations). Run at least 10,000 simulations to estimate your answer. You may use\nthe following helper functions.\n# the smallest difference in means that would look statistically significant\nk = calculate_k()\n# create a matrix with n_rows by n_cols elements, each of which is Uni(0, 1)\nmatrix = random_matrix(n_rows, n_cols)\n# from the matrix, return the column (as a list) which has the smallest mean\nmin_mean_col = get_min_mean_col(matrix)\n# from the matrix, return the row (as a list) which has the largest mean\nmax_mean_col = get_max_mean_col(matrix)\n# calculate the p-value between two lists using bootstrapping (like in pset5)\np_value = bootstrap(list1, list2)\nWrite pseudocode:\nn_significant = 0\nk = calculate_k()\nfor i in range(N_TRIALS):\ndataset = random_matrix(20, 5)\ncol_max = get_max_mean_col(dataset)\ncol_min = get_min_mean_col(dataset)}\ndiff = np.mean(col_max) - np.mean(col_min)}\nif diff >= k:\nn_significant += 1}\nprint(n_significant / N_TRIALS)\n3\nThis is a header\nDifferential Privacy\nRecently, many organizations have released machine learning models trained on massive datasets (GPT-\n3, YOLO, etc...). This is a great contribution to science and streamlines modern AI research. However,\npublicizing these models allows for the potential ``reverse engineering'' of models to uncover the training\ndata for the model. Specifically, an attacker can download a model, look at the parameter values and then\ntry to reconstruct the original training data. This is particularly bad for models trained on sensetive data\nlike health information. In this section we are going to use randomness as a method to defend against\nalgorithmic ``reverse engineering.''\nInjecting Randomness\nOne way to combat algorithmic reverse engineering is to add some random element to an already existing\ndataset. Let\nX ,\u2026,X i.\u223ci.dBern(p)\n1 i\nrepresent a set of real human data. Consider the following snippet of code:\ndef calculateXi(Xi):\nreturn Xi\nQuite simply, an attacker can call the above for all 100 samples and uncover all 100 data points. Instead,\nwe can inject an element of randomness:\ndef calculateYi(Xi):\nobfuscate = random() # Bern with parameter p=0.5\nif obfuscate:\nreturn indicator(random())\nelse:\nreturn Xi\nThe attacker can in expectation call the new function 100 times and get the correct values for 50 of them\n(but they wont know which 50).\np\nRecovering\nNow consider if we publish the function calculateYi, how could a researcher who is interested in the\nmean of the samples get useful data? They can look at:\n100\nZ=\u2211Y.\ni\nn=1\nWhich has expectation:\n100 100 100 p 1\nE[Z]=E[\u2211Y]=\u2211E[Y]=\u2211( + )=50p+25\ni i 2 4\nn=1 n=1 n=1\nThen to uncover an estimate, the scientist can do,\nZ\u221225\np\u2248\n50\nAnd proceed to conduct more research!\n1\nPart 5: Machine Learning\nThis is a header\nParameter Estimation\nWe have learned many different distributions for random variables and all of those distributions had\nparameters: the numbers that you provide as input when you define a random variable. So far when we\nwere working with random variables, we either were explicitly told the values of the parameters, or, we\ncould divine the values by understanding the process that was generating the random variables.\nWhat if we don't know the values of the parameters and we can't estimate them from our own expert\nknowledge? What if instead of knowing the random variables, we have a lot of examples of data\ngenerated with the same underlying distribution? In this chapter we are going to learn formal ways of\nestimating parameters from data.\nThese ideas are critical for artificial intelligence. Almost all modern machine learning algorithms work\nlike this: (1) specify a probabilistic model that has parameters. (2) Learn the value of those parameters\nfrom data.\nParameters\nBefore we dive into parameter estimation, first let's revisit the concept of parameters. Given a model, the\nparameters are the numbers that yield the actual distribution. In the case of a Bernoulli random variable,\nthe single parameter was the value p. In the case of a Uniform random variable, the parameters are the a\nand b values that define the min and max value. Here is a list of random variables and the corresponding\nparameters. From now on, we are going to use the notation \u03b8 to be a vector of all the parameters:\nDistribution Parameters\nBernoulli(p) \u03b8=p\nPoisson(\u03bb) \u03b8=\u03bb\nUniform(a,b) \u03b8=[a,b]\nNormal(\u03bc,\u03c32) \u03b8=[\u03bc,\u03c32]\nIn the real world often you don't know the \"true\" parameters, but you get to observe data. Next up, we\nwill explore how we can use data to estimate the model parameters.\nIt turns out there isn't just one way to estimate the value of parameters. There are two main schools of\nthought: Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP). Both of these\nschools of thought assume that your data are independent and identically distributed (IID) samples:\nX 1,X 2,\u2026X n.\n1\nThis is a header\nMaximum Likelihood Estimation\nOur first algorithm for estimating parameters is called Maximum Likelihood Estimation (MLE). The\ncentral idea behind MLE is to select that parameters (\u03b8) that make the observed data the most likely.\nThe data that we are going to use to estimate the parameters are going to be n independent and\nidentically distributed (IID) samples: X 1,X 2,\u2026X n.\nLikelihood\nWe made the assumption that our data are identically distributed. This means that they must have either\nthe same probability mass function (if the data are discrete) or the same probability density function (if\nthe data are continuous). To simplify our conversation about parameter estimation we are going to use the\nnotation f(X=x|\u0398=\u03b8) to refer to this shared PMF or PDF. Our new notation is interesting in two\nways. First, we have now included a conditional on \u03b8 which is our way of indicating that the likelihood of\ndifferent values of X depends on the values of our parameters. Second, we are going to use the same\nsymbol f for both discrete and continuous distributions.\nWhat does likelihood mean and how is \"likelihood\" different than \"probability\"? In the case of discrete\ndistributions, likelihood is a synonym for the probability mass, or joint probability mass, of your data. In\nthe case of continuous distribution, likelihood refers to the probability density of your data.\nSince we assumed that each data point is independent, the likelihood of all of our data is the product of\nthe likelihood of each data point. Mathematically, the likelihood of our data give parameters \u03b8 is:\nn\nL(\u03b8)=\u220ff(X =x|\u0398=\u03b8)\ni i\ni=1\nFor different values of parameters, the likelihood of our data will be different. If we have correct\nparameters our data will be much more probable than if we have incorrect parameters. For that reason we\nwrite likelihood as a function of our parameters (\u03b8).\nMaximization\nIn maximum likelihood estimation (MLE) our goal is to chose values of our parameters (\u03b8) that\nmaximizes the likelihood function from the previous section. We are going to use the notation\n\u03b8^\nto\nrepresent the best choice of values for our parameters. Formally, MLE assumes that:\n\u03b8^=argmax L(\u03b8)\n\u03b8\nArgmax is short for Arguments of the Maxima. The argmax of a function is the value of the domain at\nwhich the function is maximized. It applies for domains of any dimension.\nA cool property of argmax is that since log is a monotone function, the argmax of a function is the same\nas the argmax of the log of the function! That's nice because logs make the math simpler. If we find the\nargmax of the log of likelihood it will be equal to the armax of the likelihood. Thus for MLE we first\nwrite the Log Likelihood function (LL)\nLL(\u03b8)=logL(\u03b8)\nn\n=log\u220ff(X =x|\u0398=\u03b8)\ni i\ni=1\nn\n=\u2211logf(X =x|\u0398=\u03b8)\ni i\ni=1\nTo use a maximum likelihood estimator, first write the log likelihood of the data given your parameters.\nThen chose the value of parameters that maximize the log likelihood function. Argmax can be computed\nin many ways. All of the methods that we cover in this class require computing the first derivative of the\n1\nThis is a header\nfunction.\nBernoulli MLE Estimation\nFor our first example, we are going to use MLE to estimate the p parameter of a Bernoulli distribution.\nWe are going to make our estimate based on n data points which we will refer to as IID random variables\nX 1,X 2,\u2026X n. Every one of these random variables is assumed to be a sample from the same Bernoulli,\nwith the same p, X i\u223cBer(p). We want to find out what that p is.\nStep one of MLE is to write the likelihood of a Bernoulli as a function that we can maximize. Since a\nBernoulli is a discrete distribution, the likelihood is the probability mass function.\nThe probability mass function of a Bernoulli X can be written as f(x)=px(1\u2212p)1\u2212x. Wow! What's up\nwith that? It's an equation that allows us to say that the probability that X=1 is p and the probability\nthat X=0 is 1\u2212p. Convince yourself that when X i=0 and X i=1 the PMF returns the right\nprobabilities. We write the PMF this way because its derivable.\nNow let's do some MLE estimation:\nn\nL(\u03b8)=\u220fpxi(1\u2212p)1\u2212xi Firstwritethelikelihoodfunction\ni=1\nn\nLL(\u03b8)=\u2211logpxi(1\u2212p)1\u2212xi Thenwritetheloglikelihoodfunction\ni=1\nn\n=\u2211x(logp)+(1\u2212x)log(1\u2212p)\ni i\ni=1\nn\n=Y logp+(n\u2212Y)log(1\u2212p) where Y =\u2211x\ni\ni=1\nGreat Scott! We have the log likelihood equation. Now we simply need to chose the value of p that\nmaximizes our log-likelihood. As your calculus teacher probably taught you, one way to find the value\nwhich maximizes a function that is to find the first derivative of the function and set it equal to 0.\n\u03b4LL(p) 1 \u22121\n=Y +(n\u2212Y) =0\n\u03b4p p 1\u2212p\nY \u2211n x\np^= = i=1 i\nn n\nAll that work and find out that the MLE estimate is simply the sample mean...\nNormal MLE Estimation\nPractice is key. Next up we are going to try and estimate the best parameter values for a normal\ndistribution. All we have access to are n samples from our normal which we refer to as IID random\nvariables X 1,X 2,\u2026X n. We assume that for all i, X i\u223cN(\u03bc=\u03b8 0,\u03c32=\u03b8 1). This example seems\ntrickier since a normal has two parameters that we have to estimate. In this case \u03b8 is a vector with two\nvalues, the first is the mean (\u03bc) parameter. The second is the variance(\u03c32) parameter.\nn\nL(\u03b8)=\u220ff(X|\u03b8)\ni\ni=1\n=\u220fn 1 e\u2212(xi 2\u2212 \u03b8\u03b8 10)2\nLikelihoodforacontinuousvariableisthePDF\n\u221a2\u03c0\u03b8\ni=1 1\nLL(\u03b8)=\u2211n\nlog\n1 e\u2212(xi 2\u2212 \u03b8\u03b8 10)2\nWewanttocalculateloglikelihood\n\u221a2\u03c0\u03b8\ni=1 1\nn 1\n=\u2211[\u2212log(\u221a2\u03c0\u03b8 )\u2212 (x \u2212\u03b8 )2]\n1 2\u03b8 i 0\ni=1 1\nAgain, the last step of MLE is to chose values of \u03b8 that maximize the log likelihood function. In this case\nwe can calculate the partial derivative of the LL function with respect to both \u03b8 0 and \u03b8 1, set both\nequations to equal 0 and than solve for the values of \u03b8. Doing so results in the equations for the values\n2\nThis is a header \u03bc^=\u03b8^ 0 and \u03c3^ 2=\u03b8^ 1 that maximize likelihood. The result is: \u03bc^= n1 \u2211n i=1x i and\n\u03c3^ 2= n1 \u2211n i=1(x i\u2212\u03bc^)2 .\nLinear Transform Plus Noise\nMLE is an algorithm that can be used for any probability model with a derivable likelihood function. As\nan example lets estimate the parameter \u03b8 in a model where there is a random variable Y such that\nY =\u03b8X+Z, Z\u223cN(0,\u03c32) and X is an unknown distribution.\nIn the case where you are told the value of X, \u03b8X is a number and \u03b8X+Z is the sum of a gaussian and a\nnumber. This implies that Y|X\u223cN(\u03b8X,\u03c32). Our goal is to chose a value of \u03b8 that maximizes the\nprobability IID: (X 1,Y 1),(X 2,Y 2),\u2026(X n,Y n).\nWe approach this problem by first finding a function for the log likelihood of the data given \u03b8. Then we\nfind the value of \u03b8 that maximizes the log likelihood function. To start, use the PDF of a Normal to\nexpress the probability of Y|X,\u03b8:\nf(Y i|X i,\u03b8)=\n1 e\u2212(Yi\u2212 2\u03c3\u03b8X 2i)2\n\u221a2\u03c0\u03c3\nNow we are ready to write the likelihood function, then take its log to get the log likelihood function:\nn\nL(\u03b8)=\u220ff(Y,X|\u03b8) Let'sbreakupthisjoint\ni i\ni=1\nn\n=\u220ff(Y|X,\u03b8)f(X) f(X) isindependentof \u03b8\ni i i i\ni=1\n=\u220fn 1 e\u2212(Yi\u2212 2\u03c3\u03b8X 2i)2\nf(X i) Substituteinthedefinitionof f(Y i|X i)\n\u221a2\u03c0\u03c3\ni=1\nLL(\u03b8)=logL(\u03b8)\n=log\u220fn 1 e\u2212(Yi\u2212 2\u03c3\u03b8X 2i)2\nf(X i) Substitutein L(\u03b8)\n\u221a2\u03c0\u03c3\ni=1\n=\u2211n\nlog\n1 e\u2212(Yi\u2212 2\u03c3\u03b8X 2i)2 +\u2211n\nlogf(X i) Logofaproductisthesumoflogs\n\u221a2\u03c0\u03c3\ni=1 i=1\n1 1 n n\n=nlog \u2212 \u2211(Y \u2212\u03b8X)2+\u2211logf(X)\n\u221a2\u03c0\u03c3 2\u03c32 i i i\ni=1 i=1\nRemove constant multipliers and terms that don't include \u03b8. We are left with trying to find a value of \u03b8\nthat maximizes:\nm\n\u03b8^=argmax\u2212\u2211(Y \u2212\u03b8X)2\ni i\n\u03b8 i=1\nm\n=argmin\u2211(Y \u2212\u03b8X)2\ni i\n\u03b8 i=1\nThis result says that the value of \u03b8 that makes the data most likely is one that minimizes the squared error\nof predictions of Y. We will see in a few days that this is the basis for linear regression.\n3\nThis is a header\nMaximum A Posteriori\nMLE is great, but it is not the only way to estimate parameters! This section introduces an alternate\nalgorithm, Maximum A Posteriori (MAP).The paradigm of MAP is that we should chose the value for\nour parameters that is the most likely given the data. At first blush this might seem the same as MLE,\nhowever notice that MLE chooses the value of parameters that makes the \\emph{data} most likely.\nFormally, for IID random variables X 1,\u2026,X n:\n\u03b8 =argmax f(\u0398=\u03b8|X =x ,X =x ,\u2026X =x )\nMAP 1 1 2 2 n n\n\u03b8\nIn the equation above we trying to calculate the conditional probability of unobserved random variables\ngiven observed random variables. When that is the case, think Bayes Theorem! Expand the function f\nusing the continuous version of Bayes Theorem.\n\u03b8 =argmax f(\u0398=\u03b8|X =x ,X =x ,\u2026X =x )\nMAP 1 1 2 2 n n\n\u03b8\nf(X =x ,X =x ,\u2026,X =x |\u0398=\u03b8)f(\u0398=\u03b8)\n=argmax 1 1 2 2 n n Bayes\nf(X =x ,X =x ,\u2026X =x )\n\u03b8 1 1 2 2 n n\nNote that f are all probability densities or probability mass functions. Now we are going to leverage two\nobservations. First, the data is assumed to be IID so we can decompose the density of the data given \u03b8.\nSecond, the denominator is a constant with respect to \u03b8. As such its value does not affect the argmax and\nwe can drop that term. Mathematically:\nf(\u0398=\u03b8)\u22c5\u220fn f(X =x|\u0398=\u03b8)\n\u03b8 =argmax i=1 i i SincethesamplesareIID\nMAP f(X =x ,X =x ,\u2026X =x )\n\u03b8 1 1 2 2 n n\nn\n=argmax f(\u0398=\u03b8)\u22c5\u220ff(X =x|\u0398=\u03b8) Denom.isconstantwithrespectto \u03b8\ni i\n\u03b8 i=1\nAs before, it will be more convenient to find the argmax of the log of the MAP function, which gives us\nthe final form for MAP estimation of parameters.\nn\n\u03b8 =argmax (logf(\u0398=\u03b8)+\u2211log(f(X =x|\u0398=\u03b8)))\nMAP i i\n\u03b8 i=1\nUsing Bayesian terminology, the MAP estimate is the mode of the \"posterior\" distribution for \u03b8. If you\nlook at this equation side by side with the MLE equation you will notice that MAP is the argmax of the\nexact same function \\emph{plus} a term for the log of the prior.\nParameter Priors\nIn order to get ready for the world of MAP estimation, we are going to need to brush up on our\ndistributions. We will need reasonable distributions for each of our different parameters. For example, if\nyou are predicting a Poisson distribution, what is the right random variable type for the prior of \u03bb?\nA desiderata for prior distributions is that the resulting posterior distribution has the same functional\nform. We call these \"conjugate\" priors. In the case where you are updating your belief many times,\nconjugate priors makes programming in the math equations much easier.\nHere is a list of different parameters and the distributions most often used for their priors:\nParameter Distribution\nBernoulli p Beta\nBinomial p Beta\nPoisson \u03bb Gamma\nExponential \u03bb Gamma\nMultinomial p Dirichlet\ni\nNormal \u03bc Normal\nNormal \u03c32 InverseGamma\n1\nThis is a header\nYou are only expected to know the new distributions on a high level. You do not need to know Inverse\nGamma. I included it for completeness.\nThe distributions used to represent your \"prior\" belief about a random variable will often have their own\nparameters. For example, a Beta distribution is defined using two parameters (a,b). Do we have to use\nparameter estimation to evaluate a and b too? No. Those parameters are called \"hyperparameters\". That is\na term we reserve for parameters in our model that we fix before running parameter estimate. Before you\nrun MAP you decide on the values of (a,b).\nDirichlet\nThe Dirichlet distribution generalizes Beta in same way Multinomial generalizes Bernoulli. A random\nvariable X that is Dirichlet is parametrized as X\u223cDirichlet(a 1,a 2,\u2026,a m). The PDF of the\ndistribution is:\nm\nf(X 1=x 1,X 2=x 2,\u2026,X m=x m)=K\u220fxa ii\u22121\ni=1\nWhere K is a normalizing constant.\nYou can intuitively understand the hyperparameters of a Dirichlet distribution: imagine you have seen\n\u2211m i=1a i\u2212m imaginary trials. In those trials you had (a i\u22121) outcomes of value i. As an example\nconsider estimating the probability of getting different numbers on a six-sided Skewed Dice (where each\nside is a different shape). We will estimate the probabilities of rolling each side of this dice by repeatedly\nrolling the dice n times. This will produce n IID samples. For the MAP paradigm, we are going to need a\nprior on our belief of each of the parameters p 1\u2026p 6. We want to express that we lightly believe that\neach roll is equally likely.\nBefore you roll, let's imagine you had rolled the dice six times and had gotten one of each possible\nvalues. Thus the \"prior\" distribution would be Dirichlet(2,2,2,2,2,2). After observing\nn 1+n 2+\u22ef+n 6 new trials with n i results of outcome i, the \"posterior\" distribution is Dirichlet(\n2+n 1,\u20262+n 6). Using a prior which represents one imagined observation of each outcome is called\n\"Laplace smoothing\" and it guarantees that none of your probabilities are 0 or 1.\nGamma\nThe Gamma(k,\u03b8) distribution is the conjugate prior for the \u03bb parameter of the Poisson distribution (It is\nalso the conjugate for Exponential, but we won't delve into that).\nThe hyperparameters can be interpreted as: you saw k total imaginary events during \u03b8 imaginary time\nperiods. After observing n events during the next t time periods the posterior distribution is Gamma(\nk+n,\u03b8+t).\nFor example Gamma(10, 5) would represent having seen 10 imaginary events in 5 time periods. It is like\nimagining a rate of 2 with some degree of confidence. If we start with that Gamma as a prior and then see\n11 events in the next 2 time periods our posterior is Gamma(21,7) which is equivalent to an updated rate\nof 3.\n2\nThis is a header\nMachine Learning\nMachine Learning is the subfield of computer science that gives computers the ability to perform tasks\nwithout being explicitly programmed. There are several different tasks that fall under the domain of\nmachine learning and several different algorithms for \"learning\". In this chapter, we are going to focus on\nClassification and two classic Classification algorithms: Naive Bayes and Logistic Regression.\nClassification\nIn classification tasks, your job is to use training data with feature/label pairs (x, y) in order to estimate a\nfunction y^=g(x). This function can then be used to make a prediction. In classification the value of y\ntakes on one of a \\textbf{discrete} number of values. As such we often chose\ng(x)=argmax P^(Y =y|X=x).\ny\nIn the classification task you are given N training pairs: (x(1),y(1)),(x(2),y(2)),\u2026,(x(N),y(N)) Where\nx(i) is a vector of m discrete features for the ith training example and y(i) is the discrete label for the ith\ntraining example.\nIn our introduction to machine learning, we are going to assume that all values in our training data-set are\nbinary. While this is not a necessary assumption, it makes it much easier to learn the core concepts.\nSpecifically we assume that all labels are binary y(i)\u2208{0,1} \u2200i and all features are binary\nx(i)\u2208{0,1} \u2200i,j.\nj\n1\nThis is a header\nNa\u00efve Bayes\nNaive Bayes is a Machine Learning algorithm for the ``classification task\". It make the substantial\nassumption (called the Naive Bayes assumption) that all features are independent of one another, given\nthe classification label. This assumption is wrong, but allows for a fast and quick algorithm that is often\nuseful. In order to implement Naive Bayes you will need to learn how to train your model and how to use\nit to make predictions, once trained.\nTraining (aka Parameter Estimation)\nThe objective in training is to estimate the probabilities P(Y) and P(X i|Y) for all 0<i\u2264m features.\nWe use the symbol p^ to make it clear that the probability is an estimate.\nUsing an MLE estimate:\n(#trainingexampleswhere X =x and Y =y)\np^(X =x|Y =y)= i i\ni i (#trainingexampleswhere Y =y)\nUsing a Laplace MAP estimate:\n(#trainingexampleswhere X =x and Y =y)+1\np^(X =x|Y =y)= i i\ni i (#trainingexampleswhere Y =y)+2\nThe prior probability of Y trained using an MLE estimate:\n(#trainingexampleswhere Y =y)\np^(Y =y)=\n(#trainingexamples)\nPrediction\nFor an example with x=[x 1,x 2,\u2026,x m], estimate the value of y as:\nm\ny^=arg max logp^(Y =y)+\u2211logp^(X =x|Y =y)\ni i\ny={0,1} i=1\nNote that for small enough datasets you may not need to use the log version of the argmax.\nTheory\nIn the world of classification when we make a prediction we want to chose the value of y that maximizes\nP(Y =y|X).\ny^=arg maxP(Y =y|X=X) Ourobjective\ny={0,1}\nP(Y =y)P(X=x|Y =y)\n=arg max Bybayestheorem\nP(X=x)\ny={0,1}\n=arg maxP(Y =y)P(X=x|Y =y)) Since P(X=x) isconstantwithrespectto Y\ny={0,1}\nUsing our training data we could interpret the joint distribution of X and Y as one giant multinomial with\na different parameter for every combination of X=x and Y =y. If for example, the input vectors are\nonly length one. In other words |x|=1 and the number of values that x and y can take on are small, say\nbinary, this is a totally reasonable approach. We could estimate the multinomial using MLE or MAP\nestimators and then calculate argmax over a few lookups in our table.\nThe bad times hit when the number of features becomes large. Recall that our multinomial needs to\nestimate a parameter for every unique combination of assignments to the vector x and the value y. If\nthere are |x|=n binary features then this strategy is going to take order O(2n) space and there will\n1\nThis is a header\nlikely be many parameters that are estimated without any training data that matches the corresponding\nassignment.\nNaive Bayes Assumption\nThe Na\u00efve Bayes Assumption is that each feature of x is independent of one another given y.\nThe Na\u00efve Bayes Assumption is wrong, but useful. This assumption allows us to make predictions using\nspace and data which is linear with respect to the size of the features: O(n) if |x|=n. That allows us to\ntrain and make predictions for huge feature spaces such as one which has an indicator for every word on the\ninternet. Using this assumption the prediction algorithm can be simplified.\ny^=arg max P(Y =y)P(X=x|Y =y) Aswelastleftoff\ny={0,1}\n=arg max P(Y =y)\u220fP(X i=x i|Y =y) Na\u00efvebayesassumption\ny={0,1} i\n=arg max logP(Y =y)+\u2211logP(X =x|Y =y) Fornumericalstability\ni i\ny={0,1} i\nIn the last step we leverage the fact that the argmax of a function is equal to the argmax of the log of a\nfunction. This algorithm is both fast and stable both when training and making predictions.\n2\nThis is a header\nLogistic Regression\nLogistic Regression is a classification algorithm (I know, terrible name. Perhaps Logistic Classification\nwould have been better) that works by trying to learn a function that approximates P(y|x). It makes the\ncentral assumption that P(y|x) can be approximated as a sigmoid function applied to a linear\ncombination of input features. It is particularly important to learn because logistic regression is the basic\nbuilding block of artificial neural networks.\nMathematically, for a single training datapoint (x,y) Logistic Regression assumes:\nm\nP(Y =1|X=x)=\u03c3(z) where z=\u03b8 +\u2211\u03b8x\n0 i i\ni=1\nThis assumption is often written in the equivalent forms:\nP(Y =1|X=x)=\u03c3(\u03b8Tx) wherewealwaysset x tobe1\n0\nP(Y =0|X=x)=1\u2212\u03c3(\u03b8Tx) bytotallawofprobability\nUsing these equations for probability of Y|X we can create an algorithm that selects values of theta that\nmaximize that probability for all data. I am first going to state the log probability function and partial\nderivatives with respect to theta. Then later we will (a) show an algorithm that can chose optimal values\nof theta and (b) show how the equations were derived.\nAn important thing to realize is that: given the best values for the parameters (\u03b8), logistic regression often\ncan do a great job of estimating the probability of different class labels. However, given bad , or even\nrandom, values of \u03b8 it does a poor job. The amount of ``intelligence\" that you logistic regression machine\nlearning algorithm has is dependent on having good values of \u03b8.\nNotation\nBefore we get started I want to make sure that we are all on the same page with respect to notation. In\nlogistic regression, \u03b8 is a vector of parameters of length m and we are going to learn the values of those\nparameters based off of n training examples. The number of parameters should be equal to the number of\nfeatures of each datapoint.\nTwo pieces of notation that we use often in logistic regression that you may not be familiar with are:\nm\n\u03b8Tx=\u2211\u03b8x =\u03b8 x +\u03b8 x +\u22ef+\u03b8 x dotproduct,akaweightedsum\ni i 1 1 2 2 m m\ni=1\n1\n\u03c3(z)= sigmoidfunction\n1+e\u2212z\nLog Likelihood\nIn order to chose values for the parameters of logistic regression we use Maximum Likelihood\nEstimation (MLE). As such we are going to have two steps: (1) write the log-likelihood function and (2)\nfind the values of \u03b8 that maximize the log-likelihood function.\nThe labels that we are predicting are binary, and the output of our logistic regression function is supposed\nto be the probability that the label is one. This means that we can (and should) interpret the each label as\na Bernoulli random variable: Y \u223cBern(p) where p=\u03c3(\u03b8Tx).\nTo start, here is a super slick way of writing the probability of one datapoint (recall this is the equation\nform of the probability mass function of a Bernoulli):\nP(Y\n=y|X=x)=\u03c3(\u03b8Tx)y\u22c5[1\u2212\u03c3(\u03b8Tx)](1\u2212y)\nNow that we know the probability mass function, we can write the likelihood of all the data:\n1\nThis is a header n\nL(\u03b8)=\u220fP(Y =y(i)|X=x(i)) Thelikelihoodofindependenttraininglabels\ni=1\nn (1\u2212y(i))\n=\u220f\u03c3(\u03b8Tx(i))y(i)\u22c5[1\u2212\u03c3(\u03b8Tx(i))] SubstitutingthelikelihoodofaBernoulli\ni=1\nAnd if you take the log of this function, you get the reported Log Likelihood for Logistic Regression. The\nlog likelihood equation is:\nn\nLL(\u03b8)=\u2211y(i)log\u03c3(\u03b8Tx(i))+(1\u2212y(i))log[1\u2212\u03c3(\u03b8Tx(i))]\ni=1\nRecall that in MLE the only remaining step is to chose parameters (\u03b8) that maximize log likelihood.\nGradient of Log Likelihood\nNow that we have a function for log-likelihood, we simply need to chose the values of theta that maximize\nit. We can find the best values of theta by using an optimization algorithm. However, in order to use an\noptimization algorithm, we first need to know the partial derivative of log likelihood with respect to each\nparameter. First I am going to give you the partial derivative (so you can see how it is used). Then I am\ngoing to show you how to derive it:\n\u2202LL(\u03b8) n\n=\u2211[y(i)\u2212\u03c3(\u03b8Tx(i))]x(i)\n\u2202\u03b8 j\nj i=1\nGradient Descent Optimization\nOur goal is to choosing parameters (\u03b8) that maximize likelihood, and we know the partial derivative of\nlog likelihood with respect to each parameter. We are ready for our optimization algorithm.\nIn the case of logistic regression we can't solve for \u03b8 mathematically. Instead we use a computer to chose\n\u03b8. To do so we employ an algorithm called gradient descent (a classic in optimization theory). The idea\nbehind gradient descent is that if you continuously take small steps downhill (in the direction of your\nnegative gradient), you will eventually make it to a local minima. In our case we want to maximize our\nlikelihood. As you can imagine, minimizing a negative of our likelihood will be equivalent to\nmaximizing our likelihood.\nThe update to our parameters that results in each small step can be calculated as:\n\u2202LL(\u03b8 old)\n\u03b8 new=\u03b8 old+\u03b7\u22c5\nj j \u2202\u03b8 old\nj\nn\n=\u03b8 old+\u03b7\u22c5\u2211[y(i)\u2212\u03c3(\u03b8Tx(i))]x(i)\nj j\ni=1\nWhere \u03b7 is the magnitude of the step size that we take. If you keep updating \u03b8 using the equation above\nyou will converge on the best values of \u03b8. You now have an intelligent model. Here is the gradient ascent\nalgorithm for logistic regression in pseudo-code:\nPro-tip: Don't forget that in order to learn the value of \u03b8 0 you can simply define x 0 to always be 1.\n2\nThis is a header\nDerivations\nIn this section we provide the mathematical derivations for the gradient of log-likelihood. The derivations\nare worth knowing because these ideas are heavily used in Artificial Neural Networks.\nOur goal is to calculate the derivative of the log likelihood with respect to each theta. To start, here is the\ndefinition for the derivative of a sigmoid function with respect to its inputs:\n\u2202\n\u03c3(z)=\u03c3(z)[1\u2212\u03c3(z)] togetthederivativewithrespectto \u03b8,usethechainrule\n\u2202z\nTake a moment and appreciate the beauty of the derivative of the sigmoid function. The reason that\nsigmoid has such a simple derivative stems from the natural exponent in the sigmoid denominator.\nSince the likelihood function is a sum over all of the data, and in calculus the derivative of a sum is the\nsum of derivatives, we can focus on computing the derivative of one example. The gradient of theta is\nsimply the sum of this term for each training datapoint.\nFirst I am going to show you how to compute the derivative the hard way. Then we are going to look at\nan easier method. The derivative of gradient for one datapoint (x,y):\n\u2202LL(\u03b8) \u2202 \u2202\n= ylog\u03c3(\u03b8Tx)+ (1\u2212y)log[1\u2212\u03c3(\u03b8Tx] derivativeofsumofterms\n\u2202\u03b8 \u2202\u03b8 \u2202\u03b8\nj j j\ny 1\u2212y \u2202\n=[ \u2212 ] \u03c3(\u03b8Tx) derivativeoflog f(x)\n\u03c3(\u03b8Tx) 1\u2212\u03c3(\u03b8Tx) \u2202\u03b8\nj\ny 1\u2212y\n=[ \u2212 ]\u03c3(\u03b8Tx)[1\u2212\u03c3(\u03b8Tx)]x chainrule+derivativeofsigma\n\u03c3(\u03b8Tx) 1\u2212\u03c3(\u03b8Tx) j\ny\u2212\u03c3(\u03b8Tx)\n=[ ]\u03c3(\u03b8Tx)[1\u2212\u03c3(\u03b8Tx)]x algebraicmanipulation\n\u03c3(\u03b8Tx)[1\u2212\u03c3(\u03b8Tx)] j\n=[y\u2212\u03c3(\u03b8Tx)]x cancellingterms\nj\nDerivatives Without Tears\nThat was the hard way. Logistic regression is the building block of Artificial Neural Networks. If we\nwant to scale up, we are going to have to get used to an easier way of calculating derivatives. For that we\nare going to have to welcome back our old friend the chain rule. By the chain rule:\n\u2202LL(\u03b8) \u2202LL(\u03b8) \u2202p\n= \u22c5 Where p=\u03c3(\u03b8Tx)\n\u2202\u03b8 \u2202p \u2202\u03b8\nj j\n\u2202LL(\u03b8) \u2202p \u2202z\n= \u22c5 \u22c5 Where z=\u03b8Tx\n\u2202p \u2202z \u2202\u03b8\nj\nChain rule is the decomposition mechanism of calculus. It allows us to calculate a complicated partial\n\u2202LL(\u03b8)\nderivative ( ) by breaking it down into smaller pieces.\n\u2202\u03b8j\nLL(\u03b8)=ylogp+(1\u2212y)log(1\u2212p) Where p=\u03c3(\u03b8Tx)\n\u2202LL(\u03b8) y 1\u2212y\n= \u2212 Bytakingthederivative\n\u2202p p 1\u2212p\np=\u03c3(z) Where z=\u03b8Tx\n\u2202p\n=\u03c3(z)[1\u2212\u03c3(z)] Bytakingthederivativeofthesigmoid\n\u2202z\nz=\u03b8Tx Aspreviouslydefined\n\u2202z\n=x Only x interactswith \u03b8\n\u2202\u03b8 j j j\nj\nEach of those derivatives was much easier to calculate. Now we simply multiply them together.\n3\nThis is a header \u2202LL(\u03b8) \u2202LL(\u03b8) \u2202p \u2202z\n= \u22c5 \u22c5\n\u2202\u03b8 \u2202p \u2202z \u2202\u03b8\nj j\ny 1\u2212y\n=[ \u2212 ]\u22c5\u03c3(z)[1\u2212\u03c3(z)]\u22c5x Bysubstitutinginforeachterm\np 1\u2212p j\ny 1\u2212y\n=[ \u2212 ]\u22c5p[1\u2212p]\u22c5x Since p=\u03c3(z)\np 1\u2212p j\n=[y(1\u2212p)\u2212p(1\u2212y)]\u22c5x Multiplyingin\nj\n=[y\u2212p]x Expanding\nj\n=[y\u2212\u03c3(\u03b8Tx)]x Since p=\u03c3(\u03b8Tx)\nj\n4\nThis is a header\nDiffusion\nDiffusion Task\nGoal: Create a model that can generate pictures of trees from the \"tree photo distribution\"\nData: Many pictures of trees:\nBig Picture Idea\nSupplement your dataset by iteratively adding gaussian noise to pixels, then train a deep learning model\nto remove noise.\nA reasonable number of steps would be to add 10% noise each time step, so that after 10 timesteps each\npixel is fully noise.\nThe key task is to train a deep neural network to predict the \"denoised\" value of pixels:\nLoss: Mean squared error between the predicted pixels and the true color. Set the parameters of your\nneural network to minimize loss. Then you have a model which can remove 10% noise one step at a time.\nStart with random noise, then run it through your denoising neural network 10 times.\n1\nThis is a header\nTheory Behind Diffusion Models\nThe magic of diffusion models lies in the Gaussian noise process. Let\u2019s break it down:\n1. Adding Noise: The Forward Process\nAt each step t, we add Gaussian noise to the pixel values:\nx =x +n where n \u223cN(0,\u03c32).\nt+1 t t t\nThis gradually turns the original image into pure noise.\n2. Removing Noise: The Reverse Process\nTo reverse this process, we need the conditional distribution x t\u22121|x t. Here\u2019s the surprising part:\nCritical Fact #1: x t\u22121|x t is Gaussian with known variance\nIf the noise variance \u03c32 is small enough, the distribution of x t\u22121|x t can be approximated as:\nx |x \u223cN(\u03bc (x),\u03c32),\nt\u22121 t t\u22121 t\nwhere:\n\u03bc t\u22121(x t): The mean of the Gaussian, which depends on x t.\n\u03c32: The known variance of the noise.\nThis is great news! It means we only need to estimate the mean \u03bc t\u22121(x t) to fully describe x t\u22121|x t.\n3. Training the Neural Network\nCritical Fact #2: Standard regression is all you need!\nTo train the neural network, we need it to predict \u03bc t\u22121(x t), the mean of the Gaussian. How do we\nmeasure the quality of the predictions?\nThe difference between the predicted Gaussian q \u03b8(x t\u22121|x t) (from the neural network) and the true\nGaussian p(x t\u22121|x t) can be measured by the KL divergence. Happily in this case:\nMinimizingKLdivergence \u21d4Minimizingmeansquarederror(MSE).\nThis is only true because the distributions are Gaussian. Thus, we can simply train the neural network to\nminimize the MSE between its prediction of pixel values (\u03bc t\u22121(x t)) and the true pixel values.\nOnce trained, the neural network can iteratively denoise an image, starting with random noise, until it\ngenerates a clear, realistic image.\n4. The Complete Diffusion Algorithm\nHere\u2019s the full workflow for a diffusion model:\n1. Forward process: Add Gaussian noise to turn images into pure noise.\n2. Reverse process: Train a neural network to predict the mean \u03bc t\u22121(x t) and remove noise step-by-step.\n3. Image generation: Start with random noise and run the neural network in reverse T times to generate\na realistic image.\nThis elegant approach combines simple Gaussian noise with the power of deep learning to generate\nstunning results!\n2\nThis is a header\nProof Sketch of Critical Idea #1\nClaim: x t\u22121|x t is approximately Gaussian when the noise variance \u03c32 is small enough.\nWe start with Bayes' theorem to express the conditional probability:\nP(x|x )P(x )\nP(x |x)= t t\u22121 t\u22121\nt\u22121 t P(x)\nt\nWe are going to think about the log of this expression. This is because the log of a Gaussian is a quadratic\nfunction, which will make our math easier. We can write:\nlogP(x |x)=logP(x|x )+logP(x )\u2212logP(x)\nt\u22121 t t t\u22121 t\u22121 t\nLet's break down the terms in this expression.\nForward process likelihood:\nFrom the forward process, x t given x t\u22121 is Gaussian:\n1 (x \u2212x )2\nP(x|x )= exp(\u2212 t t\u22121 ).\nt t\u22121 \u221a2\u03c0\u03c32 2\u03c32\nTaking the log, we get:\n(x \u2212x )2\nlogP(x|x )=\u2212 t t\u22121 +constant\nt t\u22121 2\u03c32\nPrior on x t\u22121:\nThe prior p(x t\u22121) is the probability of x t\u22121 at the previous step. This one is hard to know! What is the\nprior distribution of a pixel of a tree? However we employ a really neat trick. Its log-density can be\nTaylor expanded around x t, assuming x t\u22121 is close to x t:\n\u2202\nlogP(x )\u2248logP(x)+[ logP(x)](x \u2212x)\nt\u22121 t \u2202x t t\u22121 t\nCompleting the square:\nThere are two terms in the above expressions involving the difference between x t\u22121 and x t. As a helpful\nstep, we will complete the square for these terms.\nComplete the square for this sum of terms:\n(x \u2212x )2 \u2202\n\u2212 t t\u22121 +[ logP(x)](x \u2212x)\n2\u03c32 \u2202x t t\u22121 t\nFirst, rewrite (x t\u2212x t\u22121)2:\n(x \u2212x )2=(x \u2212x)2\nt t\u22121 t\u22121 t\nAllowing us to rewrite our sum as:\n1 \u2202\n\u2212 (x \u2212x)2+[ logP(x)](x \u2212x)\n2\u03c32 t\u22121 t \u2202x t t\u22121 t\nFactor out \u2212 1 to make the quadratic term more explicit:\n2\u03c32\n1 \u2202\n\u2212 [(x \u2212x)2\u22122\u03c32[ logP(x)](x \u2212x)]\n2\u03c32 t\u22121 t \u2202x t t\u22121 t\nThe expression inside the brackets is a quadratic expression in (x t\u22121\u2212x t). Let\u2019s complete the square for:\n\u2202\n(x \u2212x)2\u22122\u03c32[ logP(x)](x \u2212x)\nt\u22121 t \u2202x t t\u22121 t\nThis allows us to rewrite the quadratic expression as:\n3\nThis is a header \u2202 2 \u2202 2\n[(x \u2212x)\u2212\u03c32[ logP(x)]] \u2212(\u03c32[ logP(x)])\nt\u22121 t \u2202x t \u2202x t\nSubstitute this back. Let K stand in for constant:\nlogP(x |x)=logP(x|x )+logP(x )\u2212logP(x)\nt\u22121 t t t\u22121 t\u22121 t\n(x \u2212x )2 \u2202\n=\u2212 t t\u22121 +(logP(x)+[ logP(x)](x \u2212x))\u2212logP(x)+K\n2\u03c32 t \u2202x t t\u22121 t t\n(x \u2212x )2 \u2202\n=\u2212 t t\u22121 +[ logP(x)](x \u2212x)+K\n2\u03c32 \u2202x t t\u22121 t\n1 \u2202 2\n=\u2212 [(x \u2212x \u2212\u03c32[ logP(x)]) ]+K\n2\u03c32 t\u22121 t \u2202x t\nFinal Result: Recall that the log of the gaussian PMF looks like this:\nLet X\u223cN(\u03bc,\u03c32). What is the log of the PMF of X?\n1\nlogP(X=x)=\u2212 (x\u2212\u03bc)2+K\n2\u03c32\nFrom the above, we see that x t\u22121|x t is Gaussian. How do we know this? The distribution is identical, up to\nadditive factors, to the log-density of a Normal distribution.\nx |x \u223cN(\u03bc ,\u03c32),\nt\u22121 t t\u22121\nwhere:\n\u2202\n\u03bc =x +\u03c32[ logP(x)]\nt\u22121 t \u2202x t\nThe variance remains \u03c32, which is fixed from the forward process.\n4\nThis is a header\nMLE Normal Demo\nLets manually perform maximum likelihood estimation. Your job is to chose parameter values that make\nthe data look as likely as possible. Here are the 20 data points, which we assume come from a Normal\ndistribution\nData = [6.3 , 5.5 , 5.4, 7.1, 4.6, 6.7, 5.3 , 4.8, 5.6, 3.4, 5.4, 3.4, 4.8, 7.9, 4.6, 7.0, 2.9, 6.4, 6.0 , 4.3]\nChose your parameter estimates\nParameter \u03bc: 5 Parameter \u03c3: 3\nLikelihood of the data given your params\nLikelihood: 4.0307253523200347e-19\nLog Likelihood: -399.7\nBest Seen: -399.7\nYour Gaussian\n1\nThis is a header\nMLE of a Pareto Distribution\nYou are creating artwork with different sized circles which follow a Pareto distribution:\nX\u223cPareto(\u03b1)\nA Pareto distribution is defined by a single parameter \u03b1 and has PDF\n\u03b1\nf(x)=\nx\u03b1+1\nYou would like the alpha in your artwork to match that of sand in your local beach. You go to the\nbeachand collect 100 particles of sand and measure their size. Call the measured radii x 1,\u2026,x 100:\nobservations = [1.677, 3.812, 1.463, 2.641, 1.256, 1.678, 1.157,\n1.146, 1.323, 1.029, 1.238, 1.018, 1.171, 1.123, 1.074, 1.652,\n1.873, 1.314, 1.309, 3.325, 1.045, 2.271, 1.305, 1.277, 1.114,\n1.391, 3.728, 1.405, 1.054, 2.789, 1.019, 1.218, 1.033, 1.362,\n1.058, 2.037, 1.171, 1.457, 1.518, 1.117, 1.153, 2.257, 1.022,\n1.839, 1.706, 1.139, 1.501, 1.238, 2.53 , 1.414, 1.064, 1.097,\n1.261, 1.784, 1.196, 1.169, 2.101, 1.132, 1.193, 1.239, 1.518,\n2.764, 1.053, 1.267, 1.015, 1.789, 1.099, 1.25 , 1.253, 1.418,\n1.494, 1.015, 1.459, 2.175, 2.044, 1.551, 4.095, 1.396, 1.262,\n1.351, 1.121, 1.196, 1.391, 1.305, 1.141, 1.157, 1.155, 1.103,\n1.048, 1.918, 1.889, 1.068, 1.811, 1.198, 1.361, 1.261, 4.093,\n2.925, 1.133, 1.573]\nDerive a formula for the MLE estimate of \u03b1 based on the data you have collected.\nWriting the Log Likelihood Function\nThe first major objective in MLE is to come up with a log likelihood expression for our data. To do so we\nstart by writing how likely our dataset looks, if we are told the value of \u03b1:\nn \u03b1\nL(\u03b1)=f(x \u2026x )=\u220f\n1 n x\u03b1+1\ni=1 i\nOptimization will be much easier if we instead try to optimize the log likelihood:\nn \u03b1\nLL(\u03b1)=logL(\u03b1)=log\u220f\nx\u03b1+1\ni=1 i\nn \u03b1\n=\u2211log\nx\u03b1+1\ni=1 i\nn\n=\u2211log\u03b1\u2212(\u03b1+1)logx\ni\ni=1\nn\n=nlog\u03b1\u2212(\u03b1+1)\u2211logx\ni\ni=1\n\u03b1\nSelecting\nWe are going to select \u03b1 to be the value which maximizes the log likelihood. To do so we are going to\nneed the derivative of LL w.r.t. \u03b1\n\u2202LL(\u03b1) \u2202LL(\u03b1) n\n= (nlog\u03b1\u2212(\u03b1+1)\u2211logx)\n\u2202\u03b1 \u2202\u03b1 i\ni=1\nn n\n= \u2212\u2211logx\n\u03b1 i\ni=1\nOne way to optimize is to take the derivative and set it equal to zero:\n1\nThis is a header n n\n0= \u2212\u2211logx\n\u03b1 i\ni=1\nn n\n\u2211logx =\ni \u03b1\ni=1\nn\n\u03b1=\nn\n\u2211logx\ni\ni=1\nAt this point we have a formula that we can use to calculate \u03b1! Wahoo\nPutting it into code\nimport math\ndef estimate_alpha(observations):\n# This code computes the MLE estimate of alpha\nlog_sum = 0\nfor x_i in observations:\nlog_sum += math.log(x_i)\nn = len(observations)\nreturn n / log_sum\ndef main():\nobservations = [1.677, 3.812, 1.463, 2.641, 1.256, 1.678, 1.157, 1.146,\n1.323, 1.029, 1.238, 1.018, 1.171, 1.123, 1.074, 1.652, 1.873, 1.314,\n1.309, 3.325, 1.045, 2.271, 1.305, 1.277, 1.114, 1.391, 3.728, 1.405,\n1.054, 2.789, 1.019, 1.218, 1.033, 1.362, 1.058, 2.037, 1.171, 1.457,\n1.518, 1.117, 1.153, 2.257, 1.022, 1.839, 1.706, 1.139, 1.501, 1.238,\n2.53 , 1.414, 1.064, 1.097, 1.261, 1.784, 1.196, 1.169, 2.101, 1.132,\n1.193, 1.239, 1.518, 2.764, 1.053, 1.267, 1.015, 1.789, 1.099, 1.25 ,\n1.253, 1.418, 1.494, 1.015, 1.459, 2.175, 2.044, 1.551, 4.095, 1.396,\n1.262, 1.351, 1.121, 1.196, 1.391, 1.305, 1.141, 1.157, 1.155, 1.103,\n1.048, 1.918, 1.889, 1.068, 1.811, 1.198, 1.361, 1.261, 4.093, 2.925,\n1.133, 1.573]\nalpha = estimate_alpha(observations)\nprint(alpha)\nif __name__ == '__main__':\nmain()\n2\nThis is a header\nGaussian Mixtures\nData = [6.47, 5.82, 8.7, 4.76, 7.62, 6.95, 7.44, 6.73, 3.38, 5.89, 7.81, 6.93, 7.23, 6.25, 5.31, 7.71, 7.42,\n5.81, 4.03, 7.09, 7.1, 7.62, 7.74, 6.19, 7.3, 7.37, 6.99, 2.97, 3.3, 7.08, 6.23, 3.67, 3.05, 6.67, 6.5, 6.08,\n3.7, 6.76, 6.56, 3.61, 7.25, 7.34, 6.27, 6.54, 5.83, 6.44, 5.34, 7.7, 4.19, 7.34]\nParameter t: Parameter \u03bc a: Parameter \u03c3 a: Parameter \u03bc b: Parameter \u03c3 b:\n0.2 3.5 0.7 6.8 0.7\nLikelihood: 1.847658621579746e-34\nLog Likelihood: -77.7\nBest Seen: -77.7\nWhat is a Gaussian Mixture?\nA Gaussian Mixture describes a random variable whose PDF could come from one of two Gaussians (or\nmore, but we will just use two in this demo). There is a certain probability the sample will come from the\nfirst gaussian, otherwise it comes from the second. It has five parameters: 4 to describe the two gaussians\nand one to describe the relative weighting of the two gaussians.\nGenerative Code\nfrom scipy import stats\ndef sample():\n# choose group membership\nmembership = stats.bernoulli.rvs(0.2)\nif membership == 1:\n# sample from gaussian 1\nreturn stats.norm.rvs(3.5,0.7)\nelse:\n# sample from gaussian 2\nreturn stats.norm.rvs(6.8,0.7)\nProbability Density Function\nf(X=x)=t\u22c5f(A=x)+(1\u2212t)\u22c5f(B=x)\nst\nA\u223cN(\u03bc ,\u03c32)\na a\nB\u223cN(\u03bc ,\u03c32)\nb b\nPutting it all together, the PDF of a Gaussian Mixture is:\n1\nThis is a header f(x)=t\u22c5( 1 e\u22121 2(x\u2212 \u03c3a\u03bca)2)+(1\u2212t)\u22c5( 1 e\u22121 2(x\u2212 \u03c3b\u03bcb)2)\n\u221a2\u03c0\u03c3 \u221a2\u03c0\u03c3\na b\nMLE for Gaussian Mixture\nSpecial note: even though the generative story has a bernoulli (group membership) it is never observed.\nMLE maximizes the likelihood of the observed data.\nLet \u03b8\u2192=[t,\u03bc a,\u03bc b,\u03c3 a,\u03c3 b] be the parameters. Because the math will get long I will use \u03b8 as notation in\nplace of\n\u03b8\u2192\n. Just keep in mind that it is a vector.\nThe MLE idea is to chose values of \u03b8 which maximize log likelihood. All optimization methods require\nus to calculate the partial derivatives of the thing we want to optimize (log likelihood) with respect to the\nvalues we can change (our parameters).\nLikelihood function\nn\nL(\u03b8)=\u220ff(x|\u03b8)\ni\ni\n=\u220fn [t\u22c5( 1 e\u22121 2(xi \u03c3\u2212 a\u03bca)2)+(1\u2212t)\u22c5( 1 e\u22121 2(xi \u03c3\u2212 b\u03bcb)2)]\n\u221a2\u03c0\u03c3 \u221a2\u03c0\u03c3\ni a b\nLog Likelihood function\nLL(\u03b8)=logL(\u03b8)\nn\n=log\u220ff(x|\u03b8)\ni\ni\nn\n=\u2211logf(x|\u03b8)\ni\ni\nThat is sufficient for now, but if you wanted to expand out the term you would get:\nLL(\u03b8)=\u2211n log[t\u22c5( 1 e\u22121 2(xi \u03c3\u2212 a\u03bca)2)+(1\u2212t)\u22c5( 1 e\u22121 2(xi \u03c3\u2212 b\u03bcb)2)]\n\u221a2\u03c0\u03c3 \u221a2\u03c0\u03c3\ni a b\nDerivative of LL with respect to \u03b8\nHere is an example of calculating a partial derivative with respect to one of the parameters, \u03bc a. You\nwould need a derivative like this for all parameters.\nCaution: When I first wrote this demo I thought it would be a simple derivative . It is not so simple\nbecause the log has a sum in it. As such the log term doesn't reduce. The log still serves to make the\nouter \u220f into a \u2211. As such the LL partial derivatives are solvable, but the proof uses quite a lot of\nchain rule.\nTakeaway: The main takeaway from this section (in case you want to skip the derivative proof) is that\nthe resulting derivative is complex enough that we will want a way to compute argmax without having\nto set that derivative equal to zero and solving for \u03bc a. Enter gradient descent!\nA good first step when doing a huge derivative of a log likelihood function is to think of the derivative\nfor the log of likelihood of a single datapoint. This is the inner sum in the log likelihood expression:\nd\nlogf(x|\u03b8)\nd\u03bc i\na\nBefore we start: notice that \u03bc a does not show up in this term from f(x i|\u03b8):\n(1\u2212t)\u22c5( 1 e\u22121 2(xi \u03c3\u2212 b\u03bcb)2)=K\n\u221a2\u03c0\u03c3\nb\nIn the proof, when we encounter this term, we are going to think of it as a constant which we call K. Ok,\nlets go for it!\n2\n\u23a2 \u23a5\nThis is a header d\nlogf(x|\u03b8)\nd\u03bc i\na\n1 d\n= f(x|\u03b8) chainruleon log\nf(x|\u03b8) d\u03bc i\ni a\n1 d 1\n=\nf(x i|\u03b8) d\u03bc\na[t\u22c5(\n\u221a2\u03c0\u03c3\nae\u22121 2(xi \u03c3\u2212 a\u03bca)2)+K] substitutein f(x i|\u03b8)\n1 d 1 d\n= [t\u22c5( e\u22121(xi\u2212\u03bca)2)] K=0\nf(x i|\u03b8) d\u03bc a \u221a2\u03c0\u03c3 a\n2 \u03c3a\nd\u03bc a\nt d\n= \u22c5 e\u22121(xi\u2212\u03bca)2 pulloutconst\nf(x i|\u03b8)\u221a2\u03c0\u03c3 a d\u03bc a\n2 \u03c3a\nt d 1 x \u2212\u03bc\n=\nf(x i|\u03b8)\u221a2\u03c0\u03c3 a\n\u22c5e\u22121 2(xi \u03c3\u2212 a\u03bca)2\u22c5\nd\u03bc a\n\u2212 2( i\n\u03c3 a\na)2 chainon ex\nt x \u2212\u03bc d x \u2212\u03bc\n=\nf(x i|\u03b8)\u221a2\u03c0\u03c3 a\n\u22c5e\u22121 2(xi \u03c3\u2212 a\u03bca)2\u22c5[\u2212( i\n\u03c3 a\na)\nd\u03bc\na( i\n\u03c3 a\na)] chainon x2\n=\nf(x\ni|\u03b8)t\n\u221a2\u03c0\u03c3\na\n\u22c5e\u22121 2(xi \u03c3\u2212 a\u03bca)2\u22c5[\u2212(x i \u03c3\u2212 a\u03bc a)\u22c5 \u2212\n\u03c3\na1 ] finalderivative\nt\n= \u22c5e\u22121(xi\u2212\u03bca)2\u22c5(x \u2212\u03bc ) simplify\n2 \u03c3a i a\nf(x|\u03b8)\u221a2\u03c0\u03c33\ni a\nThat was for a single data-point. For the full dataset:\ndLL(\u03b8) n d\n=\u2211 logf(x|\u03b8)\nd\u03bc d\u03bc i\na i a\n=\u2211n t \u22c5e\u22121 2(xi \u03c3\u2212 a\u03bca)2\u22c5(x i\u2212\u03bc a)\nf(x|\u03b8)\u221a2\u03c0\u03c33\ni i a\nThis process should be repeated for all five parameters! Now, how should we find a value of \u03bc a, which,\nin the presence of the other settings to parameters, and the data, makes this derivative zero? Setting the\nderivative = 0 and solving for \u03bc a is not going to work.\nUse an Optimizer to Estimate Params\nOnce we have a LL function and the derivative of LL with respect to each parameter we are ready to\ncompute argmax using an optimizer. In this case the best choice would probably be gradient ascent (or\ngradient descent with negative log likelihood).\n\u23a1 dLL(\u03b8)\u23a4\ndt\ndLL(\u03b8)\nd\u03bca\n\u2207 LL(\u03b8)= dLL(\u03b8)\n\u03b8 d\u03bcb\ndLL(\u03b8)\nd\u03c3a\n\u23a3 dLL(\u03b8)\u23a6\nd\u03c3b\n3 <END>"}
{"prompt": "Lecture notes from cs109_lec04_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 4: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nBayes' Theorem: Terminology 3 / 3 pts\n1.1 Prior 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Likelihood 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.3 Posterior 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nConditional Probability: Rolling Fair Dice 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nBayes' Theorem: Diagnosing An Illness 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Bayes' Theorem: Terminology\n3 Points\nP(B\u2223A)P(A)\nConsider Bayes' Theorem written as follows: P(A\u2223B) = .\nP(B)\nQ1.1 Prior\n1 Point\nWhich of these is the known as the prior?\nP(A)\nP(B\u2223A)\nP(A\u2223B)\nP(B)\nQ1.2 Likelihood\n1 Point\nWhich of these is the known as the likelihood?\nP(A)\nP(A\u2223B)\nP(B\u2223A)\nP(B)\nQ1.3 Posterior\n1 Point\nWhich of these is the known as the posterior?\nP(B\u2223A)\nP(A\u2223B)\nP(A)\nP(B)\nQ2 Conditional Probability: Rolling Fair Dice\n1 Point\nAssume that two fair, six-sided dice are rolled, and let D and D be the values\n1 2\nof the first and second die rolls, respectively. What is the probability that D = 3\n1\ngiven that D + D < 7?\n1 2\n1\n6\n1\n5\n3\n7\n4\n7\n7\n9\nQ3 Bayes' Theorem: Diagnosing An Illness\n1 Point\nConsider the following hypothetical scenario regarding an illness. Consider that\n8% of all people have the illness and further that there has been a test developed\nfor the illness with a 95% true positive rate and a 7% false positive rate ).\nAssuming someone tests positive for the illness, what is the probability that they\nactually have the disease? Please round your answer to two decimal places, e.g.,\n0.17, with the leading zero.\n0.54 <END>"}
{"prompt": "Lecture notes from 16_cont_joint_i_annotated.txt\n\n###\n\n", "completion": "16: Continuous Joint\nDistributions\nJerry Cain\nMay 6th, 2024\nLecture Discussion on Ed\n1\nContinuous\nJoint\nDistributions\n2\nStanford logo with darts\nThe Stanford letterhead logo was\ncreated by throwing 500,000 darts\naccording to a joint distribution.\nnot really, but let\u2019s pretend\nIf we throw another dart according to\nthe same distribution, what is\nP(dart hits within \ud835\udc5f pixels of center)?\nQuick check: What is the probability that a dart\nhits at (456.2344132343, 532.1865739012)?\nzero\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nCS109 logo with darts\nP(dart hits within \ud835\udc5f pixels of center)?\n1 pixel = 1 dart thrown\nat screen\nPossible dart counts (in 100x100 boxes)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nCS109 logo with darts\nP(dart hits within \ud835\udc5f pixels of center)?\nPossible dart counts (in 50x50 boxes)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nCS109 logo with darts\nP(dart hits within \ud835\udc5f pixels of center)?\nPossible dart counts\n(in infinitesimally small boxes)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nContinuous joint probability density functions\nIf two random variables \ud835\udc4b and \ud835\udc4c are jointly continuous, then there exists a\njoint probability density function \ud835\udc53 defined over \u2212\u221e < \ud835\udc65, \ud835\udc66 < \u221e such that:\n!,#\n& \u2019\n\" \"\n\ud835\udc43 \ud835\udc4e \u2264 \ud835\udc4b \u2264 \ud835\udc4e \ud835\udc4f \u2264 \ud835\udc4c \u2264 \ud835\udc4f = 1 1 \ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc51\ud835\udc65\n$ %, $ % !,#\n& \u2019\n! !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nFrom one continuous RV to jointly continuous RVs\nSingle continuous RV \ud835\udc4b\nProbability =\n) area under curve\n\u2022 PDF \ud835\udc53 such that \u222b \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65 = 1\n! !\n()\n\u2022 Integrate to get probabilities !\n0 \u2026 44 52 60 \u2026 90\nJointly continuous RVs \ud835\udc4b and \ud835\udc4c\n) )\n\u2022 PDF \ud835\udc53 such that\u222b \u222b \ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc51\ud835\udc65 = 1\n!,# !,#\n() ()\n\u2022 Double integrate to get probabilities\nProbability for jointly continuous RVs is volume under a surface.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nDouble integrals without tears\nLet \ud835\udc4b and \ud835\udc4c be two continuous random variables.\n\u2022 Support: 0 \u2264 \ud835\udc4b \u2264 1, 0 \u2264 \ud835\udc4c \u2264 2.\nIs \ud835\udc54 \ud835\udc65, \ud835\udc66 = \ud835\udc65\ud835\udc66 a valid joint PDF over \ud835\udc4b and \ud835\udc4c?\nWrite down the definite double integral that\nmust integrate to 1:\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nDouble integrals without tears\nLet \ud835\udc4b and \ud835\udc4c be two continuous random variables.\n\u2022 Support: 0 \u2264 \ud835\udc4b \u2264 1, 0 \u2264 \ud835\udc4c \u2264 2.\nIs \ud835\udc54 \ud835\udc65, \ud835\udc66 = \ud835\udc65\ud835\udc66 a valid joint PDF over \ud835\udc4b and \ud835\udc4c?\nWrite down the definite double integral that\nmust integrate to 1:\n% $ $ %\n1 1 \ud835\udc65\ud835\udc66 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = 1 or 1 1 \ud835\udc65\ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc51\ud835\udc65 = 1\n*+, -+, -+, *+,\n(used in next slide)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nDouble integrals without tears\nLet \ud835\udc4b and \ud835\udc4c be two continuous random variables.\n\u2022 Support: 0 \u2264 \ud835\udc4b \u2264 1, 0 \u2264 \ud835\udc4c \u2264 2.\nIs \ud835\udc54 \ud835\udc65, \ud835\udc66 = \ud835\udc65\ud835\udc66 a valid joint PDF over \ud835\udc4b and \ud835\udc4c?\n0. Set up integral:\n\" \" & (\n1 = $ $ \ud835\udc54 \ud835\udc65, \ud835\udc66 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = $ $ \ud835\udc65\ud835\udc66 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66\n!\" !\" #$% \u2019$%\n1. Evaluate inside integral by treating \ud835\udc66 as a constant:\n& ( & ( & \ud835\udc65& ( & 1\n$ $ \ud835\udc65\ud835\udc66 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = $ \ud835\udc66 $ \ud835\udc65 \ud835\udc51\ud835\udc65 \ud835\udc51\ud835\udc66 = $ \ud835\udc66 \ud835\udc51\ud835\udc66 = $ \ud835\udc66 \ud835\udc51\ud835\udc66\n2 2\n#$% \u2019$% #$% \u2019$% #$% #$%\n%\n2. Evaluate remaining (single) integral:\n&\n& &\n1 \ud835\udc66\nYes, \ud835\udc54 \ud835\udc65,\ud835\udc66 is a valid joint PDF\n$ \ud835\udc66 \ud835\udc51\ud835\udc66 = = 1 \u2212 0 = 1\n2 4 because it integrates to 1.\n#$%\n#$%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nMarginal distributions\nSuppose \ud835\udc4b and \ud835\udc4c are continuous random\nvariables with joint PDF:\n\ud835\udc53 \ud835\udc65\n\" \" ) \ud835\udc53\n$ $ \ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc51\ud835\udc65 = 1\n*\ud835\udc66\n),*\n!\" !\"\nThe marginal density functions\u2014that is, the marginal PDFs\u2014are therefore:\n) )\n\ud835\udc53 \ud835\udc4e = 1 \ud835\udc53 \ud835\udc4e, \ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc53 \ud835\udc4f = 1 \ud835\udc53 \ud835\udc65, \ud835\udc4f \ud835\udc51x\n! !,# # !,#\n() ()\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nJoint CDFs\n13\nCDFs and PDFs in one dimension Review\nFor a one-dimensional continuous random variable \ud835\udc4b with PDF \ud835\udc53, the CDF\n(cumulative distribution function) is\n&\n\ud835\udc39 \ud835\udc4e = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e = 1 \ud835\udc53 \ud835\udc65 \ud835\udc51\ud835\udc65\n()\nThe density \ud835\udc53 is the derivative of the CDF, \ud835\udc39:\nFundamental Theorem\n\ud835\udc51\nof Calculus\n\ud835\udc53 \ud835\udc65 = \ud835\udc39 \ud835\udc65\n\ud835\udc51\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nSingle variable CDF, graphically Review\nlim \ud835\udc39 \ud835\udc65 = 1\n)\n\u2019\u2192.\"\nlim \ud835\udc39 \ud835\udc65 = 0\n-\n\u2019\u2192!\"\n\ud835\udc53 \ud835\udc65 \ud835\udc39 \ud835\udc65 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65\n! !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nJoint cumulative distribution function\nFor two random variables \ud835\udc4b and \ud835\udc4c, there can be a joint cumulative\ndistribution function \ud835\udc39 :\n!,#\n\ud835\udc39 \ud835\udc4e, \ud835\udc4f = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc4e, \ud835\udc4c \u2264 \ud835\udc4f\n!,#\nFor discrete \ud835\udc4b and \ud835\udc4c: For continuous \ud835\udc4b and \ud835\udc4c:\n& \u2019\n\ud835\udc39 \ud835\udc4e, \ud835\udc4f = 1 1 \ud835\udc53 \ud835\udc65, \ud835\udc66 \ud835\udc51\ud835\udc66 \ud835\udc51\ud835\udc65\n\ud835\udc39 \ud835\udc4e, \ud835\udc4f = ; ; \ud835\udc5d (\ud835\udc65, \ud835\udc66) !,# !,#\n!,# !,#\n() ()\n-3& *3\u2019 1\"\n\ud835\udc53 \ud835\udc4e, \ud835\udc4f = \ud835\udc39 \ud835\udc4e, \ud835\udc4f\n!,# !,#\n1& 1\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nJoint CDF, graphically\nlim \ud835\udc39 \ud835\udc65, \ud835\udc66 = 1\n),*\n\u2019,#\u2192.\"\nlim \ud835\udc39 \ud835\udc65, \ud835\udc66 = 0\n),*\n\u2019,#\u2192!\"\n\ud835\udc53 \ud835\udc65, y \ud835\udc39 \ud835\udc65, \ud835\udc66 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65, \ud835\udc4c \u2264 \ud835\udc66\n!,# !,#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nIndependent\nContinuous RVs\n18\nIndependent continuous RVs\nTwo continuous random variables \ud835\udc4b and \ud835\udc4c are independent if:\n\u2200\ud835\udc65, \ud835\udc66\n\ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65, \ud835\udc4c \u2264 \ud835\udc66 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 \ud835\udc43 \ud835\udc4c \u2264 \ud835\udc66\nEquivalently:\n\ud835\udc39 \ud835\udc65, \ud835\udc66 = \ud835\udc39 \ud835\udc65 \ud835\udc39 \ud835\udc66 \u2200\ud835\udc65, \ud835\udc66\n!,# ! #\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc66\n!,# ! #\nProof for PDF:\n& &\n\ud835\udf15 \ud835\udf15\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc39 \ud835\udc65, \ud835\udc66 = \ud835\udc39 \ud835\udc65 \ud835\udc39 \ud835\udc66\n),* ),* ) *\n\ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc66 \ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc66\n\ud835\udf15 \ud835\udf15 \ud835\udf15 \ud835\udf15\n= \ud835\udc39 \ud835\udc65 \ud835\udc39 \ud835\udc66 = \ud835\udc39 \ud835\udc65 \ud835\udc39 \ud835\udc66\n) * ) *\n\ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc66 \ud835\udf15\ud835\udc65 \ud835\udf15\ud835\udc66\n= \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc66\n) *\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nIndependent continuous RVs\nTwo continuous random variables \ud835\udc4b and \ud835\udc4c are independent if:\n\u2200\ud835\udc65, \ud835\udc66\n\ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65, \ud835\udc4c \u2264 \ud835\udc66 = \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 \ud835\udc43 \ud835\udc4c \u2264 \ud835\udc66\nEquivalently:\n\ud835\udc39 \ud835\udc65, \ud835\udc66 = \ud835\udc39 \ud835\udc65 \ud835\udc39 \ud835\udc66 \u2200\ud835\udc65, \ud835\udc66\n!,# ! #\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc53 \ud835\udc65 \ud835\udc53 \ud835\udc66\n!,# ! #\nMore generally, \ud835\udc4b and \ud835\udc4c are independent if the joint PDF factors into two,\nsingle-variable marginal probability densities:\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = \ud835\udc54 \ud835\udc65 \u210e \ud835\udc66 , where \u2212 \u221e < \ud835\udc65, \ud835\udc66 < \u221e\n!,#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\n\ud835\udc53 \ud835\udc65,\ud835\udc66 = \ud835\udc54 \ud835\udc65 \u210e \ud835\udc66 , independent\nPop quiz! (just kidding) !,#\nwhere \u2212 \u221e < \ud835\udc65,\ud835\udc66 < \u221e \ud835\udc4b and \ud835\udc4c\nAre \ud835\udc4b and \ud835\udc4c independent in the following cases?\n(4- (%*\n1. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 6\ud835\udc52 \ud835\udc52\n!,#\nwhere 0 < \ud835\udc65, \ud835\udc66 < \u221e\n2. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 4\ud835\udc65\ud835\udc66\n!,#\nwhere 0 < \ud835\udc65, \ud835\udc66 < 1\n3. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 24\ud835\udc65\ud835\udc66\n!,#\nwhere 0 < \ud835\udc65 + \ud835\udc66 < 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\ud835\udc53 \ud835\udc65,\ud835\udc66 = \ud835\udc54 \ud835\udc65 \u210e \ud835\udc66 , independent\nPop quiz! (just kidding) !,#\nwhere \u2212 \u221e < \ud835\udc65,\ud835\udc66 < \u221e \ud835\udc4b and \ud835\udc4c\nAre \ud835\udc4b and \ud835\udc4c independent in the following cases?\n\u2705 1. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 6\ud835\udc52(4- \ud835\udc52(%* Separable functions: \ud835\udc54 \ud835\udc65 = 3\ud835\udc52!:\u2019\n!,#\n\u210e \ud835\udc66 = 2\ud835\udc52!&#\nwhere 0 < \ud835\udc65, \ud835\udc66 < \u221e\n2. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 4\ud835\udc65\ud835\udc66 Separable functions: \ud835\udc54 \ud835\udc65 = 2\ud835\udc65\n\u2705\n!,#\n\u210e \ud835\udc66 = 2\ud835\udc66\nwhere 0 < \ud835\udc65, \ud835\udc66 < 1\n3. \ud835\udc53 \ud835\udc65, \ud835\udc66 = 24\ud835\udc65\ud835\udc66 Cannot capture constraint on \ud835\udc65 + \ud835\udc66!\n\u274c\n!,#\nwhere 0 < \ud835\udc65 + \ud835\udc66 < 1\nIf you can factor densities over the entire\nsupport, you have independence.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nMore pop quiz! (more kidding)\n!:\u2019\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = 3\ud835\udc52\n\ud835\udc4b and \ud835\udc4c have the following joint PDF: ),*\nwhere 0 < \ud835\udc65 < \u221e, 1 < \ud835\udc66 < 2\n1. Are \ud835\udc4b and \ud835\udc4c independent?\n2. What is the marginal\nPDF of \ud835\udc4b? Of \ud835\udc4c?\n3. What is \ud835\udc38 \ud835\udc4b + \ud835\udc4c ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nMore pop quiz! (more kidding)\n!:\u2019\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = 3\ud835\udc52\n\ud835\udc4b and \ud835\udc4c have the following joint PDF: ),*\nwhere 0 < \ud835\udc65 < \u221e, 1 < \ud835\udc66 < 2\n1. Are \ud835\udc4b and \ud835\udc4c independent? \ud835\udc54 \ud835\udc65 = 3\ud835\udc36\ud835\udc52!:\u2019, 0 < \ud835\udc65 < \u221e \ud835\udc36 is a\n\u2705\n\u210e \ud835\udc66 = 1/\ud835\udc36, 1 < \ud835\udc66 < 2 constant\n2. What is the marginal\nPDF of \ud835\udc4b? Of \ud835\udc4c?\n3. What is \ud835\udc38 \ud835\udc4b + \ud835\udc4c ?\n\ud835\udc66\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\n\ud835\udc66\n,\ud835\udc65\n\ud835\udc53\n*,)\nMore pop quiz! (more kidding)\n!:\u2019\n\ud835\udc53 \ud835\udc65, \ud835\udc66 = 3\ud835\udc52\n\ud835\udc4b and \ud835\udc4c have the following joint PDF: ),*\nwhere 0 < \ud835\udc65 < \u221e, 1 < \ud835\udc66 < 2\n1. Are \ud835\udc4b and \ud835\udc4c independent? \ud835\udc54 \ud835\udc65 = 3\ud835\udc52!:\u2019, 0 < \ud835\udc65 < \u221e\n\u2705\n\u210e \ud835\udc66 = 1, 1 < \ud835\udc66 < 2\n2. What is the marginal\nPDF of \ud835\udc4b? Of \ud835\udc4c?\n3. What is \ud835\udc38 \ud835\udc4b + \ud835\udc4c ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nThe joy of meetings\nTwo people set up a meeting time. Each arrives independently at a time uniformly\ndistributed between 12pm and 12:30pm.\nDefine \ud835\udc4b = # minutes past 12pm that person 1 arrives. \ud835\udc4b~Uni 0, 30\n\ud835\udc4c = # minutes past 12pm that person 2 arrives. \ud835\udc4c~Uni 0, 30\nWhat is the probability that the first to arrive waits >10 mins for the other?\nCompute: \ud835\udc43 \ud835\udc4b + 10 < \ud835\udc4c + \ud835\udc43 \ud835\udc4c + 10 < \ud835\udc4b = 2\ud835\udc43 \ud835\udc4b + 10 < \ud835\udc4c (by symmetry)\n1. What is symmetry here?\n2. How do we integrate to compute this probability?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nDouble integrals: A guide\n(by symmetry,\nFrom last slide: 2\ud835\udc43 \ud835\udc4b + 10 < \ud835\udc4c = 2 @ 1/30 & \ud835\udc51\ud835\udc65\ud835\udc51\ud835\udc66\nindependence)\n\u2019.(%;#,\n%<\u2019,#,<:%\nSteps:\n1. Draw a picture.\n2. Set bounds \"from outside in\".\n\u2022 Outer integral bounds should\n:% #!(%\nbe full range possible 2\n= $ $ \ud835\udc51\ud835\udc65\ud835\udc51\ud835\udc66\n\u2022 Inner integral can depend on 30&\n(% %\nintegration variable of outer\n:%\n2 4\nintegral\n= $ \ud835\udc66 \u2212 10 \ud835\udc51\ud835\udc66 = \u22ef =\n30& 9\n(%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nSum of\nIndependent\nGaussians\n28\nSum of independent Gaussians\n%\n\ud835\udc4b~\ud835\udca9 \ud835\udf07 , \ud835\udf0e ,\n$ $ \" \"\n\ud835\udc4b + \ud835\udc4c ~\ud835\udca9(\ud835\udf07 + \ud835\udf07 , \ud835\udf0e + \ud835\udf0e )\n%\n\ud835\udc4c~\ud835\udca9 \ud835\udf07 , \ud835\udf0e ! \" ! \"\n% %\n\ud835\udc4b, \ud835\udc4c independent\n(proof left to Wikipedia)\nHolds in general case:\n6 6 6\n&\n\ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e\n= = = ; \ud835\udc4b ~\ud835\udca9 ; \ud835\udf07 , ; \ud835\udf0e%\n5 5 5\n\ud835\udc4b independent for \ud835\udc56 = 1, \u2026 , \ud835\udc5b\n=\n5+$ 5+$ 5+$\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nBack for another playoff game\n\ud835\udc43 \ud835\udc34 > \ud835\udc34\n! \"\nThis is a probability of an event\ninvolving two random variables!\nWe will compute:\n\ud835\udc43 \ud835\udc34 \u2212 \ud835\udc34 > 0\nWhat is the probability that the Warriors win?\n! \"\nHow do you model zero-sum games?\nA sum of Normals!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nMotivating idea: Zero sum games\nWant: \ud835\udc43 Warriors win = \ud835\udc43 \ud835\udc34 \u2212 \ud835\udc34 > 0 Warriors ) ~, - = 1657,2000\n*\n7 8\n0.0025 !=1657\nAssume \ud835\udc34 , \ud835\udc34 are independent. 0.002\n7 8\n0.0015\nLet \ud835\udc37 = \ud835\udc34 \u2212 \ud835\udc34 .\n0.001\n7 8\n0.0005\n0\n1000 1500 2000 2500\nWhat is the distribution of \ud835\udc37? Opponents ) ~, - = 1470,2000\n1\n0.0025\nA. \ud835\udc37~\ud835\udca9 1657 \u2212 1470, 200% \u2212 200% 0.002 !=1470\n0.0015\n% %\nB. \ud835\udc37~\ud835\udca9 1657 \u2212 1470, 200 + 200\n0.001\nC. \ud835\udc37~\ud835\udca9 1657 + 1470, 200% + 200% 0.0005\n0\n%\nD. \ud835\udc37~\ud835\udca9 1657 + 1470, 200\n1000 1500 2000 2500\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nMotivating idea: Zero sum games\nWant: \ud835\udc43 Warriors win = \ud835\udc43 \ud835\udc34 \u2212 \ud835\udc34 > 0 Warriors ) ~, - = 1657,2000\n*\n7 8\n0.0025 !=1657\nAssume \ud835\udc34 , \ud835\udc34 are independent. 0.002\n7 8\n0.0015\nLet \ud835\udc37 = \ud835\udc34 \u2212 \ud835\udc34 .\n0.001\n7 8\n0.0005\n0\n1000 1500 2000 2500\nWhat is the distribution of \ud835\udc37? Opponents ) ~, - = 1470,2000\n1\n0.0025\nA. \ud835\udc37~\ud835\udca9 1657 \u2212 1470, 200% \u2212 200% 0.002 !=1470\n0.0015\n% %\nB. \ud835\udc37~\ud835\udca9 1657 \u2212 1470, 200 + 200\n0.001\nC. \ud835\udc37~\ud835\udca9 1657 + 1470, 200% + 200% 0.0005\n0\n%\nD. \ud835\udc37~\ud835\udca9 1657 + 1470, 200\n1000 1500 2000 2500\nIf \ud835\udc4b~\ud835\udca9 \ud835\udf07 , \ud835\udf0e& ,\n(\nthen \u2212\ud835\udc4b ~\ud835\udca9 \u2212\ud835\udf07, \u22121 & \ud835\udf0e& = \ud835\udf0e& .\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nMotivating idea: Zero sum games\nWant: \ud835\udc43 Warriors win = \ud835\udc43 \ud835\udc34 \u2212 \ud835\udc34 > 0 Warriors ) ~, - = 1657,2000\n*\n7 8\n0.0025 !=1657\nAssume \ud835\udc34 , \ud835\udc34 are independent. 0.002\n7 8\n0.0015\nLet \ud835\udc37 = \ud835\udc34 \u2212 \ud835\udc34 .\n0.001\n7 8\n0.0005\n0\n1000 1500 2000 2500\n% %\n\ud835\udc37~\ud835\udca9 1657 \u2212 1470, 200 +200 Opponents ) ~, - = 1470,2000\n1\n0.0025\n%\n~\ud835\udca9 187, 2 \u22c5 200 \ud835\udf0e \u2248 282.842\n!=1470\n0.002\n0.0015\n0.001\n0 \u2212 187\n0.0005\n\ud835\udc43 \ud835\udc37 > 0 = 1 \u2212 \ud835\udc39 0 = 1 \u2212 \u03a6\n0\n9\n282.842\n1000 1500 2000 2500\n\u2248 0.74574\n>>> from scipy.stats import norm\n>>> 1 - norm(187, 80000 ** 0.5).cdf(0)\n0.7457402843526317\nCompare with 0.7488, calculated by sampling! >>> 1 - norm(0, 1).cdf(-187 / (80000 ** 0.5))\n0.7457402843526317\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nVirus infections\nSuppose you are working with the WHO to initiate a response to the onset\nof a virus. There are two exposed groups:\n\u2022 G1: 20000 people, each independently infected with \ud835\udc5d = 0.1\n(\n\u2022 G2: 10000 people, each independently infected with \ud835\udc5d = 0.4\n&\nWhat is \ud835\udc43 people infected \u2265 6100 ? An approximation is okay.\n1. Define RVs Strategy:\n& state goal\nA. Sum of independent Binomials\nLet \ud835\udc34 = # infected in G1. B. Sum of independent Poissons\n\ud835\udc34~Bin 20000,0.1 C. Sum of independent Gaussians\n\ud835\udc35 = # infected in G2. D. Sum of independent Exponentials\n\ud835\udc35~Bin 10000,0.4\nWant: \ud835\udc43 \ud835\udc34 + \ud835\udc35 \u2265 6100\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\nVirus infections\nSuppose you are working with the WHO to initiate a response to the onset\nof a virus. There are two exposed groups:\n\u2022 G1: 20000 people, each independently infected with \ud835\udc5d = 0.1\n(\n\u2022 G2: 10000 people, each independently infected with \ud835\udc5d = 0.4\n&\nWhat is \ud835\udc43 people infected \u2265 6100 ? An approximation is okay.\n1. Define RVs 2. Approximate as sum of Gaussians\n& state goal\n\ud835\udc34 \u2248 \ud835\udc4b~\ud835\udca9 2000, 1800 \ud835\udc35 \u2248 \ud835\udc4c~\ud835\udca9 4000, 2400\ncontinuity\nLet \ud835\udc34 = # infected in G1. \ud835\udc43 \ud835\udc34 + \ud835\udc35 \u2265 6100 \u2248 \ud835\udc43 \ud835\udc4b + \ud835\udc4c \u2265 6099.5\ncorrection\n\ud835\udc34~Bin 20000,0.1 3. Solve\n\ud835\udc35 = # infected in G2.\n\ud835\udc35~Bin 10000,0.4\nWant: \ud835\udc43 \ud835\udc34 + \ud835\udc35 \u2265 6100\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\n>>> 1 - norm(6000, 4200 ** 0.5).cdf(6099.5)\nVirus infections 0.06235282662988528\n>>> 1 - norm(0, 1).cdf((6099.5 - 6000)/(4200 ** 0.5))\n0.06235282662988528\nSuppose you are working with the WHO to initiate a response to the onset\nof a virus. There are two exposed groups:\n\u2022 G1: 20000 people, each independently infected with \ud835\udc5d = 0.1\n(\n\u2022 G2: 10000 people, each independently infected with \ud835\udc5d = 0.4\n&\nWhat is \ud835\udc43 people infected \u2265 6100 ? An approximation is okay.\n1. Define RVs 2. Approximate as sum of Gaussians\n& state goal\n\ud835\udc34 \u2248 \ud835\udc4b~\ud835\udca9 2000, 1800 \ud835\udc35 \u2248 \ud835\udc4c~\ud835\udca9 4000, 2400\ncontinuity\nLet \ud835\udc34 = # infected in G1. \ud835\udc43 \ud835\udc34 + \ud835\udc35 \u2265 6100 \u2248 \ud835\udc43 \ud835\udc4b + \ud835\udc4c \u2265 6099.5\ncorrection\n\ud835\udc34~Bin 20000,0.1 3. Solve\n\ud835\udc35 = # infected in G2. Let \ud835\udc4a = \ud835\udc4b + \ud835\udc4c~\ud835\udca9 6000, 4200\n6099.5 \u2212 6000\n\ud835\udc35~Bin 10000,0.4\n\ud835\udc43 \ud835\udc4a \u2265 6099.5 = 1 \u2212 \u03a6\n4200\nWant: \ud835\udc43 \ud835\udc34 + \ud835\udc35 \u2265 6100\n\u2248 1 \u2212 \u03a6(1.53531) \u2248 0.06235\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nSum of Independent Gaussians\n%\n\ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e ,\n$ $ $ \" \"\n\ud835\udc4b + \ud835\udc4b ~\ud835\udca9(\ud835\udf07 + \ud835\udf07 , \ud835\udf0e + \ud835\udf0e )\n%\n\ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e ! \" ! \" ! \"\n% % %\n\ud835\udc4b , \ud835\udc4b independent\n$ %\nIs this related to linear transformations of Gaussians?\nRecall:\n\" \"\nIf \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, then \ud835\udc4c~\ud835\udca9 \ud835\udc4e\ud835\udf07 + \ud835\udc4f, \ud835\udc4e \ud835\udf0e\n! !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nTeaser: Linear transforms vs. independence \u26a0\n%\nLet \ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e ) and \ud835\udc4c = \ud835\udc4b + \ud835\udc4b. What is the distribution of \ud835\udc4c?\n\u2022 Are both approaches valid?\nIndependent RVs approach Linear transform approach\nLet \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e& , \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e& Let \ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e& ).\n( ( ( & & &\nbe independent. If \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f,\nThen \ud835\udc4c = \ud835\udc4b + \ud835\udc4b ~\ud835\udca9(\ud835\udf07 + \ud835\udf07 , \ud835\udf0e& + \ud835\udf0e& ) then \ud835\udc4c~\ud835\udca9(\ud835\udc4e\ud835\udf07 + \ud835\udc4f, \ud835\udc4e&\ud835\udf0e&).\n( & ( & ( &\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nTeaser: Linear transforms vs. independence \u26a0\n%\nLet \ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e ) and \ud835\udc4c = \ud835\udc4b + \ud835\udc4b. What is the distribution of \ud835\udc4c?\n\u2022 Are both approaches valid?\nIndependent RVs approach \u274c Linear transform approach \u2705\nLet \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e& , \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e& Let \ud835\udc4b~\ud835\udca9(\ud835\udf07, \ud835\udf0e& ).\n( ( ( & & &\nbe independent. If \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f,\nThen \ud835\udc4c = \ud835\udc4b + \ud835\udc4b ~\ud835\udca9(\ud835\udf07 + \ud835\udf07 , \ud835\udf0e& + \ud835\udf0e& ) then \ud835\udc4c~\ud835\udca9(\ud835\udc4e\ud835\udf07 + \ud835\udc4f, \ud835\udc4e&\ud835\udf0e&).\n( & ( & ( &\numm, \ud835\udc4b is NOT independent of \ud835\udc4b!\n\ud835\udc4c = \ud835\udc4b + \ud835\udc4b \ud835\udc4c = 2\ud835\udc4b\n\ud835\udc4b + \ud835\udc4b~\ud835\udca9 \ud835\udf07 + \ud835\udf07, \ud835\udf0e% + \ud835\udf0e% ? \ud835\udc4c~\ud835\udca9(2\ud835\udf07, 4\ud835\udf0e% )\n%\n\ud835\udc4c~\ud835\udca9 2\ud835\udf07, 2\ud835\udf0e ?\n& &\nFor independent \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e , \ud835\udc4b ~\ud835\udca9 \ud835\udf07 , \ud835\udf0e ,\n( ( ( & & &\n& & & &\n\ud835\udc4e\ud835\udc4b + \ud835\udc4f\ud835\udc4b + \ud835\udc50~\ud835\udca9 \ud835\udc4e\ud835\udf07 + \ud835\udc4f\ud835\udf07 + \ud835\udc50, \ud835\udc4e \ud835\udf0e + \ud835\udc4f \ud835\udf0e\n( & ( & ( &\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39 <END>"}
{"prompt": "Lecture notes from 01_intros_and_counting_annotated.txt\n\n###\n\n", "completion": "CS109: Probability for\nComputer Scientists\nJerry Cain\nApril 1, 2024\nLecture Discussion on Ed\n1\nWelcome to\nCS109!\n2\nJerry Cain\nMy interests over time\nI went here from 1987\nChemistry\nthrough 1991 and\nmajored in chemistry. and Physics\nComputer\nThen I came here for a PhD in chem, switched to CS\nScience\nReceived MSCS 1998\nSTEM\nLecturer: nearly 28 years\nEducation\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nWhy Jerry likes probability\n\u2022 I majored in chemistry and focused on physical chemistry\u2014thermodynamics,\nquantum mechanics, etc.\u2014and my undergraduate research was rooted in\nsurface science and statistical mechanics.\n\u2022 When I switched to CS as a grad\nstudent here, I focused on CS theory\nand all the beautiful mathematics\nthat comes with it.\n\u2022 Probability has revived parts of AI and\ninformation theory that were thought\nto be borderline dead when I was getting\nmy MSCS degree here during the 90\u2019s.\n1974 1996\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nWhat makes this quarter important\nWe are seeing a huge surge in statistics, predictions, and probabilistic\nmodels shared through global news, governing bodies, and social media.\nThe technological and social innovation we develop during this time will\nstrongly influence how we solve interesting problems impacting the lives of\ncountless people across the globe.\nWorld Politics\nNational Weather https://abcnews.go.com/538\nService Alerts https://www.nytimes.com/\nhttps://www.economist.com/\nhttps://www.weather.gov/\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nCourse\nMechanics\n6\nPrerequisites\nCS106B MATH 51 CS103\nProgramming Multivariate differentiation Proofs (induction)\nRecursion\nMultivariate integration Set theory\nHash tables Working knowledge of linear Mathematical\nBinary trees\nalgebra (e.g., vectors) maturity\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nCompanion class: CS109ACE\n\u2022 CS109ACE is an extra 1-unit \"ACE\" section that provides additional\nsupport, practice, and instruction for undergraduate students\nconcerned about their preparation and mathematical background.\n\u2022 Meets for an additional weekly section and has additional review\nsessions, office hours, and practice problems\n\u2022 Admission is via application. You can ignore the published deadline in\nthe form, as our CS109ACE application is due this Friday, April 5th at\n5:00pm.\n\u2022 CS109ACE meets on Mondays from 5:30 \u2013 7:20pm,\n(location TBD) and starts on April 8th.\n\u2022 Feel free to email Michelle Qin at\nmdqin@stanford.edu\nwith any questions.\nMichelle Qin\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nCourse components\n42% 6 Problem Sets\n22% Two Midterms\n21% Final Exam\n5% Section Participation\n10% Concept Checks\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nCourse components\n42% 6 Problem Sets Written portion\n\u2022 LaTeX for powerful typesetting\n\u2022 Tutorial on CS109 website\n22% Two Midterms\nCoding portion in Python\n\u2022 Review session on Thursday\n21% Final Exam 04/04 at noon in Huang 018\nLate policy\n\u2022 Need a short extension? No need to ask!\n5% Section Participation\nTake an extra class period.\n\u2022 Need a longer extension? Just ask us and\nwe\u2019ll probably be okay with it.\n10% Concept Checks\n\u2022 Extensions can be at most two extra class\nperiods.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nCourse components\n42% 6 Problem Sets\n\u2022 In person! But held outside of class so we\ncan let you work sans time pressure.\n\u2022 Closed-book, mostly-closed-notes, closed-\n22% Two Midterms\ncomputer, no calculators.\n\u2022 You can bring two 8.5\u201d x 11\u201d pages of\nnotes\u2014using both sides\u2014and refer to them\n21% Final Exam\nduring the exams.\n\u2022 Held on Wednesdays.\nWeek 4: Wed, 04/24, 7:00 \u2013 9:00pm\no\n5% Section Participation\nWeek 7: Wed, 05/15, 7:00 \u2013 9:00pm\no\nIrreconcilable Conflict? Let Jerry know and\n\u2022\nwe\u2019ll work something out.\n10% Concept Checks\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nCourse components\n42% 6 Problem Sets\n\u2022 Scheduled for Saturday, June 8th from\n22% Two Midterms\n8:30 until 11:30am (our official time).\n\u2022 Closed-book, mostly-closed-notes, closed\ncomputer, no calculators.\n21% Final Exam\n\u2022 You can prepare four 8.5\u201d x 11\u201d pages of\nnotes\u2014using both sides\u2014and refer to them\nand a provided reference sheet during the\n5% Section Participation\nexam.\n\u2022 Conflict with another final exam? I\u2019ll offer\nthe final on Friday, June 7th from 12:15pm\n10% Concept Checks\nto 3:15pm for those with a documented\nconflict with another final exam.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nCourse components\n42% 6 Problem Sets\n\u2022 Sections meet on Thursdays\n22% Two Midterms\nand Fridays. Times are already\nposted right here.\n\u2022 Sections start Week 2\n21% Final Exam\n\u2022 Your section grade is 100%,\nbut each absence (beyond one\nfreebie) reduces the weight of\n5% Section Participation\nsection participation and\nincreases the weight of the\nfinal exam\n10% Concept Checks\n\u2022 Go to section!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nCourse components\n42% 6 Problem Sets\n\u2022 Short set of questions released\nafter each lecture.\n\u2022 Questions are straightforward\n22% Two Midterms\nand there to ensure you\u2019ve\nabsorbed the key points and\nformulas from class.\n21% Final Exam\n\u2022 All of Week n\u2019s concept checks\nare due the Tuesday of Week\nn + 1 at noon.\n5% Section Participation\n\u2022 No late submissions accepted\nunless truly extenuating\ncircumstances make it truly\n10% Concept Checks\nimpossible to meet deadline.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nCS109 Contest\n\u2022 Announced mid-quarter, genuinely optional\n\u2022 Boost final course grades after letter\ngrade buckets have been determined\nYour baseline is CS109, and the sky is the limit.\nSome of last quarter\u2019s winners:\n\u2022 The Probability of Curing Cancer: Will My Clinical Trial Succeed?\n\u2022 Modeling Indexical Fields as Bayesian Networks\n\u2022 StatTuring: Distinguishing between LLM and Human text\n\u2022 Parka: A Mobile App for Early Parkinson\u2019s Disease Detection\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nWhy you\nshould take\nCS109\n16\nTraditional View of Probability\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nCS view of probability\nhhhttttttppp::://////wwwwwwwww...sssiiittteee...cccooommm\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nMoonshot: Machine Learning\nBuild a\nData probabilistic Predict\nmodel\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nBinary Classification Silliness\nchihuahua or muffin? poodle or fried chicken?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nClassification: Where is this useful?\nA machine learning algorithm\nperforms better than the best\ndermatologists.\nDeveloped in 2017 at Stanford.\nEsteva, Andre, et al. \"Dermatologist-level classification of skin cancer with deep neural networks.\"\nNature 542.7639 (2017): 115-118.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nProbability is more than\njust machine learning.\n22\nProbability and medicine\nPredicted Hospital\nResource Use in United\nStates (IHME)\nhttps://covid19.healthdata.org\n/projections\nHow do COVID-19, RSV, and\nmonkeypox testing rates in a\nregion correlate with the actual\nspread of the disease?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nProbability and art\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nProbability, Meteorology, and Earthquake Prediction\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nProbability and ethics\nSo far, there are no unified ethical standards \u2026 for autonomous cars. The\nbigMoral Machine studyconducted by MIT showed that it\u2019s hard to\nidentify universal ethical values. The moral choices that people made in\nthe MIT survey were different and varied even at a local level. That\u2019s why\nit\u2019s hard to create a universal ethics of self-driving cars that won\u2019t be\ncontroversial. [source]\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nCounting\n27\nWhat is Counting?\nAn experiment\nOutcome\nExperiment\nin probability:\nCounting: How many possible outcomes can occur by\nperforming this experiment?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 28\nWhat is Counting Combinatorial Analysis?\n{1, 2, 3,\n6\n3\n{2, 4, 6}\n4, 5, 6}\nRoll Roll even only\n{(1, 1) , (1, 2), (1, 3), (1, 4), (1, 5), (1, 6),\n(2, 1) , (2, 2), (2, 3), (2, 4), (2, 5), (2, 6),\n(3, 1) , (3, 2), (3, 3), (3, 4), (3, 5), (3, 6),\n36\n(4, 1) , (4, 2), (4, 3), (4, 4), (4, 5), (4, 6),\n(5, 1) , (5, 2), (5, 3), (5, 4), (5, 5), (5, 6),\nRoll\n(6, 1) , (6, 2), (6, 3), (6, 4), (6, 5), (6, 6)}\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 29\nSum Rule of Counting, Inclusion-Exclusion Principle\nIf the outcome of an experiment can be either from\nSet \ud835\udc34, where \ud835\udc34 = \ud835\udc5a,\nor Set \ud835\udc35, where \ud835\udc35 = \ud835\udc5b,\nwhere \ud835\udc34 and \ud835\udc35 may overlap, then\nThe total number of outcomes of the experiment is\n\ud835\udc34 \u222a \ud835\udc35 = \ud835\udc34 + \ud835\udc35 \u2212 |\ud835\udc34 \u2229 \ud835\udc35|.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 30\nProduct Rule of Counting\nIf an experiment has two parts, where\nthe first part\u2019s outcomes are drawn from \ud835\udc34, where \ud835\udc34 = \ud835\udc5a,\nand the second part\u2019s outcomes are drawn from \ud835\udc35, where \ud835\udc35 = \ud835\udc5b,\nThen the number of outcomes of the experiment is\n\ud835\udc34 \ud835\udc35 = \ud835\udc5a\ud835\udc5b.\nTwo-step experiment\nA B\nThis generalizes to multistep experiments\u2014i.e., three steps, five steps, fifty\nsteps, and so forth.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 31\nBaby\u2019s First Example: Transmitting bytes over a network\nAn 8-bit string is sent over a network.\n01001100\n\u2022 The receiver only accepts strings that\neither start with 01 or end with 00.\nHow many 8-bit strings will the receiver accept? byte (8 bits)\nDefine\n\ud835\udc34 : 8-bit strings\nstarting with 01\n\ud835\udc35 : 8-bit strings\nending with 00\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 32\nBaby\u2019s First Example: Transmitting bytes over a network\nAn 8-bit string is sent over a network.\n01001100\n\u2022 The receiver only accepts strings that\neither start with 01 or end with 00.\nHow many 8-bit strings will the receiver accept? byte (8 bits)\nDefine\n\ud835\udc34 : 8-bit strings\nstarting with 01\n\ud835\udc35 : 8-bit strings\nending with 00\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 33\nLicense plates\nHow many CA license plates are possible with each of the following formats?\n(pre-1982)\n(present day)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 34\nLicense plates\nHow many CA license plates are possible with each of the following formats?\n(pre-1982)\n(present day)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 35\nPermutations I\n36\nUnique 6-digit passcodes with six smudges\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of six distinct numbers?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 37\nArrange \ud835\udc5b indistinct objects\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 38\nArrange \ud835\udc5b distinct objects\nMichelle Jacob Groucho Isabel Kathleen\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 39\nArrange \ud835\udc5b distinct objects\nSteps:\n1. Choose 1st can 5 options\n2. Choose 2nd can 4 options\n\u2026\n5. Choose 5th can 1 option\n1st 2nd 3rd 4th 5th\nTotal = 5 \u00d7 4 \u00d7 3 \u00d7 2 \u00d7 1\n= 120\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 40\nPermutations\nA permutation is an ordered arrangement of objects.\nThe number of unique orderings (permutations) of \ud835\udc5b distinct objects is\n\ud835\udc5b! = \ud835\udc5b \u00d7 \ud835\udc5b \u2212 1 \u00d7 \ud835\udc5b \u2212 2 \u00d7 \u22ef \u00d7 2 \u00d7 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 41\nUnique 6-digit passcodes with six smudges\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of six distinct numbers?\nTotal = 6!\n= 720 passcodes\n>>> import math\n>>> math.factorial(6)\n720\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 42\nUnique 6-digit passcodes with four smudges\nHow many unique 6-digit passcodes are possible if a\nphone password uses each of four distinct numbers?\nNext time!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Winter 2024 43 <END>"}
{"prompt": "Lecture notes from cs109_lec22_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 22: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n4 / 4 pts\nQuestion 1\nMAP vs MLE: Intuition 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nBiased Coin 3 / 3 pts\n2.1 MLE Refresh 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.2 MAP Part 1 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n2.3 MAP Part 2 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 MAP vs MLE: Intuition\n1 Point\nWhich of these statements correctly identifies the main conceptual difference\nbetween MAP and MLE?\nMLE will choose \u03b8 to maximize the data likelihood and so will MAP.\nMLE will choose \u03b8 to maximize the data likelihood and MAP will choose \u03b8\nto minimize mean squared error.\nMAP will choose \u03b8 to maximize the data likelihood and MLE will choose \u03b8\nto minimize mean squared error.\nMLE will choose \u03b8 to maximize the data likelihood and MAP will choose \u03b8\nto maximize the product of the data likelihood and the prior belief on \u03b8.\nQ2 Biased Coin\n3 Points\nConsider that we have a coin from an alien land which flips heads with\nprobability p. We flip the coin 10 times and see the following sequence of\noutcomes: H,H,T,T,H,T,T,T,H,T\nQ2.1 MLE Refresh\n1 Point\nWhat is the maximum likelihood estimate of p? Please write your answer as a\ndecimal to 2 decimal places with the leading zero (e.g., 0.12).\n0.40\nQ2.2 MAP Part 1\n1 Point\nIf I impose a Uniform prior on p (i.e., p \u223c Uni(0,1), what is my MAP estimate of\np? Please write your answer as a decimal to 2 decimal places with the leading\nzero (e.g., 0.12).\n0.40\nQ2.3 MAP Part 2\n1 Point\nIf I impose a prior on p, namely that p \u223c Beta(10,10). What is my MAP\nestimate of p? Please write your answer as a decimal to 2 decimal places with the\nleading zero (e.g., 0.12).\n0.46 <END>"}
{"prompt": "Lecture notes from cs109_lec11_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 11: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n2 / 2 pts\nQuestion 1\nMarginal Probability of Joint PMFs 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nJoint PMF Facts 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Marginal Probability of Joint PMFs\n1 Point\nSuppose we have two random variables, X and Y , whose joint probability mass\nfunction, P X,Y(a,b) = P(X = a,Y = b), is defined by the table below.\nWhat is the marginal probability distribution function of the random variable X?\nP(X = 1) = 0.4\nP(X = 1) = 0.5,P(X = 2) = 0.4,P(X = 3) = 0.3\nP(Y = 7) = 0.6,P(Y = 9) = 0.4\nP(X = 1) = 0.4,P(X = 2) = 0.4,P(X = 3) = 0.2\nQ2 Joint PMF Facts\n1 Point\nSelect all of the following that are true about joint PMFs.\n\u2211 \u2211 P(X = a,Y = b) = 1\na b\n\u2211 P(X = a,Y = b) = P(Y = b)\na\n\u2211 P(X = a,Y = b) = P(X = b)\na\n\u2211 P(X = a,Y = b) = P(X = a)\na\n\u2211 \u2211 P(X = a,Y = b) = \u2211 P(X = a) = 1\na b a <END>"}
{"prompt": "Lecture notes from 22_map_annotated.txt\n\n###\n\n", "completion": "22: Maximum a\nPosteriori\nJerry Cain\nMay 20, 2024\nLecture Discussion on Ed\n1\nMaximum a\nPosteriori\nEstimator\n2\nMaximum A Posteriori (MAP) Estimator\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n\u2019 ( )\nMaximum What parameter \ud835\udf03 \ud835\udc3f \ud835\udf03 = \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03\n! \" #\n$\nmaximizes the likelihood\nLikelihood\n= \"\ud835\udc53 \ud835\udc4b |\ud835\udf03\nof our observed data !\nEstimator\n!\"#\n\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b ?\n(MLE) ! \" # \ud835\udf03 = arg max \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03\n$%& ! \" #\n\u2019\nlikelihood of data\nMaximum\nGiven the sample data\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\na Posteriori \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , $() ! \" #\n! \" #\n\u2019\n(MAP) what is the most probable posterior distribution\nparameter \ud835\udf03? of \ud835\udf03\nEstimator\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nMaximum A Posteriori (MAP) Estimator\nConsider a sample of \ud835\udc5b iid random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n\u2019 ( )\ndef The Maximum a Posteriori (MAP) Estimator of \ud835\udf03 is the value of \ud835\udf03 that\nmaximizes the posterior distribution of \ud835\udf03.\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n*+, \u2019 ( )\n-\nIntuition with Bayes\u2019 Theorem:\n\ud835\udc3f \ud835\udf03 , probability of data\ngiven parameter \ud835\udf03\nAfter seeing likelihood prior\nposterior\ndata, posterior\n\ud835\udc43 data \ud835\udf03 \ud835\udc43 \ud835\udf03 Before seeing data,\nbelief of \ud835\udf03 \ud835\udc43 \ud835\udf03 data =\nprior belief of \ud835\udf03\n\ud835\udc43 data\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nSolving for \ud835\udf03\n!\"#\n\u2022 Observe data: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , all iid\n! \" # $\n\u2022 Let likelihood be same as MLE: \ud835\udc53 \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b |\ud835\udf03 = \"\ud835\udc53 \ud835\udc4b | \ud835\udf03\n# % $ !\n!\"#\n\u2022 Let the prior distribution of \ud835\udf03 be \ud835\udc54 \ud835\udf03 .\n\ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 \ud835\udc54 \ud835\udf03\n! \" #\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b = arg max (Bayes\u2019 Theorem)\n$() ! \" #\n\u210e \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\u2019 \u2019 ! \" #\n#\n\ud835\udc54 \ud835\udf03 \u220f \ud835\udc53 \ud835\udc4b | \ud835\udf03\n*+! *\n= arg max\n(independence)\n\u210e \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\u2019 ! \" #\n#\n= arg max \ud835\udc54 \ud835\udf03 2\ud835\udc53 \ud835\udc4b | \ud835\udf03 (1/\u210e \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b is a positive constant w.r.t. \ud835\udf03)\n* # % $\n\u2019\n*+!\n#\n= arg max log \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b | \ud835\udf03\n*\n\u2019\n*+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\n\ud835\udf03 : Interpretation 1\n!\"#\n\u2022 Observe data: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , all iid\n! \" # $\n\u2022 Let likelihood be same as MLE: \ud835\udc53 \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b |\ud835\udf03 = \"\ud835\udc53 \ud835\udc4b | \ud835\udf03\n# % $ !\n!\"#\n\u2022 Let the prior distribution of \ud835\udf03 be \ud835\udc54 \ud835\udf03 .\n\ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 \ud835\udc54 \ud835\udf03\n! \" #\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b = arg max (Bayes\u2019 Theorem)\n$() ! \" #\n\u210e \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\u2019 \u2019 ! \" #\n#\n\ud835\udc54 \ud835\udf03 \u220f \ud835\udc53 \ud835\udc4b | \ud835\udf03\n*+! *\n= arg max\n(independence)\n\u210e \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\u2019 ! \" #\n#\n= arg max \ud835\udc54 \ud835\udf03 2\ud835\udc53 \ud835\udc4b | \ud835\udf03 (1/\u210e \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b is a positive constant w.r.t. \ud835\udf03)\n* # % $\n\u2019\n*+!\n#\n\ud835\udf03 maximizes\n= arg max log \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b | \ud835\udf03 $()\n*\nlog prior + log-likelihood\n\u2019\n*+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\n\ud835\udf03 : Interpretation 2\n!\"#\n\u2022 Observe data: \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , all iid\n! \" # $\n\u2022 Let likelihood be same as MLE: \ud835\udc53 \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b |\ud835\udf03 = \"\ud835\udc53 \ud835\udc4b | \ud835\udf03\n# % $ !\n!\"#\n\u2022 Let the prior distribution of \ud835\udf03 be \ud835\udc54 \ud835\udf03 .\n\ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 \ud835\udc54 \ud835\udf03\nThe mode of the\n! \" #\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b = arg max (Bayes\u2019 Theorem)\n$() ! \" #\nposterio\u210er d\ud835\udc4bis,tr\ud835\udc4bibu, \u2026tio,n\ud835\udc4b of \ud835\udf03\n\u2019 \u2019 ! \" #\n#\n\ud835\udc54 \ud835\udf03 \u220f \ud835\udc53 \ud835\udc4b | \ud835\udf03\n*+! *\n= arg max\n(independence)\n\u210e \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n\u2019 ! \" #\n#\n= arg max \ud835\udc54 \ud835\udf03 2\ud835\udc53 \ud835\udc4b | \ud835\udf03 (1/\u210e \ud835\udc4b ,\ud835\udc4b ,\u2026,\ud835\udc4b is a positive constant w.r.t. \ud835\udf03)\n* # % $\n\u2019\n*+!\n#\n\ud835\udf03 maximizes\n= arg max log \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b | \ud835\udf03 $()\n*\nlog prior + log-likelihood\n\u2019\n*+!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nMode: A statistic of a random variable\nThe mode of a random variable \ud835\udc4b is defined as:\narg max \ud835\udc5d \ud835\udc65 arg max \ud835\udc53 \ud835\udc65\n4 4\n(\ud835\udc4b discrete, PMF \ud835\udc5d \ud835\udc65 ) (\ud835\udc4b continuous, PDF \ud835\udc53 \ud835\udc65 )\n\u2022 Intuitively: The value of \ud835\udc4b that is \"most likely\".\n\u2022 Note some distributions don\u2019t have a unique mode\n(e.g., Uniform distribution, Bernoulli(0.5))\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n*+, \u2019 ( )\n-\n\ud835\udf03 is the most probable \ud835\udf03\n$()\ngiven the data \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nBernoulli MAP:\nChoosing a\nprior\n9\nHow does MAP work? (for Bernoulli)\nObserve data \ud835\udc5b heads, \ud835\udc5a tails\nChoose model Bernoulli \ud835\udc5d\nChoose prior on \ud835\udf03\n(some \ud835\udc54 \ud835\udf03 )\nFind \ud835\udf03 =\n$()\nmaximize\narg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" #\nlog prior + log-likelihood\n\u2019\n#\nlog \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b |\ud835\udf03\n* MAP depends on what\n*+! \ud835\udc54 \ud835\udf03 we choose.\n\u2022 Differentiate, set to 0\n\u2022 Solve\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nMAP for Bernoulli\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail.\n\u2022 Choose a prior on \ud835\udf03. What is \ud835\udf03 ?\n$()\nSuppose we pick a prior \ud835\udf03~\ud835\udca9 0.5, 1( . \ud835\udc54 \ud835\udf03 = ! \ud835\udc52- .-/.1 !/\"\n\",\n1. Determine log log \ud835\udc54 \ud835\udf03 + log \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03\n! \" #\nprior + log 1\n\ud835\udc5b + \ud835\udc5a\n- .-/.1 !/\" # 3\n= log \ud835\udc52 + log \ud835\udc5d 1 \u2212 \ud835\udc5d\nlikelihood\n\ud835\udc5b\n2\ud835\udf0b\n\ud835\udc5b + \ud835\udc5a\n= \u2212log 2\ud835\udf0b \u2212 \ud835\udc5d \u2212 0.5 %/2 + log + \ud835\udc5blog\ud835\udc5d + \ud835\udc5alog 1 \u2212 \ud835\udc5d\n\ud835\udc5b\n2. Differentiate\n\ud835\udc5b \ud835\udc5a\nWe should choose a prior that\u2019s\nwrt (each) \ud835\udf03,\n\u2212 \ud835\udc5d \u2212 0.5 + \u2212 = 0\n\ud835\udc5d 1 \u2212 \ud835\udc5d easier to deal with. This one is hard!\nset to 0\n3. Solve resulting\ncubic equations, nope not going to do it\nequations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nA better approach: Use conjugate distributions\nObserve data \ud835\udc5b heads, \ud835\udc5a tails\nChoose model Bernoulli \ud835\udc5d\nChoose prior on \ud835\udf03 (choose conjugate\n(some \ud835\udc54 \ud835\udf03 )\ndistribution)\nFind \ud835\udf03 =\n$()\nmaximize\narg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b \u2b50\n! \" #\nlog prior + log-likelihood\n\u2019\nUp next: Conjugate\n#\npriors are great\nlog \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b |\ud835\udf03\n*\nfor MAP!\n*+!\n\u2022 Differentiate, set to 0\n\u2022 Solve\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nBernoulli MAP:\nConjugate prior\n13\nBeta is a conjugate distribution for Bernoulli Mostly Review\nBeta is a conjugate distribution for Bernoulli, meaning:\n\u2022 Prior and posterior parametric forms are the same\n\u2022 Practically, conjugate means easy update:\nAdd numbers of \"successes\" and \"failures\" seen to Beta parameters.\n\u2022 You can set the prior to reflect how fair/biased you think the experiment is a priori.\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1, \ud835\udc4f = \ud835\udc5a + 1)\n*345 *345\nExperiment Observe \ud835\udc5b successes and \ud835\udc5a failures\nPosterior Beta \ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1, \ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1\n*345 *345\nBeta parameters \ud835\udc4e, \ud835\udc4f are called hyperparameters.\n\ud835\udc4e \u2212 1\nInterpret Beta(\ud835\udc4e,\ud835\udc4f): \ud835\udc4e + \ud835\udc4f \u2212 2 trials,\nMode of Beta(\ud835\udc4e, \ud835\udc4f):\n\ud835\udc4e + \ud835\udc4f \u2212 2 with \ud835\udc4e \u2212 1 successes and with \ud835\udc4f \u2212 1 failures\n(we\u2019ll prove this in a few minutes)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nHow does MAP work? (for Bernoulli)\nObserve data \ud835\udc5b heads, \ud835\udc5a tails\n\u2b50\nChoose model Bernoulli \ud835\udc5d\nChoose prior on \ud835\udf03 (choose conjugate\n(some \ud835\udc54 \ud835\udf03 )\ndistribution)\nFind \ud835\udf03 =\n$() maximize Mode of posterior\narg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # log prior + log-likelihood distribution of \ud835\udf03\n\u2019\n#\n(posterior is also\nlog \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b |\ud835\udf03\n* conjugate)\n*+!\n\u2022 Differentiate, set to 0\n\u2022 Solve\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nConjugate strategy: MAP for Bernoulli\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail. Define as data, \ud835\udc37\n\u2022 Choose a prior on \ud835\udf03. What is \ud835\udf03 ?\n$()\n1. Choose a prior Suppose we pick a prior \ud835\udf03~Beta \ud835\udc4e, \ud835\udc4f .\n2. Determine posterior Because Beta is a conjugate distribution for Bernoulli,\nthe posterior distribution is \ud835\udf03|\ud835\udc37~Beta \ud835\udc4e + \ud835\udc5b, \ud835\udc4f + \ud835\udc5a\n\ud835\udc4e + \ud835\udc5b \u2212 1\n3. Compute MAP \ud835\udf03 = (mode of Beta \ud835\udc4e + \ud835\udc5b,\ud835\udc4f + \ud835\udc5a )\n$()\n\ud835\udc4e + \ud835\udc5b + \ud835\udc4f + \ud835\udc5a \u2212 2\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nMAP in practice\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail.\n\u2022 What is the MAP estimator of the Bernoulli parameter \ud835\udc5d,\nif we assume a prior on \ud835\udc5d of Beta 2, 2 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nMAP in practice\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail.\n\u2022 What is the MAP estimator of the Bernoulli parameter \ud835\udc5d,\nif we assume a prior on \ud835\udc5d of Beta 2, 2 ?\nBefore flipping the coin,\n1. Choose a prior \ud835\udf03~Beta 2,2 . we imagined 2 trials:\n1 imaginary head, 1\nimaginary tail.\n2. Determine posterior Posterior distribution of \ud835\udf03 given observed data is Beta 9, 3\nAfter the experiment, we saw 10 trials:\n8\n3. Compute MAP \ud835\udf03 = 8 heads (imaginary and real),\n$()\n10\n2 tails (imaginary and real).\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nProving the mode of Beta\nObserve data \ud835\udc5b heads, \ud835\udc5a tails\nChoose model Bernoulli \ud835\udc5d\nChoose prior on \ud835\udf03 (choose conjugate)\n(some arbitrary \ud835\udc54 \ud835\udf03 )\nBeta \ud835\udc4e, \ud835\udc4f\nFind \ud835\udf03 =\n$() maximize Mode of posterior\narg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" # log prior + log-likelihood distribution of \ud835\udf03\n\u2019\n#\n(posterior is also\nThese are equivalent log \ud835\udc54 \ud835\udf03 + 6 log \ud835\udc53 \ud835\udc4b |\ud835\udf03\n* conjugate)\ninterpretations of \ud835\udf03 . *+!\n$()\nWe\u2019ll use this equivalence \u2022 Differentiate, set to 0\nto prove the mode of Beta. \u2022 Solve\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nMAP for Bernoulli, conjugate prior (from first principles)\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail.\n\u2022 Choose a prior on \ud835\udf03. What is \ud835\udf03 ?\n$()\n! normalizing\nSuppose we pick a prior \ud835\udf03~Beta \ud835\udc4e, \ud835\udc4f . \ud835\udc54 \ud835\udf03 = \ud835\udc5d = \ud835\udc5d4-! 1 \u2212 \ud835\udc5d 7-!\nconstant, \ud835\udefd\n6\n1. Determine log prior + log likelihood\n1\n\ud835\udc5b + \ud835\udc5a\nlog \ud835\udc54 \ud835\udf03 + log \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03 = log \ud835\udc5d4-! 1 \u2212 \ud835\udc5d 7-! + log \ud835\udc5d# 1 \u2212 \ud835\udc5d 3\n! \" #\n\ud835\udefd \ud835\udc5b\n1\n\ud835\udc5b + \ud835\udc5a\n= log + \ud835\udc4e \u2212 1 log \ud835\udc5d + \ud835\udc4f \u2212 1 log 1 \u2212 \ud835\udc5d + log + \ud835\udc5b log \ud835\udc5d + \ud835\udc5a log 1 \u2212 \ud835\udc5d\n\ud835\udefd \ud835\udc5b\n\ud835\udc4e \u2212 1 \ud835\udc5b \ud835\udc4f \u2212 1 \ud835\udc5a\n2. Differentiate\n+ \u2212 \u2212 = 0\nw.r.t. (each) \ud835\udf03, \ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d 1 \u2212 \ud835\udc5d\nset to 0\n3. Solve (next slide)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nMAP for Bernoulli, conjugate prior (from first principles)\n\u2022 Flip a coin 8 times. Observe \ud835\udc5b = 7 heads and \ud835\udc5a = 1 tail.\n\u2022 Choose a prior on \ud835\udf03. What is \ud835\udf03 ?\n$()\n! normalizing\nSuppose we pick a prior \ud835\udf03~Beta \ud835\udc4e, \ud835\udc4f . \ud835\udc54 \ud835\udf03 = \ud835\udc5d4-! 1 \u2212 \ud835\udc5d 7-!\nconstant, \ud835\udefd\n6\n3. Solve for \ud835\udc5d \ud835\udc4e \u2212 1 \ud835\udc5b \ud835\udc4f \u2212 1 \ud835\udc5a\n+ \u2212 \u2212 = 0 (from previous slide)\n\ud835\udc5d \ud835\udc5d 1 \u2212 \ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc4e + \ud835\udc5b \u2212 1 \ud835\udc4f + \ud835\udc5a \u2212 1\n\u27f9 \u2212 = 0\n\ud835\udc5d 1 \u2212 \ud835\udc5d\n\u27f9 \ud835\udc4e + \ud835\udc5b \u2212 1 \u2212 \ud835\udc4e + \ud835\udc5b \u2212 1 \ud835\udc5d = \ud835\udc4f + \ud835\udc5a \u2212 1 \ud835\udc5d\n\u27f9 \ud835\udc5d \ud835\udc4e + \ud835\udc5b + \ud835\udc4f + \ud835\udc5a \u2212 2 = \ud835\udc4e + \ud835\udc5b \u2212 1\n\ud835\udc4e + \ud835\udc5b \u2212 1\nIf we choose a conjugate prior, we avoid calculus\n\ud835\udf03 =\n$() \ud835\udc4e + \ud835\udc5b + \ud835\udc4f + \ud835\udc5a \u2212 2 \u2705 with MAP, and we can simply report mode of\nThe mode of the posterior, posterior.\nBeta \ud835\udc4e + \ud835\udc5b,\ud835\udc4f + \ud835\udc5a !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nChoosing\nhyperparameters\nfor conjugate\nprior\n22\nWhere\u2019d you get them priors?\nprior\n\u2022 Let \ud835\udf03 be the probability a coin turns up heads.\n\u2022 Model \ud835\udf03 with 2 different priors:\n\u25e6 Prior 1: Beta(3,8): 2 imaginary heads,\n\"\nmode:\n7 imaginary tails\n9\n\u25e6 Prior 2: Beta(7,4): 6 imaginary heads,\n:\nmode:\n3 imaginary tails\n9\nNow flip 100 coins and get 58 heads and 42 tails.\n1. What are the two posterior distributions?\n2. What are the modes of the two posterior distributions?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nWhere\u2019d you get them priors?\nprior\n\u2022 Let \ud835\udf03 be the probability a coin turns up heads.\n\u2022 Model \ud835\udf03 with 2 different priors:\n\u25e6 Prior 1: Beta(3,8): 2 imaginary heads,\n\"\nmode:\n7 imaginary tails\n9\n\u25e6 Prior 2: Beta(7,4): 6 imaginary heads,\n:\nmode:\n3 imaginary tails\n9\nNow flip 100 coins and get 58 heads and 42 tails. posterior\n:/\nPosterior 1: Beta(61,50) mode:\n!/9\n:;\nPosterior 2: Beta(65,46) mode:\n!/9\nProvided we collect enough data, posteriors will converge to\nthe true value and choice of prior will matter less.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nLaplace smoothing\nMAP with Laplace smoothing: a prior which represents \ud835\udc58 imagined\nobservations of each outcome.\n\u2022 Categorical data (i.e., Multinomial, Bernoulli/Binomial)\n\u2022 Also known as additive smoothing\nLaplace estimate Imagine \ud835\udc58 = 1 of each outcome\n(follows from Laplace\u2019s \"law of succession\")\nExample: Laplace estimate for probabilities from previously mentioned\nexperiment (100 coins: 58 heads, 42 tails)\nLaplace smoothing:\n59 43\nheads tails \u2022 Easy to implement/remember\n102 102\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nBack to our happy Laplace\nConsider our previous 6-sided die.\n\u2022 Roll the dice \ud835\udc5b = 12 times.\n\u2022 Observe: 3 ones, 2 twos, 0 threes, 3 fours, 1 fives, 3 sixes\n\ud835\udc5d = 3/12, \ud835\udc5d = 2/12, \ud835\udc5d = 0/12,\nRecall \ud835\udf03 : \u26a0\n! \" <\n*GH\n\ud835\udc5d = 3/12, \ud835\udc5d = 1/12, \ud835\udc5d = 3/12\n; 1 :\nWhat are your Laplace estimates for each roll outcome?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nBack to our happy Laplace\nConsider our previous 6-sided die.\n\u2022 Roll the dice \ud835\udc5b = 12 times.\n\u2022 Observe: 3 ones, 2 twos, 0 threes, 3 fours, 1 fives, 3 sixes\n\ud835\udc5d = 3/12, \ud835\udc5d = 2/12, \ud835\udc5d = 0/12,\nRecall \ud835\udf03 : \u26a0\n! \" <\n*GH\n\ud835\udc5d = 3/12, \ud835\udc5d = 1/12, \ud835\udc5d = 3/12\n; 1 :\nWhat are your Laplace estimates for each roll outcome?\n\ud835\udc4b + 1\n*\n\ud835\udc5d =\n*\n\ud835\udc5b + \ud835\udc5a\n\ud835\udc5d = 4/18, \ud835\udc5d = 3/18, \ud835\udc5d = 1/18, \u2705 Laplace smoothing:\n! \" <\n\ud835\udc5d = 4/18, \ud835\udc5d = 2/18, \ud835\udc5d = 4/18 \u2022 Easy to implement/remember\n; 1 :\n\u2022 Avoids parameter estimation of \ud835\udfce\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nExtra: Other\nConjugates\n28\nConjugate distributions\nMAP The mode of the\n\ud835\udf03 = arg max \ud835\udc53 \ud835\udf03|\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n*+, \u2019 ( )\nestimator: posterior distribution of \ud835\udf03\n-\nDistribution parameter Conjugate distribution\nBernoulli \ud835\udc5d Beta\nBinomial \ud835\udc5d Beta\nMultinomial \ud835\udc5d Dirichlet\n!\nPoisson \ud835\udf06 Gamma\nExponential \ud835\udf06 Gamma\nNormal \ud835\udf07 Normal\nNormal \ud835\udf0e% Inverse Gamma\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nMultinomial is Multiple times the fun\nDirichlet \ud835\udc4e , \ud835\udc4e , \u2026 , \ud835\udc4e is a conjugate for Multinomial.\n\u2019 ( L\n\u2022 Generalizes Beta in the\n3\n1\nsame way Multinomial 4 -!\n\ud835\udc53 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 = 2\ud835\udc65 \"\n! \" 3 \ud835\udc35 \ud835\udc4e , \ud835\udc4e , \u2026 , \ud835\udc4e *\ngeneralizes Binomial:\n! \" 3\n*+!\nPrior Dirichlet \ud835\udc4e , \ud835\udc4e , \u2026 , \ud835\udc4e\n\u2019 ( L\nL\nSaw \u2211 \ud835\udc4e \u2212 \ud835\udc5a imaginary trials, with \ud835\udc4e \u2212 1 of outcome \ud835\udc56\nMN\u2019 M M\nExperiment Observe \ud835\udc5b + \ud835\udc5b + \u22ef + \ud835\udc5b new trials, with \ud835\udc5b of outcome \ud835\udc56\n\u2019 ( L M\nPosterior Dirichlet \ud835\udc4e + \ud835\udc5b , \ud835\udc4e + \ud835\udc5b , \u2026 , \ud835\udc4e + \ud835\udc5b\nm\n\u2019 \u2019 ( ( L L\n\ud835\udc4e + \ud835\udc5b \u2212 1\n* *\nMAP: \ud835\udc5d =\n*\n\u22113\n\ud835\udc4e +\n\u22113\n\ud835\udc5b \u2212 \ud835\udc5a\n*+! * *+! *\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nGood times with Gamma\nGamma \ud835\udefc, \ud835\udefd is a conjugate for Poisson.\n\u2022 Also conjugate for Exponential,\nbut we won\u2019t delve into that\n!!\"!\"##\"$%\n\u2022 Mode of gamma: \ud835\udefc \u2212 1 /\ud835\udefd Gamma \ud835\udefc,\ud835\udefd =\n$(&)\n! !\"# \"$%\nO 4 P\nPrior \ud835\udf03~Gamma \ud835\udefc, \ud835\udefd =\nQ(R)\nSaw \ud835\udefc \u2212 1 total imaginary events during \ud835\udefd prior time periods\nExperiment Observe \ud835\udc5b events during next \ud835\udc58 time periods\nPosterior \ud835\udf03|\ud835\udc5b events in \ud835\udc58 periods ~Gamma \ud835\udefc + \ud835\udc5b, \ud835\udefd + \ud835\udc58\n\ud835\udefc + \ud835\udc5b \u2212 1\nMAP: \ud835\udf03 =\n$()\n\ud835\udefd + \ud835\udc58\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nGamma \ud835\udefc,\ud835\udefd &\u2019#\nMode:\nMAP for Poisson\nis conjugate for Poisson (\nLet \ud835\udf06 be the average # of successes in a time period.\nObserve 10 imaginary events\n1. What does it mean to have\nin 5 time periods,\na prior of \ud835\udf03~Gamma 11,5 ?\ni.e., observe at Poisson rate = 2\nNow perform the experiment and see 11 events in next 2 time periods.\n2. Given your prior, what is the\nposterior distribution?\n3. What is \ud835\udf03 ?\n*+,\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nGamma \ud835\udefc,\ud835\udefd &\u2019#\nMode:\nMAP for Poisson\nis conjugate for Poisson (\nLet \ud835\udf06 be the average # of successes in a time period.\nObserve 10 imaginary events\n1. What does it mean to have\nin 5 time periods,\na prior of \ud835\udf03~Gamma 11,5 ?\ni.e., observe at Poisson rate = 2\nNow perform the experiment and see 11 events in next 2 time periods.\n2. Given your prior, what is the\n\ud835\udf03|\ud835\udc5b events in \ud835\udc58 periods ~Gamma 22, 7\nposterior distribution?\n3. What is \ud835\udf03 ?\n*+, \ud835\udf03 = 3, the updated Poisson rate\n$()\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33 <END>"}
{"prompt": "Lecture notes from 18_clt_annotated.txt\n\n###\n\n", "completion": "18: Central Limit\nTheorem\nJerry Cain\nMay 10th, 2024\nLecture Discussion on Ed\n1\niid Random\nVariables\n2\nIndependence of multiple random variables Review\nWe have independence of \ud835\udc5b discrete random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b if\n! \" #\nfor all \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 :\n! \" #\n&\n\ud835\udc43 \ud835\udc4b = \ud835\udc65 , \ud835\udc4b = \ud835\udc65 , \u2026 , \ud835\udc4b = \ud835\udc65 = & \ud835\udc43 \ud835\udc4b = \ud835\udc65\n$ $ % % & & \u2019 \u2019\n\u2019($\n&\n\ud835\udc5d \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 = & \ud835\udc5d \ud835\udc65\n! ,! ,\u2026,! $ % & ! \u2019\n! \" # $\n\u2019($\nWe have independence of \ud835\udc5b continuous random variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b if\n! \" #\nfor all \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 :\n! \" #\n&\n\ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65 , \ud835\udc4b \u2264 \ud835\udc65 , \u2026 , \ud835\udc4b \u2264 \ud835\udc65 = & \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc65\n$ $ % % & & \u2019 \u2019\n&\n\u2019($\n\ud835\udc53 \ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 = & \ud835\udc53 \ud835\udc65\n! ,! ,\u2026,! $ % & ! \u2019\n! \" # $\n\u2019($\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\ni.i.d. random variables\nConsider \ud835\udc5b variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" #\n\ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b are independent and identically distributed if\n! \" #\n\u2022 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b are independent, and\n! \" #\n\u2022 All have the same PMF (if discrete) or PDF (if continuous).\n\u21d2 \ud835\udc38 \ud835\udc4b = \ud835\udf07 for \ud835\udc56 = 1, \u2026 , \ud835\udc5b\n$\n\"\n\u21d2 Var \ud835\udc4b = \ud835\udf0e for \ud835\udc56 = 1, \u2026 , \ud835\udc5b\n$\ni.i.d. iid IID\nSame thing:\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nQuick check\nAre \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b iid with the following distributions?\n! \" #\n1. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b independent\n$ $\n2. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b independent\n$ $ $\n3. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b = \ud835\udc4b = \u22ef = \ud835\udc4b\n$ ! \" #\n4. \ud835\udc4b ~Bin \ud835\udc5b , \ud835\udc5d , \ud835\udc4b independent\n$ $ $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nQuick check\nAre \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b iid with the following distributions?\n! \" #\n1. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b independent\n$ $ \u2705\n2. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b independent \u274c (unless \ud835\udf06 equal)\n$ $ $ \u2019\n3. \ud835\udc4b ~Exp \ud835\udf06 , \ud835\udc4b = \ud835\udc4b = \u22ef = \ud835\udc4b\n\u274c dependent: \ud835\udc4b = \ud835\udc4b = \u22ef = \ud835\udc4b\n$ ! \" # $ % &\n4. \ud835\udc4b ~Bin \ud835\udc5b , \ud835\udc5d , \ud835\udc4b independent \u274c (unless \ud835\udc5b equal)\n$ $ $ \u2019\nNote underlying Bernoulli RVs are iid!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nCentral Limit\nTheorem\nsource\n7\nCentral Limit Theorem\nConsider \ud835\udc5b independent and identically distributed (iid) variables \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b\n! \" #\nwith \ud835\udc38 \ud835\udc4b = \ud835\udf07 and Var \ud835\udc4b = \ud835\udf0e\".\n$ $\n$ As \ud835\udc5b \u2192 \u221e\n%\n! \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n!\n!\"#\nThe sum of \ud835\udc5b iid random variables is normally distributed with mean \ud835\udc5b\ud835\udf07\n\"\nand variance \ud835\udc5b\ud835\udf0e .\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nSum of dice rolls\nRoll \ud835\udc5b independent dice. Let \ud835\udc4b be the outcome of roll \ud835\udc56. \ud835\udc4b are iid\n$ %\nHow many ways\n0.2 0.2\ncan you roll a total\nof 3 vs 11?\n0.1 0.1\n0.0 0.0\n1 2 3 4 5 6 2 4 6 8 10 12 3 5 7 9 11131517\n$ % )\nSum of 1 Sum of 2 Sum of 3\n0 \ud835\udc4b 0 \ud835\udc4b 0 \ud835\udc4b\n\u2019 \u2019 \u2019\ndie roll dice rolls dice rolls\n\u2019($ \u2019($ \u2019($\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nCLT explains a lot\n& As \ud835\udc5b \u2192 \u221e\nThe sum of \ud835\udc5b iid random variables is normally\n%\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\u2019 %\ndistributed with mean \ud835\udc5b\ud835\udf07 and variance \ud835\udc5b\ud835\udf0e .\n\u2019($\nGalton Board, by Sir Francis Galton\n(1822-1911)\n\ud835\udc5b = 5\n0 1 2 3 4 5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nCLT explains a lot\n& As \ud835\udc5b \u2192 \u221e\nThe sum of \ud835\udc5b iid random variables is normally\n%\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\u2019 %\ndistributed with mean \ud835\udc5b\ud835\udf07 and variance \ud835\udc5b\ud835\udf0e .\n\u2019($\nProof:\nLet \ud835\udc4b ~Ber(\ud835\udc5d) for \ud835\udc56 = 1, \u2026 , \ud835\udc5b, where \ud835\udc4b are iid\n\u2019 \u2019\n\ud835\udc38 \ud835\udc4b = \ud835\udc5d, Var \ud835\udc4b = \ud835\udc5d(1 \u2212 \ud835\udc5d)\n\u2019 \u2019\n&\n\ud835\udc4b = 0 \ud835\udc4b\n\u2019 \ud835\udc4b~Bin(\ud835\udc5b,\ud835\udc5d)\n\u2019($\n\ud835\udc4b~\ud835\udca9 \ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e\" CLT, as \ud835\udc5b \u2192 \u221e\nNormal approximation of Binomial\nSum of iid Bernoulli RVs \u2248 Normal \ud835\udc4b~\ud835\udca9 \ud835\udc5b\ud835\udc5d, \ud835\udc5b\ud835\udc5d(1 \u2212 \ud835\udc5d) (substitute mean,\nvariance of Bernoulli)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nCLT explains a lot\n& As \ud835\udc5b \u2192 \u221e\nThe sum of \ud835\udc5b iid random variables is normally\n%\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\u2019 %\ndistributed with mean \ud835\udc5b\ud835\udf07 and variance \ud835\udc5b\ud835\udf0e .\n\u2019($\nSample of\nsize 15,\nsum values\n$*\nDistribution of \ud835\udc4b Distribution of \u2211 \ud835\udc4b\n\u2019 \u2019($ \u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nCLT explains a lot\n& As \ud835\udc5b \u2192 \u221e\nThe sum of \ud835\udc5b iid random variables is normally\n%\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\u2019 %\ndistributed with mean \ud835\udc5b\ud835\udf07 and variance \ud835\udc5b\ud835\udf0e .\n\u2019($\nSample of\nsize 15,\naverage values\n$\n$*\nDistribution of \ud835\udc4b (sample mean) Distribution of \u2211 \ud835\udc4b\n\u2019 \u2019($ \u2019\n$*\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nProof of CLT\n& As \ud835\udc5b \u2192 \u221e\nThe sum of \ud835\udc5b iid random variables is normally\n%\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\u2019 %\ndistributed with mean \ud835\udc5b\ud835\udf07 and variance \ud835\udc5b\ud835\udf0e .\n\u2019($\nSketch of Proof:\n\u2022 The Fourier Transform of a PDF is its characteristic function.\n\u2022 Take the characteristic function of the probability mass of the sample\ndistance from the mean, divided by standard deviation\n\u2022 Show that this approaches an 1!\n0\n\ud835\udc53 \ud835\udc65 = \ud835\udc52 \"\nexponential function in the limit as \ud835\udc5b \u2192 \u221e:\n\u2022 This function just happens to be the characteristic function of the\nStandard Normal, \ud835\udc4d~ \ud835\udca9(0,1).\n(the full proof is beyond the scope of CS109)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nSum of \ud835\udc5b independent Uniform RVs\n# Let \ud835\udc4b = \u2211 \ud835\udc4b be sum of iid RVs, where \ud835\udc4b ~Uni 0,1 .\n$2! $ $\nFor different \ud835\udc5b, how close is the CLT approximation of \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc5b/3 ?\n\ud835\udc5b = 2:\nExact \ud835\udc43 \ud835\udc4b \u2264 2/3 \u2248 0.2222\n\"\n\ud835\udc4b \u2248 \ud835\udc4c~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nFDP\n\ud835\udf07 = \ud835\udc38 \ud835\udc4b = 1/2\n\u2019\n\ud835\udf0e% = Var \ud835\udc4b = 1/12\n\u2019\nCLT approximation\n\u27f9 \ud835\udc4c~\ud835\udca9(1, 1/6)\n\ud835\udc43 \ud835\udc4b \u2264 2/3 \u2248 \ud835\udc43 \ud835\udc4c \u2264 2/3\n2/3 \u2212 1\n= \u03a6 \u2248 0.2071\n1/6\nSum of \ud835\udc5b independent Uniform RVs\n# Let \ud835\udc4b = \u2211 \ud835\udc4b be sum of iid RVs, where \ud835\udc4b ~Uni 0,1 .\n$2! $ $\nFor different \ud835\udc5b, how close is the CLT approximation of \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc5b/3 ?\n\ud835\udc5b = 5:\nExact \ud835\udc43 \ud835\udc4b \u2264 5/3 \u2248 0.1017\n\"\n\ud835\udc4b \u2248 \ud835\udc4c~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nFDP\n\ud835\udf07 = \ud835\udc38 \ud835\udc4b = 1/2\n\u2019\n\ud835\udf0e% = Var \ud835\udc4b = 1/12\n\u2019\nCLT approximation\n\u27f9 \ud835\udc4c~\ud835\udca9(5/2, 5/12)\n\ud835\udc43 \ud835\udc4b \u2264 5/3 \u2248 \ud835\udc43 \ud835\udc4c \u2264 5/3\n5/3 \u2212 5/2\n= \u03a6 \u2248 0.0984\n5/12\nSum of \ud835\udc5b independent Uniform RVs\n# Let \ud835\udc4b = \u2211 \ud835\udc4b be sum of iid RVs, where \ud835\udc4b ~Uni 0,1 .\n$2! $ $\nFor different \ud835\udc5b, how close is the CLT approximation of \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc5b/3 ?\n\ud835\udc5b = 10:\nExact \ud835\udc43 \ud835\udc4b \u2264 10/3 \u2248 0.0337\n\"\n\ud835\udc4b \u2248 \ud835\udc4c~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e )\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nFDP\n\ud835\udf07 = \ud835\udc38 \ud835\udc4b = 1/2\n\u2019\n\ud835\udf0e% = Var \ud835\udc4b = 1/12\n\u2019\nCLT approximation\n\u27f9 \ud835\udc4c~\ud835\udca9(5, 5/6)\n\ud835\udc43 \ud835\udc4b \u2264 10/3 \u2248 \ud835\udc43 \ud835\udc4c \u2264 10/3\n10/3 \u2212 5\n= \u03a6 \u2248 0.0339\n5/6\nSum of \ud835\udc5b independent Uniform RVs\n# Let \ud835\udc4b = \u2211 \ud835\udc4b be sum of iid RVs, where \ud835\udc4b ~Uni 0,1 .\n$2! $ $\nFor different \ud835\udc5b, how close is the CLT approximation of \ud835\udc43 \ud835\udc4b \u2264 \ud835\udc5b/3 ?\n\ud835\udc5b = 10:\n\ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nFDP\n\ud835\udf07 = \ud835\udc38 \ud835\udc4b = 1/2\n\u2019\n\ud835\udf0e% = Var \ud835\udc4b = 1/12\n\u2019\n\ud835\udc5b = 5:\n\ud835\udc65\nMost books will tell you that CLT holds if \ud835\udc5b \u2265 30, but it might hold for even smaller \ud835\udc5b\ndepending on the distribution of your iid \ud835\udc4b \u2019s, particularly if they\u2019re symmetric.\n\u2019\nFDP\n\ud835\udc5b = 2:\n\ud835\udc65\nFDP\nSample\nStatistics\n19\nWhat about other functions?\n\"\nLet \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b be iid, where \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e . As \ud835\udc5b \u2192 \u221e:\n! \" # $ $\n#\n\"\nK \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e ) Sum of iid RVs\n$\n$2!\n?\nAverage of iid RVs\n(sample mean)\n?\nMax of iid RVs\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nWhat about other functions?\n\"\nLet \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b be iid, where \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e . As \ud835\udc5b \u2192 \u221e:\n! \" # $ $\n#\n\"\nK \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e ) Sum of iid RVs\n$\n$2!\n?\nAverage of iid RVs\n(sample mean)\n?\nMax of iid RVs\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nDistribution of sample mean\n\"\nLet \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b be iid, where \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e . As \ud835\udc5b \u2192 \u221e:\n! \" # $ $\n$ $\n1\nDefine: \ud835\udc4b3 = 6\ud835\udc4b (sample mean) \ud835\udc4c = 6\ud835\udc4b (sum)\n! !\n\ud835\udc5b\n!\"# !\"#\n\"\n\ud835\udc4c~\ud835\udca9 \ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e (CLT, as \ud835\udc5b \u2192 \u221e)\n!\nL\n\ud835\udc4b = \ud835\udc4c\n#\nL\n\ud835\udc4b~\ud835\udca9( ? , ? )\n(Linear transform of a Normal)\n& The average of iid random variables (i.e.,\n%\n1 \ud835\udf0e\n0 \ud835\udc4b ~\ud835\udca9(\ud835\udf07, ) sample mean) is normally distributed with\n\u2019\n\ud835\udc5b \ud835\udc5b\n%\nmean \ud835\udf07 and variance \ud835\udf0e /\ud835\udc5b.\n\u2019($\nDemo: http://onlinestatbook.com/stat_sim/sampling_dist/\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 2222\nWhat about other functions?\n\"\nLet \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b be iid, where \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e . As \ud835\udc5b \u2192 \u221e:\n! \" # $ $\n#\n\"\nK \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e ) Sum of iid RVs\n$\n$2!\n#\n\"\n1 \ud835\udf0e\nK \ud835\udc4b ~\ud835\udca9(\ud835\udf07, ) Average of iid RVs\n$\n\ud835\udc5b \ud835\udc5b\n(sample mean)\n$2!\n?\nGumbel Max of iid RVs\n(see Fisher-Tippett Gnedenko Theorem)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nExercises\n24\n$\nDice game As \ud835\udc5b \u2192 \u221e: ,\ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07,\ud835\udc5b\ud835\udf0e%)\n!\n!\"#\nYou will roll 10 6-sided dice \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" !8\n\u2022 Let \ud835\udc4b = \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b , the total value of all 10 rolls.\n! \" !8\n\u2022 You win if \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45.\nTo the demo!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\n$\nDice game As \ud835\udc5b \u2192 \u221e: ,\ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07,\ud835\udc5b\ud835\udf0e%)\n!\n!\"#\nYou will roll 10 6-sided dice \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" !%\n\u2022 Let \ud835\udc4b = \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b , the total value of all 10 rolls.\n! \" !%\n\u2022 You win if \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45.\nAnd now the truth (according to the CLT)\u2026\n1. Define RVs and\n\ud835\udc38 \ud835\udc4b = 3.5, Want: \ud835\udc43 \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45\n\u2019\nstate goal. Var \ud835\udc4b = 35/12\nApproximate:\n\u2019 ?\n2. Solve.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\n$\nDice game As \ud835\udc5b \u2192 \u221e: ,\ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07,\ud835\udc5b\ud835\udf0e%)\n!\n!\"#\nYou will roll 10 6-sided dice \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" !%\n\u2022 Let \ud835\udc4b = \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b , the total value of all 10 rolls.\n! \" !%\n\u2022 You win if \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45.\nAnd now the truth (according to the CLT)\u2026\n1. Define RVs and\n\ud835\udc38 \ud835\udc4b = 3.5, Want: \ud835\udc43 \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45\n\u2019\nstate goal. Var \ud835\udc4b = 35/12\nApproximate:\n\u2019\n\ud835\udc4b \u2248 \ud835\udc4c~\ud835\udca9(10 3.5 , 10 35/12 )\n2. Solve.\n\ud835\udc43 \ud835\udc4c \u2264 25.5 + \ud835\udc43 \ud835\udc4c \u2265 44.5 or 1 \u2212 \ud835\udc43 25.5 \u2264 \ud835\udc4c \u2264 44.5\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\n$\nDice game As \ud835\udc5b \u2192 \u221e: ,\ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07,\ud835\udc5b\ud835\udf0e%)\n!\n!\"#\nYou will roll 10 6-sided dice \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" !%\n\u2022 Let \ud835\udc4b = \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b , the total value of all 10 rolls.\n! \" !%\n\u2022 You win if \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45.\nAnd now the truth (according to the CLT)\u2026\n1. Define RVs and\n\ud835\udc38 \ud835\udc4b = 3.5, Want: \ud835\udc43 \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45\n\u2019\nstate goal. Var \ud835\udc4b = 35/12\nApproximate:\n\u2019\n\ud835\udc4b \u2248 \ud835\udc4c~\ud835\udca9(10 3.5 , 10 35/12 )\n2. Solve.\n25.5 \u2212 35 44.5 \u2212 35\n\ud835\udc43 \ud835\udc4c \u2264 25.5 + \ud835\udc43 \ud835\udc4c \u2265 44.5 = \u03a6 + 1 \u2212 \u03a6\n10 35/12 10 35/12\n\u2248 \u03a6 \u22121.76 + 1 \u2212 \u03a6 1.76 \u2248 1 \u2212 0.9608 + 1 \u2212 0.9608 = 0.0786\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n$\nDice game As \ud835\udc5b \u2192 \u221e: ,\ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07,\ud835\udc5b\ud835\udf0e%)\n!\n!\"#\nYou will roll 10 6-sided dice \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b .\n! \" !8\n\u2022 Let \ud835\udc4b = \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b , the total value of all 10 rolls.\n! \" !8\n\u2022 You win if \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45.\nAnd now the truth (according to the CLT)\u2026 Check out\nthe code!\n(via CLT)\n0.08\n\u2248 \ud835\udc43 \ud835\udc4c \u2264 25.5 + \ud835\udc43 \ud835\udc4c \u2265 44.5\n0.06\n\u2248 0.0786\n0.04\n(exact, by computer)\n\ud835\udc43 \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45 = 0.0780\n0.02\n(sampling via computer)\n0\n10 20 30 40 50 60\n\ud835\udc43 \ud835\udc4b \u2264 25 or \ud835\udc4b \u2265 45 \u2248 0.0776\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\nSummary: Working with the CLT\n\"\nLet \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b iid, where \ud835\udc38 \ud835\udc4b = \ud835\udf07, Var \ud835\udc4b = \ud835\udf0e . As \ud835\udc5b \u2192 \u221e:\n! \" # $ $\n#\nK \ud835\udc4b ~\ud835\udca9(\ud835\udc5b\ud835\udf07, \ud835\udc5b\ud835\udf0e\" ) Sum of iid RVs\n$\n\u26a0\n$2!\nIf \ud835\udc4b is discrete:\n\u2019\n#\n\"\n1 \ud835\udf0e Use the continuity\nK \ud835\udc4b ~\ud835\udca9(\ud835\udf07, ) Average of iid RVs\n$ correction on \ud835\udc4c!\n\ud835\udc5b \ud835\udc5b\n(sample mean)\n$2!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nNext time\nCentral Limit Theorem:\nL \"\n\u2022 Sample mean \ud835\udc4b ~\ud835\udca9 \ud835\udf07, \ud835\udf0e /\ud835\udc5b\n\"\n\u2022 If we know \ud835\udf07 and \ud835\udf0e , we can compute probabilities on\nL\nsample mean \ud835\udc4b of a given sample size \ud835\udc5b\nIn real life:\n\u2022 Yes, the CLT still holds. It always holds!\n\"\n\u2022 But we often don\u2019t know \ud835\udf07 or \ud835\udf0e of our original distribution\n\u2022 However, we can collect data (a sample of size \ud835\udc5b)\n\"\n\u2022 How can we estimate the values \ud835\udf07 and \ud835\udf0e from our sample? And how\nreliable are those estimates?\n\u2026until next time!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31 <END>"}
{"prompt": "Lecture notes from cs109_lec20_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 20: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n3 / 3 pts\nQuestion 1\nQuestion 1: Key Definitions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nQuestion 2: Why Prefer LL over L? 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 3\nQuestion 3: Computer Failture Rates 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Question 1: Key Definitions\n1 Point\nWhat is the general definition of the likelihood L(\u03b8) if you have a sample of i.i.d.\nrandom variables X 1,X 2,\u2026,X n?\nn\nL(\u03b8) = \u220f f(X \u2223\u03b8)\ni=1 i\nn\nL(\u03b8) = \u2211 f(X \u2223\u03b8)\ni=1 i\nL(\u03b8) = f(X \u2223\u03b8)\ni\nQ2 Question 2: Why Prefer LL over L?\n1 Point\nWhen we maximize the likelihood function L(\u03b8), it's generally better maximize\nthe log of the likelihood function\u2014we call it LL(\u03b8)\u2014instead. Why do we\ngenerally work with LL(\u03b8)?\nNumerical stability.\nDerivatives of sums are easier to manipulate than derivatives of products.\nQ3 Question 3: Computer Failture Rates\n1 Point\nSuppose you observe the following durations\u2014recorded in minutes\u2014in between\nisolated computer failures at a datacenter:\n1.2,8.5,0.8,2.2,6.1,3.4,1.9,0.5,1.7,5.4,2.8,0.9,3.3,1.5,4.8\nAssume all durations are generated, and therefore nicely modeled by, an\nExponential distribution. What's \u03bb MLE? (Note that the 15 numbers in your\ndataset add up to 45.)\nHint: You can certainly maximize the relevant LL(\u03bb) by differentiating it, setting\nit to zero, and then solving for \u03bb. But it's easier to compute the average duration\nand assume that average is an unbiased estimate of the Exponential's true mean\nvalue. Enter your answer so that it's accurate to three decimal places.\n0.333 <END>"}
{"prompt": "Lecture notes from 21_beta_annotated.txt\n\n###\n\n", "completion": "21: Bayesian Statistics\nand Beta\nJerry Cain\nMay 17, 2024\nLecture Discussion on Ed\n1\nMLE:\nMultinomial\n2\nOkay, just one more MLE with the Multinomial\nConsider a sample of \ud835\udc5b iid random variables where:\n\u2022 Each element is drawn from one of \ud835\udc5a outcomes.\n$\n\ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , where \u2211 \ud835\udc5d = 1\n! !\"# !\n$\n\u2022 \ud835\udc4b = # of trials with outcome \ud835\udc56, where \u2211 \ud835\udc4b = \ud835\udc5b\n! !\"# !\nLet\u2019s give an\nexample!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nOkay, just one more MLE with the Multinomial\nConsider a sample of \ud835\udc5b iid random variables where:\n\u2022 Each element is drawn from one of \ud835\udc5a outcomes.\n$\n\ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , where \u2211 \ud835\udc5d = 1\n! !\"# !\n$\n\u2022 \ud835\udc4b = # of trials with outcome \ud835\udc56, where \u2211 \ud835\udc4b = \ud835\udc5b\n! !\"# !\n$\nExample: Suppose each RV is outcome of 6-sided die. \ud835\udc5a = 6, \u2019\ud835\udc5d = 1\n!\n!\"#\n\u2022 Roll the dice \ud835\udc5b = 12 times.\n\u2022 Observe data: 3 ones, 2 twos, 0 threes, 3 fours, 1 fives, 3 sixes\n\ud835\udc4b = 3, \ud835\udc4b = 2, \ud835\udc4b = 0,\n! \" #\nCheck: \ud835\udc4b + \ud835\udc4b + \u22ef + \ud835\udc4b = 12\n\ud835\udc4b = 3, \ud835\udc4b = 1, \ud835\udc4b = 3 ! \" &\n$ % &\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nOkay, just one more MLE with the Multinomial\nConsider a sample of \ud835\udc5b iid random variables where:\n\u2022 Each element is drawn from one of \ud835\udc5a outcomes.\n$\n\ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , where \u2211 \ud835\udc5d = 1\n! !\"# !\n$\n\u2022 \ud835\udc4b = # of trials with outcome \ud835\udc56, where \u2211 \ud835\udc4b = \ud835\udc5b\n! !\"# !\n1. What is the likelihood of observing\nthe sample \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b ,\n# % $\ngiven the probabilities \ud835\udc5d , \ud835\udc5d , \u2026 , \ud835\udc5d ?\n# % $\n\ud835\udc5b!\n& & &\nA. \ud835\udc5d !\ud835\udc5d \" \u22ef \ud835\udc5d #\n# % $\n\ud835\udc4b ! \ud835\udc4b ! \u22ef \ud835\udc4b !\n# % $\n& & &\nB. \ud835\udc5d !\ud835\udc5d \" \u22ef \ud835\udc5d #\n# % $\n\ud835\udc5b!\n\u2019 \u2019 \u2019\nC. \ud835\udc4b !\ud835\udc4b \" \u22ef \ud835\udc4b #\n# % $\n\ud835\udc4b ! \ud835\udc4b ! \u22ef \ud835\udc4b !\n# % $\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nOkay, just one more MLE with the Multinomial\nConsider a sample of \ud835\udc5b iid random variables where:\n\u2022 Each element is drawn from one of \ud835\udc5a outcomes.\n$\n\ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , where \u2211 \ud835\udc5d = 1\n! !\"# !\n$\n\u2022 \ud835\udc4b = # of trials with outcome \ud835\udc56, where \u2211 \ud835\udc4b = \ud835\udc5b\n! !\"# !\n1. What is the likelihood of observing\n\ud835\udc5b!\n& & &\nthe sample \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , \ud835\udc3f \ud835\udf03 = \ud835\udc5d !\ud835\udc5d \" \u22ef \ud835\udc5d #\n# % $\n# % $\n\ud835\udc4b ! \ud835\udc4b ! \u22ef \ud835\udc4b !\ngiven the probabilities \ud835\udc5d , \ud835\udc5d , \u2026 , \ud835\udc5d ? # % $\n# % $\n2. What is \ud835\udf03 ?\n+,-\n$ $\n$\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = log \ud835\udc5b! \u2212 5 log \ud835\udc4b ! + 5 \ud835\udc4b log \ud835\udc5d , such that \u2211 \ud835\udc5d = 1\n! ! ! !\"# !\n!\"# !\nOptimize with \ud835\udc4b Intuitively, probability\n.\nLagrange multipliers in \ud835\udf03 : \ud835\udc5d =\n+,- . \ud835\udc5d = proportion of outcomes\n\ud835\udc5b !\nextra slides\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nMLE for \ud835\udc4b\nWhen MLEs attack! \ud835\udc5d = !\nMultinomial: !\n\ud835\udc5b\nConsider a 6-sided die.\n\u2022 Roll the dice \ud835\udc5b = 12 times.\n\u2022 Observe: 3 ones, 2 twos, 0 threes, 3 fours, 1 fives, 3 sixes\nWhat is \ud835\udf03 ?\n+,-\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nMLE for \ud835\udc4b\nWhen MLEs attack! \ud835\udc5d = !\nMultinomial: !\n\ud835\udc5b\nConsider a 6-sided die.\n\u2022 Roll the dice \ud835\udc5b = 12 times.\n\u2022 Observe: 3 ones, 2 twos, 0 threes, 3 fours, 1 fives, 3 sixes\n\ud835\udf03 :\n+,-\n\u2022 MLE say you just never roll threes.\n\ud835\udc5d = 3/12\n!\n\u2022 Do you really believe that?\n\ud835\udc5d = 2/12\n\"\n\u26a0\n\ud835\udc5d = 0/12 But what if you can\u2019t roll any more\n#\n\ud835\udc5d = 3/12 Roll more!\ndice? More generally, what if you\n$\ncan\u2019t run enough experiments to\nprob = frequency\n\ud835\udc5d = 1/12\n%\nrealistically observe all possible\nin limit\n\ud835\udc5d = 3/12\n& Frequentist outcomes.\n\ud83d\ude31\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nBayesian\nStatistics\n9\nStarting Today!\nToday we are going to learn something unintuitive,\nbeautiful, and useful!\nWe are going to think of probabilities as\nrandom variables.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nA new definition of probability\nFlip a coin \ud835\udc5b + \ud835\udc5a times, produce \ud835\udc5b heads.\nWe don\u2019t know the probability \ud835\udf03 that the coin\ncomes up heads.\nThe world\u2019s first coin\nFrequentist\nBayesian\n\ud835\udf03 is a single value.\n\ud835\udf03 is a random variable.\n\ud835\udc5b \ud835\udc5b\n\ud835\udf03 = lim \u2248\n\ud835\udf03\u2019s continuous support: (0, 1)\n\ud835\udc5b + \ud835\udc5a \ud835\udc5b + \ud835\udc5a\n123\u21925\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nLet\u2019s play a game\nRoll 2 dice. If neither roll is a 6,\n6\nyou win (event \ud835\udc4a). Else, I win (event \ud835\udc4a ).\n\u2022 Before you play, what\u2019s the probability that you win?\n\u2022 Play once. What\u2019s the probability that you win?\n\u2022 Play three more times. What\u2019s the probability that you win?\n\"\n5\nI am constantly re-\n\ud835\udc43 \ud835\udc4a =\n6\nevaluating the situation\nFrequentist Bayesian\nBayesian statistics: Constantly update your prior beliefs.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nBayesian probability\nBayesian statistics: Probability represents our ever-\nevolving understanding of the world.\nMixing discrete and continuous random variables,\ncombined with Bayes\u2019 Theorem, allows us to reason about\nprobabilities as random variables.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nMixing discrete and continuous\nLet \ud835\udc4b be a continuous random variable, and\n\ud835\udc41 be a discrete random variable.\n\ud835\udc5d \ud835\udc5b|\ud835\udc65 \ud835\udc53 \ud835\udc65\nBayes\u2019\n9|7 7\n\ud835\udc53 \ud835\udc65|\ud835\udc5b =\n7|9\nTheorem: \ud835\udc5d \ud835\udc5b\n9\n\ud835\udc43 \ud835\udc41 = \ud835\udc5b|\ud835\udc4b = \ud835\udc65 \ud835\udc43 \ud835\udc4b = \ud835\udc65\nIntuition: \ud835\udc43 \ud835\udc4b = \ud835\udc65 \ud835\udc41 = \ud835\udc5b =\n\ud835\udc43 \ud835\udc41 = \ud835\udc5b\n\ud835\udc5d \ud835\udc5b|\ud835\udc65 \ud835\udc53 \ud835\udc65\n\ud835\udc43 \ud835\udc41 = \ud835\udc5b|\ud835\udc4b = \ud835\udc65 \ud835\udc53 \ud835\udc65 \ud835\udf00\n)|& &\n& &\n\ud835\udc53 \ud835\udc65|\ud835\udc5b \ud835\udf00 = \ud835\udc53 \ud835\udc65|\ud835\udc5b =\n&|) & \ud835\udc43 \ud835\udc41 = \ud835\udc5b &|) \ud835\udc5d \ud835\udc5b\n)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nBayes\u2019 Theorem: All Flavors\nLet \ud835\udc4b, \ud835\udc4c be continuousand \ud835\udc40, \ud835\udc41 be discrete random variables.\n: 1|3 : 3\n!|# #\nOriginal Bayes: \ud835\udc5d \ud835\udc5a|\ud835\udc5b =\n+|9\n: 1\n!\n: 1|; < ;\n!|$ $\nMix Bayes #1: \ud835\udc53 \ud835\udc65 \ud835\udc5b =\n7|9\n: 1\n!\n< ;|1 : 1\n$|! !\nMix Bayes #2: \ud835\udc5d \ud835\udc5b|\ud835\udc65 =\n9|7\n< ;\n$\n< >|; < ;\n%|$ $\nAll continuous: \ud835\udc53 \ud835\udc65 \ud835\udc66 =\n7|=\n< >\n%\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nMixing discrete and continuous\nLet \ud835\udf03 be a random variable for the probability your coin comes up heads,\nand \ud835\udc41 be the number of heads you observe in an experiment.\nlikelihood prior\nposterior\n\ud835\udc5d \ud835\udc5b|\ud835\udc65 \ud835\udc53 \ud835\udc65\n#|! !\n\ud835\udc53 \ud835\udc65|\ud835\udc5b =\n!|#\n\ud835\udc5d \ud835\udc5b\n#\nnormalization constant\n\u2022 Prior belief of parameter \ud835\udf03 \ud835\udc53 \ud835\udc65\n?\n\u2022 Likelihood of \ud835\udc41 = \ud835\udc5b heads, given parameter \ud835\udf03 = \ud835\udc65. \ud835\udc5d \ud835\udc5b|\ud835\udc65\n9|?\n\u2022 Posterior updated belief of parameter \ud835\udf03. \ud835\udc53 \ud835\udc65|\ud835\udc5b\n?|9\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nBeta RV\n17\nBeta random variable\ndef A Beta random variable \ud835\udc4b is defined as follows:\n1\n\ud835\udc4b~Beta(\ud835\udc4e, \ud835\udc4f) @A! BA!\nPDF \ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc4e > 0, \ud835\udc4f > 0\n#\nwhere \ud835\udc35 \ud835\udc4e,\ud835\udc4f = \u222b \ud835\udc65&\u2019# 1 \u2212 \ud835\udc65 (\u2019#\ud835\udc51\ud835\udc65, normalizing constant\n%\nSupport of \ud835\udc4b: 0, 1\n\ud835\udc4e \ud835\udc4e\ud835\udc4f\nExpectation \ud835\udc38 \ud835\udc4b = Variance V ar \ud835\udc4b =\n\ud835\udc4e + \ud835\udc4f \ud835\udc4e + \ud835\udc4f % \ud835\udc4e + \ud835\udc4f + 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nBeta RV with different \ud835\udc4e, \ud835\udc4f\n1\n\ud835\udc4b~Beta(\ud835\udc4e, \ud835\udc4f) @A! BA!\nPDF \ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc4e > 0, \ud835\udc4f > 0\n#\nwhere \ud835\udc35 \ud835\udc4e,\ud835\udc4f = \u222b \ud835\udc65&\u2019# 1 \u2212 \ud835\udc65 (\u2019#\ud835\udc51\ud835\udc65, normalizing constant\nSupport of \ud835\udc4b: 0, 1\n%\nSAT word: adumbrate\n5.0 3.0\nBeta(0.2,0.8) Beta(0.8. 0.2) Beta(1,1)=Uni 0,1\n4.0\n3.0\n2.0\nBeta(1,2)\n+ a third case\n2.0 Beta(1,1)\n1.0 (next slide)\n1.0 Beta(0.8,0.8)\nB e t a (\n2,1 )\n0.0 0.0\n0.0 0.2 0.4 0.6 0.8 1.0 0.0 0.2 0.4 0.6 0.8 1.0\nNote: PDF symmetric when \ud835\udc4e = \ud835\udc4f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nBeta RV with different \ud835\udc4e, \ud835\udc4f \ud835\udc4b~Beta(\ud835\udc4e,\ud835\udc4f)\nMatch PDF to distribution: 5.0\nBeta(0.2,0.8) Beta(0.8. 0.2)\n4.0\n4.0 B. Beta(2,8) C. Beta(8,2) 3.0\n2.0\nBeta(0.8,0.8)\n3.0 A. Beta(5,5) 1.0\n0.0\n2.0 0.0 0.2 0.4 0.6 0.8 1.0\n3.0\n1.0\n2.0\nBeta(1,2)\n0.0 Beta(1,1)\n1.0\n0.0 0.2 0.4 0.6 0.8 1.0 B e t a (\n2,1 )\n0.0\nA. Beta(5,5) 0.0 0.2 0.4 0.6 0.8 1.0\nB. Beta(2,8)\nIn CS109, we focus on Beta functions\nC. Beta(8,2) where \ud835\udc4e, \ud835\udc4f are both positive integers.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nBeta random variable\ndef A Beta random variable \ud835\udc4b is defined as follows:\n1\n\ud835\udc4b~Beta(\ud835\udc4e, \ud835\udc4f) @A! BA!\nPDF \ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc4e > 0, \ud835\udc4f > 0\n#\nwhere \ud835\udc35 \ud835\udc4e,\ud835\udc4f = \u222b \ud835\udc65&\u2019# 1 \u2212 \ud835\udc65 (\u2019#\ud835\udc51\ud835\udc65, normalizing constant\n%\nSupport of \ud835\udc4b: 0, 1\n\ud835\udc4e \ud835\udc4e\ud835\udc4f\nExpectation \ud835\udc38 \ud835\udc4b = Variance V ar \ud835\udc4b =\n\ud835\udc4e + \ud835\udc4f \ud835\udc4e + \ud835\udc4f % \ud835\udc4e + \ud835\udc4f + 1\nBeta can be a distribution of probabilities.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nBeta can be a distribution of probabilities. \ud835\udc4b~Beta(\ud835\udc4e,\ud835\udc4f)\n4.0 Beta(2,8) Beta(8,2)\nBeta parameters \ud835\udc4e, \ud835\udc4f are\n3.0\nBeta(5,5)\ndetermined by the outcome\n2.0\nof an experiment.\n1.0\nBut which experiment?\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nFlipping a coin\nwith unknown\nprobability\n23\nFlip a coin with unknown probability\nFlip a coin \ud835\udc5b + \ud835\udc5a times, observe \ud835\udc5b heads.\n\u2022 Before our experiment, \ud835\udf03 (the probability that the coin\ncomes up heads) is equally like to be any probability in (0, 1).\n\u2022 Let \ud835\udc41 = number of heads.\n\u2022 Given \ud835\udf03 = \ud835\udc65, coin flips are independent.\nWhat is our updated belief of \ud835\udf03 after we observe \ud835\udc41 = \ud835\udc5b?\nWhat are reasonable distributions of the following?\n1. \ud835\udf03 Bayesian prior \ud835\udf03~Uni 0,1\n2. \ud835\udc41|\ud835\udf03 = \ud835\udc65 Likelihood \ud835\udc41|\ud835\udf03 = \ud835\udc65~Bin(\ud835\udc5b + \ud835\udc5a, \ud835\udc65)\n3. \ud835\udf03|\ud835\udc41 = \ud835\udc5b\nBayesian posterior. Use Bayes\u2019!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nFlip a coin with unknown probability\nFlip a coin \ud835\udc5b + \ud835\udc5a times, observe \ud835\udc5b heads.\nPrior:\n\u2022 Before our experiment, \ud835\udf03 (the probability that the coin\n\ud835\udf03~Uni 0,1\ncomes up heads) is equally like to be any probability in (0, 1).\n\u2022 Let \ud835\udc41 = number of heads. Likelihood:\n\u2022 Given \ud835\udf03 = \ud835\udc65, coin flips are independent. \ud835\udc41|\ud835\udf03 = \ud835\udc65~Bin(\ud835\udc5b + \ud835\udc5a, \ud835\udc65)\nWhat is our updated belief of \ud835\udf03 after we observe \ud835\udc41 = \ud835\udc5b?\nPosterior: \ud835\udc53 \ud835\udf03 \ud835\udc5b\n*|)\n\ud835\udc5b + \ud835\udc5a\n\ud835\udc5d \ud835\udc5b|\ud835\udc65 \ud835\udc53 \ud835\udc65\n9|? ? \ud835\udc65+ 1 \u2212 \ud835\udc65 $ \u22c5 1\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc5b\n?|9 =\n\ud835\udc5d \ud835\udc5b\n9 \ud835\udc5d \ud835\udc5b\n)\n\ud835\udc5b + \ud835\udc5a\n#\n\ud835\udc5b 1\n+ $\n= \ud835\udc65 1 \u2212 \ud835\udc65 = \ud835\udc65+ 1 \u2212 \ud835\udc65 $ , where \ud835\udc50 = F \ud835\udc65+ 1 \u2212 \ud835\udc65 $ \ud835\udc51\ud835\udc65\n\ud835\udc5d \ud835\udc5b\n) \ud835\udc50\n-\nconstant with respect to \ud835\udc65,\ndoesn\u2019t depend onLis a\ud835\udc65 Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nLet\u2019s try it out\n4.0\n1. Start with a \ud835\udf03~Uni 0,1 over\n3.0\nprobability that a coin lands heads.\n2.0\n1.0\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\n2. Flip a coin 8 times. Observe \ud835\udc5b = 7\nheads and \ud835\udc5a = 1 tail\n3. What is our posterior belief of the\nprobability \ud835\udf03?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\n\"\n!\n!\nPPrriioorr bbeelliieeff, ,\ud835\udf03 #\n\"\ntail\n\ud83d\udc47\n1\nN !\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65 1 \u2212 \ud835\udc65\n?|9\n\ud835\udc50\n\ud835\udc50 normalizes to valid PDF\nWait a minute! #looksbetalike\nBeta RV with different \ud835\udc4e, \ud835\udc4f\n1\n\ud835\udc4b~Beta(\ud835\udc4e, \ud835\udc4f) @A! BA!\nPDF \ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc4e > 0, \ud835\udc4f > 0\n#\nwhere \ud835\udc35 \ud835\udc4e,\ud835\udc4f = \u222b \ud835\udc65&\u2019# 1 \u2212 \ud835\udc65 (\u2019#\ud835\udc51\ud835\udc65, normalizing constant\nSupport of \ud835\udc4b: 0, 1\n%\n1\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65N 1 \u2212 \ud835\udc65 ! is the PDF for Beta(8, 2)!\n\ud83c\udf1f\n?|9\n\ud835\udc50\n\ud835\udc50 normalizes to valid PDF\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nLet\u2019s try it out\n4.0\n1. Start with a \ud835\udf03~Uni 0,1 over\n3.0\nprobability that a coin lands heads.\n2.0\n1.0\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\n2. Flip a coin 8 times. Observe \ud835\udc5b = 7\nheads and \ud835\udc5a = 1 tail\n1\n3. What is our posterior belief of the N !\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65 1 \u2212 \ud835\udc65\n?|9\n\ud835\udc50\nprobability \ud835\udf03?\n\ud835\udc50 normalizes to valid PDF\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 28\n\"\n!\n!\nPPrriioorr bbeelliieeff, ,\ud835\udf03 #\n\"\ntail\n\ud83d\udc47\nBeta 8,2\n3. What is our posterior belief of the probability \ud835\udf03?\n\u2022 Start with a \ud835\udf03~Uni 0,1 over probability\n\u2022 Observe \ud835\udc5b = 7 successes and \ud835\udc5a = 1 failures\n\u2022 Your new belief about the probability of \ud835\udf03 is:\n!\n1\nN ! N !\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65 1 \u2212 \ud835\udc65 , where \ud835\udc50 = K \ud835\udc65 1 \u2212 \ud835\udc65 \ud835\udc51\ud835\udc65\n?|9\n\ud835\udc50\nP\n4.0\n3.0\n2.0\n1.0\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n\ud835\udc5b|\ud835\udc65\n\ud835\udc53\n)|*\nPosterior belief, \ud835\udf03|\ud835\udc41\nPosterior belief, \ud835\udf03|\ud835\udc41:\nBeta(\ud835\udc4e = 8, \ud835\udc4f = 2)\n1\nQA! \"A!\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65 1 \u2212 \ud835\udc65\n?|9\n\ud835\udc50\nBeta(\ud835\udc4e = \ud835\udc5b + 1, \ud835\udc4f = \ud835\udc5a + 1)\n\ud835\udc65\nCS109 focus: Beta where \ud835\udc4e, \ud835\udc4f both positive integers\n\ud835\udc4b~Beta(\ud835\udc4e,\ud835\udc4f)\nBeta parameters \ud835\udc4e, \ud835\udc4f are\n4.0 Beta(2,8) Beta(8,2)\ndetermined by the outcome\n3.0\nBeta(5,5)\nof an experiment.\n2.0\n1.0 \ud835\udc4e = \u201csuccesses\u201d + 1\n\ud835\udc4f = \u201cfailures\u201d + 1\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\n\u2022 Beta can model the randomness of the probability\nof experiment success.\n\u2022 Beta parameters depend on our data and our prior.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nConjugate\ndistributions\n31\nA note about our prior\n4.0\n1. Start with a \ud835\udf03~Uni 0,1 over\n3.0\nprobability that a coin lands heads.\n2.0\n1.0\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\n2. Flip a coin 8 times. Observe \ud835\udc5b = 7\nheads and \ud835\udc5a = 1 tail\n3. What is our posterior belief of the\nprobability \ud835\udf03?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\n\"\n!\n!\nPPrriioorr bbeelliieeff, ,\ud835\udf03 #\n\"\nokay\n1\nN !\n\ud835\udc53 \ud835\udc65 \ud835\udc5b = \ud835\udc65 1 \u2212 \ud835\udc65\n?|9\n\ud835\udc50\n\ud835\udc50 normalizes to valid PDF\nBeta 8,2\nWait another minute!\nBeta RV with different \ud835\udc4e, \ud835\udc4f Review\n1\n\ud835\udc4b~Beta(\ud835\udc4e, \ud835\udc4f) @A! BA!\nPDF \ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc4e > 0, \ud835\udc4f > 0\n#\nwhere \ud835\udc35 \ud835\udc4e,\ud835\udc4f = \u222b \ud835\udc65&\u2019# 1 \u2212 \ud835\udc65 (\u2019#\ud835\udc51\ud835\udc65, normalizing constant\nSupport of \ud835\udc4b: 0, 1\n%\n3.0 Beta(1,1)=Uni 0,1\n2.0\nBeta(1,2)\nBeta(1,1)\n1.0\nB e t a (\n2,1 )\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\nNote: PDF symmetric when \ud835\udc4e = \ud835\udc4f\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nA note about our prior\n4.0\n1. Start with a \ud835\udf03~Uni 0,1 over\n3.0\nprobability that a coin lands heads.\n2.0\n1.0\n0.0\n0.0 0.2 0.4 0.6 0.8 1.0\n2. Flip a coin 8 times. Observe \ud835\udc5b = 7\nheads and \ud835\udc5a = 1 tail\n3. What is our posterior belief of the\nprobability \ud835\udf03?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 34\n\"\n!\n!\nPPrriioorr bbeelliieeff, ,\ud835\udf03 #\nBeta 1,1\n\"\nCheck this out. Beta \ud835\udc4e = 1, \ud835\udc4f = 1 :\n1\n./# 0/#\n\ud835\udc53 \ud835\udc65 = \ud835\udc65 1 \u2212 \ud835\udc65\n\ud835\udc35 \ud835\udc4e, \ud835\udc4f\n1\n=\n#\n\u222b 1\ud835\udc51\ud835\udc65\n-\nBeta 8,2\n= 1 where 0 < \ud835\udc65 < 1\nBeta is a conjugate distribution for Bernoulli\nBeta is a conjugate distribution for Bernoulli, meaning:\n\u2022 Prior and posterior parametric forms are the same\n(proof on next slide)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nBeta is a conjugate distribution for Bernoulli\nBeta is a conjugate distribution for Bernoulli, meaning:\n1. If our prior belief of the parameter is Beta, and\n2. Our experiment is Bernoulli, then\n(observe \ud835\udc5b successes, \ud835\udc5a failures)\n3. Our posterior is also Beta.\nProof: \ud835\udf03~Beta(\ud835\udc4e, \ud835\udc4f) \ud835\udc41|\ud835\udf03~Bin(\ud835\udc5b + \ud835\udc5a, \ud835\udc65)\n\ud835\udc5b + \ud835\udc5a 1\n+ $ ./# 0/#\n\ud835\udc5d \ud835\udc5b|\ud835\udc65 \ud835\udc53 \ud835\udc65 \ud835\udc65 1 \u2212 \ud835\udc65 \u22c5 \ud835\udc65 1 \u2212 \ud835\udc65\n9|? ? \ud835\udc5a \ud835\udc35 \ud835\udc4e, \ud835\udc4f\n\ud835\udc53 \ud835\udc65 \ud835\udc5b =\n=\n?|9\n\ud835\udc5d \ud835\udc5b \ud835\udc5d \ud835\udc5b\n9 )\nconstants that 1 3 @A! BA!\n= \ud835\udc36 \u22c5 \ud835\udc65 1 \u2212 \ud835\udc65 \u22c5 \ud835\udc65 1 \u2212 \ud835\udc65\ndon\u2019t depend on \ud835\udc65\n12@A! 32BA!\n= \ud835\udc36 \u22c5 \ud835\udc65 1 \u2212 \ud835\udc65 \u2705\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nBeta is a conjugate distribution for Bernoulli This is the main\ntakeaway of Beta.\nBeta is a conjugate distribution for Bernoulli, meaning:\n\u2022 Prior and posterior parametric forms are the same\n\u2022 Practically, conjugate means easy update:\nAdd number of \u201cheads\u201d and \u201ctails\u201d seen to Beta parameters.\nYou can invent a prior to express how biased you believe the coin is a\npriori:\n\u2022 \ud835\udf03~Beta(\ud835\udc4e, \ud835\udc4f): pretend you\u2019ve conducted \ud835\udc4e + \ud835\udc4f \u2212 2 imaginary trials, where\n\ud835\udc4e \u2212 1 trials produced a head and \ud835\udc4f \u2212 1 produced a tail\n\u2022 Choosing Beta 1, 1 = Uni(0, 1) means you don\u2019t hold any prior beliefs\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1, \ud835\udc4f = \ud835\udc5a + 1)\n!$.1 !$.1\nExperiment Observe \ud835\udc5b successes and \ud835\udc5a failures\nPosterior Beta \ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1, \ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1\n!$.1 !$.1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 37\nMedicinal Beta\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"?\nFrequentist Bayesian\nLet \ud835\udc5d be the probability\nyour drug works.\n14\n\ud835\udc5d \u2248 = 0.7\nA frequentist view will not incorporate\n20\nprior/expert belief about probability.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nMedicinal Beta\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"?\nFrequentist Bayesian\nLet \ud835\udc5d be the probability Let \ud835\udf03 be the probability\nyour drug works. your drug works.\n14 \ud835\udf03 is a random variable.\n\ud835\udc5d \u2248 = 0.7\n20\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 39\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + 1)\n!)&* !)&*\nMedicinal Beta\nPosterior Beta(\ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1)\n!)&* !)&*\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"? (Bayesian interpretation)\nWhat is the prior distribution of \ud835\udf03?\n(select all that apply)\nA. \ud835\udf03~Beta 1, 1 = Uni 0, 1\nB. \ud835\udf03~Beta 81, 101\nC. \ud835\udf03~Beta 80, 20\nD. \ud835\udf03~Beta 81, 21\nE. \ud835\udf03~Beta 5, 2\n\ud83e\udd14\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + 1)\n!)&* !)&*\nMedicinal Beta\nPosterior Beta(\ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1)\n!)&* !)&*\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"? (Bayesian interpretation)\nWhat is the prior distribution of \ud835\udf03?\n(select all that apply)\nA. \ud835\udf03~Beta 1, 1 = Uni 0, 1\nB. \ud835\udf03~Beta 81, 101\nC. \ud835\udf03~Beta 80, 20\nD. \ud835\udf03~Beta 81, 21 Interpretation: 80 successes / 100 imaginary trials\nE. \ud835\udf03~Beta 5, 2\n(you can choose either based on how strongly you believe in prior data.\nWe choose E on next slide)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + 1)\n!)&* !)&*\nMedicinal Beta\nPosterior Beta(\ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1)\n!)&* !)&*\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"? (Bayesian interpretation)\nPrior: \ud835\udf03~Beta \ud835\udc4e = 5, \ud835\udc4f = 2 5.0\n4.0\nPosterior: \ud835\udf03~Beta \ud835\udc4e = 5 + 14, \ud835\udc4f = 2 + 6 Posterior\n3.0\n~Beta \ud835\udc4e = 19, \ud835\udc4f = 8\n2.0\n1.0\nP\nrio r\n0.0\n\ud835\udc65\n0.0 0.2 0.4 0.6 0.8 1.0\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 42\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + 1)\n!)&* !)&*\nMedicinal Beta\nPosterior Beta(\ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1)\n!)&* !)&*\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"? (Bayesian interpretation)\nmode\nPrior: \ud835\udf03~Beta \ud835\udc4e = 5, \ud835\udc4f = 2 5.0\n4.0\nPosterior: \ud835\udf03~Beta \ud835\udc4e = 5 + 14, \ud835\udc4f = 2 + 6 Posterior\n3.0\n~Beta \ud835\udc4e = 19, \ud835\udc4f = 8\n2.0\nWhat do you report to pharmacists?\n1.0\nP\nrio r\n0.0\n\ud835\udc65\nA. Expectation of posterior\n0.0 0.2 0.4 0.6 0.8 1.0\nB. Mode of posterior\nC. Distribution of posterior\n\ud83e\udd14\nD. Nothing\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 43\nPrior Beta(\ud835\udc4e = \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + 1)\n!)&* !)&*\nMedicinal Beta\nPosterior Beta(\ud835\udc4e = \ud835\udc5b + \ud835\udc5b + 1,\ud835\udc4f = \ud835\udc5a + \ud835\udc5a + 1)\n!)&* !)&*\n\u2022 Before being tested, a medicine is believed to \"work\" 80% of the time.\n\u2022 The medicine is administered to 20 patients.\n\u2022 It \"works\" for 14, \"doesn\u2019t work\" for 6.\nWhat is your new belief that the drug \"works\"? (Bayesian interpretation)\nmode\nPrior: \ud835\udf03~Beta \ud835\udc4e = 5, \ud835\udc4f = 2 5.0\n4.0\nPosterior: \ud835\udf03~Beta \ud835\udc4e = 5 + 14, \ud835\udc4f = 2 + 6 Posterior\n3.0\n~Beta \ud835\udc4e = 19, \ud835\udc4f = 8\n2.0\nWhat do you report to pharmacists?\n1.0\nP\nrio r\n0.0\n\ud835\udc65\n\ud835\udc4e 19 0.0 0.2 0.4 0.6 0.8 1.0\n\ud835\udc38 \ud835\udf03 = = \u2248 0.70\n\ud835\udc4e + \ud835\udc4f 19 + 8\nIn CS109, we report the mode: The\n\ud835\udc4e \u2212 1 18\nmode \ud835\udf03 = = \u2248 0.72\n\"most likely\" parameter given the data.\n\ud835\udc4e + \ud835\udc4f \u2212 2 18 + 7\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 44\nFood for thought\n\ud83d\udc49 In this lecture: If nothing is known about the parameter \ud835\udc5d,\nBayesian statisticians will:\n\u2022 Treat the parameter as a random variable \ud835\udf03\n\ud835\udc4b~Ber \ud835\udc5d with a Beta prior distribution\n\u2022 Conduct experiments\n\u2022 Based on the outcomes of those experiments,\nupdate the posterior distribution of \ud835\udf03\nFood for thought:\nAny parameter for a \u201cparameterized\u201d\n!\n\ud835\udc4c~\ud835\udca9 \ud835\udf07, \ud835\udf0e\nrandom variable can be thought of as\na random variable.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 45\nEstimating our parameter directly\n(our focus so far)\nMaximum What is the parameter \ud835\udf03 \ud835\udc3f \ud835\udf03 = \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03\n# % +\n+\nthat maximizes the\nLikelihood\n= T\ud835\udc53 \ud835\udc4b |\ud835\udf03\nlikelihood !\nEstimator\n!\"#\nof our observed data\n(MLE) \ud835\udf03 = arg max \ud835\udc53 \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b |\ud835\udf03\n\ud835\udc65 , \ud835\udc65 , \u2026 , \ud835\udc65 ? 234 # % +\n# % + *\nlikelihood of data\nObservations:\n\u2022 MLE maximizes probability of observing data\ngiven a parameter \ud835\udf03. It\u2019s fitting the curve to match the data.\n\u2022 If we are estimating \ud835\udf03, shouldn\u2019t we maximize\nthe probability of \ud835\udf03 directly? SAT word: adumbrate\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 46\nExtra: MLE:\nMultinomial\nderivation\n47\nOkay, just one more MLE with the Multinomial\nConsider a sample of \ud835\udc5b i.i.d. random variables where\n\u2022 Each element is drawn from one of \ud835\udc5a outcomes.\n$\n\ud835\udc43 outcome \ud835\udc56 = \ud835\udc5d , where \u2211 \ud835\udc5d = 1\n! !\"# !\n$\n\u2022 \ud835\udc4b = # of trials with outcome \ud835\udc56, where \u2211 \ud835\udc4b = \ud835\udc5b\n! !\"# !\n1. What is the likelihood of observing\n\ud835\udc5b!\n& & &\nthe sample \ud835\udc4b , \ud835\udc4b , \u2026 , \ud835\udc4b , \ud835\udc3f \ud835\udf03 = \ud835\udc5d !\ud835\udc5d \" \u22ef \ud835\udc5d #\n# % $\n# % $\n\ud835\udc4b ! \ud835\udc4b ! \u22ef \ud835\udc4b !\ngiven the probabilities \ud835\udc5d , \ud835\udc5d , \u2026 , \ud835\udc5d ? # % $\n# % $\n2. What is \ud835\udf03 ?\n+,-\n$ $\n$\n\ud835\udc3f\ud835\udc3f \ud835\udf03 = log \ud835\udc5b! \u2212 5 log \ud835\udc4b ! + 5 \ud835\udc4b log \ud835\udc5d , such that \u2211 \ud835\udc5d = 1\n! ! ! !\"# !\n!\"# !\"#\n\ud835\udc4b Intuitively, probability\n.\n\ud835\udf03 : \ud835\udc5d =\n+,- . \ud835\udc5d = proportion of outcomes\n\ud835\udc5b !\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 48\nOptimizing MLE for Multinomial\n\ud835\udf03 = \ud835\udc5d , \ud835\udc5d , \u2026 , \ud835\udc5d\n! \" 3\n$\nUse Lagrange multipliers\n\ud835\udf03 = arg max \ud835\udc3f\ud835\udc3f \ud835\udf03\n, where 5 \ud835\udc5d = 1\n+,- !\nto account for constraint\n?\n!\"#\n$ $ $ (drop\nLagrange\n\ud835\udc34 \ud835\udf03 = \ud835\udc3f\ud835\udc3f \ud835\udf03 + \ud835\udf06 5 \ud835\udc5d \u2212 1 = 5 \ud835\udc4b log \ud835\udc5d + \ud835\udf06 5 \ud835\udc5d \u2212 1 non-\ud835\udc5d\nmultipliers: ! ! ! ! !\nterms)\n!\"# !\"# !\"#\n\ud835\udf15\ud835\udc34 \ud835\udf03 1\nDifferentiate w.r.t. \ud835\udc4b\n= \ud835\udc4b + \ud835\udf06 = 0 !\n\u21d2 \ud835\udc5d = \u2212\n!\neach \ud835\udc5d , in turn: \ud835\udf15\ud835\udc5d \ud835\udc5d !\n\ud835\udf06\n! ! !\n$ $\nSolve for \ud835\udf06, noting \ud835\udc5b\n\ud835\udc4b\n! \u21d2 1 = \u2212 \u21d2 \ud835\udf06 = \u2212\ud835\udc5b\n$ $ 5 \ud835\udc5d = 5 \u2212 = 1\n! \ud835\udf06\n\ud835\udf06\n5\ud835\udc4b = \ud835\udc5b,5\ud835\udc5d = 1:\n! !\n!\"# !\"#\n!\"# !\"#\n\ud835\udc4b\nSubstitute \ud835\udf06 into \ud835\udc5d !\n! \ud835\udc5d =\n!\n\ud835\udc5b\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 49 <END>"}
{"prompt": "Lecture notes from cs109_lec19_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 19: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n5 / 5 pts\nQuestion 1\nMeans and Sampling 2 / 2 pts\n1.1 Definitions 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.2 Randomness 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQuestion 2\nCentral Limit Theorem 2 / 2 pts\n\uf00c + 2 pts Correct\n+ 0 pts Incorrect\nQuestion 3\nBootstrapping 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Means and Sampling\n2 Points\nX\u02c9 and \u03bc are both terms that come up in sampling and statistics.\nQ1.1 Definitions\n1 Point\nWhich of the following statements correctly define X\u02c9 and \u03bc in the context of\nsampling from a distribution in statistics?\nThey are different notations for the same quantity (the population mean)\nThey are different notations for the same quantity (the sample mean)\n\u03bc is the population mean and X\u02c9 is the sample mean\n\u03bc is the sample mean and X\u02c9 is the population mean\nQ1.2 Randomness\n1 Point\nSampling implicitly introduces randomness when drawing from a distribution.\nHow do we describe the randomness of X\u02c9 and \u03bc?\nOnly\nX\u02c9\nis a random variable\nOnly \u03bc is a random variable\nBoth quantities are random variables\nQ2 Central Limit Theorem\n2 Points\nThe Central Limit Theorem (CLT) is one of the most important results in\nprobability, statistics, and data analysis, and it greatly informs why sampling and\nbootstrapping are valid data analysis techniques. Relying on what you learned\nabout the Central Limit Theorem last lecture and what you learned about\nsampling during today's lecture, select all of the statements below that are true.\nVar(X\u02c9\n), the variance of the sample mean, is inversely proportional to\nthe size of the sample\nVar(X\u02c9\n), the variance of the sample mean, grows linearly with the size of\nthe sample\nX\u02c9\n, the sample mean, grows linearly with the size of the sample\nThe population mean \u03bc drawn, from any type of distribution is\ndistributed, normally\nX\u02c9\n, the mean of a sample drawn iid. from any type of distribution, is\ndistributed normally\n\u2211\ni\nX i, the sum of a sample drawn iid. from any type of distribution, is\ndistributed normally\nQ3 Bootstrapping\n1 Point\nBootstrapping relies on the following intuition:\nYour population distribution can be approximated as a Gaussian\nYour sample distribution is Gaussian\nYour sample distribution approximates your population distribution. <END>"}
{"prompt": "Lecture notes from 05_independence_annotated.txt\n\n###\n\n", "completion": "05: Independence\nJerry Cain\nApril 10th, 2024\nLecture Discussion on Ed\n1\nIndependence I\n2\nIndependence\nTwo events \ud835\udc38 and \ud835\udc39 are defined as independent if:\n\ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nOtherwise \ud835\udc38 and \ud835\udc39 are called dependent events.\nIf \ud835\udc38 and \ud835\udc39 are independent, then:\n\ud835\udc43 \ud835\udc38 \ud835\udc39 = \ud835\udc43(\ud835\udc38)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\nIndependent\nIntuition through proof \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nevents \ud835\udc38 and \ud835\udc39\nStatement:\nIf \ud835\udc38 and \ud835\udc39 are independent, then \ud835\udc43 \ud835\udc38 \ud835\udc39 = \ud835\udc43 \ud835\udc38 .\nProof:\n\ud835\udc43 \ud835\udc38\ud835\udc39\nDefinition of\n\ud835\udc43 \ud835\udc38 \ud835\udc39 =\n\ud835\udc43(\ud835\udc39)\nconditional probability\n\ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39\nIndependence of \ud835\udc38 and \ud835\udc39\n=\n\ud835\udc43(\ud835\udc39)\n= \ud835\udc43(\ud835\udc38 ) Taking the bus to cancellation city\nKnowing that \ud835\udc39 happened does not\nchange our belief that \ud835\udc38 happened.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\nIndependent \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nDice, our misunderstood friends\nevents \ud835\udc38 and \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 = \ud835\udc43(\ud835\udc38)\n\u2022 Roll two 6-sided dice, yielding values \ud835\udc37 and \ud835\udc37 .\n# $\n\u2022 Let event \ud835\udc38: \ud835\udc37 = 1\n#\nevent \ud835\udc39: \ud835\udc37 = 6\n$\nevent \ud835\udc3a: \ud835\udc37 + \ud835\udc37 = 5\n# $ \ud835\udc3a = { 1,4 , 2,3 , 3,2 , 4,1 }\n1. Are \ud835\udc38 and \ud835\udc39 independent? 2. Are \ud835\udc38 and \ud835\udc3a independent?\n\ud835\udc43 \ud835\udc38 = 1/6 \ud835\udc43 \ud835\udc38 = 1/6\n\ud835\udc43 \ud835\udc39 = 1/6 \ud835\udc43 \ud835\udc3a = 4/36 = 1/9\n\ud835\udc43 \ud835\udc38\ud835\udc39 = 1/36 \ud835\udc43 \ud835\udc38\ud835\udc3a = 1/36 \u2260 \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc3a)\n\u2705 independent \u274c dependent\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nGeneralizing independence\n\ud835\udc43 \ud835\udc38\ud835\udc39\ud835\udc3a = \ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc3a , and\nThree events \ud835\udc38, \ud835\udc39, and \ud835\udc3a\n\ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39), and\nare independent if:\n\ud835\udc43 \ud835\udc38\ud835\udc3a = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc3a), and\n\ud835\udc43 \ud835\udc39\ud835\udc3a = \ud835\udc43 \ud835\udc39 \ud835\udc43(\ud835\udc3a)\nfor \ud835\udc5f = 1, \u2026 , \ud835\udc5b:\n\ud835\udc5b events \ud835\udc38 , \ud835\udc38 , \u2026 , \ud835\udc38 are\n# $ % for every subset \ud835\udc38 , \ud835\udc38 , \u2026 , \ud835\udc38 :\n( ) *\nindependent if:\n\ud835\udc43 \ud835\udc38 \ud835\udc38 \u2026 \ud835\udc38 = \ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc38 \u22ef \ud835\udc43 \ud835\udc38\n( ) * ( ) *\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\nDice, increasingly misunderstood (still our friends)\n\u2022 Each roll of a 6-sided die is an independent trial.\n\u2022 Two rolls: \ud835\udc37 and \ud835\udc37 .\n# $\n\u2022 Let event \ud835\udc38: \ud835\udc37 = 1\n#\nevent \ud835\udc39: \ud835\udc37 = 6\n$\nevent \ud835\udc3a: \ud835\udc37 + \ud835\udc37 = 7 \ud835\udc3a = { 1,6 , 2,5 , 3,4 , 4,3 , 5,2 , 6,1 }\n# $\n1. Are \ud835\udc38 and \ud835\udc39 2. Are \ud835\udc38 and \ud835\udc3a 3. Are \ud835\udc39 and \ud835\udc3a 4. Are \ud835\udc38, \ud835\udc39, \ud835\udc3a\nindependent? independent? independent? independent?\n\u2705\n\ud835\udc43 \ud835\udc38\ud835\udc39 = 1/36\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\nDice, increasingly misunderstood (still our friends)\n\u2022 Each roll of a 6-sided die is an independent trial.\n\u2022 Two rolls: \ud835\udc37 and \ud835\udc37 .\n# $\n\u2022 Let event \ud835\udc38: \ud835\udc37 = 1\n#\nevent \ud835\udc39: \ud835\udc37 = 6\n$\nevent \ud835\udc3a: \ud835\udc37 + \ud835\udc37 = 7 \ud835\udc3a = { 1,6 , 2,5 , 3,4 , 4,3 , 5,2 , 6,1 }\n# $\n1. Are \ud835\udc38 and \ud835\udc39 2. Are \ud835\udc38 and \ud835\udc3a 3. Are \ud835\udc39 and \ud835\udc3a 4. Are \ud835\udc38, \ud835\udc39, \ud835\udc3a\nindependent? independent? independent? independent?\n\u2705 \u2705 \u2705 \u274c\n\ud835\udc43 \ud835\udc38\ud835\udc39 = 1/36\nPairwise independence is not sufficient to prove independence of 3 or more events!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\nIndependence II\n9\nIndependent trials\nWe often are interested in experiments consisting of \ud835\udc5b independent trials.\n\u2022 \ud835\udc5b trials, each with the same set of possible outcomes\n\u2022 \ud835\udc5b-way independence: an event in one subset of trials is independent of\nevents in other subsets of trials\nExamples:\n\u2022 Flip a coin \ud835\udc5b times\n\u2022 Roll a die \ud835\udc5b times\n\u2022 Send a multiple-choice survey to \ud835\udc5b people\n\u2022 Send \ud835\udc5b web requests to \ud835\udc58 different servers\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 10\nNetwork reliability\nConsider the following parallel network: \ud835\udc5d\n(\n\u2022 \ud835\udc5b independent routers, each with \ud835\udc5d\n)\nprobability \ud835\udc5d of functioning (where 1 \u2264 \ud835\udc56 \u2264 \ud835\udc5b)\n+\n\u2022 \ud835\udc38 = functional path from A to B exists.\n\ud835\udc5d\n,\nWhat is \ud835\udc43 \ud835\udc38 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\n\u2026\n\ud835\udc34 \ud835\udc35\nNetwork reliability\nConsider the following parallel network: \ud835\udc5d\n(\n\u2022 \ud835\udc5b independent routers, each with \ud835\udc5d\n)\nprobability \ud835\udc5d of functioning (where 1 \u2264 \ud835\udc56 \u2264 \ud835\udc5b)\n+\n\u2022 \ud835\udc38 = functional path from A to B exists.\n\ud835\udc5d\n,\nWhat is \ud835\udc43 \ud835\udc38 ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\n\u2026\n\ud835\udc34 \ud835\udc35\n\ud835\udc43 \ud835\udc38 = \ud835\udc43 \u2265 1 one router works\n= 1 \u2212 \ud835\udc43 all routers fail\n= 1 \u2212 1 \u2212 \ud835\udc5d 1 \u2212 \ud835\udc5d \u22ef 1 \u2212 \ud835\udc5d\n# $ %\n%\n= 1 \u2212 @ 1 \u2212 \ud835\udc5d \u2265 1 with independent trials:\n&\ntake complement\n&\u2019#\nExercises\n13\nIndependent \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nIndependence?\nevents \ud835\udc38 and \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 = \ud835\udc43(\ud835\udc38)\n1. True or False? Two events \ud835\udc38 and \ud835\udc39 are independent if:\nA. Knowing that \ud835\udc39 happens means that \ud835\udc38 can\u2019t happen.\nB. Knowing that \ud835\udc39 happens doesn\u2019t change probability that \ud835\udc38 happened.\n2. Are \ud835\udc38 and \ud835\udc39 independent in the following pictures?\nA. B.\nE\nE\n1/4 2/9 4/9\n1/4\nF\nS F 1/9 S\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nIndependent \ud835\udc43 \ud835\udc38\ud835\udc39 = \ud835\udc43 \ud835\udc38 \ud835\udc43(\ud835\udc39)\nIndependence?\nevents \ud835\udc38 and \ud835\udc39 \ud835\udc43 \ud835\udc38|\ud835\udc39 = \ud835\udc43(\ud835\udc38)\n1. True or False? Two events \ud835\udc38 and \ud835\udc39 are independent if:\nA. Knowing that \ud835\udc39 happens means that \ud835\udc38 can\u2019t happen.\nB. Knowing that \ud835\udc39 happens doesn\u2019t change probability that \ud835\udc38 happened.\n2. Are \ud835\udc38 and \ud835\udc39 independent in the following pictures?\nA. B.\nE\nE\n1/4 2/9 4/9\n1/4\nF\nS F 1/9 S\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\nCoin Flips\nSuppose we flip a coin \ud835\udc5b times. Each coin flip is an independent trial with\nprobability \ud835\udc5d of coming up heads. Write an expression for the following:\n1. \ud835\udc43(\ud835\udc5b heads on \ud835\udc5b coin flips)\n2. \ud835\udc43(\ud835\udc5b tails on \ud835\udc5b coin flips)\n3. \ud835\udc43(first \ud835\udc58 heads, then \ud835\udc5b \u2212 \ud835\udc58 tails)\n4. \ud835\udc43(exactly \ud835\udc58 heads on \ud835\udc5b coin flips)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\nCoin Flips\nSuppose we flip a coin \ud835\udc5b times. Each coin flip is an independent trial with\nprobability \ud835\udc5d of coming up heads. Write an expression for the following:\n1. \ud835\udc43(\ud835\udc5b heads on \ud835\udc5b coin flips)\n2. \ud835\udc43(\ud835\udc5b tails on \ud835\udc5b coin flips)\n3. \ud835\udc43(first \ud835\udc58 heads, then \ud835\udc5b \u2212 \ud835\udc58 tails)\n4. \ud835\udc43(exactly \ud835\udc58 heads on \ud835\udc5b coin flips)\n\ud835\udc5b\n( %)(\n\ud835\udc5d 1 \u2212 \ud835\udc5d\n\ud835\udc58\n# of mutually \ud835\udc43(a particular outcome\u2019s\nexclusive \ud835\udc58 heads on \ud835\udc5b coin flips)\noutcomes\nMake sure you understand #4! It will come up again.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\nProbability of events\nE or F E and F\n\ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 \ud835\udc43 \ud835\udc38\ud835\udc39\nMutually\nexclusive? Independent?\nInclusion-\nJust add! Just multiply! Chain Rule\nExclusion\nPrinciple\n\ud835\udc43 \ud835\udc38 + \ud835\udc43(\ud835\udc39) \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39 \u2212 \ud835\udc43(\ud835\udc38 \u2229 \ud835\udc39)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nProbability of events\nE or F E and F\n\ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 \ud835\udc43 \ud835\udc38\ud835\udc39\nMutually\nexclusive? Independent?\nInclusion-\nJust add! Just multiply! Chain Rule\nExclusion\n\ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39 \ud835\udc38\nPrinciple\nor\n\ud835\udc43 \ud835\udc38 + \ud835\udc43(\ud835\udc39) \ud835\udc43 \ud835\udc38 + \ud835\udc43 \ud835\udc39 \u2212 \ud835\udc43(\ud835\udc38 \u2229 \ud835\udc39) \ud835\udc43 \ud835\udc38 \ud835\udc43 \ud835\udc39\n\ud835\udc43 \ud835\udc39 \ud835\udc43(\ud835\udc38|\ud835\udc39)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nProbability of events\nDe Morgan\u2019s\nE or F E and F\n\ud835\udc43 \ud835\udc38 \u222a \ud835\udc39 \ud835\udc43 \ud835\udc38\ud835\udc39\nMutually\nexclusive? Independent?\nInclusion-\nJust add! Exclusion Just multiply! Chain Rule\nPrinciple\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\nDe Morgan\u2019s Laws De Morgan\u2019s lets you switch between AND and OR.\n\ud835\udc38 \u2229 \ud835\udc39 - = \ud835\udc38- \u222a \ud835\udc39- In probability:\nS\n, - , \ud835\udc43 \ud835\udc38 \ud835\udc38 \u22ef \ud835\udc38\n# $ %\nE F\n-\n; \ud835\udc38 = < \ud835\udc38\n+ + = 1 \u2212 \ud835\udc43 \ud835\udc38 \ud835\udc38 \u22ef \ud835\udc38 -\n# $ %\n+.( +.(\n- . .\n= 1 \u2212 \ud835\udc43 \ud835\udc38 \u222a \ud835\udc38 \u222a \u22ef \u222a \ud835\udc38\n# $ %\n-\nGreat if \ud835\udc38 mutually exclusive!\n+\nIn probability:\n- - -\n\ud835\udc38 \u222a \ud835\udc39 = \ud835\udc38 \u2229 \ud835\udc39\nS\n\ud835\udc43 \ud835\udc38 \u222a \ud835\udc38 \u222a \u22ef \u222a \ud835\udc38\n, - , # $ %\nE F\n-\n< \ud835\udc38 = ; \ud835\udc38 -\n+ + = 1 \u2212 \ud835\udc43 \ud835\udc38 \u222a \ud835\udc38 \u222a \u22ef \u222a \ud835\udc38\n# $ %\n+.( +.(\n. . .\n= 1 \u2212 \ud835\udc43 \ud835\udc38 \ud835\udc38 \u22ef \ud835\udc38\n# $ %\nGreat if \ud835\udc38 independent!\n+\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\nHash table fun\n\u2022 \ud835\udc5a strings are hashed (not uniformly) into a hash table with \ud835\udc5b buckets.\n\u2022 Each string hashed is an independent trial w.p. \ud835\udc5d of getting hashed into bucket \ud835\udc56.\n+\nWhat is \ud835\udc43 \ud835\udc38 if\n1. \ud835\udc38 = bucket 1 has \u2265 1 string hashed into it?\n2. \ud835\udc38 = at least 1 of buckets 1 to \ud835\udc58 has \u2265 1 string hashed into it?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 22\nHash table fun\n\u2022 \ud835\udc5a strings are hashed (not uniformly) into a hash table with \ud835\udc5b buckets.\n\u2022 Each string hashed is an independent trial w.p. \ud835\udc5d of getting hashed into bucket \ud835\udc56.\n+\nWhat is \ud835\udc43 \ud835\udc38 if\n1. \ud835\udc38 = bucket 1 has \u2265 1 string hashed into it?\nDefine \ud835\udc46 = string \ud835\udc56 is\n+\nhashed into bucket 1\n-\n\ud835\udc46 = string \ud835\udc56 is not\n+\nhashed into bucket 1\n\ud835\udc43 \ud835\udc46 = \ud835\udc5d\n! \"\n#\n\ud835\udc43 \ud835\udc46 = 1 \u2212 \ud835\udc5d\n! \"\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nHash table fun\n\u2022 \ud835\udc5a strings are hashed (not uniformly) into a hash table with \ud835\udc5b buckets.\n\u2022 Each string hashed is an independent trial w.p. \ud835\udc5d of getting hashed into bucket \ud835\udc56.\n+\nWhat is \ud835\udc43 \ud835\udc38 if\n1. \ud835\udc38 = bucket 1 has \u2265 1 string hashed into it?\nDefine \ud835\udc46 = string \ud835\udc56 is\n+\nhashed into bucket 1\nWTF (not-real acronym for Want To Find):\n-\n\ud835\udc46 = string \ud835\udc56 is not\n+\n\ud835\udc43 \ud835\udc38 = \ud835\udc43(\ud835\udc46 \u222a \ud835\udc46 \u222a \u22ef \u222a \ud835\udc46 ) hashed into bucket 1\n# $ 4\n-\n= 1 \u2212 \ud835\udc43 \ud835\udc46 \u222a \ud835\udc46 \u222a \u22ef \u222a \ud835\udc46 Complement\n# $ 4\n\ud835\udc43 \ud835\udc46 = \ud835\udc5d\n! \"\n= 1 \u2212 \ud835\udc43 \ud835\udc46- \ud835\udc46- \u22ef \ud835\udc46- De Morgan\u2019s Law \ud835\udc43 \ud835\udc46# = 1 \u2212 \ud835\udc5d\n# $ 4 ! \"\n4\n- - - -\n= 1 \u2212 \ud835\udc43 \ud835\udc46 \ud835\udc43 \ud835\udc46 \u22ef \ud835\udc43 \ud835\udc46 = 1 \u2212 \ud835\udc43 \ud835\udc46 \ud835\udc46 independent trials\n# $ 4 # +\n4\n= 1 \u2212 (1 \u2212 \ud835\udc5d )\n#\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nMore hash table fun: Possible approach?\n\u2022 \ud835\udc5a strings are hashed (not uniformly) into a hash table with \ud835\udc5b buckets.\n\u2022 Each string hashed is an independent trial w.p. \ud835\udc5d of getting hashed into bucket \ud835\udc56.\n+\nWhat is \ud835\udc43 \ud835\udc38 if\n1. \ud835\udc38 = bucket 1 has \u2265 1 string hashed into it?\n2. \ud835\udc38 = at least 1 of buckets 1 to \ud835\udc58 has \u2265 1 string hashed into it?\nDefine \ud835\udc39 = bucket \ud835\udc56 has at\n\ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc39 \u222a \ud835\udc39 \u222a \u22ef \u222a \ud835\udc39 +\n# $ (\nleast one string in it\n-\n= 1 \u2212 \ud835\udc43 \ud835\udc39 \u222a \ud835\udc39 \u222a \u22ef \u222a \ud835\udc39\n# $ (\n- - -\n= 1 \u2212 \ud835\udc43 \ud835\udc39 \ud835\udc39 \u22ef \ud835\udc39\n# $ (\n- - .\n? = 1 \u2212 \ud835\udc43 \ud835\udc39 \ud835\udc43 \ud835\udc39 \u22ef \ud835\udc43 \ud835\udc39\n# $ (\n\u26a0\n\ud835\udc39 bucket events are dependent!\n+\nSo we cannot approach with complement.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nMore hash table fun\n\u2022 \ud835\udc5a strings are hashed (not uniformly) into a hash table with \ud835\udc5b buckets.\n\u2022 Each string hashed is an independent trial w.p. \ud835\udc5d of getting hashed into bucket \ud835\udc56.\n+\nWhat is \ud835\udc43 \ud835\udc38 if\n1. \ud835\udc38 = bucket 1 has \u2265 1 string hashed into it?\n2. \ud835\udc38 = at least 1 of buckets 1 to \ud835\udc58 has \u2265 1 string hashed into it?\nDefine \ud835\udc39 = bucket \ud835\udc56 has at\n\ud835\udc43 \ud835\udc38 = \ud835\udc43 \ud835\udc39 \u222a \ud835\udc39 \u222a \u22ef \u222a \ud835\udc39 +\n# $ (\nleast one string in it\n-\n= 1 \u2212 \ud835\udc43 \ud835\udc39 \u222a \ud835\udc39 \u222a \u22ef \u222a \ud835\udc39\n# $ (\n- - -\n= 1 \u2212 \ud835\udc43 \ud835\udc39 \ud835\udc39 \u22ef \ud835\udc39 = \ud835\udc43 buckets 1 to \ud835\udc58 \ud835\udc1a\ud835\udc25\ud835\udc25 \ud835\udc1d\ud835\udc1e\ud835\udc27\ud835\udc22\ud835\udc1e\ud835\udc1d \ud835\udc2c\ud835\udc2d\ud835\udc2b\ud835\udc22\ud835\udc27\ud835\udc20\ud835\udc2c\n# $ (\n$\n= \ud835\udc43 each string hashes to \ud835\udc58 + 1 or higher\n= (1 \u2212 \ud835\udc5d \u2212 \ud835\udc5d \u2026\u2013 \ud835\udc5d )$\n\" % &\n4\n= 1 \u2212 (1 \u2212 \ud835\udc5d \u2212 \ud835\udc5d \u2026\u2013 \ud835\udc5d )\n# $ (\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26 <END>"}
{"prompt": "Lecture notes from cs109_lec01_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 1: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n1 / 1 pts\nQuestion 1\nHow Concept Checks Work 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 How Concept Checks Work\n1 Point\nThese concept checks are designed to help you verify your understanding of the\nmaterial in each lecture. You should expect a concept check to be posted after\nlecture has ended, and in an ideal world, you'd complete the concept check as\nsoon as possible to confirm you've understood that day's material.\nHowever, we understand that many of you can't always attend lecture and might\neven be taking another class and the same time. Because we know from past\nquarters that many of you often need the weekend to catch up, we'll set the due\ndates for an entire week's worth of concept checks to fall due the Tuesday of the\nfollowing week at noon.\nYou always have an unlimited number of submissions for each concept\ncheck question, and only your most recent submission is retained. Each\ntime you click \"Save Answer\" on a question, an \"Explanation\" box will pop up if\nyou supplied the correct answer. Otherwise the box will not appear. To try it out,\njust keep guessing a number between 16 and 20 and hitting \"Save Answer\" until\nyou get the \"right answer\":\n16\n17\n18\n19\n20 <END>"}
{"prompt": "Lecture notes from cs109_lec24_conceptcheck.txt\n\n###\n\n", "completion": "Lecture 24: Concept Check \uf111 Graded\nStudent\nNeetish Sharma\nTotal Points\n6 / 6 pts\nQuestion 1\nGradient Ascent 6 / 6 pts\n1.1 Gradient Ascent: Take I 2 / 2 pts\n\uf00c + 2 pts Correct\n+ 0 pts Incorrect\n1.2 Gradient Ascent: Convergence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\n1.3 Gradient Ascent: Take II 2 / 2 pts\n\uf00c + 2 pts Correct\n+ 0 pts Incorrect\n1.4 Gradient Ascent: Convergence 1 / 1 pt\n\uf00c + 1 pt Correct\n+ 0 pts Incorrect\nQ1 Gradient Ascent\n6 Points\nWhen using gradient ascent in practice, it's important to choose the correct step\nsize \u03b7. Consider that we are trying to maximize f(x) = 5 \u2212 (x \u2212 1)2 with\nrespect to a single variable x. For this problem please write numerical answers\nto the nearest integer without using decimals. E.g. please answer 1 instead of\n1.0.\nQ1.1 Gradient Ascent: Take I\n2 Points\nConsider that we choose our starting point x = 0 and our step size \u03b7 = 1, what\n0\nis x ? Restated, what is the value of x after running 2 iterations of gradient\n2\nascent?\n0\nQ1.2 Gradient Ascent: Convergence\n1 Point\nWill gradient ascent converge when we choose our starting point to be x = 0\n0\nwith a step size of \u03b7 = 1?\nYes\nNo\nQ1.3 Gradient Ascent: Take II\n2 Points\nAssume we choose our starting point to be x = 0 and a learning rate of \u03b7 =\n0\n0.5. What is x now?\n2\n1\nQ1.4 Gradient Ascent: Convergence\n1 Point\nWill gradient ascent converge when we choose our starting point to be x = 0\n0\nwith a step size of \u03b7 = 0.5?\nYes\nNo <END>"}
{"prompt": "Lecture notes from 05_section_soln.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May9,2024\nConditional Expectation, Introductory Inference\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\nWarm-ups\n1 Why Multiple Random Variables?\nWhatisaprobabilisticmodelwithmultiplerandomvariables?Whatdoestheterminference\nmean?Whatdoyoucalltheprobabilityofanassignmenttoallvariablesinaprobabilisticmodel?\nWhyisthatuseful?Whycanitbehardtorepresent?\nAprobabilisticmodelisawayofdefiningtherelationshipbetweenmanyrandomvariables.\nInferenceistheactofcomputingabeliefinone(ormore)variablesbasedonanobservation.\nTheprobabilityofanassignmenttoallvariablesinaprobabilisticmodeliscalledthejoint.\nThe joint can be used to solve any inference task. The number of ways of assigning values\ntovariablesisexponentialinthenumberofrandomvariables.\n2 Joint Random Variables Statistics\nTrueorFalse?Thesymbol\ud835\udc36\ud835\udc5c\ud835\udc63 iscovariance,thesymbol\u2227islogical-and,thesymbol \ud835\udf0c is\nPearsoncorrelation,thesymbol =\u21d2 islogicalimplication,and \ud835\udc4b \u22a5\ud835\udc4c isjustafancywaytosay\nthat \ud835\udc4b and\ud835\udc4c areindependent.\nAstatementlike\u201d\ud835\udc34 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(10,0.5) \u2227 \ud835\udc35 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(10,0.5) \u2227 \ud835\udc34 \u22a5 \ud835\udc35 =\u21d2 \ud835\udc34+ \ud835\udc35 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(20,0.5)\u201d\nreads\u201dIf \ud835\udc34 and \ud835\udc35 arebothdistributedasBinomialswiththesameparameters,then \ud835\udc34+ \ud835\udc35 isa\nBinomialaswellwiththesame \ud835\udc5d parameterandan \ud835\udc5b parameterthat\u2019sthesumofthethosefor \ud835\udc34\nand \ud835\udc35.\u201d\n\ud835\udc4b \u22a5\ud835\udc4c =\u21d2 \ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc4b,\ud835\udc4c) = 0 \ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b + \ud835\udc4b) = 2\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b)\n\ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc4b,\ud835\udc4c) = 0 =\u21d2 \ud835\udc4b \u22a5\ud835\udc4c \ud835\udc4b \u223c N(0,1) \u2227\ud835\udc4c \u223c N(0,1) =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 1\n\ud835\udc4c = \ud835\udc4b2 =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 1 \ud835\udc4c = 3\ud835\udc4b =\u21d2 \ud835\udf0c(\ud835\udc4b,\ud835\udc4c) = 3\nTrueorFalse?\nTrue False(... = 4\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b))\nFalse(antecedentnecessary,notsufficient) False(don\u2019tknowhowindependentX&Yare)\nFalse(\ud835\udc4c = \ud835\udc4b =\u21d2 ...) False(...=1)\n\u20132\u2013\n3 Random Number of Random Variables\nLet \ud835\udc41 beanon-negativeinteger-valuedrandomvariable\u2014thatis,arandomvariablethattakeson\nvaluesin {0,1,2,...}.Let \ud835\udc4b ,\ud835\udc4b ,\ud835\udc4b ,... beaninfinitesequenceofindependentandidentically\n1 2 3\ndistributedrandomvariables(independentof \ud835\udc41),eachwithmean \ud835\udf07,and \ud835\udc4b = (cid:205) \ud835\udc56\ud835\udc41\n=1\n\ud835\udc4b \ud835\udc56 bethesum\nofthefirst \ud835\udc41 ofthem.\nBeforedoinganywork,whatdoyouthink \ud835\udc38[\ud835\udc4b] willturnouttobe?Thenshowitmathematically\ntoseeifyourintuitioniscorrect.\n(cid:34) \ud835\udc41 (cid:35) (cid:34) \ud835\udc41 (cid:35) (cid:34) \ud835\udc5b (cid:35)\n\u2211\ufe01 \u2211\ufe01 \u2211\ufe01 \u2211\ufe01 \u2211\ufe01\n\ud835\udc38[\ud835\udc4b] = \ud835\udc38 \ud835\udc4b \ud835\udc56 = \ud835\udc38 \ud835\udc4b \ud835\udc56 | \ud835\udc41 = \ud835\udc5b \ud835\udc5d \ud835\udc41(\ud835\udc5b) = \ud835\udc38 \ud835\udc4b \ud835\udc56 | \ud835\udc41 = \ud835\udc5b \ud835\udc5d \ud835\udc41(\ud835\udc5b)\n\ud835\udc56=1 \ud835\udc5b \ud835\udc56=1 \ud835\udc5b \ud835\udc56=1\n(cid:34) \ud835\udc5b (cid:35)\n\u2211\ufe01 \u2211\ufe01 \u2211\ufe01 \u2211\ufe01\n= \ud835\udc38 \ud835\udc4b \ud835\udc56 \ud835\udc5d \ud835\udc41(\ud835\udc5b) = \ud835\udc5b\ud835\udf07\ud835\udc5d \ud835\udc41(\ud835\udc5b) = \ud835\udf07 \ud835\udc5b\ud835\udc5d \ud835\udc41(\ud835\udc5b) = \ud835\udf07\ud835\udc38[\ud835\udc41]\n\ud835\udc5b \ud835\udc56=1 \ud835\udc5b \ud835\udc5b\nAlternatively,\n\ud835\udc38[\ud835\udc4b] = \ud835\udc38[\ud835\udc38[\ud835\udc4b|\ud835\udc41]] = \ud835\udc38[\ud835\udc41\ud835\udf07] = \ud835\udf07\ud835\udc38[\ud835\udc41]\nProblems\n1 CS106A Is Popular\nCS106AisStanford\u2019sintroductoryprogrammingcourseandlargelyconsideredtheprimary\ngatewaytoourundergraduatemajor.Assumenextquarter\u2019sofferingofCS106Aisexactly600\npeople,thateachofthefourundergraduateclassesiscompromisedof1750students,andthatnext\nquarter\u2019sCS106Arosterisjustsomerandomsampleofthe7000undergraduates.Let \ud835\udc34, \ud835\udc35,\ud835\udc36,and\n\ud835\udc37 countthenumberoffreshman,sophomores,juniors,andseniorsintheclassof600.\n\u2022 Presentthejointprobabilitymassfunctionof \ud835\udc34,\ud835\udc35,\ud835\udc36,\ud835\udc37?Restated,presentanexpression\nfor \ud835\udc43(\ud835\udc34 = \ud835\udc4e,\ud835\udc35 = \ud835\udc4f,\ud835\udc36 = \ud835\udc50,\ud835\udc37 = \ud835\udc51).\n(cid:0)1750(cid:1)(cid:0)1750(cid:1)(cid:0)1750(cid:1)(cid:0)1750(cid:1)\n\ud835\udc43(\ud835\udc34 = \ud835\udc4e,\ud835\udc35 = \ud835\udc4f,\ud835\udc36 = \ud835\udc50,\ud835\udc37 = \ud835\udc51) = \ud835\udc4e \ud835\udc4f \ud835\udc50 \ud835\udc51\n(cid:0)7000(cid:1)\n600\n\u2022 DoesyourPMFfromparta)describeamultinomialrandomvariable?Intuitivelyjustify\nyouranswer.\nNo,amultinomialrandomvariablerequiresthattrialsbeindependent.Ifwedefineatrialin\nthis case as picking one student to be in CS106A, independence would require us to select\nstudentswithreplacement,whichisn\u2019tthecasehere.\n\u20133\u2013\n\u2022 Whatistheconditionalprobabilitydistributionof \ud835\udc34 giventhat \ud835\udc35+\ud835\udc36 = 300?Restated,what\nis \ud835\udc43(\ud835\udc34 = \ud835\udc4e|\ud835\udc35+\ud835\udc36 = 300)?\nThisisthesametypeofproblemasthatinparta),butwearenowdistributing300students\nacrosstwogroups,freshmenandseniors.\n(cid:0)1750(cid:1)(cid:0) 1750 (cid:1)\n\ud835\udc43(\ud835\udc34 = \ud835\udc4e|\ud835\udc35+\ud835\udc36 = 300) = \ud835\udc4e 300\u2212\ud835\udc4e\n(cid:0)3500(cid:1)\n300\n\u2022 Doyouexpect\ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc34,\ud835\udc35) tobepositive,zero,ornegative?Justifyyouranswer.\nWe expect \ud835\udc36\ud835\udc5c\ud835\udc63(\ud835\udc34,\ud835\udc35) to be negative. If there are more freshmen in the class, there will be\nfewer spots left for sophomores. Incidentally, the \ud835\udf0c(\ud835\udc34,\ud835\udc35) value\u2014that is, the normalized\ncovariance\u2014would be very, very slightly negative because of the large number of students\nandthelargeclasssize.\n2 Managing Screen Time\nPushnotificationslightupourphonesataratethat\u2019sguidedbyaPoissonprocesswithanconstant\naveragerateof5notificationsperhouratallhours,nightandday.Inanefforttomaximize\nproductivity,youputyourphonedownandignoreitasmuchaspossible.Youdo,however,\nperiodicallycheckittoclearallnotifications.Youcheckat7amwhenyouwakeup,noonwhenyou\ngrablunch,5pmasyouwrapupclassesfortheday,andthenagainat10pmbeforeyougotosleep.\nLetW,X,Y,andZbePoissonrandomvariablesthatcountthenumberofpushnotificationsthat\nhaveaccumulatedfrom10pmto7am,7amtonoon,noonto5pm,and5pmto10pm,respectively.\nWeassumethatthenumberofpushnotificationsthatarrivewithineachintervalareallmutually\nindependentofallotherintervals.\n\u2022 ComputethejointPMFonW,X,Y,andZ.\nSince all four variables are independent, the joint PMF is the product of the four single-\ndimensionalPMFs.Thatmeansthat:\n\ud835\udc52\u22124545\ud835\udc64 \ud835\udc52\u22122525\ud835\udc65 \ud835\udc52\u22122525\ud835\udc66 \ud835\udc52\u22122525\ud835\udc67\n\ud835\udc43(\ud835\udc4a = \ud835\udc64,\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66,\ud835\udc4d = \ud835\udc67) =\n\ud835\udc64! \ud835\udc65! \ud835\udc66! \ud835\udc67!\nShipit!\n\u2022 ComputetheconditionaljointPMFonW,X,Y,andZgiventhatW+X+Y+Z=150.\n\u20134\u2013\nWhenaddingPoissonrandomvariables,it\u2019snicetohaveanotherrandomvariablemodelling\nthat sum. Let\u2019s define \ud835\udc46 = \ud835\udc4a + \ud835\udc4b +\ud835\udc4c + \ud835\udc4b with the understanding that the sum of indepen-\ndent Poisson random variables is itself a Poisson where the one parameter is the sum of\ntheindividualones.Thatmeans\ud835\udc46 \u223c \ud835\udc43\ud835\udc5c\ud835\udc56(120)andthat\ud835\udc43(\ud835\udc46 = \ud835\udc60) = \ud835\udc52\u2212120120\ud835\udc60 = \ud835\udc52\u2212120120\ud835\udc64+\ud835\udc67+\ud835\udc66+\ud835\udc67 .\n\ud835\udc60! \ud835\udc60!\nWhat\u2019stheconditionaljointPMFofinterest?Checkthisout:\n\ud835\udc43(\ud835\udc4a = \ud835\udc64,\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66,\ud835\udc4d = \ud835\udc67|\ud835\udc46 = \ud835\udc60)\n\ud835\udc43(\ud835\udc46 = \ud835\udc60,\ud835\udc4a = \ud835\udc64,\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66,\ud835\udc4d = \ud835\udc67)\n=\n\ud835\udc43(\ud835\udc46 = \ud835\udc60)\n\ud835\udc43(\ud835\udc4a = \ud835\udc64,\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66,\ud835\udc4d = \ud835\udc67)\n=\n\ud835\udc43(\ud835\udc46 = \ud835\udc60)\n\ud835\udc52\u22124545\ud835\udc64 \ud835\udc52\u22122525\ud835\udc65 \ud835\udc52\u22122525\ud835\udc66 \ud835\udc52\u22122525\ud835\udc67\n\ud835\udc64! \ud835\udc65! \ud835\udc66! \ud835\udc67!\n=\n\ud835\udc52\u2212120120\ud835\udc60\n\ud835\udc60!\n45\ud835\udc64 25\ud835\udc65 25\ud835\udc66 25\ud835\udc67\n\ud835\udc64! \ud835\udc65! \ud835\udc66! \ud835\udc67!\n=\n120\ud835\udc64+\ud835\udc67+\ud835\udc66+\ud835\udc67\n\ud835\udc60!\n(cid:18) \ud835\udc60 (cid:19) 9 5 5 5\n\ud835\udc64 \ud835\udc65 \ud835\udc66 \ud835\udc67\n= ( ) ( ) ( ) ( )\n\ud835\udc64,\ud835\udc65,\ud835\udc66,\ud835\udc67 24 24 24 24\nThetransitionfromthefirstlinetothesecondisjuststatingthat\ud835\udc46 = \ud835\udc60\u2019spresenceinthejoint\nPMFisredundant,since \ud835\udc60 = \ud835\udc64+\ud835\udc65+\ud835\udc66+\ud835\udc67.ThebottomlinehereisthattheconditionalPMF\ndevolvesintoamultinomialrandomvariable.Whensis150,ourprobabilityisjust\n(cid:18) (cid:19)\n150 9 5 5 5\n\ud835\udc43(\ud835\udc4a = \ud835\udc64,\ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66,\ud835\udc4d = \ud835\udc67|\ud835\udc46 = 150) = ( )\ud835\udc64 ( )\ud835\udc65 ( )\ud835\udc66 ( )\ud835\udc67\n\ud835\udc64,\ud835\udc65,\ud835\udc66,\ud835\udc67 24 24 24 24\n\u2022 ComputetheconditionalPMFofX+Y+Z\u2014that\u2019sthenumberofnotificationsthatarrive\nwhileyou\u2019reawake\u2014giventhatW+X+Y+Z=150.\nThiscanbederivedfromfirstprinciplesmuchaswederivedtheconditionaljointPMFinthe\npreviousparttothisquestion.Orwecansimplymergethethreeintervalsofthemultinomial\ntoarriveatabinomial,i.e., \ud835\udc4b +\ud835\udc4c + \ud835\udc4d|\ud835\udc46 = 150 \u223c \ud835\udc35\ud835\udc56\ud835\udc5b(150, 15) = \ud835\udc35\ud835\udc56\ud835\udc5b(150, 5).\n24 8\n\u2022 Compute \ud835\udc38[\ud835\udc4b +\ud835\udc4c + \ud835\udc4d|\ud835\udc4a + \ud835\udc4b +\ud835\udc4c + \ud835\udc4d = 150] and\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b +\ud835\udc4c + \ud835\udc4d|\ud835\udc4a + \ud835\udc4b +\ud835\udc4c + \ud835\udc4d = 150).\n\ud835\udc38[\ud835\udc4b +\ud835\udc4c +\ud835\udc4d|\ud835\udc4a +\ud835\udc4b +\ud835\udc4c +\ud835\udc4d = 150] = 150\u00b7 5 = 93.75and\ud835\udc49\ud835\udc4e\ud835\udc5f(\ud835\udc4b +\ud835\udc4c +\ud835\udc4d|\ud835\udc4a +\ud835\udc4b +\ud835\udc4c +\ud835\udc4d =\n8\n150) = 150\u00b7 5 \u00b7 3 = 35.15625\n8 8\n\u20135\u2013\n3 Understanding Bayes Nets\nA=0 A=1\nB=0 B=1 B=0 B=1\nC=0 0.36 0.20 0.00 0.00\nC=1 0.04 0.20 0.10 0.10\nThejointprobabilitytable(above)forrandomvariables \ud835\udc34, \ud835\udc35 and\ud835\udc36 isequivalenttotheBayes\nnetwork(below).Bothgivetheprobabilityofanycombinationoftherandomvariables.Inthe\nBayesnetworktheprobabilityofeachrandomvariableisprovidedgivenitscausalparents.\n\u2022 UsetheBayesnetworktoexplainwhy \ud835\udc43(\ud835\udc34 = 0,\ud835\udc35 = 1,\ud835\udc36 = 1) = 0.20\n\ud835\udc43(\ud835\udc34 = 0,\ud835\udc35 = 1,\ud835\udc36 = 1) = \ud835\udc43(\ud835\udc34 = 0)\ud835\udc43(\ud835\udc35 = 1)\ud835\udc43(\ud835\udc36 = 1|\ud835\udc34 = 0,\ud835\udc35 = 1) = 0.8\u22170.5\u22170.5 = 0.2.\n\u2022 Whatis \ud835\udc43(\ud835\udc34 = 1|\ud835\udc36 = 1)?\nUsingthetable,weseethat\n0.1+0.1 0.2 5\n\ud835\udc43(\ud835\udc34 = 1|\ud835\udc36 = 1) = = =\n0.1+0.1+0.2+0.04 0.44 11\n\u2022 Is \ud835\udc34 independentof \ud835\udc35?Explainyouranswer.\nYes.Thisfollowsdirectlyfromthestructureofthebayesiannetwork,becauseAandBhave\nno shared ancestors. Alternatively, note that \ud835\udc43(\ud835\udc34 = \ud835\udc4e,\ud835\udc35 = \ud835\udc4f) = \ud835\udc43(\ud835\udc34 = \ud835\udc4e)\ud835\udc43(\ud835\udc35 = \ud835\udc4f), which\nsatisfiesthedefinitionofindependence.\n\u2022 Is \ud835\udc34 independentof \ud835\udc35 given\ud835\udc36 = 1?Explainyouranswer.\n\u20136\u2013\nNo.Fromthetable,wecanseethat \ud835\udc43(\ud835\udc35 = 1|\ud835\udc34 = 0,\ud835\udc36 = 1) = 0.2 \u2260 \ud835\udc43(\ud835\udc35 = 1|\ud835\udc34 = 1,\ud835\udc36 =\n0.4+0.2\n1) = 0.1 . So given \ud835\udc36 = 1, knowing the value of A informs us about the value of B, and\n0.1+0.1\nthereforeAandBarenotconditionallyindependentgivenC.\nNote: This phenomenon is sometimes called \u201dExplaining Away\u201d if you\u2019re curious to read\nmore.\n4 Fish Sticks [courtesy of Lisa Yan]\nFishSticks,theonlineplatformdesignedtomeetallofyourfishstickneeds,wantstomodeltheir\nhourlyhomepagetrafficfromStanford.Thecompanydecidestomodeltwodifferentbehaviorsfor\nhomepagevisitsaccordingtotheBayesianNetworkbelow:\n\ud835\udc34 and \ud835\udc35 arethenumbersofStanfordstudentsandfaculty,respectively,whovisittheFishSticks\nhomepageinanhour.SinceFishSticksdoesnotknowwhenStanfordpeopleeat,thecompany\nmodelsdemandasa\u201dhidden\u201dBernoullirandomvariable \ud835\udc37,whichdeterminesthedistributionof\n\ud835\udc34and \ud835\udc35.RecallthatinaBayesianNetwork,randomvariablesareconditionallyindependentgiven\ntheirparents.Forexample,given \ud835\udc37 = 0, \ud835\udc34 \u223c Poi(5) and \ud835\udc35 \u223c Poi(3),twoindependentrandom\nvariables.\na. Giventhat6usersfromgroup \ud835\udc34 visitthehomepageinthenexthour,whatistheprobability\nthat \ud835\udc37 = 0?\nNote that given \ud835\udc37 = 0, \ud835\udc34 \u223c Poi(\ud835\udf06 = 5), and given \ud835\udc37 = 1, \ud835\udc34 \u223c Poi(\ud835\udf06 = 8). By Bayes\u2019\nTheorem,\n\ud835\udc43(\ud835\udc34 = 6|\ud835\udc37 = 0)\ud835\udc43(\ud835\udc37 = 0)\n\ud835\udc43(\ud835\udc37 = 0|\ud835\udc34 = 6) =\n\ud835\udc43(\ud835\udc34 = 6|\ud835\udc37 = 0)\ud835\udc43(\ud835\udc37 = 0) + \ud835\udc43(\ud835\udc34 = 6|\ud835\udc37 = 1)\ud835\udc43(\ud835\udc37 = 1)\n56\ud835\udc52\u22125(1\u22120.3)\n= 6!\n56\ud835\udc52\u22125(1\u22120.3)\n+\n86\ud835\udc52\u22128(0.3)\n6! 6!\n56\ud835\udc52\u22125(1\u22120.3)\n= \u2248 0.7364\n56\ud835\udc52\u22125(1\u22120.3) +86\ud835\udc52\u22128(0.3)\nb. Whatistheprobabilitythatinthenexthour,thetotal numberofuserswhovisitthe\nhomepagefromgroups \ud835\udc34 and \ud835\udc35 isequalto12,i.e.,whatis \ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12)?\n\u20137\u2013\nByLawofTotalProbability,\n\ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12) = \ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12|\ud835\udc37 = 0)\ud835\udc43(\ud835\udc37 = 0) + \ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12|\ud835\udc37 = 1)\ud835\udc43(\ud835\udc37 = 1).\n\ud835\udc34 and \ud835\udc35 are conditionally independent Poisson random variables given \ud835\udc37, and therefore\n\ud835\udc34+ \ud835\udc35|\ud835\udc37 = 0 \u223c Poi(\ud835\udf06 = 8) and \ud835\udc34+ \ud835\udc35|\ud835\udc37 = 1 \u223c Poi(\ud835\udf06 = 14).UsingthePoissonPMF,\n812\ud835\udc52\u22128 1412\ud835\udc52\u221214\n\ud835\udc43(\ud835\udc34+ \ud835\udc35 = 12) = \u00b7 (1\u22120.3) + \u00b7 (0.3) \u2248 0.0632.\n12! 12!\nc. Nowsimulate \ud835\udc43(\ud835\udc34+ \ud835\udc35 = total),wheretotal = 12,byimplementingthe\ninfer prob total(total, ntrials)functionbelowusingrejectionsampling.\n\u2022 totalisthetotalnumberofusersfromgroups \ud835\udc34 and \ud835\udc35 intheevent \ud835\udc34+ \ud835\udc35 = total.\n\u2022 ntrialsisthenumberofobservationstogenerateforrejectionsampling.\n\u2022 probisthereturnvaluetothefunction,whereprob \u2248 \ud835\udc43(\ud835\udc34+ \ud835\udc35 = total).\n\u2022 Thefunctioncallisimplementedforyouatthebottomofthecodeblock.\nYoucancallthefollowingfunctionsfromthescipypackage:\n\u2022 stats.bernoulli.rvs(\ud835\udc5d),whichrandomlygeneratesa1withprobability \ud835\udc5d,and\ngeneratesa0otherwise.\n\u2022 stats.poisson.rvs(\ud835\udf06),whichrandomlygeneratesavalueaccordingtoaPoisson\ndistributionwithparameter\ud835\udf06\nYouarenotrequiredtouselistsornumpyarraysinthisquestion(butyoucanifyouwant).\nPseudo-codeisfineaslongasyourcodeaccuratelyconveysyourapproach.\nimport numpy as np\nfrom scipy import stats\ndef infer_prob_total(total, ntrials):\n# here's where your implementation belongs\nreturn prob\ntotal = 12\nntrials = 50000\nprint('Simulated% P(A + B)=', infer_prob_total(total, ntrials))\nThisisthefullimplementationrighthere:\nimport numpy as np\nfrom scipy import stats\ndef infer_prob_total(total, ntrials):\n\u20138\u2013\nn_samples_event = 0\nfor i in range(ntrials):\nd = stats.bernoulli.rvs(0.3)\nif d == 0:\nuser_sum = stats.poisson.rvs(5) + stats.poisson.rvs(3)\nelse:\nuser_sum = stats.poisson.rvs(8) + stats.poisson.rvs(6)\nif user_sum == total: n_samples_event += 1\nprob = n_samples_event/ntrials\nreturn prob\nntrials = 50000\ntotal = 12\nprint(\"Simulated P(A + B)=\", infer_prob_total(total, ntrials))\n5 ChatGPT, Watermarking, and Bayesian Inference\nChatGPTisagenerativeAItechnologythatcanbecoarselysummarizedtobeachatbotwitha\nseeminglyboundlessabilitytodiscussanytopic\u2014history,computerscience,art,nuclearphysics,\nprobability,andeventheethicsofusingChatGPT\u2014inanyoneofseveralwrittenlanguages,\nincludingEnglish,French,Spanish,C++,JavaScript,Python,andsome100others.\nUnsurprisingly,wewillsoonbelefttowonderwhetherapoem,aTweet,aC++function,ora\ncollegethesisiswrittenbyChatGPTorahumanbeing.Questionsaboutauthorship,accuracy,and\nattributionhavepromptedOpenAI,thecompanybehindChatGPT,toaddresstheseconcernsby\nimplementingChatGPTtoemploywhat\u2019stermedwatermarkingandinsertcertainwordsmoreor\nlessoftenthaniscustomaryineventhebestofhuman-authoredwriting.\nToillustrate,let\u2019sassumethatmosthumansusethewordtheanaverageof4.8timesper100\nwords,whereasChatGPTmightgenerateprosewheretheappearsonaverage6.5timesper100\nwords.Similarly,humansusethewordofonaverageabout3.9timesper100words,whereas\nChatGPTmightleverageofabout6.2timesper100words.Conversely,ChatGPTmightgenerate\nthewordbyonly1.6timesper100words,whereashumansusethewordbyabout2.7timesper\n100words.\na. YouelecttomodelwordfrequencyofallwordsusingeitheraPoissonforparagraphsof200\norsowords\u2014butasaGaussianforlargerdocuments\u2014say10000wordsormore.Explain\nwhytheGaussianmightbethebetterchoiceforlargerdocumentsthanthePoisson,whereas\nPoissonismoreeasilydefendedforsmallerdocuments.\nThePoissondistributionprovidesanaccurateestimatefordocumentswithlowwordcounts\nsinceweexpectmostlylowwordcountswithalongrighttailforhigherwordcounts.\n\u20139\u2013\nAs our documents get larger, by the CLT we know that the Gaussian is an accurate,\ncomputationallyefficientapproximateofthewordfrequencies.\nOther answers we accepted were: discussions of variance, discussion of the require-\nmentsforbinomialapproximation,discussionofCLT,discussionofcomputationefficiency.\nb. Adeeperstatisticalanalysisofmanyhuman-writtendocumentsstronglysuggeststhat\n\ud835\udc3b \u223c N(5,1) and \ud835\udc3b \u223c N(4,1),whereasaseparatebutequallydeepanalysisstrongly\nthe by\nsuggeststhat\ud835\udc36 \u223c N(3,1) and\ud835\udc36 \u223c N(2,1).(Theparametersareroundedvaluesfor\nthe by\nsimplicityandassumedtobeper-100-words.)\nAssumingapriorbeliefthataverylongdocumentwaswrittenbyahumanis0.99,whatis\nyourposteriorbeliefthatthedocumentwaswrittenbyahumanifthedocumentcontainsan\naverageof5the\u2019severy100wordsbutonly1byevery100words.Youmayassumeall\nGaussiandistributionsofinterestareindependent.\nWewanttofindourposteriorbelief:\n\ud835\udc53(\ud835\udc3b|5 ,1 )\nthe by\nByBayes:\n\ud835\udc53(5 ,1 |\ud835\udc3b)\ud835\udc43(\ud835\udc3b)\nthe by\n=\n\ud835\udc53(5 ,1 )\nthe by\nByLOTP:\n\ud835\udc53(5 ,1 |\ud835\udc3b)\ud835\udc43(\ud835\udc3b)\nthe by\n=\n\ud835\udc53(5 ,1 |\ud835\udc3b)\ud835\udc43(\ud835\udc3b) + \ud835\udc53(5 ,1 |\ud835\udc36)\ud835\udc43(\ud835\udc36)\nthe by the by\nByourindependence,wecanexpandthejointPDFwithasimpleproduct\n0.99\u00b7 \u221a1 \ud835\udc52\u22121 2(0)2 \u00b7 \u221a1 \ud835\udc52\u22121 2(\u22123)2\n2\ud835\udf0b 2\ud835\udf0b\n=\n0.99\u00b7 \u221a1 \ud835\udc52\u22121 2(0)2 \u00b7 \u221a1 \ud835\udc52\u22121 2(\u22123)2 +0.01\u00b7 \u221a1 \ud835\udc52\u22121 2(2)2 \u00b7 \u221a1 \ud835\udc52\u22121 2(\u22121)2\n2\ud835\udf0b 2\ud835\udf0b 2\ud835\udf0b 2\ud835\udf0b\n0.99\u00b7\ud835\udc52\u22121 2(\u22123)2\n=\n0.99\u00b7\ud835\udc52\u22121 2(\u22123)2 +0.01\u00b7\ud835\udc52\u2212 21(2)2 \u00b7\ud835\udc52\u22121 2(\u22121)2\n0.99\u00b7\ud835\udc52\u2212 29\n=\n0.99\u00b7\ud835\udc52\u22129\n2\n+0.01\u00b7\ud835\udc52\u22125\n2\nwhichsimplifiestoabout0.9305.\nInreality,theGaussiansherearenotindependent,sincethepresenceofonewordimplies\ntheabsenceofanother.Assumingacorrelationvalue \ud835\udf0c thatisslightlynegative,wouldyou\nexpecttheobservationsstatedinpartb)toresultinalargerposteriorprobabilityora\nsmallerone?Brieflyexplainwhy.\n\u201310\u2013\nWe anticipate a larger posterior. Negative correlation implies that an increased usage of\n\u201dthe\u201d is correlated with a decreased usage of \u201dby\u201d. This is aligned with what we observed,\nwith\u201dby\u201dbeingusedlessthanaverage.Thus,webelievethat \ud835\udc53(5 ,1 ) > \ud835\udc53(5 )\ud835\udc53(1 ).\nthe by the by <END>"}
{"prompt": "Lecture notes from 13_joint_statistics_annotated.txt\n\n###\n\n", "completion": "13: Statistics on Multiple\nRandom Variables\nJerry Cain\nApril 29th, 2024\nLecture Discussion on Ed\n1\nCoupon\nCollecting\n2\nCoupon collecting and server requests\nThe coupon collector\u2019s problem in probability theory: Servers\n\u2022 You buy boxes of cereal. requests\n\ud835\udc58 servers\n\u2022 There are \ud835\udc58 different types of coupons\nrequest to\n\u2022 For each box you buy, you \"collect\"\nserver \ud835\udc56\na coupon of type \ud835\udc56.\n1. How many coupons do you expect What is the expected number of\nafter buying \ud835\udc5b boxes of cereal? servers utilized after \ud835\udc5b requests?\n* 52% of Amazon profits\n** more profitable than Amazon\u2019s\nNorth America commerce operations\nsource\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 3\n$ $\nComputer cluster utilization \ud835\udc38 \"\ud835\udc4b = \"\ud835\udc38 \ud835\udc4b\n! !\n!\"# !\"#\nConsider a computer cluster with \ud835\udc58 servers. We send \ud835\udc5b requests.\n\u2022 Requests independently go to server \ud835\udc56 with probability \ud835\udc5d\n!\n\u2022 Let \ud835\udc4b = # servers that receive \u2265 1 request.\nWhat is \ud835\udc38 \ud835\udc4b ?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 4\n$ $\nComputer cluster utilization \ud835\udc38 \"\ud835\udc4b = \"\ud835\udc38 \ud835\udc4b\n! !\n!\"# !\"#\nConsider a computer cluster with \ud835\udc58 servers. We send \ud835\udc5b requests.\n\u2022 Requests independently go to server \ud835\udc56 with probability \ud835\udc5d\n!\n\u2022 Let \ud835\udc4b = # servers that receive \u2265 1 request.\nWhat is \ud835\udc38 \ud835\udc4b ?\n1. Define additional 2. Solve.\nrandom variables.\n)\nLet: \ud835\udc34 = event that server \ud835\udc56 \ud835\udc38 \ud835\udc4b = \ud835\udc43 \ud835\udc34 = 1 \u2212 1 \u2212 \ud835\udc5d\n% % % %\nreceives \u2265 1 request ( ( (\n\ud835\udc4b = indicator for \ud835\udc34 \ud835\udc38 \ud835\udc4b = \ud835\udc38 ) \ud835\udc4b = ) \ud835\udc38 \ud835\udc4b = ) 1 \u2212 1 \u2212 \ud835\udc5d\n)\n% % % % %\n%&\u2019 %&\u2019 %&\u2019\n( (\n(\n\ud835\udc43 \ud835\udc34 = 1 \u2212 \ud835\udc43 no requests to \ud835\udc56\n%\n)\n= 1 \u2212 1 \u2212 \ud835\udc5d ) = ) 1 \u2212 ) 1 \u2212 \ud835\udc5d % = \ud835\udc58 \u2212 ) 1 \u2212 \ud835\udc5d )\n% %\n%&\u2019 %&\u2019\n%&\u2019\nNote: \ud835\udc34 are dependent!\n!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 5\nCoupon collecting problems: Hash tables\nThe coupon collector\u2019s problem in probability theory: Servers Hash Tables\n\u2022 You buy boxes of cereal. requests strings\n\ud835\udc58 servers \ud835\udc58 buckets\n\u2022 There are \ud835\udc58 different types of coupons\nrequest to hashed to\n\u2022 For each box you buy, you \"collect\"\nserver \ud835\udc56 bucket \ud835\udc56\na coupon of type \ud835\udc56.\n1. How many coupons do you expect What is the expected number of\nafter buying \ud835\udc5b boxes of cereal? utilized servers after \ud835\udc5b requests?\n2. How many boxes do you expect What is the expected number of\nto buy until you have one of strings to hash until each bucket\neach coupon?\nhas \u2265 1 string?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 6\n$ $\nHash Tables \ud835\udc38 \"\ud835\udc4b = \"\ud835\udc38 \ud835\udc4b\n! !\n!\"# !\"#\nConsider a hash table with \ud835\udc58 buckets.\n\u2022 Strings are equally likely to get hashed into any bucket (independently).\n\u2022 Let \ud835\udc4c = # strings to hash until each bucket \u2265 1 string.\nWhat is \ud835\udc38 \ud835\udc4c ?\n1. Define additional\nrandom variables. How should we define \ud835\udc4c such that \ud835\udc4c = - \ud835\udc4c ?\n! !\n!\n2. Solve.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 7\n$ $\nHash Tables \ud835\udc38 \"\ud835\udc4b = \"\ud835\udc38 \ud835\udc4b\n! !\n!\"# !\"#\nConsider a hash table with \ud835\udc58 buckets.\n\u2022 Strings are equally likely to get hashed into any bucket (independently).\n\u2022 Let \ud835\udc4c = # strings to hash until each bucket \u2265 1 string.\nWhat is \ud835\udc38 \ud835\udc4c ?\n1. Define additional\nLet: \ud835\udc4c = # of trials needed to get success after \ud835\udc56-th success\n%\nrandom variables. \u2022 Success: hash string to previously empty bucket\n(*%\n\u2022 If \ud835\udc56 non-empty buckets: \ud835\udc43 success =\n(\n)*\u2019\n2. Solve. \ud835\udc56 \ud835\udc58 \u2212 \ud835\udc56\n\ud835\udc43 \ud835\udc4c = \ud835\udc5b =\n%\n\ud835\udc58 \ud835\udc58\n1 \ud835\udc58\n(*%\nEquivalently, \ud835\udc4c~Geo \ud835\udc5d = \ud835\udc38 \ud835\udc4c = =\n% %\n( \ud835\udc5d \ud835\udc58 \u2212 \ud835\udc56\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 8\n$ $\nHash Tables \ud835\udc38 \"\ud835\udc4b = \"\ud835\udc38 \ud835\udc4b\n! !\n!\"# !\"#\nConsider a hash table with \ud835\udc58 buckets.\n\u2022 Strings are equally likely to get hashed into any bucket (independently).\n\u2022 Let \ud835\udc4c = # strings to hash until each bucket \u2265 1 string.\nWhat is \ud835\udc38 \ud835\udc4c ?\n1. Define additional\nLet: \ud835\udc4c = # of trials to needed get success after \ud835\udc56-th success\n%\nrandom variables.\n\ud835\udc58 \u2212 \ud835\udc56 1 \ud835\udc58\n\ud835\udc4c~Geo \ud835\udc5d = , \ud835\udc38 \ud835\udc4c = =\n% %\n\ud835\udc58 \ud835\udc5d \ud835\udc58 \u2212 \ud835\udc56\n2. Solve. \ud835\udc4c = \ud835\udc4c + \ud835\udc4c + \u22ef + \ud835\udc4c\n+ \u2019 (*\u2019\n\ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4c + \ud835\udc38 \ud835\udc4c + \u22ef + \ud835\udc38 \ud835\udc4c\n+ \u2019 (*\u2019\n\ud835\udc58 \ud835\udc58 \ud835\udc58 \ud835\udc58 1 1\n= + + + \u22ef + = \ud835\udc58 + + \u22ef + 1 = \ud835\udc42 \ud835\udc58 log \ud835\udc58\n\ud835\udc58 \ud835\udc58 \u2212 1 \ud835\udc58 \u2212 2 1 \ud835\udc58 \ud835\udc58 \u2212 1\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 9\nCovariance\n10\nStatistics of sums of RVs\nFor any random variables \ud835\udc4b and \ud835\udc4c,\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\nVar \ud835\udc4b + \ud835\udc4c = ?\nBut first, a new statistic!\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 11\nSpot the difference\nCompare/contrast the following two distributions: Assume all points are\nequally likely.\n1\n\ud835\udc43 \ud835\udc4b = \ud835\udc65,\ud835\udc4c = \ud835\udc66 =\n\ud835\udc41\nBoth distributions have the same \ud835\udc38 \ud835\udc4b , \ud835\udc38 \ud835\udc4c , Var \ud835\udc4b , and Var \ud835\udc4c\nDifference: how the two variables vary with each other.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 12\nCovariance\nThe covariance of two variables \ud835\udc4b and \ud835\udc4c is:\nCov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nProof of second part (rewriting \ud835\udc38 \ud835\udc4b , \ud835\udc38 \ud835\udc4c as \ud835\udf07 , \ud835\udf07 to emphasize that they\u2019re each constants):\n\" #\nCov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udf07 \ud835\udc4c \u2212 \ud835\udf07\n, -\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udf07 \ud835\udc4b \u2212 \ud835\udf07 \ud835\udc4c + \ud835\udf07 \ud835\udf07\n- , , -\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udf07 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udf07 \ud835\udc4c + \ud835\udc38 \ud835\udf07 \ud835\udf07\n(linearity of expectation)\n- , , -\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udf07 \ud835\udf07 \u2212 \ud835\udf07 \ud835\udf07 + \ud835\udf07 \ud835\udf07 (\ud835\udf07 , \ud835\udf07 are constants)\n! \"\n, - , - , -\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udf07 \ud835\udf07 = \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n, -\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 13\nCovariance\nThe covariance of two variables \ud835\udc4b and \ud835\udc4c is:\nCov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nCovariance measures how one random variable varies with a second.\n\u2022 Outside temperature and utility bills have a negative covariance.\n\u2022 Handedness and musical ability have near zero covariance.\n\u2022 Product demand and price have a positive covariance.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 14\nFeel the covariance\nIs the covariance positive, negative, or zero?\n1. 3.\n\ud835\udc4b = \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 15\n\ud835\udc66\n=\n\ud835\udc4c\n2.\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\n\ud835\udc4b = \ud835\udc65\n\ud835\udc66\n=\n\ud835\udc4c\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\n\ud835\udc4b = \ud835\udc65\n\ud835\udc66\n=\n\ud835\udc4c\nCov \ud835\udc4b,\ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\nFeel the covariance\nIs the covariance positive, negative, or zero?\n1. 3.\n\ud835\udc4b = \ud835\udc65\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 16\n\ud835\udc66\n=\n\ud835\udc4c\n2.\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\n\ud835\udc4b = \ud835\udc65\n\ud835\udc66\n=\n\ud835\udc4c\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\n\ud835\udc4b = \ud835\udc65\n\ud835\udc66\n=\n\ud835\udc4c\nCov \ud835\udc4b,\ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n\ud835\udc38[\ud835\udc4b]\n\ud835\udc38[\ud835\udc4c]\npositive negative zero\nCov \ud835\udc4b,\ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\nCovarying humans\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nWeight (kg) Height (in) W \u00b7 H\nWhat is the covariance of weight \ud835\udc4a and\n64 57 3648 height \ud835\udc3b?\n71 59 4189\nCov \ud835\udc4a, \ud835\udc3b = \ud835\udc38 \ud835\udc4a\ud835\udc3b \u2212 \ud835\udc38 \ud835\udc4a \ud835\udc38 \ud835\udc3b\n53 49 2597\n= 3355.83 \u2212 62.75 52.75\n67 62 4154\n(p ositiv e) = 45.77\n55 51 2805\n58 50 2900 70\n77 55 4235\n60\n57 48 2736\n50\n56 42 2352\n51 42 2142\n40\n76 61 4636 45 55 65 75 85\n68 57 3876\n\ud835\udc38 \ud835\udc4a \ud835\udc38 \ud835\udc3b \ud835\udc38 \ud835\udc4a\ud835\udc3b\n= 62.75 = 52.75 = 3355.83\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 17\n)sehcni(\n!\nthgieH\nWeight \" (kilograms)\nCovariance > 0: one variable \u2191, other variable \u2191\nProperties of Covariance\nThe covariance of two variables \ud835\udc4b and \ud835\udc4c is:\nCov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nProperties:\n1. Cov \ud835\udc4b, \ud835\udc4c = Cov \ud835\udc4c, \ud835\udc4b\n0 0\n2. Var \ud835\udc4b = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc4b\ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4b = Cov \ud835\udc4b, \ud835\udc4b\n3. Covariance of sums = sum of all pairwise covariances\n(proof left to you)\nCov \ud835\udc4b + \ud835\udc4b , \ud835\udc4c + \ud835\udc4c = Cov \ud835\udc4b , \ud835\udc4c + Cov \ud835\udc4b , \ud835\udc4c + Cov \ud835\udc4b , \ud835\udc4c + Cov \ud835\udc4b , \ud835\udc4c\n\u2019 1 \u2019 1 \u2019 \u2019 1 \u2019 \u2019 1 1 1\n4. Covariance under linear transformation: Cov \ud835\udc4e\ud835\udc4b + \ud835\udc4f, \ud835\udc4c = \ud835\udc4eCov \ud835\udc4b, \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 18\nZero covariance does not imply independence\nLet \ud835\udc4b take on values \u22121,0,1\nwith equal probability 1/3.\n1 if \ud835\udc4b = 0\nDefine \ud835\udc4c = 8\n0 otherwise\nWhat is the joint PMF of \ud835\udc4b and \ud835\udc4c?\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 19\nZero covariance does not imply independence\nLet \ud835\udc4b take on values \u22121,0,1\nwith equal probability 1/3.\n1 if \ud835\udc4b = 0\nDefine \ud835\udc4c = 8\n0 otherwise\n\ud835\udc4b\n-1 0 1\n0 1/3 0 1/3 2/3\n1 0 1/3 0 1/3\n1/3 1/3 1/3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 20\n\ud835\udc4c\n1. \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc4c =\n2. \ud835\udc38 \ud835\udc4b\ud835\udc4c =\n3. Cov \ud835\udc4b, \ud835\udc4c =\nMarginal\nPMF of\n\ud835\udc4c, \ud835\udc5d \ud835\udc66\n&\n4. Are \ud835\udc4b and \ud835\udc4c independent?\nMarginal PMF\nof \ud835\udc4b, \ud835\udc5d \ud835\udc65\n%\nZero covariance does not imply independence\nLet \ud835\udc4b take on values \u22121,0,1\nwith equal probability 1/3.\n1 if \ud835\udc4b = 0\nDefine \ud835\udc4c = 8\n0 otherwise\n\ud835\udc4b\n-1 0 1\n0 1/3 0 1/3 2/3\n1 0 1/3 0 1/3\n1/3 1/3 1/3\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 21\n\ud835\udc4c\n1. \ud835\udc38 \ud835\udc4b = \ud835\udc38 \ud835\udc4c =\n1 1 1 2 1\n= 0 = 1/3\n\u22121 + 0 + 1 0 + 1\n3 3 3 3 3\n1 1 1\n2. \ud835\udc38 \ud835\udc4b\ud835\udc4c = \u22121 \u22c5 0 + 0 \u22c5 1 + 1 \u22c5 0\n3 3 3\n= 0\n3. Cov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nMarginal\ndoes not imply = 0 \u2212 0 1/3 = 0\nPMF of \u26a0\nindependence!\n\ud835\udc4c, \ud835\udc5d \ud835\udc66\n&\n4. Are \ud835\udc4b and \ud835\udc4c independent?\n\u274c\n\ud835\udc43 \ud835\udc4c = 0|\ud835\udc4b = 1 = 1\nMarginal PMF\nof \ud835\udc4b, \ud835\udc5d \ud835\udc65\n% \u2260 \ud835\udc43 \ud835\udc4c = 0 = 2/3\nVariance of\nsums of RVs\n22\nStatistics of sums of RVs\nFor any random variables \ud835\udc4b and \ud835\udc4c,\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\nVar \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + 2 \u22c5 Cov \ud835\udc4b, \ud835\udc4c + Var \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 23\nVariance of general sum of RVs\nFor any random variables \ud835\udc4b and \ud835\udc4c,\nVar \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + 2 \u22c5 Cov \ud835\udc4b, \ud835\udc4c + Var \ud835\udc4c\nProof:\nVar \ud835\udc4b + \ud835\udc4c = Cov \ud835\udc4b + \ud835\udc4c, \ud835\udc4b + \ud835\udc4c Var \ud835\udc4b = Cov \ud835\udc4b,\ud835\udc4b\ncovariance of\n= Cov \ud835\udc4b, \ud835\udc4b + Cov \ud835\udc4b, \ud835\udc4c + Cov \ud835\udc4c, \ud835\udc4b + Cov \ud835\udc4c, \ud835\udc4c\nall pairs\n= Var \ud835\udc4b + 2 \u22c5 Cov \ud835\udc4b, \ud835\udc4c + Var \ud835\udc4c Symmetry of covariance +\nCov \ud835\udc4b,\ud835\udc4b = Var \ud835\udc4b\nMore generally:\n) ) ) )\nVar ) \ud835\udc4b = ) Var \ud835\udc4b + 2 ) ) Cov \ud835\udc4b , \ud835\udc4b\n(proof in extra slides)\n% % % 6\n%&\u2019 %&\u2019 %&\u2019 6&78\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 24\nStatistics of sums of RVs\nFor any random variables \ud835\udc4b and \ud835\udc4c,\n\ud835\udc38 \ud835\udc4b + \ud835\udc4c = \ud835\udc38 \ud835\udc4b + \ud835\udc38 \ud835\udc4c\nVar \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + 2 \u22c5 Cov \ud835\udc4b, \ud835\udc4c + Var \ud835\udc4c\nFor independent \ud835\udc4b and \ud835\udc4c,\n\ud835\udc38 \ud835\udc4b\ud835\udc4c = \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n(Lemma: proof in extra slides)\nVar \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + Var \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 25\nVariance of sum of independent RVs\nFor independent \ud835\udc4b and \ud835\udc4c,\nVar \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + Var \ud835\udc4c\nProof:\n1. Cov \ud835\udc4b, \ud835\udc4c = \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c def. of covariance\n= \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n\ud835\udc4b and \ud835\udc4c are independent\n= 0\n2. Var \ud835\udc4b + \ud835\udc4c = Var \ud835\udc4b + 2 \u22c5 Cov \ud835\udc4b, \ud835\udc4c + Var \ud835\udc4c\n= Var \ud835\udc4b + Var \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 26\nProving Variance of the Binomial\n\ud835\udc4b~Bin(\ud835\udc5b, \ud835\udc5d)\nVar \ud835\udc4b = \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d\n9\n)\nLet \ud835\udc4b = - \ud835\udc4b Var \ud835\udc4b = Var ) \ud835\udc4b\n! %\n%&\u2019\n!78\n)\n\ud835\udc4b are independent,\n$\nLet \ud835\udc4b = \ud835\udc56th trial is heads = ) Var \ud835\udc4b therefore variance of sum\n% %\n= sum of variance\n\ud835\udc4b ~Ber \ud835\udc5d\n% %&\u2019\nVar \ud835\udc4b = \ud835\udc5d 1 \u2212 \ud835\udc5d )\n%\n= ) \ud835\udc5d 1 \u2212 \ud835\udc5d Variance of Bernoulli\n\ud835\udc4b are independent %&\u2019\n%\n(by definition)\n= \ud835\udc5b\ud835\udc5d 1 \u2212 \ud835\udc5d\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 27\nCorrelation\n28\nCov \ud835\udc4b,\ud835\udc4c = \ud835\udc38 \ud835\udc4b \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4c\nCovarying humans\n= \ud835\udc38 \ud835\udc4b\ud835\udc4c \u2212 \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\n70\n60\n50\n40\n45 55 65 75 85\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 29\n)sehcni(\n!\nthgieH\nWhat is the covariance of\nweight \ud835\udc4a and height \ud835\udc3b?\nCov \ud835\udc4a, \ud835\udc3b = \ud835\udc38 \ud835\udc4a\ud835\udc3b \u2212 \ud835\udc38 \ud835\udc4a \ud835\udc38 \ud835\udc3b\n= 3355.83 \u2212 62.75 52.75\n= 45.77\n(positive)\nWeight \" (kilograms)\nWhat about weight (lb) and 180\nheight (cm)? 160\n140\nCov 2.20\ud835\udc4a, 2.54\ud835\udc3b\n120\n= \ud835\udc38 2.20\ud835\udc4a \u22c5 2.54\ud835\udc3b \u2212 \ud835\udc38 2.20\ud835\udc4a \ud835\udc38 2.54\ud835\udc3b\n100\n= 18752.38 \u2212 138.05 133.99 100 120 140 160 180\n= 255.06\n)mc(\n!\nthgieH\nWeight \" (lb)\n(positive)\nCovariance depends Sign of covariance (+/\u2013) more\n\u26a0\non units!\nmeaningful than magnitude\nCorrelation\nThe correlation of two variables \ud835\udc4b and \ud835\udc4c is:\nCov \ud835\udc4b, \ud835\udc4c\n\ud835\udf0e% = Var \ud835\udc4b ,\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c =\n\"\n%\n\ud835\udf0e \ud835\udf0e \ud835\udf0e = Var \ud835\udc4c\n#\n! \"\n\u2022 Note: \u22121 \u2264 \ud835\udf0c \ud835\udc4b, \ud835\udc4c \u2264 1\n\u2022 Correlation measures the linear relationship between \ud835\udc4b and \ud835\udc4c:\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c = 1 \u27f9 \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, where \ud835\udc4e = \ud835\udf0e /\ud835\udf0e\n: ;\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c = \u22121 \u27f9 \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f, where \ud835\udc4e = \u2212\ud835\udf0e /\ud835\udf0e\n: ;\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c = 0 \u27f9 uncorrelated (absence of linear relationship)\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 30\nA. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = 1\nCorrelation reps\nB. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = \u22121\nC. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = 0\nWhat is the correlation coefficient \ud835\udf0c \ud835\udc4b, \ud835\udc4c ? D. Other\n1.\n2.\n3. 4.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 31\nA. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = 1\nCorrelation reps\nB. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = \u22121\nC. \ud835\udf0c \ud835\udc4b,\ud835\udc4c = 0\nWhat is the correlation coefficient \ud835\udf0c \ud835\udc4b, \ud835\udc4c ? D. Other\n1.\n2.\nB. \ud835\udf0c \ud835\udc4b, \ud835\udc4c = \u22121 A. \ud835\udf0c \ud835\udc4b, \ud835\udc4c = 1\n\ud835\udc4c = \u2212\ud835\udc4e\ud835\udc4b + \ud835\udc4f \ud835\udc4c = \ud835\udc4e\ud835\udc4b + \ud835\udc4f\n\ud835\udc4e > 0 \ud835\udc4e > 0\n3. 4.\nC. \ud835\udf0c \ud835\udc4b, \ud835\udc4c = 0 C. \ud835\udf0c \ud835\udc4b, \ud835\udc4c = 0\n\ud835\udc4c = \ud835\udc4b1\n\u201cuncorrelated\u201d\n\ud835\udc4b and \ud835\udc4c can be nonlinearly related even if \ud835\udf0c \ud835\udc4b, \ud835\udc4c = 0.\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 32\nThrowback to CS103: Conditional statements\nStatement \ud835\udc43 \u2192 \ud835\udc44: Independence \u00e0 No correlation\n\u2705\nContrapositive \u00ac\ud835\udc44 \u2192 \u00ac\ud835\udc43: Correlation \u00e0 Dependence \u2705 (logically\nequivalent)\nInverse \u00ac\ud835\udc43 \u2192 \u00ac\ud835\udc44: Dependence \u00e0 Correlation \u274c\n(not always)\n\ud835\udc4c = \ud835\udc4b\u2019\n\ud835\udf0c \ud835\udc4b,\ud835\udc4c = 0\nConverse \ud835\udc44 \u2192 \ud835\udc43: No correlation \u00e0 Independence\n\u274c\n(not always)\n\u201cCorrelation does not imply causation\u201d\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 33\nSpurious\nCorrelation\n34\nSpurious Correlations\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c is used a lot to statistically quantify the relationship b/t X and Y.\nCorrelation:\n0.947091\nSpurious correlations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 35\nSpurious Correlations\n\ud835\udf0c \ud835\udc4b, \ud835\udc4c is used a lot to statistically quantify the relationship b/t X and Y.\nCorrelation:\n0.947091\nSpurious correlations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 36\nDivorce vs. Margarine\nhttp://www.bbc.com/news/magazine-27537142\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024\nArcade revenue vs. CS PhDs\nCorrelation:\n0.947091\nSpurious correlations\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 38\nExtras\n39\nExpectation of product of independent RVs\nIf \ud835\udc4b and \ud835\udc4c are\n\ud835\udc38 \ud835\udc4b\ud835\udc4c = \ud835\udc38 \ud835\udc4b \ud835\udc38 \ud835\udc4c\nindependent, then\n\ud835\udc38 \ud835\udc54 \ud835\udc4b \u210e \ud835\udc4c = \ud835\udc38 \ud835\udc54 \ud835\udc4b \ud835\udc38 \u210e \ud835\udc4c\nProof: \ud835\udc38 \ud835\udc54 \ud835\udc4b \u210e \ud835\udc4c = ) ) \ud835\udc54 \ud835\udc65 \u210e \ud835\udc66 \ud835\udc5d \ud835\udc65, \ud835\udc66 (for continuous proof, replace\n,,-\nsummations with integrals)\n; <\n= ) ) \ud835\udc54 \ud835\udc65 \u210e \ud835\udc66 \ud835\udc5d \ud835\udc65 \ud835\udc5d \ud835\udc66 \ud835\udc4b and \ud835\udc4c are independent\n, -\n; <\n= ) \u210e \ud835\udc66 \ud835\udc5d \ud835\udc66 ) \ud835\udc54 \ud835\udc65 \ud835\udc5d \ud835\udc65 Terms dependent on \ud835\udc66\n- ,\nare constant in integral of \ud835\udc65\n; <\n= ) \ud835\udc54 \ud835\udc65 \ud835\udc5d \ud835\udc65 ) \u210e \ud835\udc66 \ud835\udc5d \ud835\udc66 Summations separate\n, -\n< ;\n= \ud835\udc38 \ud835\udc54 \ud835\udc4b \ud835\udc38 \u210e \ud835\udc4c\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 40\nVariance of Sums of Variables\n) ) ) )\nVar ) \ud835\udc4b = ) Var \ud835\udc4b + 2 ) ) Cov \ud835\udc4b , \ud835\udc4b\n% % % 6\n%&\u2019 %&\u2019 %&\u2019 6&78\u2019\nProof: ( V =a r C\ud835\udc4b o v \ud835\udc4b, \ud835\udc4b ( ( c o v a ar li l a pn ac ire (s\no f\n(\nVar >\ud835\udc4b = Cov >\ud835\udc4b ,>\ud835\udc4b = >>Cov \ud835\udc4b ,\ud835\udc4b\n! ! ! ! )\n!&\u2019 !&\u2019 !&\u2019 !&\u2019 )&\u2019\n( ( (\nSymmetry of covariance\n= >Var \ud835\udc4b + > > Cov \ud835\udc4b ,\ud835\udc4b\n! ! ) Cov \ud835\udc4b,\ud835\udc4b = Var \ud835\udc4b\n!&\u2019 !&\u2019 )&\u2019,)+!\n( ( (\n= >Var \ud835\udc4b + 2 > > Cov \ud835\udc4b ,\ud835\udc4b Adjust summation bounds\n! ! )\n!&\u2019 !&\u2019 )&$,\u2019\nLisa Yan, Chris Piech, Mehran Sahami, and Jerry Cain, CS109, Spring 2024 41 <END>"}
{"prompt": "Lecture notes from 08_section.txt\n\n###\n\n", "completion": "\u20131\u2013\nCS109 May30,2024\nMaximum A Posteriori and Na\u00a8\u0131ve Bayes Estimation\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthis\nweek\u2019ssection.TheCAleadingyourdiscussionsectioncanenterthepasswordneededonce\nyou\u2019vesubmitted.\n1 Warmups\n1.1 Maximum A Posteriori\na. Intuitively,whatisMAP?Whatproblemisittryingtosolve?HowdoesitdifferfromMLE?\nb. Givena6-sideddie(possiblyunfair),yourollthedie \ud835\udc41 timesandobservethecountsfor\neachofthe6outcomesas \ud835\udc5b ,...,\ud835\udc5b .Whatisthemaximumaposterioriestimateofthis\n1 6\ndistribution,usingLaplacesmoothing?Recallthatthedierollsthemselvesfollowa\nmultinomialdistribution.\n1.2 Naive Bayes Review\nRecalltheclassificationsetting:wehavedatavectorsoftheform \ud835\udc4b = (\ud835\udc4b 1,...,\ud835\udc4b \ud835\udc5a) andwewant\ntopredictalabel\ud835\udc4c \u2208 {0,1}.\na. RecallinNaiveBayes,givenadatapoint\ud835\udc65,wecompute \ud835\udc43(\ud835\udc4c = 1|\ud835\udc4b = \ud835\udc65) andpredict\ud835\udc4c = 1\nprovidedthisquantityis \u2265 0.5,andotherwisewepredict\ud835\udc4c = 0.Decompose\n\ud835\udc43(\ud835\udc4c = 1|\ud835\udc4b = \ud835\udc65) intosmallerterms,andstatewheretheNaiveBayesassumptionisused.\nb. Supposewearegivenexamplevectorswithlabelsprovided.Giveaformulatoestimate\n(usingmaximumlikelihood)eachquantity \ud835\udc43(\ud835\udc4b \ud835\udc56 = \ud835\udc65 \ud835\udc56|\ud835\udc4c = \ud835\udc66) above,for\ud835\udc56 \u2208 {1,...,\ud835\udc5a} and\n\ud835\udc66 \u2208 {0,1}.Youcanassumethereisafunctioncountwhichtakesinanynumberofboolean\nconditionsandreturnsacountoverthedataofthenumberofexamplesinwhichtheyare\ntrue.Forexample,count(\ud835\udc4b = 2,\ud835\udc4b = 7) returnsthenumberofexampleswhere \ud835\udc4b = 2and\n3 5 3\n\ud835\udc4b = 7.\n5\n2 Problems\n2.1 Why Boba Cares About MAP\nYoudon\u2019tunderstandwhythere\u2019snobobaplacewithinwalkingdistancearoundcampus,soyou\ndecidetostartone.Inordertoestimatetheamountofingredientsneededandthetimeyouwill\nspendinthebusiness(youstillneedtostudy),youwanttoestimatehowmanyordersyouwill\nreceiveperhour.AftertakingCS109,youareprettyconfidentthatincomingorderscanbe\nconsideredasindependenteventsandtheprocesscanbemodeledwithaPoisson.\nNowthequestionis-whatisthe\ud835\udf06 parameterofthePoisson?Inthefirsthourofyoursoftopening,\nyouarevisitedby4curiousstudents,eachofwhommadeanorder.Youhaveapriorbeliefthat\n\ud835\udc53(\u039b = \ud835\udf06) = \ud835\udc3e \u00b7\ud835\udf06 \u00b7\ud835\udc52\u2212\ud835\udf06 2.WhatistheMLEestimate?Whatisinferenceof\ud835\udf06 giventheobservation?\nWhatistheMaximumaPosteriori(MAP)estimateof\ud835\udf06?Throughyourprocesstrytoidentify\nwhatisapoint-estimate,andwhatisadistribution.\n\u20132\u2013\n2.2 Multiclass Bayes\nInthisproblemwearegoingtoexplorehowtowriteNaiveBayesformultipleoutputclasses.We\nwanttopredictasingleoutputvariableYwhichrepresentshowauserfeelsaboutabook.Unlike\ninyourhomework,theoutputvariableYcantakeononeofthefour valuesintheset\n{Like,Love,Haha,Sad}.Wewillbaseourpredictionsoffofthreebinaryfeaturevariables\n\ud835\udc4b 1,\ud835\udc4b 2, and \ud835\udc4b 3 whichareindicatorsoftheuser\u2019staste.Allvalues \ud835\udc4b \ud835\udc56 \u2208 {0,1}.\nWehaveaccesstoadatasetwith10,000users.Eachuserinthedatasethasavaluefor \ud835\udc4b ,\ud835\udc4b ,\ud835\udc4b\n1 2 3\nand\ud835\udc4c.Youcanuseaspecialquerymethodcountthatreturnsthenumberofusersinthedataset\nwiththegivenequalityconstraints(andonlyequalityconstraints).Herearesomeexampleusages\nof count:\ncount(\ud835\udc4b = 1,\ud835\udc4c = Haha) returnsthenumberofuserswhere \ud835\udc4b = 1and\ud835\udc4c = Haha.\n1 1\ncount(\ud835\udc4c = Love) returnsthenumberofuserswhere\ud835\udc4c = Love.\ncount(\ud835\udc4b = 0,\ud835\udc4b = 0) returnsthenumberofuserswhere \ud835\udc4b = 0,and \ud835\udc4b = 0.\n1 3 1 3\nYouaregivenanewuserwith \ud835\udc4b = 1, \ud835\udc4b = 1, \ud835\udc4b = 0.Whatisthebestpredictionforhowtheuser\n1 2 3\nwillfeelaboutthebook(\ud835\udc4c)?Youmayleaveyouranswerintermsofanargmaxfunction.You\nshouldexplainhowyouwouldcalculateallprobabilitiesusedinyourexpression.UseLaplace\nestimationwhencalculatingprobabilities.\n2.3 Gaussian Na\u00a8\u0131ve Bayes\nTheversionofNa\u00a8\u0131veBayesthatweusedinclassworkedgreatwhenthefeaturevalueswereall\nbinary.Ifinsteadtheyarecontinuous,wearegoingtohavetorethinkhowweestimateofthe\nprobabilityofthe\ud835\udc56thfeaturegiventhelabel, \ud835\udc43(\ud835\udc4b \ud835\udc56|\ud835\udc4c).Theubiquitoussolutionistomakethe\nGaussianInputAssumptionthat:\nIf\ud835\udc4c = 0,then \ud835\udc4b \ud835\udc56 \u223c \ud835\udc41(\ud835\udf07 \ud835\udc56,0,\ud835\udf0e \ud835\udc562 ,0)\nIf\ud835\udc4c = 1,then \ud835\udc4b \ud835\udc56 \u223c \ud835\udc41(\ud835\udf07 \ud835\udc56,1,\ud835\udf0e \ud835\udc562 ,1)\nForeachfeature,thereare4parameters(meanandvarianceforbothclasslabels).Thereisafinal\nparameter, \ud835\udc5d,whichistheestimateof \ud835\udc43(\ud835\udc4c = 1).Assumethatyouhavetrainedondatawithtwo\ninputfeaturesandhavealreadyestimatedall9parametervalues,includingthat \ud835\udc5d = 0.6:\nFeature\ud835\udc56 \ud835\udf07\n\ud835\udc56,0\n\ud835\udf07\n\ud835\udc56,1\n\ud835\udf0e \ud835\udc562\n,0\n\ud835\udf0e \ud835\udc562\n,1\n1 5 0 1 1\n2 0 3 1 4\nWriteaninequalitytopredictwhether\ud835\udc4c = 1forinput [\ud835\udc4b = 5,\ud835\udc4b = 3].UsetheNa\u00a8\u0131veBayes\n1 2\nassumptionandtheGaussianInputAssumption.Yourexpressionshouldbeintermsofthe\nlearnedparameters(eitherusingnumbersorsymbolsisfine).\n\u20133\u2013\n3 Ethics and Beta Distribution\nWhiletherewon\u2019tbeanyethicsmaterialonthefinalexam,we\u2019reincludingaproblemthatwillnot\nonlyexercisesomeprobability,buthopefullyprovokeyoutothinkabouttheimpactthat\nprobability-anddata-drivendecisionshaveonsociety.\nTheEconomistusedabetadistributiontoforecastresultsforthe2020U.S.presidentialelection.1\nFigure1:UpdatedpredictionofDemocraticvoteshareis\u201dPosterior\u201dprediction.\n1. Whyisthebetadistributionappropriateformodelingapresidentialelection?\n2. ReadthepollingreportpublishedbyTheEconomist.Whatshouldbeconsideredwhen\nusingthismodelandreleasingitselectionpredictions?\n1Gelman,A.,&Heidemanns,M.(2020).Howtheeconomistpresidentialforecastworks.TheEconomist. <END>"}
{"prompt": "Lecture notes from 01_section.txt\n\n###\n\n", "completion": "CS109 April11,2024\nSection 1: Combinatorics and Probability\nChrisPiech,MehranSahami,JerryCain,LisaYan,andnumerousCS109CA\u2019s.\nOverview of Section Materials\nThewarm-upquestionsprovidedwillhelpstudentspracticeconceptsintroducedinlectures.Thesectionprob-\nlemsaremeanttoapplytheseconceptsinmorecomplexscenariossimilartowhatyouwillseeinproblemsets\nandexams.Infact,manyofthemareoldexamquestions.\nBeforeyouleavelab,makesureyouclickheresothatyou\u2019remarkedashavingattendedthisweek\u2019ssection.The\nCAleadingyourdiscussionsectioncanenterthepasswordneededonceyou\u2019vesubmitted.\nWarm-ups\n1. Equality versus Inequality\nShowthatforanyevents \ud835\udc34 and \ud835\udc35 that\n\ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35) \u22121 \u2264 \ud835\udc43(\ud835\udc34\u2229 \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34\u222a \ud835\udc35) \u2264 \ud835\udc43(\ud835\udc34) + \ud835\udc43(\ud835\udc35)\nForeachofthethreeinequalities,describesets \ud835\udc34 and \ud835\udc35 thatwouldresultinequality.\n2. Fish Pond\nSupposethereare7bluefish,4redfish,and8greenfishinalargefishingtank.Youdropanetintoitandendup\nwith2fish.Whatistheprobabilityyouget2bluefish?\nProblems\n3. Rolling Fair Dice\nConsideranexperimentwherewerollafair,six-sideddiemultipletimes.\na. Whatistheprobabilitythatatleastone3appearswhenyourollthesamefairdie10times?\nb. Whatistheprobabilitythatatleasttwo3\u2019sappearwhenyourollthesamefairdie20times?Youmay\nleaveyouranswerintermsofoneormorechooseterms.\nc. Whatistheprobabilitythatatleast \ud835\udc5b 3\u2019sappearwhenyourollthesamefairdie10\ud835\udc5b times?Youranswer\nwillcertainlyinvolveasumofmanycombinatorialterms,andyouneedn\u2019tsimplifyprovidedweunder-\nstandthestructureofyouranswer.\nd. Doyouexpecttheprobabilityfrompartctoincreaseordecreaseas \ud835\udc5b increases?Providesomeintuitionas\ntowhyyouexpecttheincreaseordecrease.\n4. Baking Cookies\nThefollowingproblemisbasedontrueevents.Itwasalsoatake-homeexamquestionseveralyearsago.\nJerryandtheCS109coursestaffarebakingM&McookiesonarainySaturdaymorning,buttheyonlyhave\nenoughflourtomake6cookies.Theyhave15M&M\u2019s,allofwhicharedifferentcolors.Forallsub-parts,as-\nsumethatwedon\u2019tdistinguishbetweendifferentarrangementsofM&M\u2019sonthesamecookie.Thatis,M&M\u2019s\nhavenoorderingonacookie.\na. Howmanywayscanthe15M&M\u2019sbedistributedacrossthesixcookies?Forthissubpart,assumethe\ncookiesthemselvesAREdistinguishable,andtheM&M\u2019sAREdistinguishable.Itispossibleforacookie\ntohavenoM&M\u2019s,anditispossibleforacookietohaveallofthem.\nb. Howmanywayscanthe15M&M\u2019sbedistributedacrossthesixcookies?Forthissubpart,assumethe\ncookiesthemselvesaredistinguishable,andtheM&M\u2019sareindistinguishable.Itispossibleforacookieto\nhavenoM&M\u2019s,anditispossibleforacookietohaveallofthem.\nc. What\u2019stheprobabilitythateachofthesixcookiesendsupwithadifferentnumberofM&M\u2019s?Notethat\nthiswouldrequirethateachofthesixcookiesget0,1,2,3,4,and5M&M\u2019sinsomeorder.Forthissub-\npart,assumethecookiesthemselvesaredistinguishable,andtheM&M\u2019saredistinguishable.Assumefur-\ntherthatanM&Misequallylikelytoappearonanycookie.\nd. IfwenolongerrequireallM&M\u2019sbeused,what\u2019stheprobabilityallcookiesendupwiththesamenum-\nberofM&M\u2019s?Forthissubpart,assumethecookiesthemselvesaredistinguishable,andtheM&M\u2019s\naredistinguishable.AssumefurtherthatanM&Misequallylikelytoappearonanycookie,andthatwe\nshouldincludethepossibilitythatnoneofthecookiesgetM&M\u2019s.Concretely,treat\u201cnocookie\u201dasan-\nothercookiewithequallikelihoodtoothercookies.\n5. The Birthday Problem\nWhensolvingacountingproblem,itcanoftenbeusefultocomeupwithagenerativeprocess,aseriesofsteps\nthat\u201cgenerates\u201dexamples.Acorrectgenerativeprocesstocounttheelementsofset \ud835\udc34 will(1)generateeveryel-\nementof \ud835\udc34 and(2)notgenerateanyelementof \ud835\udc34 morethanonce.Ifourprocesshastheaddedpropertythat(3)\nanygivenstepalwayshasthesamenumberofpossibleoutcomes,thenwecanusetheproductruleofcounting.\nProblem:Assumethatbirthdayshappenonanyofthe365daysoftheyearwithequallikelihood(we\u2019llignore\nleapyears).\na. Whatistheprobabilitythatofthe \ud835\udc5b peopleinclass,atleasttwopeoplesharethesamebirthday?\nb. Whatistheprobabilitythatthisclasscontainsexactlyonepairofpeoplewhoshareabirthday?\n6. Flipping Coins\nOnethingthatstudentsoftenfindtrickywhenlearningcombinatoricsishowtofigureoutwhenaproblemin-\nvolvespermutationsandwhenitinvolvescombinations.Naturally,wewilllookataproblemthatcanbesolved\nwithbothapproaches.Payattentiontowhatpartsofyoursolutionrepresentdistinctobjectsandwhatpartsrep-\nresentindistinctobjects.\nProblem:Weflipafaircoin \ud835\udc5b times,hoping(forsomereason)toget \ud835\udc58 heads.\na. Howmanywaysaretheretogetexactly \ud835\udc58 heads?CharacterizeyouranswerasapermutationofH\u2019sand\nT\u2019s.\nb. Forwhat\ud835\udc65 and \ud835\udc66 isyouranswertopart(a)equalto (cid:0)\ud835\udc65(cid:1) ?Whydoesthiscombinationmakesenseasanan-\n\ud835\udc66\nswer?\nc. Whatistheprobabilitythatwegetexactly \ud835\udc58 heads?\n7. Combinatorial Proofs\nShowthat\n(cid:0)\ud835\udc5a+\ud835\udc5b(cid:1)\n=\n(cid:205)\ud835\udc58 (cid:0)\ud835\udc5a(cid:1)(cid:0) \ud835\udc5b (cid:1)\nviaacombinatorialproof.\n\ud835\udc58 \ud835\udc57=0 \ud835\udc57 \ud835\udc58\u2212\ud835\udc57 <END>"}
